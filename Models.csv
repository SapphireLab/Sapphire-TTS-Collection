Title,Abbreviation,Class,ArXiv,ArXiv v1 Date,ArXiv New Version,ArXiv New Date,Publication,Publication Date,DOI,Authors,OpenSource,Official Code,HuggingFace,Demo Page,Page Number,Cite Number,Google Scholar,Cited by,Theory,Propose,Architecture,Tasks,Datasets,Compare Methods,Tags,AR/NAR,Update Time
Adam: A Method for Stochastic Optimization,Adam,Optimizer,https://arxiv.org/abs/1412.6980,2014.12.22,v9,2017.01.30,ICLR2015,,,"Diederik P. Kingma, Jimmy Ba",,,,,,,https://scholar.google.com/scholar?cluster=16194105527543080940,192990,,,,,,,,,2024.10.15
Batch Normlization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,BatchNormalization,Trick,https://arxiv.org/abs/1502.03167,2015.02.11,v3,2015.03.02,ICML2015,,,"Sergey Ioffe, Christian Szegedy",,,,,,,,,,,,,,,,,2024.10.23
WORLD: A Vocoder-Based High-Quality Speech Synthesis System for Real-Time Applications,WORLD,Vocoder,[Unavailable],2016.07.01,[Unavailable],[Unavailable],IEICE TransInf2016,2016.07.01,https://doi.org/10.1587/transinf.2015EDP7457,"Masanori Morise, Fumiya Yokomori, Kenji Ozawa",,,,,,,https://scholar.google.com/scholar?cluster=1666706309019212851,1478,,,,TTS,,,,,2024.10.15
Layer Normalization,Layer Normalization,Trick,https://arxiv.org/abs/1607.06450,2016.07.21,v1,2016.07.21,,,,"Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton",,,,,,,[Unavailable],12783,,,,,,,,,2024.10.23
WaveNet: A Generative Model for Raw Audio,WaveNet,Vocoder,https://arxiv.org/abs/1609.03499,2016.09.12,v2,2016.09.19,,,,"Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu",,,,,,,,,,,,,,,,AR,2024.10.23
SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,SampleRNN,Vocoder,https://arxiv.org/abs/1612.07837,2016.12.22,v2,2017.02.11,ICLR2017,,,"Soroush Mehri, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham Jain, Jose Sotelo, Aaron Courville, Yoshua Bengio",,,,,,,,,,,,,,,,,2024.10.23
Char2Wav: End-to-End Speech Synthesis,Char2Wav,,[Unavailable],2017.02.18,[Unavailable],[Unavailable],ICLR2017,2017.02.18,https://openreview.net/forum?id=B1VWyySKx,,,,,,,,https://scholar.google.com/scholar?cluster=6778319284287669999,522,,,,TTS,,,,,2024.10.23
Deep Voice: Real-Time Neural Text-to-Speech,DeepVoice,,https://arxiv.org/abs/1702.07825,2017.02.25,v2,2017.03.07,ICML2017,2017.08.06,https://proceedings.mlr.press/v70/arik17a.html,"Sercan O. Arik, Mike Chrzanowski, Adam Coates, Gregory Diamos, Andrew Gibiansky, Yongguo Kang, Xian Li, John Miller, Andrew Ng, Jonathan Raiman, Shubho Sengupta, Mohammad Shoeybi",,,,,,,https://scholar.google.com/scholar?cluster=18296399576126585694,819,,,,TTS,,,,,2024.10.23
Tacotron: Towards End-to-End Speech Synthesis,Tacotron,,https://arxiv.org/abs/1703.10135,2017.03.29,v2,2017.04.06,InterSpeech2017,2017.08.20,https://doi.org/10.21437/Interspeech.2017-1452,"Yuxuan Wang, R.J. Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous",,,,,,,https://scholar.google.com/scholar?cluster=11291739830353377265,2175,,,,TTS,,,,,2024.10.08
Deep Voice 2: Multi-Speaker Neural Text-to-Speech,DeepVoice2,,https://arxiv.org/abs/1705.08947,2017.05.24,v2,2017.09.20,NeurIPS2017,,https://dl.acm.org/doi/abs/10.5555/3294996.3295056,"Sercan Arik, Gregory Diamos, Andrew Gibiansky, John Miller, Kainan Peng, Wei Ping, Jonathan Raiman, Yanqi Zhou",,,,,,,https://scholar.google.com/scholar?cluster=188402189689268087,656,,,,TTS,,,Multi-Speaker,,2024.10.25
VoiceLoop: Voice Fitting and Synthesis via A Phonological Loop,VoiceLoop,,https://arxiv.org/abs/1707.06588,2017.07.20,v3,2018.02.01,ICLR2018Poster,2018.02.16,https://openreview.net/forum?id=SkFAWax0-,"Yaniv Taigman, Lior Wolf, Adam Polyak, Eliya Nachmani",,https://github.com/facebookarchive/loop,,,,,https://scholar.google.com/scholar?cluster=14159878382438547497,191,,,,,,,,,2024.10.25
Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,DeepVoice3,,https://arxiv.org/abs/1710.07654,2017.10.20,v3,2018.02.22,ICLR2018Poster,2018.02.16,https://openreview.net/forum?id=HJtEm4p6Z,"Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O. Arik, Ajay Kannan, Sharan Narang, Jonathan Raiman, John Miller",,,,,,,https://scholar.google.com/scholar?cluster=1828409622662260131,546,,,,TTS,,,,,2024.10.25
Neural Discrete Representation Learning,VQ-VAE,Trick,https://arxiv.org/abs/1711.00937,2017.11.02,v2,2018.05.30,NeurIPS2017,2017.12.04,https://dl.acm.org/doi/abs/10.5555/3295222.3295378,"Aaron van den Oord, Oriol Vinyals, Koray Kavukcuoglu",,,,,,,https://scholar.google.com/scholar?cluster=9141153084529999933,4522,,,,,,,,,2024.10.25
Decoupled Weight Decay Regularization,AdamW,Optimizer,https://arxiv.org/abs/1711.05101,2017.11.14,v3,2019.01.04,ICLR2019,,,"Ilya Loshchilov, Frank Hutter",,https://github.com/loshchil/AdamW-and-SGDW,,,,,,,,,,,,,,,2024.10.25
Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Parallel WaveNet,Vocoder,https://arxiv.org/abs/1711.10433,2017.11.28,v1,2017.11.28,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions,Tacotron2,,https://arxiv.org/abs/1712.05884,2017.12.16,v2,2018.02.16,ICASSP2018,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
Adversarial Audio Synthesis,WaveGAN,Vocoder,https://arxiv.org/abs/1802.04208,2018.02.12,v3,2019.02.09,ICLR2019,,,,,,,,,,,,,,,,,,,,2024.09.21
Efficient Neural Audio Synthesis,WaveRNN,Vocoder,https://arxiv.org/abs/1802.08435,2018.02.23,v2,2018.06.25,,,,,,,,,,,,,,,,,,,,,2024.09.21
Transfer Learning from Speaker Verification to Multispeaker Text-to-Speech Synthesis,SV2TTS,,https://arxiv.org/abs/1806.04558,2018.06.12,v4,2019.01.02,NeurIPS2018,2018.12.03,https://dl.acm.org/doi/abs/10.5555/3327345.3327360,,,,,,,,https://scholar.google.com/scholar?cluster=14002861277903846410,961,,,,TTS,,,,,2024.09.24
Representation Learning with Contrastive Predictive Coding,CPC,Representation,https://arxiv.org/abs/1807.03748,2018.07.10,v2,2019.01.22,,,,,,,,,,,https://scholar.google.com/scholar?cluster=3606056486908097181,9408,,,,,,,,,2024.09.24
ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech,ClariNet,,https://arxiv.org/abs/1807.07281,2018.07.19,v3,2019.02.22,ICLR2019Poster,2018.12.21,https://openreview.net/forum?id=HklY120cYm,,,,,,,,https://scholar.google.com/scholar?cluster=1675505652651694755,413,,,,TTS,,,,,2024.09.24
Neural Speech Synthesis with Transformer Network,Transformer TTS,,https://arxiv.org/abs/1809.08895,2018.09.19,v3,2019.01.30,AAAI2019,2019.07.17,https://doi.org/10.1609/aaai.v33i01.33016706,,,,,,,,,,,,,TTS,,,,,2024.10.10
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,BERT,TextLM,https://arxiv.org/abs/1810.04805,2018.10.11,v2,2019.05.24,,,,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",,,,,,,[Unavailable],112766,,,,,,,,,2024.10.23
LPCNet: Improving Neural Speech Synthesis Through Linear Prediction,LPCNet,Vocoder,https://arxiv.org/abs/1810.11846,2018.10.28,v2,2019.02.19,ICASSP2019,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
WaveGlow: A Flow-Based Generative Network for Speech Synthesis,WaveGlow,Vocoder,https://arxiv.org/abs/1811.00002,2018.10.31,v1,2018.10.31,,,,,,,,,,,,,Flow,,,TTS,,,,,2024.09.24
FloWaveNet : A Generative Flow for Raw Audio,FloWaveNet,Vocoder,https://arxiv.org/abs/1811.02155,2018.11.06,v3,2019.05.20,ICML2019,,,,,,,,,,,,,,,,,,,,2024.09.21
Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design,Flow++,Image,https://arxiv.org/abs/1902.00275,2019.02.01,v2,2019.05.15,ICML2019,,https://proceedings.mlr.press/v97/ho19a,,,,,,,,https://scholar.google.com/scholar?cluster=7151289546461544772,486,Flow,,,,,,,,2024.09.24
GANSynth: Adversarial Neural Audio Synthesis,GANSynth,Vocoder,https://arxiv.org/abs/1902.08710,2019.02.23,v2,2019.04.15,,,,,,,,,,,,,,,,,,,,,2024.09.21
LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech,LibriTTS,Dataset,https://arxiv.org/abs/1904.02882,2019.04.05,v1,2019.04.05,InterSpeech2019,2019.09.15,https://doi.org/10.21437/Interspeech.2019-2441,"Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J. Weiss, Ye Jia, Zhifeng Chen, Yonghui Wu",,,,,,,https://scholar.google.com/scholar?cluster=2687491316639568904,885,,,,TTS,,,,,2024.10.08
Wav2Vec: Unsupervised Pre-Training for Speech Recognition,Wav2Vec,Representation,https://arxiv.org/abs/1904.05862,2019.04.11,v4,2019.09.11,InterSpeech2019,2019.09.15,https://doi.org/10.21437/Interspeech.2019-1873,"Steffen Schneider, Alexei Baevski, Ronan Collobert, Michael Auli",,https://github.com/pytorch/fairseq,,,,,https://scholar.google.com/scholar?cluster=613778405574274068,1576,,,,,,,,,2024.10.08
MOSNet: Deep Learning-Based Objective Assessment for Voice Conversion,MOSNet,,https://arxiv.org/abs/1904.08352,2019.04.17,v3,2021.07.14,InterSpeech2019,2019.09.15,https://doi.org/10.21437/Interspeech.2019-2003,"Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, Xin Wang, Junichi Yamagishi, Yu Tsao, Hsin-Min Wang",,,,,,,https://scholar.google.com/scholar?cluster=7203377453771793013,294,,,,,,,,,2024.10.10
Non-Autoregressive Neural Text-to-Speech,ParaNet,,https://arxiv.org/abs/1905.08459,2019.05.21,v3,2020.06.29,ICML2020,,,,,,,,,,,,,,,TTS,,,,NAR,2024.09.24
FastSpeech: Fast Robust and Controllable Text to Speech,FastSpeech,,https://arxiv.org/abs/1905.09263,2019.05.22,v5,2019.11.20,NeurIPS2019,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
RoBERTa: A Robustly Optimized BERT Pretraining Approach,RoBERTa,TextLM,https://arxiv.org/abs/1907.11692,2019.07.26,v1,2019.07.26,,,,,,,,,,,[Unavailable],15137,,,,,,,,,2024.10.23
High Fidelity Speech Synthesis with Adversarial Networks,GAN-TTS,Vocoder,https://arxiv.org/abs/1909.11646,2019.09.25,v2,2019.09.26,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis,MelGAN,Vocoder,https://arxiv.org/abs/1910.06711,2019.10.08,v3,2019.12.09,NeurIPS2019,,,,,,,,,,,,,,,,,,,,2024.10.10
vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,VQ-Wav2Vec,Representation,https://arxiv.org/abs/1910.05453,2019.10.12,v3,2020.02.16,ICLR2020Poster,,https://openreview.net/forum?id=rylwJxrYDS,,,,,,,,https://scholar.google.com/scholar?cluster=1142923229168041752,716,,,,,,,,,2024.09.23
WaveFlow: A Compact Flow-Based Model for Raw Audio,WaveFlow,Vocoder,https://arxiv.org/abs/1912.01219,2019.12.03,v4,2020.06.24,ICML2020,,,,,,,,,,,,Flow,,,,,,,,2024.09.24
AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment,AlignTTS,,https://arxiv.org/abs/2003.01950,2020.03.04,v1,2020.03.04,ICASSP2020,,,,,,,,,,https://scholar.google.com/scholar?cluster=1600438380822500245,86,,,,TTS,,,,,2024.09.24
Flow-TTS: A Non-Autoregressive Network for Text to Speech Based on Flow,Flow-TTS,,[Unavailable],2020.04.09,[Unavailable],[Unavailable],ICASSP2020,2020.04.09,https://doi.org/10.1109/ICASSP40776.2020.9054484,,,,,,,,https://scholar.google.com/scholar?cluster=7765078935283625839,134,Flow,,,TTS,,,,NAR,2024.09.24
Flowtron: An Autoregressive Flow-Based Generative Network for Text-to-Speech Synthesis,Flowtron,,https://arxiv.org/abs/2005.05957,2020.05.12,v3,2020.07.16,ICLR2021Poster,2021.01.12,https://openreview.net/forum?id=Ig53hpHxS4,,,https://github.com/NVIDIA/flowtron,,,10,,,170,Flow,,,TTS,,,,AR,2024.09.24
JDI-T: Jointly Trained Duration Informed Transformer for Text-to-Speech without Explicit Alignment,JDI-T,,https://arxiv.org/abs/2005.07799,2020.05.15,v3,2020.10.05,InterSpeech2020,2020.10.25,https://doi.org/10.21437/Interspeech.2020-2123,"Dan Lim, Won Jang, Gyeonghwan O, Heayoung Park, Bongwan Kim, Jaesam Yoon",,,,,,,https://scholar.google.com/scholar?cluster=7479320311701544613,45,,,,TTS,,,,,2024.10.08
Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search,Glow-TTS,,https://arxiv.org/abs/2005.11129,2020.05.22,v2,2020.10.23,NeurIPS2020,,,,,,,,,,,,Flow,,,TTS,,,,,2024.09.24
Language Models are Few-Shot Learners,GPT-3,TextLM,https://arxiv.org/abs/2005.14165,2020.05.28,v4,2020.07.22,,,,,,,,,,,,,,,,,,,Few-Shot,,2024.10.23
End-to-End Adversarial Text-to-Speech,EATS,,https://arxiv.org/abs/2006.03575,2020.06.05,v3,2021.03.17,ICLR2021Oral,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
MultiSpeech: Multi-Speaker Text to Speech with Transformer,MultiSpeech,,https://arxiv.org/abs/2006.04664,2020.06.08,v2,2022.08.01,,,,,,,,,,,,,,,,TTS,,,Multi-Speaker,,2024.09.24
FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,FastSpeech2,,https://arxiv.org/abs/2006.04558,2020.06.08,v8,2022.08.08,ICLR2021,,,,,,,https://speechresearch.github.io/fastspeech2/,,,,,,,,TTS,,,,,2024.09.24
NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity,NanoFlow,Vocoder,https://arxiv.org/abs/2006.06280,2020.06.11,v4,2020.10.23,NeurIPS2020,,,,,https://github.com/L0SG/NanoFlow,,,,,,,Flow,,,,,,,,2024.09.24
FastPitch: Parallel Text-to-speech with Pitch Prediction,FastPitch,,https://arxiv.org/abs/2006.06873,2020.06.11,v2,2021.02.16,ICASSP2021,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,Wav2Vec 2.0,Representation,https://arxiv.org/abs/2006.11477,2020.06.20,v3,2020.10.22,NeurIPS2020,,,,,,,,,,,,,,,,,,,,2024.09.21
VocGAN: A High-Fidelity Real-Time Vocoder with A Hierarchically-Nested Adversarial Network,VocGAN,Vocoder,https://arxiv.org/abs/2007.15256,2020.07.30,v1,2020.07.30,InterSpeech2020,2020.10.25,https://doi.org/10.21437/Interspeech.2020-1238,"Jinhyeok Yang, Junmo Lee, Youngik Kim, Hoon-Young Cho, Injung Kim",,,,,,,https://scholar.google.com/scholar?cluster=9472340814284569042,93,,,,,,,,,2024.10.08
SpeedySpeech: Efficient Neural Speech Synthesis,SpeedySpeech,,https://arxiv.org/abs/2008.03802,2020.08.09,v1,2020.08.09,InterSpeech2020,2020.10.25,https://doi.org/10.21437/Interspeech.2020-2867,"Jan Vainer, Ondrej Dusek",,,,,,,https://scholar.google.com/scholar?cluster=9573017801428970202,55,,,,TTS,,,,,2024.10.08
WaveGrad: Estimating Gradients for Waveform Generation,WaveGrad,Vocoder,https://arxiv.org/abs/2009.00713,2020.09.02,v2,2020.10.09,ICLR2021Poster,,,,,,,https://wavegrad.github.io/,,,https://scholar.google.com/scholar?cluster=9166479714962885889,724,,,,,,,,,2024.09.23
DiffWave: A Versatile Diffusion Model for Audio Synthesis,DiffWave,Vocoder,https://arxiv.org/abs/2009.09761,2020.09.21,v3,2021.03.30,ICLR2021Oral,,,,,,,,,,https://scholar.google.com/scholar?cluster=8775132726722534164,1176,Diffusion,,,,,,,,2024.09.24
HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,HiFi-GAN,Vocoder,https://arxiv.org/abs/2010.05646,2020.10.12,v2,2020.10.23,NeurIPS2020,,,,,https://github.com/jik876/hifi-gan,,,,,,,,,,TTS,,,,,2024.09.24
Reformer-TTS: Neural Speech Synthesis with Reformer Network,Reformer-TTS,,[Unavailable],2020.10.25,[Unavailable],[Unavailable],InterSpeech2020,2020.10.25,https://doi.org/10.21437/Interspeech.2020-2189,"Hyeong Rae Ihm, Joun Yeop Lee, Byoung Jin Choi, Sung Jun Cheon, Nam Soo Kim",,,,,,,https://scholar.google.com/scholar?cluster=6050518452267327546,11,,,,,,,,,2024.10.10
Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech,BVAE-TTS,,[Unavailable],2021.01.13,[Unavailable],[Unavailable],ICLR2021Poster,2021.01.13,https://openreview.net/forum?id=o3iritJHLfO,,,https://github.com/LEEYOONHYUNG/BVAE-TTS,,,,,,,,,,TTS,,,,NAR,2024.09.24
On Generative Spoken Language Modeling from Raw Audio,GSLM,SpeechLM,https://arxiv.org/abs/2102.01192,2021.02.01,v2,2021.09.09,MIT@TACL2021,2022.01.04,https://doi.org/10.1162/tacl_a_00430,"Kushal Lakhotia, Evgeny Kharitonov, Wei-Ning Hsu, Yossi Adi, Adam Polyak, Benjamin Bolte, Tu-Anh Nguyen, Jade Copet, Alexei Baevski, Adelrahman Mohamed, Emmanuel Dupoux",,https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm,,https://speechbot.github.io/gslm/,19,X,https://scholar.google.com/scholar?cluster=10339951252730122651,317,,,CPC/Wav2Vec2.0/HuBERT+Transformer (FairSeq)+Tacotron2+WaveGlow,Acoustic Unit Discovery/Spoken Language Modeling/Discrete Speech Resynthesis/Speech Generation,,,,,2024.10.23
LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search,LightSpeech,,https://arxiv.org/abs/2102.04040,2021.02.08,v1,2021.02.08,ICASSP2021,2021.05.13,https://doi.org/10.1109/ICASSP39728.2021.9414403,"Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Jinzhu Li, Sheng Zhao, Enhong Chen, Tie-Yan Liu",,,,https://speechresearch.github.io/lightspeech,,,https://scholar.google.com/scholar?cluster=12714255025013417554,70,,,,TTS,,,,,2024.10.18
AdaSpeech: Adaptive Text to Speech for Custom Voice,AdaSpeech,,https://arxiv.org/abs/2103.00993,2021.03.01,v1,2021.03.01,ICLR2021Poster,2021.01.12,https://openreview.net/forum?id=Drynvt7gg4L,"Mingjian Chen, Xu Tan, Bohan Li, Yanqing Liu, Tao Qin, Sheng Zhao, Tie-Yan Liu",,,,https://speechresearch.github.io/adaspeech/,,,https://scholar.google.com/scholar?cluster=5695102233701284044,178,,,,TTS,,,,,2024.10.18
Expressive Text-to-Speech using Style Tag,ST-TTS,,https://arxiv.org/abs/2104.00436,2021.04.01,v2,2022.10.06,InterSpeech2021,2021.08.30,https://doi.org/10.21437/Interspeech.2021-465,,,,,,,,,,,,,TTS,,,,,2024.09.24
Diff-TTS: A Denoising Diffusion Model for Text-to-Speech,Diff-TTS,,https://arxiv.org/abs/2104.01409,2021.04.03,v1,2021.04.03,InterSpeech2021,2021.08.30,https://doi.org/10.21437/Interspeech.2021-469,,,,,,,,https://scholar.google.com/scholar?cluster=386505123268486129,184,Diffusion,,,TTS,,,,,2024.09.24
AdaSpeech 2: Adaptive Text to Speech with Untranscribed Data,AdaSpeech2,,https://arxiv.org/abs/2104.09715,2021.04.20,v1,2021.04.20,ICASSP2021,,,,,,,https://speechresearch.github.io/adaspeech2/,,,,,,,,TTS,,,,,2024.09.24
Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech,Grad-TTS,,https://arxiv.org/abs/2105.06337,2021.05.13,v2,2021.08.05,ICML2021,,https://proceedings.mlr.press/v139/popov21a,,,,,,,,https://scholar.google.com/scholar?cluster=6905767521784147251,450,Diffusion,,,TTS,,,,,2024.09.24
ByT5: Towards A Token-Free Future with Pre-Trained Byte-to-Byte Models,ByT5,TextLM,https://arxiv.org/abs/2105.13626,2021.05.28,v3,2022.03.08,MIT@TACL2022,,https://doi.org/10.1162/tacl_a_00461,,,,,,,,https://scholar.google.com/scholar?cluster=765429917132805319,371,,,,,,,,,2024.10.23
Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech,VITS,,https://arxiv.org/abs/2106.06103,2021.06.11,v1,2021.06.11,ICML2021,,https://proceedings.mlr.press/v139/kim21f,,Training+Inference+Weight,https://github.com/jaywalnut310/vits,,https://jaywalnut310.github.io/vits-demo/index.html,15,45,,720,,,,TTS,LJSpeech/VCTK,Tacotron2+HiFi-GAN/Glow-TTS+HiFi-GAN,,,2024.09.24
PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior,PriorGrad,Vocoder,https://arxiv.org/abs/2106.06406,2021.06.11,v2,2022.02.20,,,,,,,,https://speechresearch.github.io/priorgrad/,,,,,Diffusion,,,,,,,,2024.09.24
HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units,HuBERT,Representation,https://arxiv.org/abs/2106.07447,2021.06.14,v1,2021.06.14,IEEE/ACM@TASLP2021,,,,,,,,,,,,,,,,,,,,2024.10.10
UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation,UnivNet,Vocoder,https://arxiv.org/abs/2106.07889,2021.06.15,v1,2021.06.15,InterSpeech2021,2021.08.30,https://doi.org/10.21437/Interspeech.2021-1016,,,,,,,,,,,,,,,,,,2024.09.21
RAD-TTS: Parallel Flow-Based TTS with Robust Alignment Learning and Diverse Synthesis,RAD-TTS,,[Unavailable],2021.06.16,[Unavailable],[Unavailable],ICML2021Poster,,https://openreview.net/forum?id=0NQwnnwAORi,,,,,,,,,,Flow,,,,,,,,2024.09.24
WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis,WaveGrad2,Vocoder,https://arxiv.org/abs/2106.09660,2021.06.17,v2,2021.06.19,InterSpeech2021,2021.08.30,https://doi.org/10.21437/Interspeech.2021-1897,,,,,https://wavegrad.github.io/v2,,,https://scholar.google.com/scholar?cluster=7794140642380946818,52,,,,TTS,,,,,2024.09.24
LoRA: Low-Rank Adaptation of Large Language Models,LoRA,PEFT,https://arxiv.org/abs/2106.09685,2021.06.17,V2,2021.10.16,,,,,,,,,,,https://scholar.google.com/scholar?cluster=12933070321040047372,6603,,,,,,,,,2024.09.23
Glow-WaveGAN: Learning Speech Representations from GAN-Based Variational Auto-Encoder for High Fidelity Flow-Based Speech Synthesis,Glow-WaveGAN,,https://arxiv.org/abs/2106.10831,2021.06.21,v2,2021.06.22,InterSpeech2021,2021.08.30,https://doi.org/10.21437/Interspeech.2021-414,,,,,,,,https://scholar.google.com/scholar?cluster=2756717255530588573,29,Flow,,,TTS,,,,,2024.09.24
AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style,AdaSpeech3,,https://arxiv.org/abs/2107.02530,2021.07.06,v1,2021.07.06,InterSpeech2021,2021.08.30,https://doi.org/10.21437/Interspeech.2021-584,,,,,,,,https://scholar.google.com/scholar?cluster=9301647847588887674,41,,,,TTS,,,,,2024.09.24
SoundStream: An End-to-End Neural Audio Codec,SoundStream,Codec,https://arxiv.org/abs/2107.03312,2021.07.07,v1,2021.07.07,IEEE/ACM@TASLP2021,,https://doi.org/10.1109/TASLP.2021.3129994,,,,,https://google-research.github.io/seanet/soundstream/examples/,13,68,,511,,,,,,,,,2024.10.10
W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training,W2V-BERT,Representation,https://arxiv.org/abs/2108.06209,2021.08.07,v2,2021.09.13,IEEE@ASRU2021,,https://doi.org/10.1109/ASRU51503.2021.9688253,,,,,,,,https://scholar.google.com/scholar?cluster=1094787119642800600,379,,,,,,,,,2024.09.23
Neural HMMs are all you need (for high-quality attention-free TTS),Neural HMM TTS,,https://arxiv.org/abs/2108.13320,2021.08.30,v6,2022.02.16,ICASSP2022,2022.04.27,https://doi.org/10.1109/ICASSP43922.2022.9746686,"Shivam Mehta, Eva Szekely, Jonas Beskow, Gustav Eje Henter",,,,,,,,,,,,,,,,,2024.10.10
Text-Free Prosody-Aware Generative Spoken Language Modeling,pGSLM,SpeechLM,https://arxiv.org/abs/2109.03264,2021.09.07,v2,2022.05.10,ACL2022,2022.05.22,https://doi.org/10.18653/v1/2022.acl-long.593,"Eugene Kharitonov, Ann Lee, Adam Polyak, Yossi Adi, Jade Copet, Kushal Lakhotia, Tu-Anh Nguyen, Morgane Riviere, Abdelrahman Mohamed, Emmanuel Dupoux, Wei-Ning Hsu",,https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm,,https://speechbot.github.io/pgslm,16,X,https://scholar.google.com/scholar?cluster=6860409912627023988,114,,,,,,,,,2024.10.23
Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme,DiffVC,VC,https://arxiv.org/abs/2109.13821,2021.09.28,v2,2022.08.04,ICLR2022Oral,2022.01.29,https://openreview.net/forum?id=8c50f-DoWAu,,,,,,,,https://scholar.google.com/scholar?cluster=17487782166390673105,95,,,,VC,,,,,2024.09.24
DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2021,DelightfulTTS,,https://arxiv.org/abs/2110.12612,2021.10.15,v2,2021.11.19,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
VISinger: Variational Inference with Adversarial Learning for End-to-End Singing Voice Synthesis,VISinger,SVS,https://arxiv.org/abs/2110.08813,2021.10.17,v2,2022.02.24,ICASSP2022,,,,,,,,,,,,,,,,,,,,2024.09.23
SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text Joint Pre-Training,SLAM,,https://arxiv.org/abs/2110.10329,2021.10.20,v1,2021.10.20,[Unavailable],[Unavailable],[Unavailable],"Ankur Bapna, Yu-an Chung, Nan Wu, Anmol Gulati, Ye Jia, Jonathan H. Clark, Melvin Johnson, Jason Riesa, Alexis Conneau, Yu Zhang",,,,,13,X,https://scholar.google.com/scholar?cluster=1425876612245513028,88,,,,,,,,,2024.10.23
WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing,WavLM,Representation,https://arxiv.org/abs/2110.13900,2021.10.26,v5,2022.06.17,IEEE@JSTSP2022,,https://doi.org/10.1109/JSTSP.2022.3188113,,,,,,,,https://scholar.google.com/scholar?cluster=10100955724765491326,1459,,,,,,,,,2024.09.24
YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for Everyone,YourTTS,,https://arxiv.org/abs/2112.02418,2021.12.04,v4,2023.04.30,ICML2022,,https://proceedings.mlr.press/v162/casanova22a.html,,,,,,,,https://scholar.google.com/scholar?cluster=8575580251111777245,331,,,,TTS/VC,,,Zero-Shot/Multi-Speaker,,2024.09.24
High-Resolution Image Synthesis with Latent Diffusion Models,LDM,Image,https://arxiv.org/abs/2112.10752,2021.12.20,v2,2022.04.13,IEEE/CVF@CVPR2022,,https://doi.org/10.1109/CVPR52688.2022.01042,,,,,,,,https://scholar.google.com/scholar?cluster=2427242760668866618,10759,Diffusion,,,,,,,,2024.09.24
MaskGIT: Masked Generative Image Transformer,MaskGIT,Image,https://arxiv.org/abs/2202.04200,2022.02.08,v1,2022.02.08,IEEE/CVF@CVPR,,,,,,,,,,,,,,,,,,,,2024.10.10
Autoregressive Image Generation using Residual Quantization,RQ-VAE,,https://arxiv.org/abs/2203.01941,2022.03.03,v2,2022.03.09,IEEE/CVF@CVPR2022,2022.09.27,https://doi.org/10.1109/CVPR52688.2022.01123,,,https://github.com/kakaobrain/rq-vae-transformer,,,,,https://scholar.google.com/scholar?cluster=5953877530421044413,166,,,,,,,,,2024.09.23
iSTFTNet: Fast and Lightweight Mel-Spectrogram Vocoder Incorporating Inverse Short-Time Fourier Transform,iSTFTNet,Vocoder,https://arxiv.org/abs/2203.02395,2022.03.04,v1,2022.03.04,ICASSP2022,,,,,,,https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet/,,,,,,,,,,,,,2024.09.21
HiFi++: A Unified Framework for Bandwidth Extension and Speech Enhancement,HiFi++,Vocoder,https://arxiv.org/abs/2203.13086,2022.03.24,v4,2023.12.10,ICASSP2023,,,,,,,,,,,,,,,,,,,,2024.09.21
VoiceMe: Personalized Voice Generation in TTS,VoiceMe,,https://arxiv.org/abs/2203.15379,2022.03.29,v2,2022.07.11,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-10855,,,,,https://polvanrijn.github.io/VoiceMe/,,,,,,,,,,,,,2024.09.21
Generative Spoken Dialogue Language Modeling,dGSLM,SpeechLM,https://arxiv.org/abs/2203.16502,2022.03.30,v2,2022.11.22,MIT@TACL2023,,https://doi.org/10.1162/tacl_a_00545,"Tu Anh Nguyen, Eugene Kharitonov, Jade Copet, Yossi Adi, Wei-Ning Hsu, Ali Elkahky, Paden Tomasello, Robin Algayres, Benoit Sagot, Abdelrahman Mohamed, Emmanuel Dupoux",,https://github.com/facebookresearch/fairseq/tree/main/examples/textless_nlp/dgslm,,https://speechbot.github.io/dgslm,17,X,https://scholar.google.com/scholar?cluster=9049539949210726832,87,,,HuBERT+Dialogue Transformer Language Model+HiFiGAN,,,,,,2024.10.23
SpeechPrompt: An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks,SpeechPrompt,,https://arxiv.org/abs/2203.16773,2022.03.31,v3,2022.07.10,Interspeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-10610,"Kai-Wei Chang, Wei-Cheng Tseng, Shang-Wen Li, Hung-yi Lee",,https://github.com/ga642381/SpeechPrompt,,https://kwchang.org/SpeechPrompt/speech-prompt-v1.html,5,35,https://scholar.google.com/scholar?cluster=6498497973942463265,49,,,,,,,,,2024.10.29
SpecGrad: Diffusion Probabilistic Model Based Neural Vocoder with Adaptive Noise Spectral Shaping,SpecGrad,Vocoder,https://arxiv.org/abs/2203.16749,2022.03.31,v2,2022.08.04,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-301,,,,,http://wavegrad.github.io/specgrad/,,,,,Diffusion,,,,,,,,2024.09.24
AdaSpeech 4: Adaptive Text to Speech in Zero-Shot Scenarios,AdaSpeech4,,https://arxiv.org/abs/2204.00436,2022.04.01,v1,2022.04.01,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-901,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis,FastDiff,,https://arxiv.org/abs/2204.09934,2022.04.21,v1,2022.04.21,IJCAI2022,,,,,,,https://fastdiff.github.io/,,,,,Diffusion,,,TTS,,,,,2024.09.24
NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality,NaturalSpeech,,https://arxiv.org/abs/2205.04421,2022.05.09,v2,2022.05.10,TPAMI,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech,GenerSpeech,,https://arxiv.org/abs/2205.07211,2022.05.15,v2,2022.10.12,NeurIPS2022,,,,,,,https://generspeech.github.io/,,,,,,,,TTS,,,,,2024.09.24
StyleTTS: A Style-Based Generative Model for Natural and Diverse Text-to-Speech Synthesis,StyleTTS,,https://arxiv.org/abs/2205.15439,2022.05.30,v2,2023.11.20,[Unavailable],[Unavailable],[Unavailable],,,,,,,,https://scholar.google.com/scholar?cluster=14437583393601108052,34,,,,TTS,,,,,2024.09.25
BigVGAN: A Universal Neural Vocoder with Large-Scale Training,BigVGAN,Vocoder,https://arxiv.org/abs/2206.04658,2022.06.09,v2,2023.02.16,ICLR2023Poster,,https://openreview.net/forum?id=iTtGCMDEzS_,,,https://github.com/NVIDIA/BigVGAN,,https://bigvgan-demo.github.io/,20,X,https://scholar.google.com/scholar?cluster=14265847301322679424,159,GAN,,AMP module+Snake Activation,,LibriTTS/(VCTK/LJSpeech[Unseen]),SC-WaveRNN/WaveGlow/WaveFlow/HiFi-GAN/UnivNet,,,2024.09.24
SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech,SANE-TTS,,https://arxiv.org/abs/2206.12132,2022.06.24,v1,2022.06.24,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-46,,,,,,,,,,,,,TTS,,,,,2024.09.24
JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech,JETS,,https://arxiv.org/abs/2203.16852,2022.07.01,v2,2022.07.01,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-10294,,,,,,,,https://scholar.google.com/scholar?cluster=15869678961981985812,50,,,,TTS,,,,,2024.09.24
Glow-WaveGAN 2: High-quality Zero-shot Text-to-speech Synthesis and Any-to-any Voice Conversion,Glow-WaveGAN2,,https://arxiv.org/abs/2207.01832,2022.07.05,v1,2022.07.05,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-684,,,,,,,,,,,,,TTS/VC,,,Zero-Shot,,2024.09.24
DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders,DelightfulTTS2,,https://arxiv.org/abs/2207.04646,2022.07.11,v1,2022.07.11,InterSpeech2022,2022.09.18,https://doi.org/10.21437/Interspeech.2022-277,,,,,,,,,,,,,TTS,,,,,2024.09.24
WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation,WaveGAN,Image,https://arxiv.org/abs/2207.07288,2022.07.15,v2,2022.08.09,ECCV2022,,,,Training+Inference+Weight,https://github.com/kobeshegu/ECCV2022_WaveGAN,,,,,https://scholar.google.com/scholar?cluster=3247766894580497169,50,GAN,,,,,,Few-Shot,,2024.09.24
MuLan: A Joint Embedding of Music Audio and Natural Language,MuLan,,https://arxiv.org/abs/2208.12415,2022.08.26,v1,2022.08.26,ISMIR2022,,https://ismir2022program.ismir.net/poster_150.html,,,,,,,,https://scholar.google.com/scholar?cluster=10540722819061261900,130,,,,,,,,,2024.09.25
AudioLM: A Language Modeling Approach to Audio Generation,AudioLM,SpeechLM,https://arxiv.org/abs/2209.03143,2022.09.07,v2,2023.07.26,IEEE/ACM@TASLP2023,2023.06.21,https://doi.org/10.1109/TASLP.2023.3288409,"Zalan Borsos, Rapha?l Marinier, Damien Vincent, Eugene Kharitonov, Olivier Pietquin, Matt Sharifi, Dominik Roblek, Olivier Teboul, David Grangier, Marco Tagliasacchi, Neil Zeghidour",,,,https://google-research.github.io/seanet/audiolm/examples/,11,65,https://scholar.google.com/scholar?cluster=16664344357726277649,475,,,,,,,,,2024.10.23
AudioGen: Textually Guided Audio Generation,AudioGen,SpeechLM,https://arxiv.org/abs/2209.15352,2022.09.30,v2,2023.06.05,ICLR2023Poster,2023.02.01,https://openreview.net/forum?id=CYK7RfcOzQ4,"Felix Kreuk, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre Defossez, Jade Copet, Devi Parikh, Yaniv Taigman, Yossi Adi",,https://felixkreuk.github.io/audiogen/,,https://felixkreuk.github.io/audiogen/,16,X,https://scholar.google.com/scholar?cluster=11166122285082527856,288,,,,,,,,AR,2024.10.23
High Fidelity Neural Audio Compression,EnCodec,Codec,https://arxiv.org/abs/2210.13438,2022.10.24,v1,2022.10.24,TMLR,,,,Training+Inference+Weight,https://github.com/facebookresearch/encodec,,,19,,https://scholar.google.com/scholar?cluster=11269141130994676820,462,,EnCodec,,,,,,,2024.09.23
FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion,FreeVC,VC,https://arxiv.org/abs/2210.15418,2022.10.27,v1,2022.10.27,IEEE@ICASSP2023,2023.05.05,https://doi.org/10.1109/ICASSP49357.2023.10095191,,,,,,,,https://scholar.google.com/scholar?cluster=16505500752330187346,76,,,,VC,,,One-Shot,,2024.09.24
HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference Using Self-supervised Representations for Speech Synthesis,HierSpeech,,[Unavailable],2022.11.01,[Unavailable],[Unavailable],NeurIPS2022,2022.11.01,https://openreview.net/forum?id=awdyRVnfQKX,,,,,,,,https://scholar.google.com/scholar?cluster=10216809622451649383,39,,,,TTS,,,,,2024.09.24
VISinger 2: High-Fidelity End-to-End Singing Voice Synthesis Enhanced by Digital Signal Processing Synthesizer,VISinger2,SVS,https://arxiv.org/abs/2211.02903,2022.11.05,v1,2022.11.05,InterSpeech2023,2023.08.20,https://doi.org/10.21437/Interspeech.2022-391,,,,,,,,https://scholar.google.com/scholar?cluster=13300051646424906650,16,,,,,,,,,2024.09.23
A Unified One-Shot Prosody and Speaker Conversion System with Self-Supervised Discrete Speech Units,UUVC,VC,https://arxiv.org/abs/2211.06535,2022.11.12,v1,2022.11.12,IEEE@ICASSP2023,2023.05.05,https://doi.org/10.1109/ICASSP49357.2023.10095565,,,https://github.com/b04901014/uuvc,,https://b04901014.github.io/UUVC/,,,https://scholar.google.com/scholar?cluster=16859671418509076699,6,,,,VC,,,,,2024.09.25
OverFlow: Putting Flows on Top of Neural Transducers for Better TTS,OverFlow,,https://arxiv.org/abs/2211.06892,2022.11.13,v2,2023.05.29,InterSpeech2023,2023.08.20,https://doi.org/10.21437/Interspeech.2022-1996,,,,,https://shivammehta25.github.io/OverFlow/,,,https://scholar.google.com/scholar?cluster=15444001209274851942,15,Flow,,,,,,,,2024.09.24
PromptTTS: Controllable Text-to-Speech with Text Descriptions,PromptTTS,,https://arxiv.org/abs/2211.12171,2022.11.22,v1,2022.11.22,ICASSP2023,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
Robust Speech Recognition via Large-Scale Weak Supervision,Whisper,,https://arxiv.org/abs/2212.04356,2022.12.06,v1,2022.12.06,ICML2023Poster,2023.04.24,https://proceedings.mlr.press/v202/radford23a.html,"Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever",,,,,,,https://scholar.google.com/scholar?cluster=14594961257476535034,2695,,,,,,,,,2024.09.21
Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers,VALL-E,CLM,https://arxiv.org/abs/2301.02111,2023.01.05,v1,2023.01.05,[Unavailable],[Unavailable],[Unavailable],"Chengyi Wang, Sanyuan Chen, Yu Wu, Ziqiang Zhang, Long Zhou, Shujie Liu, Zhuo Chen, Yanqing Liu, Huaming Wang, Jinyu Li, Lei He, Sheng Zhao, Furu Wei",[Unavailable],,,https://aka.ms/valle,16,49,https://scholar.google.com/scholar?cluster=8330191945346870138,504,,VALL-E,EnCodec (RVQ 8 Codebook) ¡ú AR Transformer (Code 1)  ¡ú NAR Transformer (Code 2:8),TTS,LibriLight (Train)/LibriSpeech+VCTK (Test),S2S: GSLM/AudioLM; TTS: YourTTS (VCTK+LibriTTS+TTS-Portuguese),Zero-Shot,AR+NAR,2024.10.26
MusicLM: Generating Music From Text,MusicLM,,https://arxiv.org/abs/2301.11325,2023.01.26,v1,2023.01.26,[Unavailable],[Unavailable],[Unavailable],"Andrea Agostinelli, Timo I. Denk, Zalan Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, Matt Sharifi, Neil Zeghidour, Christian Frank",,,,https://google-research.github.io/seanet/musiclm/examples/,15,X,https://scholar.google.com/scholar?cluster=17376728213237187356,494,,MusicLM/MusicCaps (Dataset),,,,,,,2024.10.26
AudioLDM: Text-to-Audio Generation with Latent Diffusion Models,AudioLDM,,https://arxiv.org/abs/2301.12503,2023.01.29,v3,2023.09.09,ICML2023,,https://proceedings.mlr.press/v202/liu23f.html,,,,,,,,https://scholar.google.com/scholar?cluster=3166553528222335360,378,Diffusion,,,,,,,,2024.09.24
Make-An-Audio: Text-to-Audio Generation with Prompt-Enhanced Diffusion Models,Make-An-Audio,,https://arxiv.org/abs/2301.12661,2023.01.30,v1,2023.01.30,ICML2023,,https://proceedings.mlr.press/v202/huang23i.html,,,,,https://text-to-audio.github.io/,,,https://scholar.google.com/scholar?cluster=14204166098403262471,210,Diffusion,,,,,,,,2024.09.24
InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt,InstructTTS,,https://arxiv.org/abs/2301.13662,2023.01.31,v2,2023.06.25,IEEE/ACM@TASLP2024,2024.05.20,https://doi.org/10.1109/TASLP.2024.3402088,,,,,,,,https://scholar.google.com/scholar?cluster=16890941306445601074,65,,,,,,,,,2024.10.10
Speak Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision,SPEAR-TTS,,https://arxiv.org/abs/2302.03540,2023.02.07,v1,2023.02.07,MIT@TACL2023,2023.12.21,https://doi.org/10.1162/tacl_a_00618,"Eugene Kharitonov, Damien Vincent, Zalan Borsos, Raphael Marinier, Sertan Girgin, Olivier Pietquin, Matt Sharifi, Marco Tagliasacchi, Neil Zeghidour",[Unavailable],,,https://google-research.github.io/seanet/speartts/examples/,16,X,https://scholar.google.com/scholar?cluster=15014701949812441701,156,,,,TTS,,,,,2024.10.27
QuickVC: Any-to-Many Voice Conversion Using Inverse Short-time Fourier Transform for Faster Conversion,QuickVC,VC,https://arxiv.org/abs/2302.08296,2023.02.16,v4,2023.02.23,,,,,,,,,,,https://scholar.google.com/scholar?cluster=8865818686073432109,9,,,,VC,,,,,2024.09.24
LLaMA: Open and Efficient Foundation Language Models,LLaMA,TextLM,https://arxiv.org/abs/2302.13971,2023.02.27,v1,2023.02.27,,,,,,,,,,,https://scholar.google.com/scholar?cluster=7549877693210626200,8738,,,,,,,,,2024.10.23
SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks,SpeechPrompt v2,,https://arxiv.org/abs/2303.00733,2023.03.01,v1,2023.03.01,[Unavailable],[Unavailable],[Unavailable],,,https://github.com/ga642381/SpeechPrompt-v2,,https://kwchang.org/SpeechPrompt/speech-prompt-v2.html,7,33,https://scholar.google.com/scholar?cluster=17237359125895838493,30,,,,,,,,,2024.10.29
Vocos: Closing the Gap between Time-Domain and Fourier-Based Neural Vocoders for High-Quality Audio Synthesis,Vocos,Vocoder,https://arxiv.org/abs/2306.00814,2023.03.01,v3,2024.05.29,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=vY9nzQmQBw,,Training+Inference+Weight,https://github.com/gemelo-ai/vocos,https://huggingface.co/charactr/vocos-mel-24khz,https://gemelo-ai.github.io/vocos/,15,X,https://scholar.google.com/scholar?cluster=4445816452466808234,34,,,,,LibriTTS,HiFi-GAN/iSTFTNet/BigVGAN,,,2024.09.24
Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages,Google USM,,https://arxiv.org/abs/2303.01037,2023.03.02,v3,2023.09.25,[Unavailable],[Unavailable],[Unavailable],"Yu Zhang, Wei Han, James Qin, Yongqiang Wang, Ankur Bapna, Zhehuai Chen, Nanxin Chen, Bo Li, Vera Axelrod, Gary Wang, Zhong Meng, Ke Hu, Andrew Rosenberg, Rohit Prabhavalkar, Daniel S. Park, Parisa Haghani, Jason Riesa, Ginger Perng, Hagen Soltau, Trevor Strohman, Bhuvana Ramabhadran, Tara Sainath, Pedro Moreno, Chung-Cheng Chiu, Johan Schalkwyk, Fran?oise Beaufays, Yonghui Wu",,,,,20,89,https://scholar.google.com/scholar?cluster=17752285616737220261,243,,,,,,,,,2024.10.28
End-to-End Speech Recognition: A Survey,[Unavailable],Survey,https://arxiv.org/abs/2303.03329,2023.03.03,v1,2023.03.03,IEEE/ACM@TASLP2023,2023.10.30,https://doi.org/10.1109/TASLP.2023.3328283,,,,,,,,https://scholar.google.com/scholar?cluster=12935209782382517287,113,,,,,,,,,2024.10.10
FoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model,FoundationTTS,,https://arxiv.org/abs/2303.02939,2023.03.06,v3,2023.03.06,[Unavailable],[Unavailable],[Unavailable],"Ruiqing Xue, Yanqing Liu, Lei He, Xu Tan, Linquan Liu, Edward Lin, Sheng Zhao",,,,,,,https://scholar.google.com/scholar?cluster=7389306401877363213,9,,,,TTS,,,,,2024.10.29
Speak Foreign Languages with Your Own Voice:Cross-Lingual Neural Codec Language Modeling,VALL-E X,CLM,https://arxiv.org/abs/2303.03926,2023.03.07,v1,2023.03.07,,,,,,,,https://aka.ms/vallex,,,,,,,,,,,,,2024.09.24
LMCodec: A Low Bitrate Speech Codec with Causal Transformer Models,LMCodec,Codec,https://arxiv.org/abs/2303.12984,2023.03.23,v1,2023.03.23,ICASSP2023,,,,,,,https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec,,,,,,,,,,,,,2024.09.21
NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers,NaturalSpeech2,,https://arxiv.org/abs/2304.09116,2023.04.18,v3,2023.05.30,ICLR2024Spotlight,,,,,,,,,,,,Diffusion,,,,,,Zero-Shot,,2024.10.10
"AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head",AudioGPT,,https://arxiv.org/abs/2304.12995,2023.04.25,v1,2023.04.25,AAAI2024,2024.03.24,https://doi.org/10.1609/aaai.v38i21.30570,"Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, Yi Ren, Zhou Zhao, Shinji Watanabe",,https://github.com/AIGC-Audio/AudioGPT,https://huggingface.co/spaces/AIGC-Audio/AudioGPT,,,,https://scholar.google.com/scholar?cluster=10625702268349818855,144,,,,,,,,,2024.10.27
HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec,HiFi-Codec,Codec,https://arxiv.org/abs/2305.02765,2023.05.04,v2,2023.05.07,,,,,,,,,,,,,,,,,,,,,2024.09.21
CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model,CoMoSpeech,,https://arxiv.org/abs/2305.06908,2023.05.11,v4,2023.10.29,ACM MultiMedia2023,2023.10.27,https://doi.org/10.1145/3581783.3612061,"Zhen Ye, Wei Xue, Xu Tan, Jie Chen, Qifeng Liu, Yike Guo",,https://github.com/zhenye234/CoMoSpeech,,https://comospeech.github.io/,9,41,https://scholar.google.com/scholar?cluster=125530389504723191,26,Diffusion/Consistency,,,TTS,,,,,2024.10.07
Better Speech Synthesis through Scaling,TorToise-TTS,,https://arxiv.org/abs/2305.07243,2023.05.12,v2,2023.05.23,,,,James Betker,,https://github.com/neonbjb/tortoise-tts,,http://nonint.com/static/tortoise_v2_examples.html,,,https://scholar.google.com/scholar?cluster=12308206494684283413,47,Diffusion,,,TTS,,,,,2024.10.07
APNet: An All-Frame-Level Neural Vocoder Incorporating Direct Prediction of Amplitude and Phase Spectra,APNet,Vocoder,https://arxiv.org/abs/2305.07952,2023.05.13,v1,2023.05.13,IEEE/ACM@TASLP2023,,https://doi.org/10.1109/TASLP.2023.3277276,,,,,,,,,,,,,,,,,,2024.10.10
SoundStorm: Efficient Parallel Audio Generation,SoundStorm,,https://arxiv.org/abs/2305.09636,2023.05.16,v1,2023.05.16,ICLR2024Reject,2023.09.23,https://openreview.net/forum?id=KknWbD5j95,"Zalan Borsos, Matt Sharifi, Damien Vincent, Eugene Kharitonov, Neil Zeghidour, Marco Tagliasacchi",,,,https://google-research.github.io/seanet/soundstorm/examples/,9,X,https://scholar.google.com/scholar?cluster=12476111044975033127,84,,,,,,,,,2024.10.27
Palm 2 Technical Report,PaLM2,TextLM,https://arxiv.org/abs/2305.10403,2023.05.17,v3,2023.09.13,,,,,,,,,,,https://scholar.google.com/scholar?cluster=8537582669272475110,1198,,,,,,,,,2024.10.23
SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities,SpeechGPT,,https://arxiv.org/abs/2305.11000,2023.05.18,v2,2023.05.19,EMNLP2023Findings,2023.12.06,https://doi.org/10.18653/v1/2023.findings-emnlp.1055,"Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, Xipeng Qiu",,https://github.com/0nutation/SpeechGPT,,https://0nutation.github.io/SpeechGPT.github.io/,13,X,https://scholar.google.com/scholar?cluster=6768447378252129444,177,,,,,,,,,2024.10.29
Listen Think and Understand,LTU,,https://arxiv.org/abs/2305.10790,2023.05.18,v3,2024.02.19,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=nBZBPXdJlC,"Yuan Gong, Hongyin Luo, Alexander H. Liu, Leonid Karlinsky, James Glass",,https://github.com/YuanGongND/ltu,https://huggingface.co/spaces/yuangongfdu/ltu,,30,X,https://scholar.google.com/scholar?cluster=10650236499486566217,109,,LTU/OpenAQA-5M (Dataset),,Understanding,,,,AR,2024.10.27
Pengi: An Audio Language Model for Audio Tasks,Pengi,,https://arxiv.org/abs/2305.11834,2023.05.19,v2,2024.01.19,NeurIPS2023Poster,2023.09.22,https://dl.acm.org/doi/abs/10.5555/3666122.3666917,"Soham Deshmukh, Benjamin Elizalde, Rita Singh, Huaming Wang",,https://github.com/microsoft/Pengi,,,19,65,https://scholar.google.com/scholar?cluster=10580047223748383516,98,,,,,,,,,2024.10.29
U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech,U-DiT TTS,,https://arxiv.org/abs/2305.13195,2023.05.22,v1,2023.05.22,IEEE@SpeechCommunication,2023.12.18,https://doi.org/10.30420/456164010,,,,,,,,https://scholar.google.com/scholar?cluster=11840959028878808925,5,Diffusion,,,TTS,,,,,2024.09.24
Textually Pretrained Speech Language Models,TWIST,,https://arxiv.org/abs/2305.13009,2023.05.22,v3,2024.01.30,NeurIPS2023Poster,2023.09.22,https://dl.acm.org/doi/abs/10.5555/3666122.3668893,"Michael Hassid, Tal Remez, Tu Anh Nguyen, Itai Gat, Alexis Conneau, Felix Kreuk, Jade Copet, Alexandre Defossez, Gabriel Synnaeve, Emmanuel Dupoux, Roy Schwartz, Yossi Adi",,https://github.com/facebookresearch/textlesslib/tree/main/examples/twist,,https://pages.cs.huji.ac.il/adiyoss-lab/twist/,,,https://scholar.google.com/scholar?cluster=2726323772873175239,43,,,,,,,,,2024.10.29
QLoRA: Efficient Finetuning of Quantized LLMs,QLoRA,PEFT,https://arxiv.org/abs/2305.14314,2023.05.23,v1,2023.05.23,,,,,,,,,,,https://scholar.google.com/scholar?cluster=1698009957296542951,1405,,,,,,,,,2024.09.23
Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM,,Spectron,https://arxiv.org/abs/2305.15255,2023.05.24,v4,2024.05.31,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=izrOLJov5y,"Eliya Nachmani, Alon Levkovitch, Roy Hirsch, Julian Salazar, Chulayuth Asawaroengchai, Soroosh Mariooryad, Ehud Rivlin, RJ Skerry-Ryan, Michelle Tadmor Ramanovich",,,,https://michelleramanovich.github.io/spectron/spectron,16,X,https://scholar.google.com/scholar?cluster=2239314690427158927,14,,,,,,,,,2024.10.29
VioLA: Unified Codec Language Models for Speech Recognition Synthesis and Translation,VioLA,MLLM,https://arxiv.org/abs/2305.16107,2023.05.25,v1,2023.05.25,[Unavailable],[Unavailable],[Unavailable],"Tianrui Wang, Long Zhou, Ziqiang Zhang, Yu Wu, Shujie Liu, Yashesh Gaur, Zhuo Chen, Jinyu Li, Furu Wei",[Unavailable],,,,11,X,https://scholar.google.com/scholar?cluster=3175310480496805997,77,,VioLA,Decoder-Only,,,,,,2024.10.27
AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec,AudioDec,Codec,https://arxiv.org/abs/2305.16608,2023.05.26,v1,2023.05.26,ICASSP2023,,,,,,,,,,,,,,,,,,,,2024.09.21
Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation,Make-An-Audio2,,https://arxiv.org/abs/2305.18474,2023.05.29,v1,2023.05.29,[Unavailable],[Unavailable],[Unavailable],,,https://github.com/bytedance/Make-An-Audio-2,,https://make-an-audio-2.github.io,,,https://scholar.google.com/scholar?cluster=13517159671265524532,33,,,,,,,,,2024.10.07
Make-A-Voice: Unified Voice Synthesis With Discrete Representation,Make-A-Voice,,https://arxiv.org/abs/2305.19269,2023.05.30,v1,2023.05.30,[Unavailable],[Unavailable],[Unavailable],"Rongjie Huang, Chunlei Zhang, Yongqi Wang, Dongchao Yang, Luping Liu, Zhenhui Ye, Ziyue Jiang, Chao Weng, Zhou Zhao, Dong Yu",,,,https://make-a-voice.github.io/,16,47,https://scholar.google.com/scholar?cluster=12763739973148023166,25,,,,,,,,,2024.10.29
PromptStyle: Controllable Style Transfer for Text-to-Speech with Natural Language Descriptions,PromptStyle,,https://arxiv.org/abs/2305.19522,2023.05.31,v2,2023.06.01,InterSpeech2023,2023.08.20,https://doi.org/10.21437/Interspeech.2022-1779,,,,,,,,https://scholar.google.com/scholar?cluster=14591664902776788259,31,,,,TTS,,,,,2024.09.24
SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts,SpeechGen,,https://arxiv.org/abs/2306.02207,2023.06.03,v3,2023.08.25,[Unavailable],[Unavailable],[Unavailable],"Haibin Wu, Kai-Wei Chang, Yuan-Kuei Wu, Hung-yi Lee",,https://github.com/ga642381/SpeechGen,,https://ga642381.github.io/SpeechPrompt/speechgen,14,X,https://scholar.google.com/scholar?cluster=16623612908585464130,21,,,,,,,,,2024.10.29
Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias,Mega-TTS,,https://arxiv.org/abs/2306.03509,2023.06.06,v1,2023.06.06,[Unavailable],[Unavailable],[Unavailable],"Ziyue Jiang, Yi Ren, Zhenhui Ye, Jinglin Liu, Chen Zhang, Qian Yang, Shengpeng Ji, Rongjie Huang, Chunfeng Wang, Xiang Yin, Zejun Ma, Zhou Zhao",,,,https://mega-tts.github.io/demo-page,20,67,https://scholar.google.com/scholar?cluster=15692405188854768212,54,,,,TTS,,,Zero-Shot,,2024.10.29
Simple and Controllable Music Generation,MusicGen,,https://arxiv.org/abs/2306.05284,2023.06.08,v3,2024.01.30,NeurIPS2023Poster,2023.09.22,https://openreview.net/forum?id=jtiQ26sCJi,"Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, Alexandre Defossez",Training+Inference+Weight,https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md,,https://ai.honu.io/papers/musicgen/,17,X,https://scholar.google.com/scholar?cluster=8869808453563782269,329,,,,,,,,,2024.10.29
High-Fidelity Audio Compression with Improved RVQGAN,DAC,Codec,https://arxiv.org/abs/2306.06546,2023.06.11,v2,2023.10.26,NeurIPS2023Spotlight,,,,,,,,,,,,,,,,,,,,2024.09.21
StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models,StyleTTS2,,https://arxiv.org/abs/2306.07691,2023.06.13,v2,2023.11.20,NeurIPS2023,,,,,,,https://styletts2.github.io/,,,,,Diffusion,,,TTS,,,,,2024.09.24
UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding,UniCATS,,https://arxiv.org/abs/2306.07547,2023.06.13,v6,2024.03.28,AAAI2024,2024.03.24,https://doi.org/10.1609/aaai.v38i16.29747,"Chenpeng Du, Yiwei Guo, Feiyu Shen, Zhijun Liu, Zheng Liang, Xie Chen, Shuai Wang, Hui Zhang, Kai Yu",,,,,,,https://scholar.google.com/scholar?cluster=6957476100902778449,30,,,,,,,,,2024.09.25
AudioPaLM: A Large Language Model That Can Speak and Listen,AudioPaLM,,https://arxiv.org/abs/2306.12925,2023.06.22,v1,2023.06.22,[Unavailable],[Unavailable],[Unavailable],"Paul K. Rubenstein, Chulayuth Asawaroengchai, Duc Dung Nguyen, Ankur Bapna, Zalan Borsos, Felix de Chaumont Quitry, Peter Chen, Dalia El Badawy, Wei Han, Eugene Kharitonov, Hannah Muckenhirn, Dirk Padfield, James Qin, Danny Rozenberg, Tara Sainath, Johan Schalkwyk, Matt Sharifi, Michelle Tadmor Ramanovich, Marco Tagliasacchi, Alexandru Tudor, Mihajlo Velimirovic, Damien Vincent, Jiahui Yu, Yongqiang Wang, Vicky Zayats, Neil Zeghidour, Yu Zhang, Zhishuai Zhang, Lukas Zilka, Christian Frank",,,,https://google-research.github.io/seanet/audiopalm/examples,27,X,https://scholar.google.com/scholar?cluster=15189287243147910049,140,,,,,,,,,2024.10.29
Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale,Voicebox,,https://arxiv.org/abs/2306.15687,2023.06.23,v2,2023.10.19,NeurIPS2023Poster,2023.09.21,https://dl.acm.org/doi/abs/10.5555/3666122.3666740,"Matthew Le, Apoorv Vyas, Bowen Shi, Brian Karrer, Leda Sari, Rashel Moritz, Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, Wei-Ning Hsu",,,,https://voicebox.metademolab.com/,30,67,https://scholar.google.com/scholar?cluster=8321587129194615781,195,FlowMatching,,,,,,,NAR,2024.10.29
UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data,UnitSpeech,,https://arxiv.org/abs/2306.16083,2023.06.28,v1,2023.06.28,InterSpeech2023Oral,2023.08.20,https://doi.org/10.21437/Interspeech.2023-2326,,,,,,,,,,,,,TTS,,,,,2024.09.24
Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis,Mega-TTS2,,https://arxiv.org/abs/2307.07218,2023.07.14,v4,2024.04.10,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=mvMI3N4AvD,"Ziyue Jiang, Jinglin Liu, Yi Ren, Jinzheng He, Zhenhui Ye, Shengpeng Ji, Qian Yang, Chen Zhang, Pengfei Wei, Chunfeng Wang, Xiang Yin, Zejun Ma, Zhou Zhao",,,,https://boostprompt.github.io/boostprompt/,21,X,https://scholar.google.com/scholar?cluster=16735322993503076322,37,,,,TTS,,,Zero-Shot,,2024.10.29
Llama 2: Open Foundation and Fine-Tuned Chat Models,LLaMA2,TextLM,https://arxiv.org/abs/2307.09288,2023.07.18,v2,2023.07.19,,,,,,,,,,,https://scholar.google.com/scholar?cluster=10722545090167785628,7996,,,,,,,,,2024.10.23
VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design,VITS2,,https://arxiv.org/abs/2307.16430,2023.07.31,v1,2023.07.31,InterSpeech2023,2023.08.20,https://doi.org/10.21437/Interspeech.2022-534,,,,,,,,,,,,,TTS,,,,,2024.09.24
DiffProsody: Diffusion-Based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training,DiffProsody,,https://arxiv.org/abs/2307.16549,2023.07.31,v1,2023.07.31,IEEE/ACM@TASLP2024,2024.05.01,https://doi.org/10.1109/TASLP.2024.3395994,,,,,,,,https://scholar.google.com/scholar?cluster=13675380349094484432,8,Diffusion,,,TTS,,,,,2024.10.10
AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining,AudioLDM2,,https://arxiv.org/abs/2308.05734,2023.08.10,v3,2024.05.11,IEEE/ACM@TASLP2024,2024.05.13,https://doi.org/10.1109/TASLP.2024.3399607,"Haohe Liu, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Qiao Tian, Yuping Wang, Wenwu Wang, Yuxuan Wang, Mark D. Plumbley",,https://github.com/haoheliu/audioldm2,,https://audioldm.github.io/audioldm2,,,https://scholar.google.com/scholar?cluster=9432035319079812866,76,Diffusion,,,,,,,,2024.10.10
iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN,iSTFTNet2,Vocoder,https://arxiv.org/abs/2308.07117,2023.08.14,v1,2023.08.14,InterSpeech2023,2023.08.20,https://doi.org/10.21437/Interspeech.2022-1726,,,,,https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/,,,,,,,,,,,,,2024.09.21
SpeechX: Neural Codec Language Model as a Versatile Speech Transformer,SpeechX,,https://arxiv.org/abs/2308.06873,2023.08.14,v2,2024.06.25,IEEE/ACM@TASLP2024,2024.06.28,https://doi.org/10.1109/TASLP.2024.3419418,"Xiaofei Wang, Manthan Thakker, Zhuo Chen, Naoyuki Kanda, Sefik Emre Eskimez, Sanyuan Chen, Min Tang, Shujie Liu, Jinyu Li, Takuya Yoshioka",,,,https://aka.ms/speechx,10,43,https://scholar.google.com/scholar?cluster=3146656686281147659,53,,,,,,,,,2024.10.29
TextrolSpeech: A Text Style Control Speech Corpus with Codec Language Text-to-Speech Models,TextrolSpeech,Dataset,https://arxiv.org/abs/2308.14430,2023.08.28,v1,2023.08.28,,,,,,,,https://sall-e.github.io/,,,,,,,,TTS,,,,,2024.09.24
SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models,SpeechTokenizer,Codec,https://arxiv.org/abs/2308.16692,2023.08.31,v2,2024.01.23,ICLR2024,,,,,https://github.com/ZhangXInFD/SpeechTokenizer/,,,,,,,,,,,,,,,2024.09.21
RepCodec: A Speech Representation Codec for Speech Tokenization,RepCodec,Codec,https://arxiv.org/abs/2309.00169,2023.08.31,v3,2024.07.22,ACL2024,2024.08.00,,,,,,,,,,,,,,,,,,,2024.09.21
PromptTTS 2: Describing and Generating Voices with Text Prompt,PromptTTS2,,https://arxiv.org/abs/2309.02285,2023.09.05,v2,2023.10.12,ICLR2024Poster,,,,,,,https://speechresearch.github.io/prompttts2,,,,,,,,,,,,,2024.10.10
Matcha-TTS: A Fast Tts Architecture with Conditional Flow Matching,Matcha-TTS,,https://arxiv.org/abs/2309.03199,2023.09.06,v2,2024.01.09,ICASSP2024,2024.03.18,,,,,,https://shivammehta25.github.io/Matcha-TTS/,5,,https://scholar.google.com/scholar?cluster=3378090602595584425,21,,,,,,,,,2024.09.21
BigVSAN: Enhancing GAN-Based Neural Vocoders with Slicing Adversarial Network,BigVSAN,Vocoder,https://arxiv.org/abs/2309.02836,2023.09.06,v2,2024.03.25,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10446121,,Training+Inference+Weight,https://github.com/sony/bigvsan,,https://takashishibuyasony.github.io/bigvsan/,5,41,https://scholar.google.com/scholar?cluster=2015463515017027949,11,GAN,,Least Squares SAN: MelSAN/Parallel WaveSAN/BigVSAN,,LJSpeech/LibriTTS/VCTK,MelGAN/Parallel WaveGAN/BigVGAN,,,2024.09.21
VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching,VoiceFlow,,https://arxiv.org/abs/2309.05027,2023.09.10,v3,2024.09.01,ICASSP2024,2024.03.18,,,,,,,,,,,,,,TTS,,,,,2024.09.24
NExT-GPT: Any-to-Any Multimodal LLM,NExT-GPT,,https://arxiv.org/abs/2309.05519,2023.09.11,v3,2024.06.25,ICML2024Oral,2024.05.02,https://openreview.net/forum?id=NZQkumsNlf,"Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, Tat-Seng Chua",,https://github.com/NExT-GPT/NExT-GPT,,https://next-gpt.github.io,32,X,https://scholar.google.com/scholar?cluster=10489512657753192238,331,,,,,,,,,2024.10.29
SnakeGAN: A Universal Vocoder Leveraging DDSP Prior Knowledge and Periodic Inductive Bias,SnakeGAN,Vocoder,https://arxiv.org/abs/2309.07803,2023.09.14,v1,2023.09.14,ICME2023,,,,,,,,,,,,,,,,,,,,2024.09.21
FunCodec: A Fundamental Reproducible and Integrable Open-source Toolkit for Neural Speech Codec,FunCodec,Codec,https://arxiv.org/abs/2309.07405,2023.09.14,v2,2023.10.07,ICASSP2024,2024.03.18,,,,https://github.com/alibaba-damo-academy/FunCodec,,,,,,,,,,,,,,,2024.09.21
Fewer-token Neural Speech Codec with Time-invariant Codes,TiCodec,Codec,https://arxiv.org/abs/2310.00014,2023.09.15,v2,2024.03.11,ICASSP2024,2024.03.18,,,,,,,,,,,,,,,,,,,2024.09.21
HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise Filter and Inverse Short Time Fourier Transform,HiFTNet,Vocoder,https://arxiv.org/abs/2309.09493,2023.09.18,v1,2023.09.18,,,,,,,,,,,,,,,,,,,,,2024.09.21
VoiceLDM: Text-to-Speech with Environmental Context,VoiceLDM,,https://arxiv.org/abs/2309.13664,2023.09.24,v1,2023.09.24,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10448268,,,,,https://voiceldm.github.io/,,,https://scholar.google.com/scholar?cluster=3766695167763370661,3,,,,TTS,,,,,2024.09.24
Qwen Technical Report,Qwen,TextLM,https://arxiv.org/abs/2309.16609,2023.09.28,v1,2023.09.28,,,,,,,,,,,https://scholar.google.com/scholar?cluster=16379938937265481547,948,,,,,,,,,2024.10.23
UniAudio: An Audio Foundation Model Toward Universal Audio Generation,UniAudio,,https://arxiv.org/abs/2310.00704,2023.10.01,v5,2023.12.11,ICLR2024Reject,2023.09.24,https://openreview.net/forum?id=nhgTmx1TZJ,"Dongchao Yang, Jinchuan Tian, Xu Tan, Rongjie Huang, Songxiang Liu, Xuankai Chang, Jiatong Shi, Sheng Zhao, Jiang Bian, Xixin Wu, Zhou Zhao, Shinji Watanabe, Helen Meng",,https://github.com/yangdongchao/UniAudio,,http://dongchaoyang.top/UniAudio_demo/,24,X,https://scholar.google.com/scholar?cluster=6416249801268158267,72,,,,,,,,,2024.10.29
Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction,MR-HuBERT,Representation,https://arxiv.org/abs/2310.02720,2023.10.04,v2,2024.01.30,ICLR2024Spotlight,2024.01.16,https://openreview.net/forum?id=kUuKFW7DIF,,,,,,,,https://scholar.google.com/scholar?cluster=7067681971216917737,15,,,,,,,,,2024.09.23
UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions,UniverSLU,,https://arxiv.org/abs/2310.02973,2023.10.04,v2,2024.04.03,ACL@NAACL2024,2024.06.16,https://doi.org/10.18653/v1/2024.naacl-long.151,"Siddhant Arora, Hayato Futami, Jee-weon Jung, Yifan Peng, Roshan Sharma, Yosuke Kashiwagi, Emiru Tsunoo, Karen Livescu, Shinji Watanabe",,,,,21,X,https://scholar.google.com/scholar?cluster=579811530707940055,8,,,,,,,,,2024.10.29
LauraGPT: Listen Attend Understand and Regenerate Audio with GPT,LauraGPT,MLLM,https://arxiv.org/abs/2310.04673,2023.10.07,v4,2024.07.03,ICLR2024Reject,2023.09.22,https://openreview.net/forum?id=jDy2Djjrge,"Zhihao Du, Jiaming Wang, Qian Chen, Yunfei Chu, Zhifu Gao, Zerui Li, Kai Hu, Xiaohuan Zhou, Jin Xu, Ziyang Ma, Wen Wang, Siqi Zheng, Chang Zhou, Zhijie Yan, Shiliang Zhang",,,,https://lauragpt.github.io,20,X,https://scholar.google.com/scholar?cluster=2748385677497297657,49,,,,,,,,,2024.10.29
Toward Joint Language Modeling for Speech Units and Text,"""SUTLM""",,https://arxiv.org/abs/2310.08715,2023.10.12,v1,2023.10.12,EMNLP2023Findings,2023.12.06,https://doi.org/10.18653/v1/2023.findings-emnlp.438,"Ju-Chieh Chou, Chung-Ming Chien, Wei-Ning Hsu, Karen Livescu, Arun Babu, Alexis Conneau, Alexei Baevski, Michael Auli",,,,,12,X,https://scholar.google.com/scholar?cluster=13061955866764932417,13,,,,,,,,,2024.10.29
SALM: Speech-Augmented Language Model with In-Context Learning for Speech Recognition and Translation,SLAM,,https://arxiv.org/abs/2310.09424,2023.10.13,v1,2023.10.13,IEEE@ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10447553,"Zhehuai Chen, He Huang, Andrei Andrusenko, Oleksii Hrinchuk, Krishna C. Puvvada, Jason Li, Subhankar Ghosh, Jagadeesh Balam, Boris Ginsburg",,https://github.com/NVIDIA/NeMo/tree/main/examples/multimodal/speech_llm,,,5,38,https://scholar.google.com/scholar?cluster=3972921702842422475,24,,,,,,,,,2024.10.29
SALMONN: Towards Generic Hearing Abilities for Large Language Models,SALMONN,,https://arxiv.org/abs/2310.13289,2023.10.20,v2,2024.04.08,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=14rn7HpKVk,"Changli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Lu Lu, Zejun Ma, Chao Zhang",,https://github.com/bytedance/SALMONN,,,12,X,https://scholar.google.com/scholar?cluster=10631342040411306525,148,,,,,,,,,2024.10.29
E3 TTS: Easy End-to-End Diffusion-Based Text to Speech,E3 TTS,,https://arxiv.org/abs/2311.00945,2023.11.02,v1,2023.11.02,IEEE@ASRU2023,,,,,,,,,,,,Diffusion,,,TTS,,,,,2024.10.10
COSMIC: Data Efficient Instruction-tuning for Speech In-Context Learning,COSMIC,,https://arxiv.org/abs/2311.02248,2023.11.03,v2,2024.06.14,[Unavailable],[Unavailable],[Unavailable],,,,,,,,https://scholar.google.com/scholar?cluster=1594677896343909949,11,,,,,,,,,2024.09.23
Diff-HierVC: Diffusion-Based Hierarchical Voice Conversion with Robust Pitch Generation and Masked Prior for Zero-Shot Speaker Adaptation,Diff-HierVC,VC,https://arxiv.org/abs/2311.04693,2023.11.08,v1,2023.11.08,InterSpeech2023Oral,2023.08.20,https://doi.org/10.21437/Interspeech.2023-817,,,,,,,,https://scholar.google.com/scholar?cluster=2502050713465555437,14,,,,VC,,,,,2024.09.25
Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models,Qwen-Audio,,https://arxiv.org/abs/2311.07919,2023.11.14,v2,2023.12.21,[Unavailable],[Unavailable],[Unavailable],"Yunfei Chu, Jin Xu, Xiaohuan Zhou, Qian Yang, Shiliang Zhang, Zhijie Yan, Chang Zhou, Jingren Zhou",,https://github.com/QwenLM/Qwen-Audio,,https://qwen-audio.github.io/Qwen-Audio/,,,https://scholar.google.com/scholar?cluster=11563850711266981194,140,,,,,,,,,2024.10.29
DINO-VITS: Data-Efficient Zero-Shot TTS with Self-Supervised Speaker Verification Loss for Noise Robustness,DINO-VITS,,https://arxiv.org/abs/2311.09770,2023.11.16,v3,2024.06.18,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-549,"Vikentii Pankov, Valeria Pronina, Alexander Kuzmin, Maksim Borisov, Nikita Usoltsev, Xingshan Zeng, Alexander Golubkov, Nikolai Ermolenko, Aleksandra Shirshova, Yulia Matveeva",,,,,,,https://scholar.google.com/scholar?cluster=16472542008451595473,1,,,,,,,,,2024.10.08
APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra,APNet2,Vocoder,https://arxiv.org/abs/2311.11545,2023.11.20,v1,2023.11.20,NCMMSC2023,,https://link.springer.com/chapter/10.1007/978-981-97-0601-3_6,,,,,,,,https://scholar.google.com/scholar?cluster=360953352732613526,2,,,,,,,,,2024.09.21
HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis,HierSpeech++,,https://arxiv.org/abs/2311.12454,2023.11.21,v2,2023.11.27,,,,,,https://github.com/sh-lee-prml/HierSpeechpp,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
OpenVoice: Versatile Instant Voice Cloning,OpenVoice,,https://arxiv.org/abs/2312.01479,2023.12.03,v6,2024.08.18,,,,,,,,,,,,,,,,Voice Cloning,,,,,2024.09.24
Amphion: An Open-Source Audio Music and Speech Generation Toolkit,Amphion,Toolkit,https://arxiv.org/abs/2312.09911,2023.12.15,v3,2024.09.16,IEEE@SLT2024,,,,,,,,,,,,,,,,,,,,2024.09.21
SECap: Speech Emotion Captioning with Large Language Model,SECap,,https://arxiv.org/abs/2312.10381,2023.12.16,v3,2023.12.23,AAAI2024,2024.03.24,https://doi.org/10.1609/aaai.v38i17.29902,,,,,,,,https://scholar.google.com/scholar?cluster=886143491614630621,11,,,,,,,,,2024.09.23
MM-TTS: Multi-Modal Prompt Based Style Transfer for Expressive Text-to-Speech Synthesis,MM-TTS,,https://arxiv.org/abs/2312.10687,2023.12.17,v4,2024.01.31,AAAI2024,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis,StyleSinger,SVS,https://arxiv.org/abs/2312.10741,2023.12.17,v3,2024.09.12,AAAI2024,,,"Yu Zhang, Rongjie Huang, Ruiqi Li, JinZheng He, Yan Xia, Feiyang Chen, Xinyu Duan, Baoxing Huai, Zhou Zhao",,,,https://stylesinger.github.io/,,,https://scholar.google.com/scholar?cluster=9942954876960767861,7,,,,SVS,,,,,2024.09.25
emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation,Emotion2Vec,,https://arxiv.org/abs/2312.15185,2023.12.23,v1,2023.12.23,,,,,,https://github.com/ddlBoJack/emotion2vec,,,,,https://scholar.google.com/scholar?cluster=16881884378962249456,31,,,,,,,,,2024.09.23
Audiobox: Unified Audio Generation with Natural Language Prompts,Audiobox,,https://arxiv.org/abs/2312.15821,2023.12.25,v1,2023.12.25,[Unavailable],[Unavailable],[Unavailable],"Apoorv Vyas, Bowen Shi, Matthew Le, Andros Tjandra, Yi-Chiao Wu, Baishan Guo, Jiemin Zhang, Xinyue Zhang, Robert Adkins, William Ngan, Jeff Wang, Ivan Cruz, Bapi Akula, Akinniyi Akinyemi, Brian Ellis, Rashel Moritz, Yael Yungster, Alice Rakotoarison, Liang Tan, Chris Summers, Carleigh Wood, Joshua Lane, Mary Williamson, Wei-Ning Hsu",,,,https://audiobox.metademolab.com/,,,https://scholar.google.com/scholar?cluster=607381426875410665,60,,,,,,,,,2024.10.29
Masked Audio Generation using a Single Non-Autoregressive Transformer,MAGNeT,,https://arxiv.org/abs/2401.04577,2024.01.09,v2,2024.03.05,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=Ny8NiVfi95,"Alon Ziv, Itai Gat, Gael Le Lan, Tal Remez, Felix Kreuk, Alexandre Defossez, Jade Copet, Gabriel Synnaeve, Yossi Adi",,,,https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT,,,https://scholar.google.com/scholar?cluster=5521214275734621763,20,,,,,,,,,2024.10.23
ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering,ELLA-V,CLM,https://arxiv.org/abs/2401.07333,2024.01.14,v1,2024.01.14,[Unavailable],[Unavailable],[Unavailable],"Yakun Song, Zhuo Chen, Xiaofei Wang, Ziyang Ma, Xie Chen",,,,https://ereboas.github.io/ELLAV/,,,https://scholar.google.com/scholar?cluster=14654336806963383107,19,,,,,,,,,2024.10.29
FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder,FreGrad,Vocoder,https://arxiv.org/abs/2401.10032,2024.01.18,v1,2024.01.18,ICASSP2024,2024.03.18,,,,,,,,,,,Diffusion,,,,,,,,2024.09.24
StreamVoice: Streamable Context-Aware Language Modeling for Real-Time Zero-Shot Voice Conversion,StreamVoice,,https://arxiv.org/abs/2401.11053,2024.01.19,v5,2024.07.19,ACL2024,2024.08.00,,,,,,,,,https://scholar.google.com/scholar?cluster=2992004731933175452,2,,,,VC,,,Zero-Shot,,2024.09.24
ScoreDec: A Phase-preserving High-Fidelity Audio Codec with A Generalized Score-Based Diffusion Post-filter,ScoreDec,Codec,https://arxiv.org/abs/2401.12160,2024.01.22,v1,2024.01.22,ICASSP2024,2024.03.18,,,,,,,,,,,Diffusion,,,,,,,,2024.09.24
SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation,SpeechGPT-Gen,,https://arxiv.org/abs/2401.13527,2024.01.24,v2,2024.01.25,,,,,,https://github.com/0nutation/SpeechGPT,,,,,,,,,,,,,,,2024.09.24
VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech,VALL-T,CLM,https://arxiv.org/abs/2401.14321,2024.01.25,v4,2024.01.30,[Unavailable],[Unavailable],[Unavailable],"Chenpeng Du, Yiwei Guo, Hankun Wang, Yifan Yang, Zhikang Niu, Shuai Wang, Hui Zhang, Xie Chen, Kai Yu",,https://github.com/cpdu/vallt,,http://cpdu.github.io/vallt,13,X,https://scholar.google.com/scholar?cluster=2090447978380357091,11,,,,TTS,,,,,2024.10.29
EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks,EVA-GAN,Vocoder,https://arxiv.org/abs/2402.00892,2024.01.31,v1,2024.01.31,,,,,,,,,,,,,,,,,,,,,2024.09.21
Natural Language Guidance of High-Fidelity Text-to-Speech with Synthetic Annotations,Parler-TTS (Reproduce),,https://arxiv.org/abs/2402.01912,2024.02.02,v1,2024.02.02,,,,,Training,[Reproduce] https://github.com/huggingface/parler-tts,https://huggingface.co/parler-tts/,https://text-description-to-speech.com,6,34,https://scholar.google.com/scholar?cluster=1239973316035890942,17,,,,TTS,,,,,2024.09.24
BAT: Learning to Reason about Spatial Sounds with Large Language Models,BAT,,https://arxiv.org/abs/2402.01591,2024.02.02,v2,2024.05.25,ICML2024,,,,,https://zhishengzheng.com/BAT,,,,,,,,,,,,,,,2024.09.25
Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities,Audio Flamingo,,https://arxiv.org/abs/2402.01831,2024.02.02,v3,2024.05.28,ICML2024,,,,,,,,,,,,,,,,,,,,2024.09.25
SpiRit-LM: Interleaved Spoken and Written Language Model,SpiRit-LM,MLLM,https://arxiv.org/abs/2402.05755,2024.02.08,v1,2024.02.08,,,,,,,,,,,https://scholar.google.com/scholar?cluster=7368374930715826231,5,,,,,,,,,2024.09.23
Integrating Paralinguistics in Speech-Empowered Large Language Models for Natural Conversation,USDM,,https://arxiv.org/abs/2402.05706,2024.02.08,v2,2024.08.27,,,,,,,,,,,,,,,,,,,,,2024.09.25
GLA-Grad: A Griffin-Lim Extended Waveform Generation Diffusion Model,GLA-Grad,Vocoder,https://arxiv.org/abs/2402.15516,2024.02.09,v1,2024.02.09,ICASSP2024,2024.03.18,,,,,,,,,,,Diffusion,,,,,,,,2024.09.24
GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators,GenTranslate,,https://arxiv.org/abs/2402.06894,2024.02.10,v2,2024.05.16,ACL2024,2024.08.00,,,,https://github.com/YUCHEN005/GenTranslate,,,,,,,,,,,,,,,2024.09.25
BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data,BASE TTS,,https://arxiv.org/abs/2402.08093,2024.02.12,v2,2024.02.15,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
An Embarrassingly Simple Approach for LLM with Strong ASR Capacity,SLAM-ASR,,https://arxiv.org/abs/2402.08846,2024.02.13,v1,2024.02.13,,,,,,,,,,,,,,,,,,,,,2024.09.25
MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech,MobileSpeech,,https://arxiv.org/abs/2402.09378,2024.02.14,v2,2024.06.02,ACL2024,2024.08.00,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding,APCodec,Codec,https://arxiv.org/abs/2402.10533,2024.02.16,v1,2024.02.16,IEEE/ACM@TASLP2024,,https://doi.org/10.1109/TASLP.2024.3417347,,,,,,,,,,,,,,,,,,2024.10.10
AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling,AnyGPT,,https://arxiv.org/abs/2402.12226,2024.02.19,v3,2024.03.07,,,,,,,,,,,,,,,,,,,,,2024.09.25
Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models,Language-Codec,Codec,https://arxiv.org/abs/2402.12208,2024.02.19,v3,2024.04.27,,,,,,https://github.com/jishengpeng/languagecodec,,,,,,,,,,,,,,,2024.09.21
Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations,Spoken-LLM,,https://arxiv.org/abs/2402.12786,2024.02.20,v2,2024.05.30,ACL2024,2024.08.00,,,,,,,,,https://scholar.google.com/scholar?cluster=13478771408484289779,11,,,,,,,,,2024.09.23
PAVITS: Exploring Prosody-aware VITS for End-to-End Emotional Voice Conversion,PAVITS,VC,https://arxiv.org/abs/2403.01494,2024.03.03,v1,2024.03.03,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10446191,,,,,,,,https://scholar.google.com/scholar?cluster=7490496767784139657,4,,,,VC,,,,,2024.09.24
NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models,NaturalSpeech3,,https://arxiv.org/abs/2403.03100,2024.03.05,v3,2024.04.23,ICML2024Oral,,,,,,,,,,https://scholar.google.com/scholar?cluster=11303548308295061158,50,Diffusion,,,TTS,,,Zero-Shot,,2024.09.24
RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction,RFWave,Vocoder,https://arxiv.org/abs/2403.05010,2024.03.08,v2,2024.06.02,,,,,,,,https://rfwave-demo.github.io/rfwave/,,,https://scholar.google.com/scholar?cluster=14982663450191514510,0,,,,,,,,,2024.09.21
HAM-TTS: Hierarchical Acoustic Modeling for Token-Based Zero-Shot Text-to-Speech with Model and Data Scaling,HAM-TTS,,https://arxiv.org/abs/2403.05989,2024.03.09,v1,2024.03.09,,,,,,,,,,,https://scholar.google.com/scholar?cluster=5759790909255269709,3,,,,TTS,,,Zero-Shot,,2024.09.24
VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild,VoiceCraft,,https://arxiv.org/abs/2403.16973,2024.03.25,v3,2024.06.14,ACL2024,2024.08.00,,,,,,,,,,,,,,TTS/Speech Editing,,,Zero-Shot,,2024.09.24
CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models,CM-TTS,,https://arxiv.org/abs/2404.00569,2024.03.31,v1,2024.03.31,NAACL2024Findings,2024.06.16,https://doi.org/10.18653/v1/2024.findings-naacl.240,"Xiang Li, Fan Bu, Ambuj Mehrish, Yingting Li, Jiale Han, Bo Cheng, Soujanya Poria",,https://github.com/XiangLi2022/CM-TTS,,https://cmtts.vercel.app/,,,https://scholar.google.com/scholar?cluster=14200237516690561178,3,,,,TTS,,,,,2024.10.16
WavLLM: Towards Robust and Adaptive Speech Large Language Model,WavLLM,,https://arxiv.org/abs/2404.00656,2024.03.31,v3,2024.09.21,EMNLP2024Findings,,,,,,,,,,,,,,,,,,,,2024.09.25
CLaM-TTS: Improving Neural Codec Language Modeling for Zero-Shot Text-to-Speech,CLaM-TTS,CLM,https://arxiv.org/abs/2404.02781,2024.04.03,v1,2024.04.03,,,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.21
PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning Based Adaptive Feature-aware Prompt Encoders,PromptCodec,Codec,https://arxiv.org/abs/2404.02702,2024.04.03,v2,2024.04.13,,,,,,,,,,,,,,,,,,,,,2024.09.21
RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis,RALL-E,CLM,https://arxiv.org/abs/2404.03204,2024.04.04,v3,2024.05.19,[Unavailable],[Unavailable],[Unavailable],"Detai Xin, Xu Tan, Kai Shen, Zeqian Ju, Dongchao Yang, Yuancheng Wang, Shinnosuke Takamichi, Hiroshi Saruwatari, Shujie Liu, Jinyu Li, Sheng Zhao",,,,https://ralle-demo.github.io/RALL-E,,,https://scholar.google.com/scholar?cluster=3003546630849225785,14,,,,TTS,,,,,2024.09.24
HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks,HyperTTS,,https://arxiv.org/abs/2404.04645,2024.04.06,v1,2024.04.06,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
LLaMA-VITS: Enhancing TTS Synthesis with Semantic Awareness,LLaMA-VITS,,https://arxiv.org/abs/2404.06714,2024.04.10,v2,2024.04.12,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
OpenELM: An Efficient Language Model Family with Open Training and Inference Framework,OpenELM,TextLM,https://arxiv.org/abs/2404.14619,2024.04.22,v2,2024.05.02,ICML2024Poster,,https://openreview.net/forum?id=XNMbTkxroF,,,https://github.com/apple/corenet,https://huggingface.co/apple/OpenELM,,,,https://scholar.google.com/scholar?cluster=14435877561062275373,20,,,,,,,,,2024.09.23
FlashSpeech: Efficient Zero-Shot Speech Synthesis,FlashSpeech,,https://arxiv.org/abs/2404.14700,2024.04.23,v3,2024.04.25,[Unavailable],[Unavailable],[Unavailable],"Zhen Ye, Zeqian Ju, Haohe Liu, Xu Tan, Jianyi Chen, Yiwen Lu, Peiwen Sun, Jiahao Pan, Weizhen Bian, Shulin He, Qifeng Liu, Yike Guo, Wei Xue",,,,https://flashspeech.github.io/,,,https://scholar.google.com/scholar?cluster=11063704060237437988,5,,,,TTS,,,Zero-Shot,,2024.10.08
USAT: A Universal Speaker-Adaptive Text-to-Speech Approach,USAT,,https://arxiv.org/abs/2404.18094,2024.04.28,v1,2024.04.28,IEEE/ACM@TASLP2024,2024.04.25,https://doi.org/10.1109/TASLP.2024.3393714,,,,,,,,https://scholar.google.com/scholar?cluster=9629403301496489583,4,,,,TTS,,,,,2024.10.10
MM-TTS: A Unified Framework for Multimodal Prompt-Induced Emotional Text-to-Speech Synthesis,MM-TTS,,https://arxiv.org/abs/2404.18398,2024.04.29,v1,2024.04.29,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound,SemantiCodec,Codec,https://arxiv.org/abs/2405.00233,2024.04.30,v1,2024.04.30,,,,,,https://haoheliu.github.io/SemantiCodec/,,,,,,,,,,,,,,,2024.09.21
Parameter-Efficient Fine-Tuning with Discrete Fourier Transform,FourierFT,PEFT,https://arxiv.org/abs/2405.03003,2024.05.05,v1,2024.05.05,ICML2024Poster,2024.05.02,https://openreview.net/forum?id=XUOHKSsurt,,,https://github.com/Chaos96/fourierft,,,,,https://scholar.google.com/scholar?cluster=9524360008038380215,2,,,,,,,,,2024.09.23
HILCodec: High Fidelity and Lightweight Neural Audio Codec,HILCodec,Codec,https://arxiv.org/abs/2405.04752,2024.05.08,v1,2024.05.08,[Unavailable],[Unavailable],[Unavailable],,,,,,,,https://scholar.google.com/scholar?cluster=13917553035782982630,2,,,,,,,,,2024.09.24
MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning,MoRA,PEFT,https://arxiv.org/abs/2405.12130,2024.05.20,v1,2024.05.20,,,,,,,,,,,https://scholar.google.com/scholar?cluster=12904203795044394481,5,,,,,,,,,2024.09.23
VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks,VB-LoRA,PEFT,https://arxiv.org/abs/2405.15179,2024.05.24,v2,2024.05.27,[Unavailable],[Unavailable],[Unavailable],,,,,,,,https://scholar.google.com/scholar?cluster=5223542161229055516,3,,,,,,,,,2024.09.23
Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer,GPST,,https://arxiv.org/abs/2406.00976,2024.06.03,v1,2024.06.03,ACL2024,2024.08.00,,,,,,,,,,,,,,,,,,,2024.10.10
ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control with Decoupled Codec,ControlSpeech,,https://arxiv.org/abs/2406.01205,2024.06.03,v1,2024.06.03,,,,,,https://github.com/jishengpeng/ControlSpeech,,,,,,,,,,,,,Zero-Shot,,2024.09.24
BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation,BiVocoder,Vocoder,https://arxiv.org/abs/2406.02162,2024.06.04,v1,2024.06.04,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-255,,,,,,,,,,,,,,,,,,2024.10.10
Seed-TTS: A Family of High-Quality Versatile Speech Generation Models,Seed-TTS,,https://arxiv.org/abs/2406.02430,2024.06.04,v1,2024.06.04,[Unavailable],[Unavailable],[Unavailable],,,,,https://bytedancespeech.github.io/seedtts_tech_report,,,https://scholar.google.com/scholar?cluster=2383691307056980942,12,,,,,,,,,2024.09.23
SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models,SimpleSpeech,,https://arxiv.org/abs/2406.02328,2024.06.04,v3,2024.06.14,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1392,"Dongchao Yang, Dingdong Wang, Haohan Guo, Xueyuan Chen, Xixin Wu, Helen Meng",,https://github.com/yangdongchao/SimpleSpeech,,https://simplespeech.github.io/simplespeechDemo/,5,36,https://scholar.google.com/scholar?cluster=11920915854301410313,5,Diffusion,SQ-Codec,,TTS,,,,NAR,2024.10.08
LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes,LiveSpeech,,https://arxiv.org/abs/2406.02897,2024.06.05,v2,2024.06.10,[Unavailable],[Unavailable],[Unavailable],,,,,,,,https://scholar.google.com/scholar?cluster=13829823968934264570,1,,,,TTS,,,Zero-Shot,AR,2024.09.24
Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis,Small-E,,https://arxiv.org/abs/2406.04467,2024.06.06,v2,2024.06.11,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-508,,,https://github.com/theodorblackbird/lina-speech,,,,,,,,,,TTS,,,,,2024.09.24
XTTS: A Massively Multilingual Zero-Shot Text-to-Speech Model,XTTS,,https://arxiv.org/abs/2406.04904,2024.06.07,v1,2024.06.07,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-2016,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers,VALL-E 2,CLM,https://arxiv.org/abs/2406.05370,2024.06.08,v2,2024.06.17,,,,,,,,https://aka.ms/valle2,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
WenetSpeech4TTS: A 12800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark,WenetSpeech4TTS,Dataset,https://arxiv.org/abs/2406.05763,2024.06.09,v3,2024.06.19,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-2343,,,,,,,,,,,,,,,,,,2024.09.21
JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis,JenGAN,Trick,https://arxiv.org/abs/2406.06111,2024.06.10,v1,2024.06.10,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1447,,,,,,,,,,,,HiFi-GAN/Avocodo/BigVGAN+JenGAN(Training Strategy),TTS,LJSpeech,HiFi-GAN/Avocodo/BigVGAN,,,2024.09.24
mHuBERT-147: A Compact Multilingual HuBERT Model,mHuBERT-147,Representation,https://arxiv.org/abs/2406.06371,2024.06.10,v4,2024.08.23,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-938,,,,,,,,https://scholar.google.com/scholar?cluster=12861582762998629338,1,,,,,,,,,2024.09.23
Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation,Single-Codec,Codec,https://arxiv.org/abs/2406.07422,2024.06.11,v1,2024.06.11,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1559,,,,,,,,,,,,,,,,,,2024.10.10
ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37 Emotion Datasets,ExHuBERT,Representation,https://arxiv.org/abs/2406.10275,2024.06.11,v1,2024.06.11,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-280,,,,https://huggingface.co/amiriparian/ExHuBERT,,,,[Unavailable],1,,,,,,,,,2024.09.23
EmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech,EmoSphere-TTS,,https://arxiv.org/abs/2406.07803,2024.06.12,v1,2024.06.12,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-398,"Deok-Hyeon Cho, Hyung-Seok Oh, Seung-Bin Kim, Sang-Hoon Lee, Seong-Whan Lee",,,,,,,https://scholar.google.com/scholar?cluster=18117686800584251490,2,,,,,,,,,2024.10.10
VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment,VALL-E R,,https://arxiv.org/abs/2406.07855,2024.06.12,v1,2024.06.12,[Unavailable],[Unavailable],[Unavailable],"Bing Han, Long Zhou, Shujie Liu, Sanyuan Chen, Lingwei Meng, Yanming Qian, Yanqing Liu, Sheng Zhao, Jinyu Li, Furu Wei",,,,https://aka.ms/valler,15,,https://scholar.google.com/scholar?cluster=9587981495960856896,5,,,,TTS,,,Zero-Shot,,2024.10.17
LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts for Text-to-Speech and Style Captioning,LibriTTS-P,Dataset,https://arxiv.org/abs/2406.07969,2024.06.12,v1,2024.06.12,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-692,,,,,,,,,,,,,TTS,,,,,2024.09.24
VECL-TTS: Voice identity and Emotional style controllable Cross-Lingual Text-to-Speech,VECL-TTS,,https://arxiv.org/abs/2406.08076,2024.06.12,v1,2024.06.12,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1672,"Ashishkumar Gudmalwar, Nirmesh Shah, Sai Akarsh, Pankaj Wasnik, Rajiv Ratn Shah",,,,,,,https://scholar.google.com/scholar?cluster=5765896001640726850,0,,,,,,,,,2024.10.10
FreeV: Free Lunch for Vocoders Through Pseudo Inversed Mel Filter,FreeV,Vocoder,https://arxiv.org/abs/2406.08196,2024.06.12,v1,2024.06.12,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1435,,,https://github.com/BakerBunker/FreeV,,,5,,https://scholar.google.com/scholar?cluster=13731432507109093105,1,,,,,,,,,2024.09.21
TokSing: Singing Voice Synthesis Based on Discrete Tokens,TokSing,SVS,https://arxiv.org/abs/2406.08416,2024.06.12,v2,2024.06.20,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-2360,"Yuning Wu, Chunlei zhang, Jiatong Shi, Yuxun Tang, Shan Yang, Qin Jin",,,,,,,https://scholar.google.com/scholar?cluster=18331445064621172808,3,,,,,,,,,2024.10.17
Speech ReaLLM: Real-Time Streaming Speech Recognition with Multimodal LLMs by Teaching the Flow of Time,Speech ReaLLM,,https://arxiv.org/abs/2406.09569,2024.06.13,v1,2024.06.13,[Unavailable],[Unavailable],[Unavailable],"Frank Seide, Morrie Doulaty, Yangyang Shi, Yashesh Gaur, Junteng Jia, Chunyang Wu",,,,,,,[Unavailable],4,,,,,,,,,2024.10.17
UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner,UniAudio 1.5,,https://arxiv.org/abs/2406.10056,2024.06.14,v1,2024.06.14,[Unavailable],[Unavailable],[Unavailable],"Dongchao Yang, Haohan Guo, Yuanyuan Wang, Rongjie Huang, Xiang Li, Xu Tan, Xixin Wu, Helen Meng",,,,,,,[Unavailable],4,,,,,,,Few-Shot,,2024.10.17
Period Singer: Integrating Periodic and Aperiodic Variational Autoencoders for Natural-Sounding End-to-End Singing Voice Synthesis,Period Singer,SVS,https://arxiv.org/abs/2406.09894,2024.06.14,v2,2024.09.11,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1720,,,,,,,,[Unavailable],0,,,,,,,,,2024.09.23
How Should We Extract Discrete Audio Tokens from Self-Supervised Models?,[Unavailable],,https://arxiv.org/abs/2406.10735,2024.06.15,v1,2024.06.15,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-2135,,,,,,,,[Unavailable],3,,,,,,,,,2024.09.23
NAST: Noise Aware Speech Tokenization for Speech Language Models,NAST,,https://arxiv.org/abs/2406.11037,2024.06.16,v1,2024.06.16,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-288,"Shoval Messica, Yossi Adi",,https://github.com/ShovalMessica/NAST,,,,,[Unavailable],2,,,,,,,,,2024.10.10
DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer,DiTTo-TTS,,https://arxiv.org/abs/2406.11427,2024.06.17,v1,2024.06.17,[Unavailable],[Unavailable],[Unavailable],"Keon Lee, Dong Won Kim, Jaehyeon Kim, Jaewoong Cho",,,,https://ditto-tts.github.io/,21,80,[Unavailable],5,Diffusion,,,TTS,,,Zero-Shot,,2024.10.08
Articulatory Encodec: Coding Speech through Vocal Tract Kinematics,Articulatory Encodec,Codec,https://arxiv.org/abs/2406.12998,2024.06.18,v2,2024.08.21,,,,,,,,,,,,,,,,,,,,,2024.09.21
TacoLM: GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers,TacoLM,CLM,https://arxiv.org/abs/2406.15752,2024.06.22,v1,2024.06.22,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1531,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
Improving Robustness of LLM-Based Speech Synthesis by Learning Monotonic Alignment,T5-TTS,,https://arxiv.org/abs/2406.17957,2024.06.25,v1,2024.06.25,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-335,,,,,,,,https://scholar.google.com/scholar?cluster=5261611192106137747,2,,,,TTS,,,,,2024.09.24
E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS,E2 TTS,,https://arxiv.org/abs/2406.18009,2024.06.26,v2,2024.09.12,SLT2024,,,,,,,https://aka.ms/e2tts/,,,,,,,,TTS,,,Zero-Shot,NAR,2024.09.24
DEX-TTS: Diffusion-Based EXpressive Text-to-Speech with Style Modeling on Time Variability,DEX-TTS,,https://arxiv.org/abs/2406.19135,2024.06.27,v1,2024.06.27,[Unavailable],[Unavailable],[Unavailable],"Hyun Joon Park, Jin Sob Kim, Wooseok Shin, Sung Won Han",,https://github.com/winddori2002/dex-tts,,https://dextts.github.io/demo.github.io/,20,49,https://scholar.google.com/scholar?cluster=3195017631993643554,1,Diffusion,DEX-TTS/GeDEX-TTS,,TTS,VCTK/ESD,MetaStyleSpeech+HiFi-GAN/YourTTS/GenerSpeech+HiFi-GAN/StyleTTS+HiFi-GAN,,,2024.10.08
BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5,BESTOW,,https://arxiv.org/abs/2406.19954,2024.06.28,v1,2024.06.28,,,,,,,,,,,,,,,,,,,,,2024.09.21
FLY-TTS: Fast Lightweight and High-Quality End-to-End Text-to-Speech Synthesis,FLY-TTS,,https://arxiv.org/abs/2407.00753,2024.06.30,v1,2024.06.30,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-1435,,,,,,,,,,,,,TTS,,,,,2024.09.24
Lightweight Zero-shot Text-to-Speech with Mixture of Adapters,[Unavailable],,https://arxiv.org/abs/2407.01291,2024.07.01,v1,2024.07.01,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-803,"Kenichi Fujita, Takanori Ashihara, Marc Delcroix, Yusuke Ijima",,,,https://ntt-hilab-gensp.github.io/is2024lightweightTTS/,,,https://scholar.google.com/scholar?cluster=13615806770900699221,1,,,,,,,,,2024.10.08
Lightweight Zero-shot Text-to-Speech with Mixture of Adapters,[Unavailable],,https://arxiv.org/abs/2407.01291,2024.07.01,v1,2024.07.01,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-803,"Kenichi Fujita, Takanori Ashihara, Marc Delcroix, Yusuke Ijima",,,,https://ntt-hilab-gensp.github.io/is2024lightweightTTS/,,,https://scholar.google.com/scholar?cluster=13615806770900699221,1,,,,,,,,,2024.10.10
Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference Optimization,RIO,,https://arxiv.org/abs/2407.02243,2024.07.02,v1,2024.07.02,,,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction between Humans and LLMs,FunAudioLLM,,https://arxiv.org/abs/2407.04051,2024.07.04,v3,2024.07.11,,,,,,,,,,,https://scholar.google.com/scholar?cluster=11999048316846931351,2,,,,,,,,,2024.09.23
FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-Based Vocoder,FA-GAN,Vocoder,https://arxiv.org/abs/2407.04575,2024.07.05,v1,2024.07.05,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-380,,,,,,,,,,,,,,,,,,2024.09.21
LoRA-GA: Low-Rank Adaptation with Gradient Approximation,LoRA-GA,PEFT,https://arxiv.org/abs/2407.05000,2024.07.06,v2,2024.07.16,,,,,,https://github.com/Outsider565/LoRA-GA,,,,,https://scholar.google.com/scholar?cluster=6092529847550522223,0,,,,,,,,,2024.09.23
CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer Based on Supervised Semantic Tokens,CosyVoice,,https://arxiv.org/abs/2407.05407,2024.07.07,v2,2024.07.09,,,,,,,,,,,https://scholar.google.com/scholar?cluster=16233573129404678819,8,,,,TTS,,,Zero-Shot,,2024.09.24
AffectGPT: Dataset and Framework for Explainable Multimodal Emotion Recognition,AffectGPT,,https://arxiv.org/abs/2407.07653,2024.07.10,v1,2024.07.10,[Unavailable],[Unavailable],[Unavailable],,,https://github.com/zeroQiaoba/AffectGPT,,,,,https://scholar.google.com/scholar?cluster=6374429304315607405,4,,,,,,,,,2024.09.23
Autoregressive Speech Synthesis without Vector Quantization,MELLE,,https://arxiv.org/abs/2407.08551,2024.07.11,v1,2024.07.11,,,,,,,,https://aka.ms/melle,,,,,,,,TTS,,,,AR,2024.09.24
Qwen2-Audio Technical Report,Qwen2-Audio,,https://arxiv.org/abs/2407.10759,2024.07.15,v1,2024.07.15,,,,,,https://github.com/QwenLM/Qwen2-Audio,,,,,https://scholar.google.com/scholar?cluster=13259138701210870695,12,,,,,,,,,2024.09.23
TTSDS: Text-to-Speech Distribution Score,TTSDS,Benchmark,https://arxiv.org/abs/2407.12707,2024.07.17,v2,2024.07.22,SLT2024,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
MSceneSpeech: A Multi-Scene Speech Dataset for Expressive Speech Synthesis,MSceneSpeech,Dataset,https://arxiv.org/abs/2407.14006,2024.07.19,v1,2024.07.19,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-266,,,,,,,,,,,,,TTS,,,,,2024.09.24
LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models,LLaST,,https://arxiv.org/abs/2407.15415,2024.07.22,v1,2024.07.22,ACL@Fingdings2024,,https://aclanthology.org/2024.findings-acl.416,,,https://github.com/openaudiolab/LLaST,,,,,https://scholar.google.com/scholar?cluster=15668197912305572523,2,,,,,,,,,2024.09.23
LoRA-Pro: Are Low-Rank Adapters Properly Optimized?,LoRA-Pro,PEFT,https://arxiv.org/abs/2407.18242,2024.07.25,v1,2024.07.25,,,,,,,,,,,https://scholar.google.com/scholar?cluster=5563318481080163149,0,,,,,,,,,2024.09.23
SuperCodec: A Neural Speech Codec with Selective Back-Projection Network,SuperCodec,Codec,https://arxiv.org/abs/2407.20530,2024.07.30,v1,2024.07.30,ICASSP2024,2024.03.18,,,,,,,,,,,,,,,,,,,2024.09.21
The Llama 3 Herd of Models,LLaMA3,TextLM,https://arxiv.org/abs/2407.21783,2024.07.31,v2,2024.08.15,,,,,,,,,,,https://scholar.google.com/scholar?cluster=4075166335978822586,164,,,,,,,,,2024.09.23
Make-A-Voice: Revisiting Voice Large Language Models as Scalable Multilingual and Multitask Learner,Make-A-Voice,,[Unavailable],2024.08.00,[Unavailable],[Unavailable],ACL2024,2024.08.00,https://doi.org/10.18653/v1/2024.acl-long.589,,,,,https://M-Voice.github.io,,,[Unavailable],1,,,,,,,,,2024.09.25
StreamVoice+: Evolving into End-to-end Streaming Zero-shot Voice Conversion,StreamVoice+,,https://arxiv.org/abs/2408.02178,2024.08.05,v1,2024.08.05,,,,,,,,,,,https://scholar.google.com/scholar?cluster=358099860326856545,0,,,,VC,,,Zero-Shot,,2024.09.24
Language Model Can Listen While Speaking,LSLM,MLLM,https://arxiv.org/abs/2408.02622,2024.08.05,v1,2024.08.05,,,,,,,,https://ddlbojack.github.io/LSLM,,,,,,,,,,,FullDuplex,,2024.09.21
VITA: Towards Open-Source Interactive Omni Multimodal LLM,VITA,MLLM,https://arxiv.org/abs/2408.05211,2024.08.09,v2,2024.09.10,,,,,Training+Inference+Weight,https://github.com/VITA-MLLM/VITA,https://huggingface.co/VITA-MLLM,https://vita-home.github.io/,,,https://scholar.google.com/scholar?cluster=12137474138057550166,,,,,,,,,,2024.09.24
PRESENT: Zero-Shot Text-to-Prosody Control,PRESENT,,https://arxiv.org/abs/2408.06827,2024.08.13,v1,2024.08.13,,,,,,,,,,,https://scholar.google.com/scholar?cluster=980654330328177271,0,,,,,,,Zero-Shot,,2024.09.24
VNet: A GAN-Based Multi-Tier Discriminator Network for Speech Synthesis Vocoders,VNet,Vocoder,https://arxiv.org/abs/2408.06906,2024.08.13,v1,2024.08.13,SMC2024,,,,,,,,,,,,,,G:FCN+MRF D:MTD+MPD,TTS,LibriTTS/LJSpeech,WaveGlow/Parallel WaveGAN/HiFi-GAN/BigVGAN,,,2024.09.24
Neural Speech and Audio Coding,[Unavailable],,https://arxiv.org/abs/2408.06954,2024.08.13,v1,2024.08.13,IEEE@SPM,,,,,,,,,,https://scholar.google.com/scholar?cluster=5959560004447120901,1,,,,,,,,,2024.09.23
PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation,PeriodWave,Vocoder,https://arxiv.org/abs/2408.07547,2024.08.14,v1,2024.08.14,[Unavailable],[Unavailable],[Unavailable],,ReadMe,https://github.com/sh-lee-prml/PeriodWave,[Unavailable],https://periodwave.github.io/demo/,24,X,https://scholar.google.com/scholar?cluster=14553664054487650270,1,FlowMatching,,Period-Aware Flow Matching Estimator,,LJSpeech/LibriTTS,HiFI-GAN/BigVGAN/PriorGrad/FreGrad,,,2024.09.24
Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization,PeriodWave-Turbo,Vocoder,https://arxiv.org/abs/2408.08019,2024.08.15,v1,2024.08.15,[Unavailable],[Unavailable],[Unavailable],,ReadMe,https://github.com/sh-lee-prml/PeriodWave,[Unavailable],https://periodwave-turbo.github.io/audio-demo/,9,X,https://scholar.google.com/scholar?cluster=4002945941867933119,0,FlowMatching,,PeriodWave+Few-Step Generator,,LJSpeech/LibriTTS,HiFI-GAN/BigVSAN/BigVGAN/PriorGrad/PeriodWave/UnivNet/Vocos,,,2024.09.24
SSL-TTS: Leveraging Self-Supervised Embeddings and kNN Retrieval for Zero-Shot Multi-speaker TTS,SSL-TTS,,https://arxiv.org/abs/2408.10771,2024.08.20,v1,2024.08.20,Submitted to SPL,,,,,,,,,,,,,,,TTS,,,Zero-Shot/Multi-Speaker,,2024.09.24
EELE: Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech,EELE,,https://arxiv.org/abs/2408.10852,2024.08.20,v1,2024.08.20,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
VoiceX: A Text-to-Speech Framework for Custom Voices,VoiceX,,https://arxiv.org/abs/2408.12170,2024.08.22,v1,2024.08.22,,,,,,,,,,,,,,,,TTS,,,,,2024.09.24
SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description,SpeechCraft,Dataset,https://arxiv.org/abs/2408.13608,2024.08.24,v1,2024.08.24,ACM MultiMedia2024,,,,,,,,,,,,,,,,,,,,2024.09.21
SimpleSpeech 2: Towards Simple and Efficient Text-to-Speech with Flow-Based Scalar Latent Transformer Diffusion Models,SimpleSpeech2,,https://arxiv.org/abs/2408.13893,2024.08.25,v2,2024.08.28,Submitted to TASLP,[Unavailable],[Unavailable],"Dongchao Yang, Rongjie Huang, Yuanyuan Wang, Haohan Guo, Dading Chong, Songxiang Liu, Xixin Wu, Helen Meng",,https://github.com/yangdongchao/SimpleSpeech,,https://dongchaoyang.top/SimpleSpeech2_demo/,13,74,https://scholar.google.com/scholar?cluster=12788614326807710009,1,Flow/Diffusion,,,TTS,,,,,2024.10.08
DualSpeech: Enhancing Speaker-Fidelity and Text-Intelligibility Through Dual Classifier-Free Guidance,DualSpeech,,https://arxiv.org/abs/2408.14423,2024.08.26,v2,2024.08.27,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-2005,"Jinhyeok Yang, Junhyeok Lee, Hyeong-Seok Choi, Seunghun Ji, Hyeongju Kim, Juheon Lee",,,,https://bit.ly/48Ewoib,5,33,https://scholar.google.com/scholar?cluster=5124111258456637871,1,Diffusion,,,,,,,,2024.10.08
VoiceTailor: Lightweight Plug-In Adapter for Diffusion-Based Personalized Text-to-Speech,VoiceTailor,,https://arxiv.org/abs/2408.14739,2024.08.27,v2,2024.08.28,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-63,"Heeseung Kim, Sang-gil Lee, Jiheum Yeom, Che Hyun Lee, Sungwon Kim, Sungroh Yoon",,,,https://voicetailor.github.io,,,https://scholar.google.com/scholar?cluster=14328776272648630540,2,Diffusion/LoRA,,,TTS,,,,,2024.10.08
VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling,VoxInstruct,CLM,https://arxiv.org/abs/2408.15676,2024.08.28,v1,2024.08.28,ACM MultiMedia2024 Oral,2024.07.21,https://openreview.net/forum?id=hQp6qimhbb,"Yixuan Zhou, Xiaoyu Qin, Zeyu Jin, Shuoyi Zhou, Shun Lei, Songtao Zhou, Zhiyong Wu, Jia Jia",ReadMe,https://github.com/thuhcsi/VoxInstruct,,https://voxinstruct.github.io/VoxInstruct/,,,https://scholar.google.com/scholar?cluster=217309373630171067,1,,,,,,,,,2024.10.17
WavTokenizer: An Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling,WavTokenizer,Codec,https://arxiv.org/abs/2408.16532,2024.08.29,v1,2024.08.29,[Unavailable],[Unavailable],[Unavailable],"Shengpeng Ji, Ziyue Jiang, Xize Cheng, Yifu Chen, Minghui Fang, Jialong Zuo, Qian Yang, Ruiqi Li, Ziang Zhang, Xiaoda Yang, Rongjie Huang, Yidi Jiang, Qian Chen, Siqi Zheng, Wen Wang, Zhou Zhao",,https://github.com/jishengpeng/WavTokenizer,https://huggingface.co/collections/novateur/wavtokenizer-medium-large-66de94b6fd7d68a2933e4fc0,https://wavtokenizer.github.io/,,,https://scholar.google.com/scholar?cluster=11096367345508634509,1,,,,,,,,,2024.10.17
Mini-Omni: Language Models Can Hear Talk While Thinking in Streaming,Mini-Omni,MLLM,https://arxiv.org/abs/2408.16725,2024.08.29,v2,2024.08.30,[Unavailable],[Unavailable],[Unavailable],"Zhifei Xie, Changqiao Wu",,https://github.com/gpt-omni/mini-omni,https://huggingface.co/gpt-omni/mini-omni,,,,https://scholar.google.com/scholar?cluster=6184539327856435224,2,,,,,,,,,2024.10.17
SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection,SelectTTS,,https://arxiv.org/abs/2408.17432,2024.08.30,v1,2024.08.30,Submitted to SPL,[Unavailable],[Unavailable],"Ismail Rasim Ulgen, Shreeram Suresh Chandra, Junchen Lu, Berrak Sisman",,,,,,,[Unavailable],0,,,,,,,,,2024.10.17
Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model,X-Codec,Codec,https://arxiv.org/abs/2408.17175,2024.08.30,v2,2024.09.19,[Unavailable],[Unavailable],[Unavailable],"Zhen Ye, Peiwen Sun, Jiahe Lei, Hongzhan Lin, Xu Tan, Zheqi Dai, Qiuqiang Kong, Jianyi Chen, Jiahao Pan, Qifeng Liu, Yike Guo, Wei Xue",,https://github.com/zhenye234/xcodec,,https://x-codec-audio.github.io/,,,https://scholar.google.com/scholar?cluster=3541529656247497964,1,,,,,,,,,2024.10.17
Sample-Efficient Diffusion for Text-to-Speech Synthesis,SESD,,https://arxiv.org/abs/2409.03717,2024.09.01,v1,2024.09.01,InterSpeech2024,2024.09.01,https://doi.org/10.21437/Interspeech.2024-2235,"Justin Lovelace, Soham Ray, Kwangyoun Kim, Kilian Q. Weinberger, Felix Wu",ReadMe,https://github.com/justinlovelace/SESD,,,,,https://scholar.google.com/scholar?cluster=17758461884837101947,1,Diffusion,,,TTS,,,,,2024.10.08
MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer,MaskGCT,,https://arxiv.org/abs/2409.00750,2024.09.01,v3,2024.10.20,[Unavailable],[Unavailable],[Unavailable],"Yuancheng Wang, Haoyue Zhan, Liwei Liu, Ruihong Zeng, Haotian Guo, Jiachen Zheng, Qiang Zhang, Xueyao Zhang, Shunsi Zhang, Zhizheng Wu",Inference+Weight,https://github.com/open-mmlab/Amphion/tree/main/models/tts/maskgct,https://huggingface.co/amphion/MaskGCT/tree/main,https://maskgct.github.io/,21,75,https://scholar.google.com/scholar?cluster=13665958858650548532,2,,MaskGCT,Semantic Codec ¡ú Text-to-Semantic ¡ú Semantic-to-Acoustic,TTS,Emilia (Train)/LibriSpeech+SeedTTS test-en/zh (Test),VALL-E/VoiceBox/NaturalSpeech3/VoiceCraft/XTTS-v2/CosyVoice; AR+SoundStorm,Zero-Shot,NAR,2024.10.26
SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis,SoCodec,Codec,https://arxiv.org/abs/2409.00933,2024.09.02,v1,2024.09.02,SLT2024,,,"Haohan Guo, Fenglong Xie, Kun Xie, Dongchao Yang, Dake Guo, Xixin Wu, Helen Meng",,,,,,,https://scholar.google.com/scholar?cluster=15997967599415392422,2,,,,TTS,,,,,2024.10.16
vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders,Vec2Wav2.0,VC,https://arxiv.org/abs/2409.01995,2024.09.03,v2,2024.09.11,Submitted to ICASSP2025,,,"Yiwei Guo, Zhihan Li, Junjie Li, Chenpeng Du, Hankun Wang, Shuai Wang, Xie Chen, Kai Yu",,,,https://cantabile-kwok.github.io/vec2wav2/,5,40,https://scholar.google.com/scholar?cluster=7879906795829704534,0,,,Follow CTX-Vec2Wav/WavLM+VQ-Wav2Vec+Conformer+G:BigVGAN+D:MSD+MPD,VC,LibriTTS,YourTTS/DiffVC/Diff-HierVC/UUVC/FACodec,,,2024.10.16
FireRedTTS: A Foundation Text-To-Speech Framework for Industry-Level Generative Speech Applications,FireRedTTS,,https://arxiv.org/abs/2409.03283,2024.09.05,v1,2024.09.05,[Unavailable],[Unavailable],[Unavailable],"Hao-Han Guo, Kun Liu, Fei-Yu Shen, Yi-Chen Wu, Feng-Long Xie, Kun Xie, Kai-Tuo Xu",Inference+Weight,https://github.com/FireRedTeam/FireRedTTS,https://huggingface.co/fireredteam/FireRedTTS/tree/main,https://fireredteam.github.io/demos/firered_tts,14,36,https://scholar.google.com/scholar?cluster=3169139091846859232,1,,,,,,,,,2024.10.15
LAST: Language Model Aware Speech Tokenization,LAST,,https://arxiv.org/abs/2409.03701,2024.09.05,v2,2024.09.10,,,,"Arnon Turetzky, Yossi Adi",,,,,,,https://scholar.google.com/scholar?cluster=17232524767389669426,1,,,,,,,,,2024.10.16
Investigating Neural Audio Codecs for Speech Language Model-Based Speech Generation,[Unavailable],,https://arxiv.org/abs/2409.04016,2024.09.06,v1,2024.09.06,SLT2024,[Unavailable],[Unavailable],"Jiaqi Li, Dongmei Wang, Xiaofei Wang, Yao Qian, Long Zhou, Shujie Liu, Midia Yousefi, Canrun Li, Chung-Hsien Tsai, Zhen Xiao, Yanqing Liu, Junkun Chen, Sheng Zhao, Jinyu Li, Zhizheng Wu, Michael Zeng",,,,,,,https://scholar.google.com/scholar?cluster=342682668474965838,1,,,,,,,,,2024.10.16
BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec,BigCodec,Codec,https://arxiv.org/abs/2409.05377,2024.09.09,v1,2024.09.09,,,,"Detai Xin, Xu Tan, Shinnosuke Takamichi, Hiroshi Saruwatari",Inference+Weight,https://github.com/Aria-K-Alethia/BigCodec,,https://aria-k-alethia.github.io/bigcodec-demo/,,,https://scholar.google.com/scholar?cluster=16310420500273844961,0,,,,,,,,,2024.10.16
LLaMA-Omni: Seamless Speech Interaction with Large Language Models,LLaMA-Omni,MLLM,https://arxiv.org/abs/2409.06666,2024.09.10,v1,2024.09.10,,,,"Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, Yang Feng",Inference+Weight,https://github.com/ictnlp/LLaMA-Omni,,,,,https://scholar.google.com/scholar?cluster=15649883335079795778,3,,,,,,,,,2024.10.26
MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders,MoWE-Audio,,https://arxiv.org/abs/2409.06635,2024.09.10,v2,2024.09.23,,,,"Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw",,,,,,,https://scholar.google.com/scholar?cluster=6869338195430223231,0,,,,,,,,,2024.10.16
SSR-Speech: Towards Stable Safe and Robust Zero-Shot Text-Based Speech Editing and Synthesis,SSR-Speech,,https://arxiv.org/abs/2409.07556,2024.09.11,v1,2024.09.11,Submitted to ICASSP2025,,,"Helin Wang, Meng Yu, Jiarui Hai, Chen Chen, Yuchen Hu, Rilin Chen, Najim Dehak, Dong Yu",Training+Inference+Weight,https://github.com/WangHelin1997/SSR-Speech,,https://WangHelin1997.github.io/SSR-Speech-Demo,5,35,https://scholar.google.com/scholar?cluster=1434168859161685412,0,,,,TTS/Speech Editing,,,Zero-Shot,,2024.10.16
Super Monotonic Alignment Search,Super-MAS,Alignment,https://arxiv.org/abs/2409.07704,2024.09.12,v1,2024.09.12,,,,"Junhyeok Lee, Hyeongju Kim",,https://github.com/supertone-inc/super-monotonic-align,,,,,https://scholar.google.com/scholar?cluster=911413713631039962,0,,,,,,,,,2024.10.16
NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training,NEST-RQ,Representation,https://arxiv.org/abs/2409.08680,2024.09.13,v1,2024.09.13,,,,"Minglun Han, Ye Bai, Chen Shen, Youjia Huang, Mingkun Huang, Zehua Lin, Linhao Dong, Lu Lu, Yuxuan Wang",,,,,,,https://scholar.google.com/scholar?cluster=6532872647302039708,0,,,,,,,,,2024.10.16
E1 TTS: Simple and Fast Non-Autoregressive TTS,E1 TTS,Joint,https://arxiv.org/abs/2409.09351,2024.09.14,v1,2024.09.14,[Unavailable],[Unavailable],[Unavailable],"Zhijun Liu, Shuai Wang, Pengcheng Zhu, Mengxiao Bi, Haizhou Li",Evaluation,https://github.com/e1tts/e1tts.github.io/,,https://e1tts.github.io,5,47,https://scholar.google.com/scholar?cluster=14501484319113297136,0,Diffusion,,DiT+DiT+BigVGAN,TTS,LibriTTS,Style-TTS 2/CosyVoice/ARDiT-TTS,Zero-Shot,NAR,2024.10.08
StyleTTS-ZS: Efficient High-Quality Zero-Shot Text-to-Speech Synthesis with Distilled Time-Varying Style Diffusion,StyleTTS-ZS,,https://arxiv.org/abs/2409.10058,2024.09.16,v1,2024.09.16,[Unavailable],[Unavailable],[Unavailable],"Yinghao Aaron Li, Xilin Jiang, Cong Han, Nima Mesgarani",ReadMe,https://github.com/yl4579/StyleTTS-ZS,,https://styletts-zs.github.io,,,https://scholar.google.com/scholar?cluster=717063947191306167,0,,,,TTS,,,Zero-Shot,,2024.10.08
Moshi: A Speech-Text Foundation Model for Real-Time Dialogue,Moshi,MLLM,https://arxiv.org/abs/2410.00037,2024.09.17,v2,2024.10.02,[Unavailable],[Unavailable],[Unavailable],"Alexandre Defossez, Laurent Mazare, Manu Orsini, Amelie Royer, Patrick Perez, Herve Jegou, Edouard Grave, Neil Zeghidour",,https://github.com/kyutai-labs/moshi,,,,,https://scholar.google.com/scholar?cluster=11241279630065269380,5,,,,,,,,,2024.10.27
Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation,CoFi-Speech,CLM,https://arxiv.org/abs/2409.11630,2024.09.18,v1,2024.09.18,[Unavailable],[Unavailable],[Unavailable],"Haohan Guo, Fenglong Xie, Dongchao Yang, Xixin Wu, Helen Meng",,,,https://hhguo.github.io/DemoCoFiSpeech,5,30,https://scholar.google.com/scholar?cluster=15908579864773128951,0,,,CoFi-Codec (SoCodec [OPQ])+CoFi-LM-Cos/SoS+BigVGAN,TTS,WenetSpeech4TTS,VALL-E/CosyVoice/SoCodec-TTS,Mel2Code/BPE/Multi-Scale,,2024.10.27
DPI-TTS: Directional Patch Interaction for Fast-Converging and Style Temporal Modeling in Text-to-Speech,DPI-TTS,,https://arxiv.org/abs/2409.11835,2024.09.18,v1,2024.09.18,[Unavailable],[Unavailable],Submitted to ICASSP2025,"Xin Qi, Ruibo Fu, Zhengqi Wen, Tao Wang, Chunyu Qiang, Jianhua Tao, Chenxing Li, Yi Lu, Shuchen Shi, Zhiyong Wang, Xiaopeng Wang, Yuankun Xie, Yukun Liu, Xuefei Liu, Guanjun Li",Readme,https://github.com/7Xin/DPI-TTS,,https://7xin.github.io/DPI-TTS/,5,31,https://scholar.google.com/scholar?cluster=121088358708318838,0,,,,,,,,,2024.10.10
Low Frame-rate Speech Codec: A Codec Designed for Fast High-quality Speech LLM Training and Inference,LFSC,Codec,https://arxiv.org/abs/2409.12117,2024.09.18,v1,2024.09.18,Submitted to ICASSP2025,,,"Edresson Casanova, Ryan Langman, Paarth Neekhara, Shehzeen Hussain, Jason Li, Subhankar Ghosh, Ante Jukic, Sang-gil Lee",,https://github.com/NVIDIA/NeMo,,https://edresson.github.io/Low-Frame-rate-Speech-Codec/,5,40,https://scholar.google.com/scholar?cluster=9909049349428171875,0,,,,,,,,,2024.09.21
WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification,WMCodec,Codec,https://arxiv.org/abs/2409.12121,2024.09.18,v2,2024.09.22,[Unavailable],[Unavailable],[Unavailable],"Junzuo Zhou, Jiangyan Yi, Yong Ren, Jianhua Tao, Tao Wang, Chu Yuan Zhang",,,,,,,https://scholar.google.com/scholar?cluster=11399932079667190471,0,,,,,,,,,2024.10.16
Takin: A Cohort of Superior Quality Zero-shot Speech Generation Models,Takin AudioLLM,,https://arxiv.org/abs/2409.12139,2024.09.18,v3,2024.09.24,,,,"Sijing Chen, Yuan Feng, Laipeng He, Tianwei He, Wendi He, Yanni Hu, Bin Lin, Yiting Lin, Yu Pan, Pengfei Tan, Chengwei Tian, Chen Wang, Zhicheng Wang, Ruoye Xie, Jixun Yao, Quanlei Yan, Yuguang Yang, Jianhao Ye, Jingjing Yin, Yanzhen Yu, Huimin Zhang, Xiang Zhang, Guangcheng Zhao, Hongbin Zhou, Pengpeng Zou",,,,https://everest-ai.github.io/takinaudiollm/,,,https://scholar.google.com/scholar?cluster=13516868343829741127,0,,,,,,,,,2024.10.16
NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization,NDVQ,Codec,https://arxiv.org/abs/2409.12717,2024.09.19,v1,2024.09.19,,,,"Zhikang Niu, Sanyuan Chen, Long Zhou, Ziyang Ma, Xie Chen, Shujie Liu",,,,,,,[Unavailable],1,,,,,,,,,2024.10.16
GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks,GTSinger,Dataset,https://arxiv.org/abs/2409.13832,2024.09.20,v2,2024.09.26,NeurIPS2024Spotlight,,,"Yu Zhang, Changhao Pan, Wenxiang Guo, Ruiqi Li, Zhiyuan Zhu, Jialei Wang, Wenhao Xu, Jingyu Lu, Zhiqing Hong, Chuxin Wang, LiChao Zhang, Jinzheng He, Ziyue Jiang, Yuxin Chen, Chen Yang, Jiecheng Zhou, Xinyu Cheng, Zhou Zhao",,https://github.com/GTSinger/GTSinger,https://huggingface.co/datasets/GTSinger/GTSinger,http://gtsinger.github.io/,23,29,[Unavailable],1,,,,,,,,,2024.10.15
MuCodec: Ultra Low-Bitrate Music Codec,MuCodec,Codec,https://arxiv.org/abs/2409.13216,2024.09.20,v2,2024.09.29,,,,"Yaoxun Xu, Hangting Chen, Jianwei Yu, Wei Tan, Rongzhi Gu, Shun Lei, Zhiwei Lin, Zhiyong Wu",Readme,https://github.com/xuyaoxun/MuCodec,,https://xuyaoxun.github.io/MuCodec_demo/,6,39,https://scholar.google.com/scholar?cluster=10772122697703831286,0,,,,,,,,,2024.10.16
StyleFusion TTS: Multimodal Style-control and Enhanced Feature Fusion for Zero-shot Text-to-speech Synthesis,StyleFusion TTS,,https://arxiv.org/abs/2409.15741,2024.09.24,v1,2024.09.24,PRCV2024,,,"Zhiyong Chen, Xinnuo Li, Zhiqi Ai, Shugong Xu",,,,,,,[Unavailable],0,,,,,,,,,2024.09.25
VoiceGuider: Enhancing Out-of-Domain Performance in Parameter-Efficient Speaker-Adaptive Text-to-Speech via Autoguidance,VoiceGuider,,https://arxiv.org/abs/2409.15759,2024.09.24,v1,2024.09.24,Submitted to ICASSP2025,,,"Jiheum Yeom, Heeseung Kim, Jooyoung Choi, Che Hyun Lee, Nohil Park, Sungroh Yoon",,,,https://voiceguider.github.io/,,,[Unavailable],0,,,,,,,,,2024.09.25
NanoVoice: Efficient Speaker-Adaptive Text-to-Speech for Multiple Speakers,NanoVoice,,https://arxiv.org/abs/2409.15760,2024.09.24,v1,2024.09.24,Submitted to ICASSP2025,,,"Nohil Park, Heeseung Kim, Che Hyun Lee, Jooyoung Choi, Jiheum Yeom, Sungroh Yoon",,,,https://nanovoice.github.io/,5,37,[Unavailable],0,,,VoiceTailor,,LibriTTS/LibriSpeech,VoiceTailor/UnitSpeech/XTTSv2/CosyVoice,Multi-Speaker,,2024.10.16
StyleSinger 2: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control,StyleSinger2,SVS,https://arxiv.org/abs/2409.15977,2024.09.24,v1,2024.09.24,EMNLP2024,,,"Yu Zhang, Ziyue Jiang, Ruiqi Li, Changhao Pan, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao",,,,https://stylesinger2.github.io/,,,[Unavailable],0,,,,SVS,,,,,2024.09.25
Generative Speech Foundation Model Pretraining for High-Quality Speech Extraction and Restoration,[Unavailable],,https://arxiv.org/abs/2409.16117,2024.09.24,v1,2024.09.24,Submitted to ICASSP2025,,,"Pin-Jui Ku, Alexander H. Liu, Roman Korostik, Sung-Feng Huang, Szu-Wei Fu, Ante Jukic",,https://github.com/NVIDIA/NeMo/blob/main/examples/audio/conf/flow_matching_generative_ssl_pretraining.yaml,,https://kuray107.github.io/ssl_gen25-examples/index.html,5,43,[Unavailable],0,,,,,,,,,2024.09.25
Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech,FEIM-TTS,,https://arxiv.org/abs/2409.16203,2024.09.24,v1,2024.09.24,ECCV,,,"Yunji Chu, Yunseob Shim, Unsang Park",,,,https://feim-tts.github.io/,,,[Unavailable],0,,,,,,,,,2024.09.25
FlowMAC: Conditional Flow Matching for Audio Coding at Low Bit Rates,FlowMAC,Codec,https://arxiv.org/abs/2409.17635,2024.09.26,v1,2024.09.26,Submitted to ICASSP2025,[Unavailable],[Unavailable],"Nicola Pia, Martin Strauss, Markus Multrus, Bernd Edler",,,,,5,34,[Unavailable],0,ConditionFlowMatching,,,,,,,,2024.10.01
PALM: Few-Shot Prompt Learning for Audio Language Models,PALM,,https://arxiv.org/abs/2409.19806,2024.09.29,v1,2024.09.29,EMNLP2024,[Unavailable],[Unavailable],"Asif Hanif, Maha Tufail Agro, Mohammad Areeb Qazi, Hanan Aldarmaki",,https://github.com/asif-hanif/palm,,https://asif-hanif.github.io/palm/,10,X,https://scholar.google.com/scholar?cluster=7264438063580882551,1,,,,,,,,,2024.10.27
FastAdaSP: Multitask-Adapted Efficient Inference for Large Speech Language Model,FastAdaSP,,https://arxiv.org/abs/2410.03007,2024.10.03,v1,2024.10.03,EMNLP2024,[Unavailable],[Unavailable],"Yichen Lu, Jiaqi Song, Chao-Han Huck Yang, Shinji Watanabe",Readme,https://github.com/yichen14/FastAdaSP,,,12,X,[Unavailable],0,,,,,,,,,2024.10.08
Disentangling Textual and Acoustic Features of Neural Speech Representations,[Unavailable],,https://arxiv.org/abs/2410.03037,2024.10.03,v1,2024.10.03,[Unavailable],[Unavailable],[Unavailable],"Hosein Mohebbi, Grzegorz Chrupa?a, Willem Zuidema, Afra Alishahi, Ivan Titov",,,,,,,[Unavailable],0,,,,,,,,,2024.10.08
MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech,MultiVerse,,https://arxiv.org/abs/2410.03192,2024.10.04,v1,2024.10.04,EMNLP2024Findings,[Unavailable],[Unavailable],"Taejun Bak, Youngsik Eom, SeungJae Choi, Young-Sun Joo",,,,https://nc-ai.github.io/speech/publications/multiverse/index.html,18,X,[Unavailable],0,,,,,,,Multi-Task/Zero-Shot,,2024.10.08
SyllableLM: Learning Coarse Semantic Units for Speech Language Models,SyllableLM,,https://arxiv.org/abs/2410.04029,2024.10.05,v1,2024.10.05,Submitted to ICLR2025,[Unavailable],[Unavailable],"Alan Baade, Puyuan Peng, David Harwath",,https://github.com/alanbaade/SyllableLM,,,21,X,https://scholar.google.com/scholar?cluster=1685740082033122660,0,,,,,,,,,2024.10.25
HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis,HALL-E,CLM,https://arxiv.org/abs/2410.04380,2024.10.06,v1,2024.10.06,Submitted to ICLR2025,[Unavailable],[Unavailable],"Yuto Nishimura, Takumi Hirose, Masanari Ohi, Hideki Nakayama, Nakamasa Inoue",,,,https://yutonishimura-v2.github.io/HALL-E_DEMO/,,,https://scholar.google.com/scholar?cluster=829417395349553651,0,,,,,,,,,2024.10.25
F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching,F5-TTS,,https://arxiv.org/abs/2410.06885,2024.10.09,v2,2024.10.15,[Unavailable],[Unavailable],[Unavailable],"Yushen Chen, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, Jian Zhao, Kai Yu, Xie Chen",,https://github.com/SWivid/F5-TTS,,https://swivid.github.io/F5-TTS,18,72,https://scholar.google.com/scholar?cluster=434056987428169369,0,Flow-Matching,,,,,,,,2024.10.25
Baichuan-Omni Technical Report,Baichuan-Omni,MLLM,https://arxiv.org/abs/2410.08565,2024.10.11,v1,2024.10.11,[Unavailable],[Unavailable],[Unavailable],"Yadong Li, Haoze Sun, Mingan Lin, Tianpeng Li, Guosheng Dong, Tao Zhang, Bowen Ding, Wei Song, Zhenglin Cheng, Yuqi Huo, Song Chen, Xu Li, Da Pan, Shusen Zhang, Xin Wu, Zheng Liang, Jun Liu, Tao Zhang, Keer Lu, Yaqi Zhao, Yanjun Shen, Fan Yang, Kaicheng Yu, Tao Lin, Jianhua Xu, Zenan Zhou, Weipeng Chen",,https://github.com/westlake-baichuan-mllm/bc-omni,,,,,https://scholar.google.com/scholar?cluster=13908702696420738789,1,,,,,,,,,2024.10.25
"Mini-Omni2: Towards Open-source GPT-4o Model with Vision, Speech and Duplex",Mini-Omni2,MLLM,https://arxiv.org/abs/2410.11190,2024.10.15,v1,2024.10.15,[Unavailable],[Unavailable],[Unavailable],"Zhifei Xie, Changqiao Wu",,https://github.com/gpt-omni/mini-omni2,https://huggingface.co/gpt-omni/mini-omni2,,,,[Unavailable],1,,,,,,,,,2024.10.25
DM-Codec: Distilling Multimodal Representations for Speech Tokenization,DM-Codec,Codec,https://arxiv.org/abs/2410.15017,2024.10.19,v1,2024.10.19,[Unavailable],[Unavailable],[Unavailable],"Md Mubtasim Ahasan, Md Fahim, Tasnim Mohiuddin, A K M Mahbubur Rahman, Aman Chadha, Tariq Iqbal, M Ashraful Amin, Md Mofijul Islam, Amin Ahsan Ali",,https://github.com/mubtasimahasan/DM-Codec,,,,,https://scholar.google.com/scholar?cluster=5670082760379769875,0,,,,,,,,,2024.10.25
Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant,Ichigo,MLLM,https://arxiv.org/abs/2410.15316,2024.10.20,v1,2024.10.20,[Unavailable],[Unavailable],[Unavailable],"Alan Dao (Gia Tuan Dao), Dinh Bach Vu, Huy Hoang Ha",,https://github.com/homebrewltd/ichigo,,https://demo.homebrew.ltd/,21,X,[Unavailable],0,,,,,,,,,2024.10.24
Continuous Speech Synthesis using per-token Latent Diffusion,SALAD,,https://arxiv.org/abs/2410.16048,2024.10.21,v1,2024.10.21,Submitted to ICLR2025,[Unavailable],[Unavailable],"Arnon Turetzky, Nimrod Shabtay, Slava Shechtman, Hagai Aronowitz, David Haws, Ron Hoory, Avihu Dekel",,,,,14,X,[Unavailable],0,,,,,,,,,2024.10.24
VoiceBench: Benchmarking LLM-Based Voice Assistants,VoiceBench,Evaluation,https://arxiv.org/abs/2410.17196,2024.10.22,v1,2024.10.22,[Unavailable],[Unavailable],[Unavailable],"Yiming Chen, Xianghu Yue, Chen Zhang, Xiaoxue Gao, Robby T. Tan, Haizhou Li",,https://github.com/MatthewCYM/VoiceBench,,,14,X,[Unavailable],0,,,,,,,,,2024.10.25
OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation,OmniFlatten,,https://arxiv.org/abs/2410.17799,2024.10.23,v1,2024.10.23,[Unavailable],[Unavailable],[Unavailable],"Qinglin Zhang, Luyao Cheng, Chong Deng, Qian Chen, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, Chaohong Tan",,,,https://omniflatten.github.io/,,,[Unavailable],0,,,,,,,,,2024.10.27
STTATTS: Unified Speech-To-Text And Text-To-Speech Model,STTATTS,,https://arxiv.org/abs/2410.18607,2024.10.24,v1,2024.10.24,EMNLP2024Findings,[Unavailable],[Unavailable],"Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki",,,,,11,X,[Unavailable],0,,,,,,,,,2024.10.25
