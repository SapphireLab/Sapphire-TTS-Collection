Title,Abbreviation,Class,ArXiv,ArXiv v1 Date,ArXiv New Version,ArXiv New Date,Publication,Publication Date,DOI,OpenSource,Official Code,HuggingFace,Demo Page,Page Number,Cite Number,Google Scholar,Cited by,Theory,Architecture,Tasks,Datasets,Compare Methods,Tags,AR/NAR,Update Time
Adam: A Method for Stochastic Optimization,Adam,Optimizer,https://arxiv.org/abs/1412.6980,2014.12.22,v9,2017.01.30,ICLR2015,,,,,,,,,,,,,,,,,,2024.09.21
Batch Normlization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,BatchNormalization,Trick,https://arxiv.org/abs/1502.03167,2015.02.11,v3,2015.03.02,,,,,,,,,,,,,,,,,,,2024.09.21
WORLD: A Vocoder-Based High-Quality Speech Synthesis System for Real-Time Applications,WORLD,Vocoder,[Unavailable],2016.07.01,[Unavailable],[Unavailable],IEICE TransInf2016,2016.07.01,https://doi.org/10.1587/transinf.2015EDP7457,,,,,,,,,,,TTS,,,,,2024.09.24
Layer Normalization,Layer Normalization,Trick,https://arxiv.org/abs/1607.06450,2016.07.21,v1,2016.07.21,,,,,,,,,,[Unavailable],12783,,,,,,,,2024.09.23
WaveNet: A Generative Model for Raw Audio,WaveNet,Vocoder,https://arxiv.org/abs/1609.03499,2016.09.12,v2,2016.09.19,,,,,,,,,,,,,,,,,,AR,2024.09.21
SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,SampleRNN,Vocoder,https://arxiv.org/abs/1612.07837,2016.12.22,v2,2017.02.11,ICLR2017,,,,,,,,,,,,,,,,,,2024.09.21
Char2Wav: End-to-End Speech Synthesis,Char2Wav,,[Unavailable],2017.02.18,[Unavailable],[Unavailable],ICLR2017,2017.02.18,https://openreview.net/forum?id=B1VWyySKx,,,,,,,https://scholar.google.com/scholar?cluster=6778319284287669999,522,,,TTS,,,,,2024.09.24
Deep Voice: Real-Time Neural Text-to-Speech,DeepVoice,,https://arxiv.org/abs/1702.07825,2017.02.25,v2,2017.03.07,ICML2017,2017.08.06,https://proceedings.mlr.press/v70/arik17a.html,,,,,,,https://scholar.google.com/scholar?cluster=18296399576126585694,819,,,TTS,,,,,2024.09.24
Tacotron: Towards End-to-End Speech Synthesis,Tacotron,,https://arxiv.org/abs/1703.10135,2017.03.29,v2,2017.04.06,InterSpeech2017,,,,,,,,,,,,,TTS,,,,,2024.09.24
Deep Voice 2: Multi-Speaker Neural Text-to-Speech,DeepVoice2,,https://arxiv.org/abs/1705.08947,2017.05.24,v2,2017.09.20,NeurIPS2017,,https://dl.acm.org/doi/abs/10.5555/3294996.3295056,,,,,,,https://scholar.google.com/scholar?cluster=188402189689268087,652,,,TTS,,,Multi-Speaker,,2024.09.24
VoiceLoop: Voice Fitting and Synthesis via A Phonological Loop,VoiceLoop,,https://arxiv.org/abs/1707.06588,2017.07.20,v3,2018.02.01,ICLR2018Poster,2018.02.16,https://openreview.net/forum?id=SkFAWax0-,,https://github.com/facebookarchive/loop,,,,,https://scholar.google.com/scholar?cluster=14159878382438547497,191,,,,,,,,2024.09.23
Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,DeepVoice3,,https://arxiv.org/abs/1710.07654,2017.10.20,v3,2018.02.22,ICLR2018Poster,2018.02.16,https://openreview.net/forum?id=HJtEm4p6Z,,,,,,,https://scholar.google.com/scholar?cluster=1828409622662260131,544,,,TTS,,,,,2024.09.24
Neural Discrete Representation Learning,VQ-VAE,Trick,https://arxiv.org/abs/1711.00937,2017.11.02,v2,2018.05.30,,,,,,,,,,,,,,,,,,,2024.09.21
Decoupled Weight Decay Regularization,AdamW,Optimizer,https://arxiv.org/abs/1711.05101,2017.11.14,v3,2019.01.04,ICLR2019,,,,,,,,,,,,,,,,,,2024.09.21
Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Parallel WaveNet,Vocoder,https://arxiv.org/abs/1711.10433,2017.11.28,v1,2017.11.28,,,,,,,,,,,,,,TTS,,,,,2024.09.24
Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions,Tacotron2,,https://arxiv.org/abs/1712.05884,2017.12.16,v2,2018.02.16,ICASSP2018,,,,,,,,,,,,,TTS,,,,,2024.09.24
Adversarial Audio Synthesis,WaveGAN,Vocoder,https://arxiv.org/abs/1802.04208,2018.02.12,v3,2019.02.09,ICLR2019,,,,,,,,,,,,,,,,,,2024.09.21
Efficient Neural Audio Synthesis,WaveRNN,Vocoder,https://arxiv.org/abs/1802.08435,2018.02.23,v2,2018.06.25,,,,,,,,,,,,,,,,,,,2024.09.21
Transfer Learning from Speaker Verification to Multispeaker Text-to-Speech Synthesis,SV2TTS,,https://arxiv.org/abs/1806.04558,2018.06.12,v4,2019.01.02,NeurIPS2018,2018.12.03,https://dl.acm.org/doi/abs/10.5555/3327345.3327360,,,,,,,https://scholar.google.com/scholar?cluster=14002861277903846410,961,,,TTS,,,,,2024.09.24
Representation Learning with Contrastive Predictive Coding,CPC,Representation,https://arxiv.org/abs/1807.03748,2018.07.10,v2,2019.01.22,,,,,,,,,,https://scholar.google.com/scholar?cluster=3606056486908097181,9408,,,,,,,,2024.09.24
ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech,ClariNet,,https://arxiv.org/abs/1807.07281,2018.07.19,v3,2019.02.22,ICLR2019Poster,2018.12.21,https://openreview.net/forum?id=HklY120cYm,,,,,,,https://scholar.google.com/scholar?cluster=1675505652651694755,413,,,TTS,,,,,2024.09.24
Neural Speech Synthesis with Transformer Network,Transformer TTS,,https://arxiv.org/abs/1809.08895,2018.09.19,v3,2019.01.30,,,,,,,,,,,,,,TTS,,,,,2024.09.24
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,BERT,LLM,https://arxiv.org/abs/1810.04805,2018.10.11,v2,2019.05.24,,,,,,,,,,[Unavailable],112766,,,,,,,,2024.09.23
LPCNet: Improving Neural Speech Synthesis Through Linear Prediction,LPCNet,Vocoder,https://arxiv.org/abs/1810.11846,2018.10.28,v2,2019.02.19,ICASSP2019,,,,,,,,,,,,,TTS,,,,,2024.09.24
WaveGlow: A Flow-Based Generative Network for Speech Synthesis,WaveGlow,Vocoder,https://arxiv.org/abs/1811.00002,2018.10.31,v1,2018.10.31,,,,,,,,,,,,Flow,,TTS,,,,,2024.09.24
FloWaveNet : A Generative Flow for Raw Audio,FloWaveNet,Vocoder,https://arxiv.org/abs/1811.02155,2018.11.06,v3,2019.05.20,ICML2019,,,,,,,,,,,,,,,,,,2024.09.21
Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design,Flow++,Image,https://arxiv.org/abs/1902.00275,2019.02.01,v2,2019.05.15,ICML2019,,https://proceedings.mlr.press/v97/ho19a,,,,,,,https://scholar.google.com/scholar?cluster=7151289546461544772,486,Flow,,,,,,,2024.09.24
GANSynth: Adversarial Neural Audio Synthesis,GANSynth,Vocoder,https://arxiv.org/abs/1902.08710,2019.02.23,v2,2019.04.15,,,,,,,,,,,,,,,,,,,2024.09.21
LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech,LibriTTS,Dataset,https://arxiv.org/abs/1904.02882,2019.04.05,v1,2019.04.05,InterSpeech2019,,,,,,,,,,,,,TTS,,,,,2024.09.24
Wav2Vec: Unsupervised Pre-Training for Speech Recognition,Wav2Vec,Representation,https://arxiv.org/abs/1904.05862,2019.04.11,v4,2019.09.11,InterSpeech,,,,https://github.com/pytorch/fairseq,,,,,,,,,,,,,,2024.09.21
Non-Autoregressive Neural Text-to-Speech,ParaNet,,https://arxiv.org/abs/1905.08459,2019.05.21,v3,2020.06.29,ICML2020,,,,,,,,,,,,,TTS,,,,NAR,2024.09.24
FastSpeech: Fast Robust and Controllable Text to Speech,FastSpeech,,https://arxiv.org/abs/1905.09263,2019.05.22,v5,2019.11.20,NeurIPS2019,,,,,,,,,,,,,TTS,,,,,2024.09.24
RoBERTa: A Robustly Optimized BERT Pretraining Approach,RoBERTa,LLM,https://arxiv.org/abs/1907.11692,2019.07.26,v1,2019.07.26,,,,,,,,,,[Unavailable],15137,,,,,,,,2024.09.23
High Fidelity Speech Synthesis with Adversarial Networks,GAN-TTS,Vocoder,https://arxiv.org/abs/1909.11646,2019.09.25,v2,2019.09.26,,,,,,,,,,,,,,TTS,,,,,2024.09.24
MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis,MelGAN,Vocoder,https://arxiv.org/abs/1910.06711,2019.10.08,v3,2019.12.09,,,,,,,,,,,,,,,,,,,2024.09.21
vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations,VQ-Wav2Vec,Representation,https://arxiv.org/abs/1910.05453,2019.10.12,v3,2020.02.16,ICLR2020Poster,,https://openreview.net/forum?id=rylwJxrYDS,,,,,,,https://scholar.google.com/scholar?cluster=1142923229168041752,716,,,,,,,,2024.09.23
WaveFlow: A Compact Flow-Based Model for Raw Audio,WaveFlow,Vocoder,https://arxiv.org/abs/1912.01219,2019.12.03,v4,2020.06.24,ICML2020,,,,,,,,,,,Flow,,,,,,,2024.09.24
AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment,AlignTTS,,https://arxiv.org/abs/2003.01950,2020.03.04,v1,2020.03.04,ICASSP2020,,,,,,,,,https://scholar.google.com/scholar?cluster=1600438380822500245,86,,,TTS,,,,,2024.09.24
Flow-TTS: A Non-Autoregressive Network for Text to Speech Based on Flow,Flow-TTS,,[Unavailable],2020.04.09,[Unavailable],[Unavailable],ICASSP2020,2020.04.09,https://doi.org/10.1109/ICASSP40776.2020.9054484,,,,,,,https://scholar.google.com/scholar?cluster=7765078935283625839,134,Flow,,TTS,,,,NAR,2024.09.24
Flowtron: An Autoregressive Flow-Based Generative Network for Text-to-Speech Synthesis,Flowtron,,https://arxiv.org/abs/2005.05957,2020.05.12,v3,2020.07.16,ICLR2021Poster,2021.01.12,https://openreview.net/forum?id=Ig53hpHxS4,,https://github.com/NVIDIA/flowtron,,,10,,,170,Flow,,TTS,,,,AR,2024.09.24
JDI-T: Jointly Trained Duration Informed Transformer for Text-to-Speech without Explicit Alignment,JDI-T,,https://arxiv.org/abs/2005.07799,2020.05.15,v3,2020.10.05,InterSpeech2020,,,,,,,,,,,,,TTS,,,,,2024.09.24
Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search,Glow-TTS,,https://arxiv.org/abs/2005.11129,2020.05.22,v2,2020.10.23,NeurIPS2020,,,,,,,,,,,Flow,,TTS,,,,,2024.09.24
Language Models are Few-Shot Learners,GPT-3,LLM,https://arxiv.org/abs/2005.14165,2020.05.28,v4,2020.07.22,,,,,,,,,,,,,,,,,Few-Shot,,2024.09.24
End-to-End Adversarial Text-to-Speech,EATS,,https://arxiv.org/abs/2006.03575,2020.06.05,v3,2021.03.17,ICLR2021Oral,,,,,,,,,,,,,TTS,,,,,2024.09.24
FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,FastSpeech2,,https://arxiv.org/abs/2006.04558,2020.06.08,v8,2022.08.08,ICLR2021,,,,,,https://speechresearch.github.io/fastspeech2/,,,,,,,TTS,,,,,2024.09.24
MultiSpeech: Multi-Speaker Text to Speech with Transformer,MultiSpeech,,https://arxiv.org/abs/2006.04664,2020.06.08,v2,2022.08.01,,,,,,,,,,,,,,TTS,,,Multi-Speaker,,2024.09.24
NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity,NanoFlow,Vocoder,https://arxiv.org/abs/2006.06280,2020.06.11,v4,2020.10.23,NeurIPS2020,,,,https://github.com/L0SG/NanoFlow,,,,,,,Flow,,,,,,,2024.09.24
FastPitch: Parallel Text-to-speech with Pitch Prediction,FastPitch,,https://arxiv.org/abs/2006.06873,2020.06.11,v2,2021.02.16,ICASSP2021,,,,,,,,,,,,,TTS,,,,,2024.09.24
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,Wav2Vec 2.0,Representation,https://arxiv.org/abs/2006.11477,2020.06.20,v3,2020.10.22,NeurIPS2020,,,,,,,,,,,,,,,,,,2024.09.21
VocGAN: A High-Fidelity Real-Time Vocoder with A Hierarchically-Nested Adversarial Network,VocGAN,Vocoder,https://arxiv.org/abs/2007.15256,2020.07.30,v1,2020.07.30,InterSpeech2020,,,,,,,,,,,,,,,,,,2024.09.21
SpeedySpeech: Efficient Neural Speech Synthesis,SpeedySpeech,,https://arxiv.org/abs/2008.03802,2020.08.09,v1,2020.08.09,InterSpeech2020,,,,,,,,,,,,,TTS,,,,,2024.09.24
WaveGrad: Estimating Gradients for Waveform Generation,WaveGrad,Vocoder,https://arxiv.org/abs/2009.00713,2020.09.02,v2,2020.10.09,ICLR2021Poster,,,,,,https://wavegrad.github.io/,,,https://scholar.google.com/scholar?cluster=9166479714962885889,724,,,,,,,,2024.09.23
DiffWave: A Versatile Diffusion Model for Audio Synthesis,DiffWave,Vocoder,https://arxiv.org/abs/2009.09761,2020.09.21,v3,2021.03.30,ICLR2021Oral,,,,,,,,,https://scholar.google.com/scholar?cluster=8775132726722534164,1176,Diffusion,,,,,,,2024.09.24
HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,HiFi-GAN,Vocoder,https://arxiv.org/abs/2010.05646,2020.10.12,v2,2020.10.23,NeurIPS2020,,,,https://github.com/jik876/hifi-gan,,,,,,,,,TTS,,,,,2024.09.24
Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech,BVAE-TTS,,[Unavailable],2021.01.13,[Unavailable],[Unavailable],ICLR2021Poster,2021.01.13,https://openreview.net/forum?id=o3iritJHLfO,,https://github.com/LEEYOONHYUNG/BVAE-TTS,,,,,,,,,TTS,,,,NAR,2024.09.24
On Generative Spoken Language Modeling from Raw Audio,GSLM,,https://arxiv.org/abs/2102.01192,2021.02.01,v2,2021.09.09,TACL2021,2022.01.04,https://transacl.org/index.php/tacl/article/view/3241,,https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm,,,19,,https://scholar.google.com/scholar?cluster=10339951252730122651,304,,CPC/Wav2Vec2.0/HuBERT+Transformer+Tacotron2,Acoustic Unit Discovery/Spoken Language Modeling/Discrete Speech Resynthesis/Speech Generation,,,,,2024.09.21
LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search,LightSpeech,,https://arxiv.org/abs/2102.04040,2021.02.08,v1,2021.02.08,ICASSP2021,,,,,,https://speechresearch.github.io/lightspeech,,,,,,,TTS,,,,,2024.09.24
AdaSpeech: Adaptive Text to Speech for Custom Voice,AdaSpeech,,https://arxiv.org/abs/2103.00993,2021.03.01,v1,2021.03.01,ICLR2021,,,,,,,,,,,,,TTS,,,,,2024.09.24
Expressive Text-to-Speech using Style Tag,ST-TTS,,https://arxiv.org/abs/2104.00436,2021.04.01,v2,2022.10.06,InterSpeech2021,,https://doi.org/10.21437/Interspeech.2021-465,,,,,,,,,,,TTS,,,,,2024.09.24
Diff-TTS: A Denoising Diffusion Model for Text-to-Speech,Diff-TTS,,https://arxiv.org/abs/2104.01409,2021.04.03,v1,2021.04.03,InterSpeech2021,,https://doi.org/10.21437/Interspeech.2021-469,,,,,,,https://scholar.google.com/scholar?cluster=386505123268486129,184,Diffusion,,TTS,,,,,2024.09.24
AdaSpeech 2: Adaptive Text to Speech with Untranscribed Data,AdaSpeech2,,https://arxiv.org/abs/2104.09715,2021.04.20,v1,2021.04.20,ICASSP2021,,,,,,https://speechresearch.github.io/adaspeech2/,,,,,,,TTS,,,,,2024.09.24
Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech,Grad-TTS,,https://arxiv.org/abs/2105.06337,2021.05.13,v2,2021.08.05,ICML2021,,https://proceedings.mlr.press/v139/popov21a,,,,,,,https://scholar.google.com/scholar?cluster=6905767521784147251,450,Diffusion,,TTS,,,,,2024.09.24
ByT5: Towards A Token-Free Future with Pre-Trained Byte-to-Byte Models,ByT5,LLM,https://arxiv.org/abs/2105.13626,2021.05.28,v3,2022.03.08,MIT@TACL2022,,https://doi.org/10.1162/tacl_a_00461,,,,,,,https://scholar.google.com/scholar?cluster=765429917132805319,371,,,,,,,,2024.09.23
PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior,PriorGrad,Vocoder,https://arxiv.org/abs/2106.06406,2021.06.11,v2,2022.02.20,,,,,,,https://speechresearch.github.io/priorgrad/,,,,,Diffusion,,,,,,,2024.09.24
Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech,VITS,,https://arxiv.org/abs/2106.06103,2021.06.11,v1,2021.06.11,ICML2021,,https://proceedings.mlr.press/v139/kim21f,Training+Inference+Weight,https://github.com/jaywalnut310/vits,,https://jaywalnut310.github.io/vits-demo/index.html,15,45,,720,,,TTS,LJSpeech/VCTK,Tacotron2+HiFi-GAN/Glow-TTS+HiFi-GAN,,,2024.09.24
HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units,HuBERT,Representation,https://arxiv.org/abs/2106.07447,2021.06.14,v1,2021.06.14,TASLP2021,,,,,,,,,,,,,,,,,,2024.09.21
UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation,UnivNet,Vocoder,https://arxiv.org/abs/2106.07889,2021.06.15,v1,2021.06.15,InterSpeech2021,,https://doi.org/10.21437/Interspeech.2021-1016,,,,,,,,,,,,,,,,2024.09.21
RAD-TTS: Parallel Flow-Based TTS with Robust Alignment Learning and Diverse Synthesis,RAD-TTS,,[Unavailable],2021.06.16,[Unavailable],[Unavailable],ICML2021Poster,,https://openreview.net/forum?id=0NQwnnwAORi,,,,,,,,,Flow,,,,,,,2024.09.24
LoRA: Low-Rank Adaptation of Large Language Models,LoRA,PEFT,https://arxiv.org/abs/2106.09685,2021.06.17,V2,2021.10.16,,,,,,,,,,https://scholar.google.com/scholar?cluster=12933070321040047372,6603,,,,,,,,2024.09.23
WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis,WaveGrad2,Vocoder,https://arxiv.org/abs/2106.09660,2021.06.17,v2,2021.06.19,InterSpeech2021,,https://doi.org/10.21437/Interspeech.2021-1897,,,,https://wavegrad.github.io/v2,,,https://scholar.google.com/scholar?cluster=7794140642380946818,52,,,TTS,,,,,2024.09.24
Glow-WaveGAN: Learning Speech Representations from GAN-Based Variational Auto-Encoder for High Fidelity Flow-Based Speech Synthesis,Glow-WaveGAN,,https://arxiv.org/abs/2106.10831,2021.06.21,v2,2021.06.22,InterSpeech2021,,https://doi.org/10.21437/Interspeech.2021-414,,,,,,,https://scholar.google.com/scholar?cluster=2756717255530588573,29,Flow,,TTS,,,,,2024.09.24
AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style,AdaSpeech3,,https://arxiv.org/abs/2107.02530,2021.07.06,v1,2021.07.06,InterSpeech2021,,https://doi.org/10.21437/Interspeech.2021-584,,,,,,,https://scholar.google.com/scholar?cluster=9301647847588887674,41,,,TTS,,,,,2024.09.24
SoundStream: An End-to-End Neural Audio Codec,SoundStream,Codec,https://arxiv.org/abs/2107.03312,2021.07.07,v1,2021.07.07,IEEE@TASLP2021,,https://doi.org/10.1109/TASLP.2021.3129994,,,,https://google-research.github.io/seanet/soundstream/examples/,13,68,,511,,,,,,,,2024.09.21
W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training,W2V-BERT,Representation,https://arxiv.org/abs/2108.06209,2021.08.07,v2,2021.09.13,IEEE@ASRU2021,,https://doi.org/10.1109/ASRU51503.2021.9688253,,,,,,,https://scholar.google.com/scholar?cluster=1094787119642800600,379,,,,,,,,2024.09.23
Text-Free Prosody-Aware Generative Spoken Language Modeling,pGSLM,,https://arxiv.org/abs/2109.03264,2021.09.07,v2,2022.05.10,ACL2022,,https://doi.org/10.18653/v1/2022.acl-long.593,,,,,,,https://scholar.google.com/scholar?cluster=6860409912627023988,105,,,,,,,,2024.09.23
Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme,DiffVC,VC,https://arxiv.org/abs/2109.13821,2021.09.28,v2,2022.08.04,ICLR2022Oral,2022.01.29,https://openreview.net/forum?id=8c50f-DoWAu,,,,,,,https://scholar.google.com/scholar?cluster=17487782166390673105,95,,,VC,,,,,2024.09.24
DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2021,DelightfulTTS,,https://arxiv.org/abs/2110.12612,2021.10.15,v2,2021.11.19,,,,,,,,,,,,,,TTS,,,,,2024.09.24
VISinger: Variational Inference with Adversarial Learning for End-to-End Singing Voice Synthesis,VISinger,,https://arxiv.org/abs/2110.08813,2021.10.17,v2,2022.02.24,ICASSP2022,,,,,,,,,,,,,,,,,,2024.09.23
WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing,WavLM,Representation,https://arxiv.org/abs/2110.13900,2021.10.26,v5,2022.06.17,IEEE@JSTSP2022,,https://doi.org/10.1109/JSTSP.2022.3188113,,,,,,,https://scholar.google.com/scholar?cluster=10100955724765491326,1459,,,,,,,,2024.09.24
YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for Everyone,YourTTS,,https://arxiv.org/abs/2112.02418,2021.12.04,v4,2023.04.30,ICML2022,,https://proceedings.mlr.press/v162/casanova22a.html,,,,,,,https://scholar.google.com/scholar?cluster=8575580251111777245,331,,,TTS/VC,,,Zero-Shot/Multi-Speaker,,2024.09.24
High-Resolution Image Synthesis with Latent Diffusion Models,LDM,Image,https://arxiv.org/abs/2112.10752,2021.12.20,v2,2022.04.13,IEEE/CVF@CVPR2022,,https://doi.org/10.1109/CVPR52688.2022.01042,,,,,,,https://scholar.google.com/scholar?cluster=2427242760668866618,10759,Diffusion,,,,,,,2024.09.24
MaskGIT: Masked Generative Image Transformer,MaskGIT,Image,https://arxiv.org/abs/2202.04200,2022.02.08,v1,2022.02.08,,,,,,,,,,,,,,,,,,,2024.09.21
Autoregressive Image Generation using Residual Quantization,RQ-VAE,,https://arxiv.org/abs/2203.01941,2022.03.03,v2,2022.03.09,IEEE/CVF@CVPR2022,2022.09.27,https://doi.org/10.1109/CVPR52688.2022.01123,,https://github.com/kakaobrain/rq-vae-transformer,,,,,https://scholar.google.com/scholar?cluster=5953877530421044413,166,,,,,,,,2024.09.23
iSTFTNet: Fast and Lightweight Mel-Spectrogram Vocoder Incorporating Inverse Short-Time Fourier Transform,iSTFTNet,Vocoder,https://arxiv.org/abs/2203.02395,2022.03.04,v1,2022.03.04,ICASSP2022,,,,,,https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet/,,,,,,,,,,,,2024.09.21
HiFi++: A Unified Framework for Bandwidth Extension and Speech Enhancement,HiFi++,Vocoder,https://arxiv.org/abs/2203.13086,2022.03.24,v4,2023.12.10,ICASSP2023,,,,,,,,,,,,,,,,,,2024.09.21
VoiceMe: Personalized Voice Generation in TTS,VoiceMe,,https://arxiv.org/abs/2203.15379,2022.03.29,v2,2022.07.11,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-10855,,,,https://polvanrijn.github.io/VoiceMe/,,,,,,,,,,,,2024.09.21
Generative Spoken Dialogue Language Modeling,dGSLM,,https://arxiv.org/abs/2203.16502,2022.03.30,v2,2022.11.22,MIT@TACL2023,,https://doi.org/10.1162/tacl_a_00545,,,,,,,https://scholar.google.com/scholar?cluster=9049539949210726832,80,,,,,,,,2024.09.23
SpecGrad: Diffusion Probabilistic Model Based Neural Vocoder with Adaptive Noise Spectral Shaping,SpecGrad,Vocoder,https://arxiv.org/abs/2203.16749,2022.03.31,v2,2022.08.04,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-301,,,,http://wavegrad.github.io/specgrad/,,,,,Diffusion,,,,,,,2024.09.24
AdaSpeech 4: Adaptive Text to Speech in Zero-Shot Scenarios,AdaSpeech4,,https://arxiv.org/abs/2204.00436,2022.04.01,v1,2022.04.01,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-901,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis,FastDiff,,https://arxiv.org/abs/2204.09934,2022.04.21,v1,2022.04.21,IJCAI2022,,,,,,https://fastdiff.github.io/,,,,,Diffusion,,TTS,,,,,2024.09.24
NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality,NaturalSpeech,,https://arxiv.org/abs/2205.04421,2022.05.09,v2,2022.05.10,TPAMI,,,,,,,,,,,,,TTS,,,,,2024.09.24
GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech,GenerSpeech,,https://arxiv.org/abs/2205.07211,2022.05.15,v2,2022.10.12,NeurIPS2022,,,,,,https://generspeech.github.io/,,,,,,,TTS,,,,,2024.09.24
StyleTTS: A Style-Based Generative Model for Natural and Diverse Text-to-Speech Synthesis,StyleTTS,,https://arxiv.org/abs/2205.15439,2022.05.30,v2,2023.11.20,,,,,,,,,,,,,,TTS,,,,,2024.09.24
BigVGAN: A Universal Neural Vocoder with Large-Scale Training,BigVGAN,Vocoder,https://arxiv.org/abs/2206.04658,2022.06.09,v2,2023.02.16,ICLR2023Poster,,https://openreview.net/forum?id=iTtGCMDEzS_,,https://github.com/NVIDIA/BigVGAN,,https://bigvgan-demo.github.io/,20,X,https://scholar.google.com/scholar?cluster=14265847301322679424,159,GAN,AMP module+Snake Activation,,LibriTTS/(VCTK/LJSpeech[Unseen]),SC-WaveRNN/WaveGlow/WaveFlow/HiFi-GAN/UnivNet,,,2024.09.24
SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech,SANE-TTS,,https://arxiv.org/abs/2206.12132,2022.06.24,v1,2022.06.24,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-46,,,,,,,,,,,TTS,,,,,2024.09.24
JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to Speech,JETS,,https://arxiv.org/abs/2203.16852,2022.07.01,v2,2022.07.01,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-10294,,,,,,,https://scholar.google.com/scholar?cluster=15869678961981985812,50,,,TTS,,,,,2024.09.24
Glow-WaveGAN 2: High-quality Zero-shot Text-to-speech Synthesis and Any-to-any Voice Conversion,Glow-WaveGAN2,,https://arxiv.org/abs/2207.01832,2022.07.05,v1,2022.07.05,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-684,,,,,,,,,,,TTS/VC,,,Zero-Shot,,2024.09.24
DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders,DelightfulTTS2,,https://arxiv.org/abs/2207.04646,2022.07.11,v1,2022.07.11,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-277,,,,,,,,,,,TTS,,,,,2024.09.24
WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation,WaveGAN,Image,https://arxiv.org/abs/2207.07288,2022.07.15,v2,2022.08.09,ECCV2022,,,Training+Inference+Weight,https://github.com/kobeshegu/ECCV2022_WaveGAN,,,,,https://scholar.google.com/scholar?cluster=3247766894580497169,50,GAN,,,,,Few-Shot,,2024.09.24
AudioLM: A Language Modeling Approach to Audio Generation,AudioLM,,https://arxiv.org/abs/2209.03143,2022.09.07,v2,2023.07.26,TASLP2023,2023.06.21,https://doi.org/10.1109/TASLP.2023.3288409,,,,,11,65,https://scholar.google.com/scholar?cluster=16664344357726277649,446,,,,,,,,2024.09.23
AudioGen: Textually Guided Audio Generation,AudioGen,,https://arxiv.org/abs/2209.15352,2022.09.30,v2,2023.06.05,ICLR,,https://openreview.net/forum?id=CYK7RfcOzQ4,,,,,,,https://scholar.google.com/scholar?cluster=11166122285082527856,253,,,,,,,,2024.09.23
High Fidelity Neural Audio Compression,EnCodec,Codec,https://arxiv.org/abs/2210.13438,2022.10.24,v1,2022.10.24,TMLR,,,Training+Inference+Weight,https://github.com/facebookresearch/encodec,,,19,,https://scholar.google.com/scholar?cluster=11269141130994676820,462,,,,,,,,2024.09.23
FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion,FreeVC,VC,https://arxiv.org/abs/2210.15418,2022.10.27,v1,2022.10.27,IEEE@ICASSP2023,2023.05.05,https://doi.org/10.1109/ICASSP49357.2023.10095191,,,,,,,https://scholar.google.com/scholar?cluster=16505500752330187346,76,,,VC,,,One-Shot,,2024.09.24
HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference Using Self-supervised Representations for Speech Synthesis,HierSpeech,,[Unavailable],2022.11.01,[Unavailable],[Unavailable],NeurIPS2022,2022.11.01,https://openreview.net/forum?id=awdyRVnfQKX,,,,,,,https://scholar.google.com/scholar?cluster=10216809622451649383,39,,,TTS,,,,,2024.09.24
VISinger 2: High-Fidelity End-to-End Singing Voice Synthesis Enhanced by Digital Signal Processing Synthesizer,VISinger2,,https://arxiv.org/abs/2211.02903,2022.11.05,v1,2022.11.05,InterSpeech2023,,https://doi.org/10.21437/Interspeech.2022-391,,,,,,,https://scholar.google.com/scholar?cluster=13300051646424906650,16,,,,,,,,2024.09.23
A Unified One-Shot Prosody and Speaker Conversion System with Self-Supervised Discrete Speech Units,UUVC,VC,https://arxiv.org/abs/2211.06535,2022.11.12,v1,2022.11.12,IEEE@ICASSP2023,2023.05.05,https://doi.org/10.1109/ICASSP49357.2023.10095565,,https://github.com/b04901014/uuvc,,https://b04901014.github.io/UUVC/,,,https://scholar.google.com/scholar?cluster=16859671418509076699,6,,,VC,,,,,2024.09.25
OverFlow: Putting Flows on Top of Neural Transducers for Better TTS,OverFlow,,https://arxiv.org/abs/2211.06892,2022.11.13,v2,2023.05.29,InterSpeech2023,,https://doi.org/10.21437/Interspeech.2022-1996,,,,https://shivammehta25.github.io/OverFlow/,,,https://scholar.google.com/scholar?cluster=15444001209274851942,15,Flow,,,,,,,2024.09.24
PromptTTS: Controllable Text-to-Speech with Text Descriptions,PromptTTS,,https://arxiv.org/abs/2211.12171,2022.11.22,v1,2022.11.22,ICASSP2023,,,,,,,,,,,,,TTS,,,,,2024.09.24
Robust Speech Recognition via Large-Scale Weak Supervision,Whisper,,https://arxiv.org/abs/2212.04356,2022.12.06,v1,2022.12.06,ICML2023,,https://proceedings.mlr.press/v202/radford23a.html,,,,,,,https://scholar.google.com/scholar?cluster=14594961257476535034,2695,,,,,,,,2024.09.21
Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers,VALL-E,CLM,https://arxiv.org/abs/2301.02111,2023.01.05,v1,2023.01.05,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=8330191945346870138,460,,,TTS,,,Zero-Shot,,2024.09.24
MusicLM: Generating Music From Text,MusicLM,,https://arxiv.org/abs/2301.11325,2023.01.26,v1,2023.01.26,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=17376728213237187356,457,,,,,,,,2024.09.23
AudioLDM: Text-to-Audio Generation with Latent Diffusion Models,AudioLDM,,https://arxiv.org/abs/2301.12503,2023.01.29,v3,2023.09.09,ICML2023,,https://proceedings.mlr.press/v202/liu23f.html,,,,,,,https://scholar.google.com/scholar?cluster=3166553528222335360,378,Diffusion,,,,,,,2024.09.24
Make-An-Audio: Text-to-Audio Generation with Prompt-Enhanced Diffusion Models,Make-An-Audio,,https://arxiv.org/abs/2301.12661,2023.01.30,v1,2023.01.30,ICML2023,,https://proceedings.mlr.press/v202/huang23i.html,,,,https://text-to-audio.github.io/,,,https://scholar.google.com/scholar?cluster=14204166098403262471,210,Diffusion,,,,,,,2024.09.24
InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt,InstructTTS,,https://arxiv.org/abs/2301.13662,2023.01.31,v2,2023.06.25,IEEE@TASLP2024,2024.05.20,https://doi.org/10.1109/TASLP.2024.3402088,,,,,,,https://scholar.google.com/scholar?cluster=16890941306445601074,65,,,,,,,,2024.09.23
Speak Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision,SPEAR-TTS,,https://arxiv.org/abs/2302.03540,2023.02.07,v1,2023.02.07,MIT@TACL2023,2023.12.21,https://doi.org/10.1162/tacl_a_00618,,,,https://google-research.github.io/seanet/speartts/examples/,,,https://scholar.google.com/scholar?cluster=15014701949812441701,144,,,TTS,,,,,2024.09.24
QuickVC: Any-to-Many Voice Conversion Using Inverse Short-time Fourier Transform for Faster Conversion,QuickVC,,https://arxiv.org/abs/2302.08296,2023.02.16,v4,2023.02.23,,,,,,,,,,https://scholar.google.com/scholar?cluster=8865818686073432109,9,,,VC,,,,,2024.09.24
LLaMA: Open and Efficient Foundation Language Models,LLaMA,LLM,https://arxiv.org/abs/2302.13971,2023.02.27,v1,2023.02.27,,,,,,,,,,https://scholar.google.com/scholar?cluster=7549877693210626200,8738,,,,,,,,2024.09.23
Vocos: Closing the Gap between Time-Domain and Fourier-Based Neural Vocoders for High-Quality Audio Synthesis,Vocos,Vocoder,https://arxiv.org/abs/2306.00814,2023.03.01,v3,2024.05.29,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=vY9nzQmQBw,Training+Inference+Weight,https://github.com/gemelo-ai/vocos,https://huggingface.co/charactr/vocos-mel-24khz,https://gemelo-ai.github.io/vocos/,15,X,https://scholar.google.com/scholar?cluster=4445816452466808234,34,,,,LibriTTS,HiFi-GAN/iSTFTNet/BigVGAN,,,2024.09.24
SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks,SpeechPrompt v2,,https://arxiv.org/abs/2303.00733,2023.03.01,v1,2023.03.01,,,,,,,,,,https://scholar.google.com/scholar?cluster=17237359125895838493,29,,,,,,,,2024.09.23
Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages,Google USM,,https://arxiv.org/abs/2303.01037,2023.03.02,v3,2023.09.25,,,,,,,,,,https://scholar.google.com/scholar?cluster=17752285616737220261,225,,,,,,,,2024.09.23
FoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model,FoundationTTS,,https://arxiv.org/abs/2303.02939,2023.03.06,v3,2023.03.06,,,,,,,,,,https://scholar.google.com/scholar?cluster=7389306401877363213,9,,,TTS,,,,,2024.09.24
Speak Foreign Languages with Your Own Voice:Cross-Lingual Neural Codec Language Modeling,VALL-E X,CLM,https://arxiv.org/abs/2303.03926,2023.03.07,v1,2023.03.07,,,,,,,https://aka.ms/vallex,,,,,,,,,,,,2024.09.24
LMCodec: A Low Bitrate Speech Codec with Causal Transformer Models,LMCodec,Codec,https://arxiv.org/abs/2303.12984,2023.03.23,v1,2023.03.23,ICASSP2023,,,,,,https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec,,,,,,,,,,,,2024.09.21
NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers,NaturalSpeech2,,https://arxiv.org/abs/2304.09116,2023.04.18,v3,2023.05.30,,,,,,,,,,,,Diffusion,,,,,Zero-Shot,,2024.09.24
HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec,HiFi-Codec,Codec,https://arxiv.org/abs/2305.02765,2023.05.04,v2,2023.05.07,,,,,,,,,,,,,,,,,,,2024.09.21
CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model,CoMoSpeech,,https://arxiv.org/abs/2305.06908,2023.05.11,v4,2023.10.29,ACM MultiMedia2023,2023.10.27,https://doi.org/10.1145/3581783.3612061,,,,https://comospeech.github.io/,,,https://scholar.google.com/scholar?cluster=125530389504723191,26,,,,,,,,2024.09.23
APNet: An All-Frame-Level Neural Vocoder Incorporating Direct Prediction of Amplitude and Phase Spectra,APNet,Vocoder,https://arxiv.org/abs/2305.07952,2023.05.13,v1,2023.05.13,TASLP,,,,,,,,,,,,,,,,,,2024.09.21
SoundStorm: Efficient Parallel Audio Generation,SoundStorm,,https://arxiv.org/abs/2305.09636,2023.05.16,v1,2023.05.16,,,,,,,,,,,,,,,,,,,2024.09.21
Palm 2 Technical Report,PaLM2,LLM,https://arxiv.org/abs/2305.10403,2023.05.17,v3,2023.09.13,,,,,,,,,,https://scholar.google.com/scholar?cluster=8537582669272475110,1198,,,,,,,,2024.09.23
Listen Think and Understand,LTU,,https://arxiv.org/abs/2305.10790,2023.05.18,v3,2024.02.19,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=nBZBPXdJlC,,https://github.com/YuanGongND/ltu,https://huggingface.co/spaces/yuangongfdu/ltu,,,,https://scholar.google.com/scholar?cluster=10650236499486566217,87,,,,,,,,2024.09.23
SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities,SpeechGPT,,https://arxiv.org/abs/2305.11000,2023.05.18,v2,2023.05.19,,,,,,,,,,,,,,,,,,,2024.09.21
Pengi: An Audio Language Model for Audio Tasks,Pengi,,https://arxiv.org/abs/2305.11834,2023.05.19,v2,2024.01.19,NeurIPS2023Poster,2023.09.22,https://openreview.net/forum?id=gJLAfO4KUq,,,,,,,https://scholar.google.com/scholar?cluster=10580047223748383516,80,,,,,,,,2024.09.23
Textually Pretrained Speech Language Models,TWIST,,https://arxiv.org/abs/2305.13009,2023.05.22,v3,2024.01.30,NeurIPS2023Poster,2023.09.22,https://openreview.net/forum?id=UlHueVjAKr,,,,,,,https://scholar.google.com/scholar?cluster=2726323772873175239,36,,,,,,,,2024.09.23
U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech,U-DiT TTS,,https://arxiv.org/abs/2305.13195,2023.05.22,v1,2023.05.22,IEEE@SpeechCommunication,2023.12.18,https://doi.org/10.30420/456164010,,,,,,,https://scholar.google.com/scholar?cluster=11840959028878808925,5,Diffusion,,TTS,,,,,2024.09.24
QLoRA: Efficient Finetuning of Quantized LLMs,QLoRA,PEFT,https://arxiv.org/abs/2305.14314,2023.05.23,v1,2023.05.23,,,,,,,,,,https://scholar.google.com/scholar?cluster=1698009957296542951,1405,,,,,,,,2024.09.23
VioLA: Unified Codec Language Models for Speech Recognition Synthesis and Translation,VioLA,CLM,https://arxiv.org/abs/2305.16107,2023.05.25,v1,2023.05.25,,,,,,,,,,https://scholar.google.com/scholar?cluster=3175310480496805997,69,,,,,,,,2024.09.24
AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec,AudioDec,Codec,https://arxiv.org/abs/2305.16608,2023.05.26,v1,2023.05.26,ICASSP2023,,,,,,,,,,,,,,,,,,2024.09.21
PromptStyle: Controllable Style Transfer for Text-to-Speech with Natural Language Descriptions,PromptStyle,,https://arxiv.org/abs/2305.19522,2023.05.31,v2,2023.06.01,InterSpeech2023,,,,,,,,,https://scholar.google.com/scholar?cluster=14591664902776788259,31,,,TTS,,,,,2024.09.24
SpeechGen: Unlocking the Generative Power of Speech Language Models with Prompts,SpeechGen,,https://arxiv.org/abs/2306.02207,2023.06.03,v3,2023.08.25,,,,,https://github.com/ga642381/SpeechGen,,https://ga642381.github.io/SpeechPrompt/speechgen,,,https://scholar.google.com/scholar?cluster=16623612908585464130,18,,,,,,,,2024.09.23
Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias,Mega-TTS,,https://arxiv.org/abs/2306.03509,2023.06.06,v1,2023.06.06,,,,,,,https://mega-tts.github.io/demo-page,,,,,,,TTS,,,Zero-Shot,,2024.09.24
Simple and Controllable Music Generation,MusicGen,,https://arxiv.org/abs/2306.05284,2023.06.08,v3,2024.01.30,NeurIPS2023Poster,2023.09.22,https://openreview.net/forum?id=jtiQ26sCJi,Training+Inference+Weight,https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md,,https://ai.honu.io/papers/musicgen/,17,X,https://scholar.google.com/scholar?cluster=8869808453563782269,274,,,,,,,,2024.09.23
High-Fidelity Audio Compression with Improved RVQGAN,DAC,Codec,https://arxiv.org/abs/2306.06546,2023.06.11,v2,2023.10.26,NeurIPS2023Spotlight,,,,,,,,,,,,,,,,,,2024.09.21
StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models,StyleTTS2,,https://arxiv.org/abs/2306.07691,2023.06.13,v2,2023.11.20,NeurIPS2023,,,,,,https://styletts2.github.io/,,,,,Diffusion,,TTS,,,,,2024.09.24
AudioPaLM: A Large Language Model That Can Speak and Listen,AudioPaLM,,https://arxiv.org/abs/2306.12925,2023.06.22,v1,2023.06.22,,,,,,,https://google-research.github.io/seanet/audiopalm/examples,,,https://scholar.google.com/scholar?cluster=15189287243147910049,120,,,,,,,,2024.09.23
Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale,Voicebox,,https://arxiv.org/abs/2306.15687,2023.06.23,v2,2023.10.19,NeurIPS2023,,,,,,https://voicebox.metademolab.com/,,,,,,,,,,,,2024.09.21
UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data,UnitSpeech,,https://arxiv.org/abs/2306.16083,2023.06.28,v1,2023.06.28,InterSpeech2023 Oral,,,,,,,,,,,,,TTS,,,,,2024.09.24
Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis,Mega-TTS2,,https://arxiv.org/abs/2307.07218,2023.07.14,v4,2024.04.10,ICLR,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
Llama 2: Open Foundation and Fine-Tuned Chat Models,LLaMA2,LLM,https://arxiv.org/abs/2307.09288,2023.07.18,v2,2023.07.19,,,,,,,,,,https://scholar.google.com/scholar?cluster=10722545090167785628,7996,,,,,,,,2024.09.23
DiffProsody: Diffusion-Based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training,DiffProsody,,https://arxiv.org/abs/2307.16549,2023.07.31,v1,2023.07.31,IEEE@TASLP2024,2024.05.01,https://doi.org/10.1109/TASLP.2024.3395994,,,,,,,https://scholar.google.com/scholar?cluster=13675380349094484432,8,Diffusion,,TTS,,,,,2024.09.24
VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design,VITS2,,https://arxiv.org/abs/2307.16430,2023.07.31,v1,2023.07.31,InterSpeech2023,,,,,,,,,,,,,TTS,,,,,2024.09.24
AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining,AudioLDM2,,https://arxiv.org/abs/2308.05734,2023.08.10,v3,2024.05.11,IEEE@TASLP2024,2024.05.13,https://doi.org/10.1109/TASLP.2024.3399607,,,,,,,https://scholar.google.com/scholar?cluster=9432035319079812866,74,,,,,,,,2024.09.23
SpeechX: Neural Codec Language Model as A Versatile Speech Transformer,SpeechX,CLM,https://arxiv.org/abs/2308.06873,2023.08.14,v2,2024.06.25,IEEE@TASLP2024,2024.06.28,https://doi.org/10.1109/TASLP.2024.3419418,,,,,,,https://scholar.google.com/scholar?cluster=3146656686281147659,47,,,,,,,,2024.09.24
iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN,iSTFTNet2,Vocoder,https://arxiv.org/abs/2308.07117,2023.08.14,v1,2023.08.14,InterSpeech2023,,,,,,https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/,,,,,,,,,,,,2024.09.21
TextrolSpeech: A Text Style Control Speech Corpus with Codec Language Text-to-Speech Models,TextrolSpeech,Dataset,https://arxiv.org/abs/2308.14430,2023.08.28,v1,2023.08.28,,,,,,,https://sall-e.github.io/,,,,,,,TTS,,,,,2024.09.24
RepCodec: A Speech Representation Codec for Speech Tokenization,RepCodec,Codec,https://arxiv.org/abs/2309.00169,2023.08.31,v3,2024.07.22,ACL2024,,,,,,,,,,,,,,,,,,2024.09.21
SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models,SpeechTokenizer,Codec,https://arxiv.org/abs/2308.16692,2023.08.31,v2,2024.01.23,ICLR2024,,,,https://github.com/ZhangXInFD/SpeechTokenizer/,,,,,,,,,,,,,,2024.09.21
PromptTTS 2: Describing and Generating Voices with Text Prompt,PromptTTS2,,https://arxiv.org/abs/2309.02285,2023.09.05,v2,2023.10.12,,,,,,,https://speechresearch.github.io/prompttts2,,,,,,,,,,,,2024.09.21
BigVSAN: Enhancing GAN-Based Neural Vocoders with Slicing Adversarial Network,BigVSAN,Vocoder,https://arxiv.org/abs/2309.02836,2023.09.06,v2,2024.03.25,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10446121,Training+Inference+Weight,https://github.com/sony/bigvsan,,https://takashishibuyasony.github.io/bigvsan/,5,41,https://scholar.google.com/scholar?cluster=2015463515017027949,11,GAN,Least Squares SAN: MelSAN/Parallel WaveSAN/BigVSAN,,LJSpeech/LibriTTS/VCTK,MelGAN/Parallel WaveGAN/BigVGAN,,,2024.09.21
Matcha-TTS: A Fast Tts Architecture with Conditional Flow Matching,Matcha-TTS,,https://arxiv.org/abs/2309.03199,2023.09.06,v2,2024.01.09,ICASSP2024,2024.03.18,,,,,https://shivammehta25.github.io/Matcha-TTS/,5,,https://scholar.google.com/scholar?cluster=3378090602595584425,21,,,,,,,,2024.09.21
VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching,VoiceFlow,,https://arxiv.org/abs/2309.05027,2023.09.10,v3,2024.09.01,ICASSP2024,2024.03.18,,,,,,,,,,,,TTS,,,,,2024.09.24
NExT-GPT: Any-to-Any Multimodal LLM,NExT-GPT,,https://arxiv.org/abs/2309.05519,2023.09.11,v3,2024.06.25,ICML2024Oral,2024.05.02,https://openreview.net/forum?id=NZQkumsNlf,,https://github.com/NExT-GPT/NExT-GPT,,https://next-gpt.github.io,,,https://scholar.google.com/scholar?cluster=10489512657753192238,280,,,,,,,,2024.09.23
FunCodec: A Fundamental Reproducible and Integrable Open-source Toolkit for Neural Speech Codec,FunCodec,Codec,https://arxiv.org/abs/2309.07405,2023.09.14,v2,2023.10.07,ICASSP2024,2024.03.18,,,https://github.com/alibaba-damo-academy/FunCodec,,,,,,,,,,,,,,2024.09.21
SnakeGAN: A Universal Vocoder Leveraging DDSP Prior Knowledge and Periodic Inductive Bias,SnakeGAN,Vocoder,https://arxiv.org/abs/2309.07803,2023.09.14,v1,2023.09.14,ICME2023,,,,,,,,,,,,,,,,,,2024.09.21
Fewer-token Neural Speech Codec with Time-invariant Codes,TiCodec,Codec,https://arxiv.org/abs/2310.00014,2023.09.15,v2,2024.03.11,ICASSP2024,2024.03.18,,,,,,,,,,,,,,,,,2024.09.21
HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise Filter and Inverse Short Time Fourier Transform,HiFTNet,Vocoder,https://arxiv.org/abs/2309.09493,2023.09.18,v1,2023.09.18,,,,,,,,,,,,,,,,,,,2024.09.21
VoiceLDM: Text-to-Speech with Environmental Context,VoiceLDM,,https://arxiv.org/abs/2309.13664,2023.09.24,v1,2023.09.24,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10448268,,,,https://voiceldm.github.io/,,,https://scholar.google.com/scholar?cluster=3766695167763370661,3,,,TTS,,,,,2024.09.24
Qwen Technical Report,Qwen,LLM,https://arxiv.org/abs/2309.16609,2023.09.28,v1,2023.09.28,,,,,,,,,,https://scholar.google.com/scholar?cluster=16379938937265481547,948,,,,,,,,2024.09.23
UniAudio: An Audio Foundation Model Toward Universal Audio Generation,UniAudio,,https://arxiv.org/abs/2310.00704,2023.10.01,v5,2023.12.11,,,,,https://github.com/yangdongchao/UniAudio,,,,,,,,,,,,,,2024.09.21
Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction,MR-HuBERT,Representation,https://arxiv.org/abs/2310.02720,2023.10.04,v2,2024.01.30,ICLR2024Spotlight,2024.01.16,https://openreview.net/forum?id=kUuKFW7DIF,,,,,,,https://scholar.google.com/scholar?cluster=7067681971216917737,15,,,,,,,,2024.09.23
UniverSLU: Universal Spoken Language Understanding for Diverse Tasks with Natural Language Instructions,UniverSLU,,https://arxiv.org/abs/2310.02973,2023.10.04,v2,2024.04.03,ACL@NAACL2024,,https://doi.org/10.18653/v1/2024.naacl-long.151,,,,,,,https://scholar.google.com/scholar?cluster=579811530707940055,9,,,,,,,,2024.09.23
LauraGPT: Listen Attend Understand and Regenerate Audio with GPT,LauraGPT,,https://arxiv.org/abs/2310.04673,2023.10.07,v4,2024.07.03,ICLR2024(Reject),,,,,,,,,,,,,,,,,,2024.09.21
SALMONN: Towards Generic Hearing Abilities for Large Language Models,SALMONN,,https://arxiv.org/abs/2310.13289,2023.10.20,v2,2024.04.08,ICLR2024Poster,2024.01.16,https://openreview.net/forum?id=14rn7HpKVk,,https://github.com/bytedance/SALMONN,,,,,https://scholar.google.com/scholar?cluster=10631342040411306525,111,,,,,,,,2024.09.23
E3 TTS: Easy End-to-End Diffusion-Based Text to Speech,E3 TTS,,https://arxiv.org/abs/2311.00945,2023.11.02,v1,2023.11.02,ASRU2023,,,,,,,,,,,Diffusion,,TTS,,,,,2024.09.24
COSMIC: Data Efficient Instruction-tuning for Speech In-Context Learning,COSMIC,,https://arxiv.org/abs/2311.02248,2023.11.03,v2,2024.06.14,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=1594677896343909949,11,,,,,,,,2024.09.23
Diff-HierVC: Diffusion-Based Hierarchical Voice Conversion with Robust Pitch Generation and Masked Prior for Zero-Shot Speaker Adaptation,Diff-HierVC,VC,https://arxiv.org/abs/2311.04693,2023.11.08,v1,2023.11.08,InterSpeech2023Oral,,https://doi.org/10.21437/Interspeech.2023-817,,,,,,,https://scholar.google.com/scholar?cluster=2502050713465555437,14,,,VC,,,,,2024.09.25
Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models,Qwen-Audio,,https://arxiv.org/abs/2311.07919,2023.11.14,v2,2023.12.21,,,,,https://github.com/QwenLM/Qwen-Audio,,,,,,,,,,,,,,2024.09.21
APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra,APNet2,Vocoder,https://arxiv.org/abs/2311.11545,2023.11.20,v1,2023.11.20,NCMMSC2023,,https://link.springer.com/chapter/10.1007/978-981-97-0601-3_6,,,,,,,https://scholar.google.com/scholar?cluster=360953352732613526,2,,,,,,,,2024.09.21
HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis,HierSpeech++,,https://arxiv.org/abs/2311.12454,2023.11.21,v2,2023.11.27,,,,,https://github.com/sh-lee-prml/HierSpeechpp,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
OpenVoice: Versatile Instant Voice Cloning,OpenVoice,,https://arxiv.org/abs/2312.01479,2023.12.03,v6,2024.08.18,,,,,,,,,,,,,,Voice Cloning,,,,,2024.09.24
Amphion: An Open-Source Audio Music and Speech Generation Toolkit,Amphion,Toolkit,https://arxiv.org/abs/2312.09911,2023.12.15,v3,2024.09.16,SLT2024,,,,,,,,,,,,,,,,,,2024.09.21
SECap: Speech Emotion Captioning with Large Language Model,SECap,,https://arxiv.org/abs/2312.10381,2023.12.16,v3,2023.12.23,AAAI2024,2024.03.24,https://doi.org/10.1609/aaai.v38i17.29902,,,,,,,https://scholar.google.com/scholar?cluster=886143491614630621,11,,,,,,,,2024.09.23
MM-TTS: Multi-Modal Prompt Based Style Transfer for Expressive Text-to-Speech Synthesis,MM-TTS,,https://arxiv.org/abs/2312.10687,2023.12.17,v4,2024.01.31,AAAI2024,,,,,,,,,,,,,TTS,,,,,2024.09.24
emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation,Emotion2Vec,,https://arxiv.org/abs/2312.15185,2023.12.23,v1,2023.12.23,,,,,https://github.com/ddlBoJack/emotion2vec,,,,,https://scholar.google.com/scholar?cluster=16881884378962249456,31,,,,,,,,2024.09.23
Audiobox: Unified Audio Generation with Natural Language Prompts,Audiobox,,https://arxiv.org/abs/2312.15821,2023.12.25,v1,2023.12.25,,,,,,,https://audiobox.metademolab.com/,,,https://scholar.google.com/scholar?cluster=607381426875410665,46,,,,,,,,2024.09.23
ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering,ELLA-V,CLM,https://arxiv.org/abs/2401.07333,2024.01.14,v1,2024.01.14,,,,,,,,,,,,,,,,,,,2024.09.24
FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder,FreGrad,Vocoder,https://arxiv.org/abs/2401.10032,2024.01.18,v1,2024.01.18,ICASSP2024,2024.03.18,,,,,,,,,,Diffusion,,,,,,,2024.09.24
StreamVoice: Streamable Context-Aware Language Modeling for Real-Time Zero-Shot Voice Conversion,StreamVoice,,https://arxiv.org/abs/2401.11053,2024.01.19,v5,2024.07.19,ACL2024,,,,,,,,,https://scholar.google.com/scholar?cluster=2992004731933175452,2,,,VC,,,Zero-Shot,,2024.09.24
ScoreDec: A Phase-preserving High-Fidelity Audio Codec with A Generalized Score-Based Diffusion Post-filter,ScoreDec,Codec,https://arxiv.org/abs/2401.12160,2024.01.22,v1,2024.01.22,ICASSP2024,2024.03.18,,,,,,,,,,Diffusion,,,,,,,2024.09.24
SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation,SpeechGPT-Gen,,https://arxiv.org/abs/2401.13527,2024.01.24,v2,2024.01.25,,,,,https://github.com/0nutation/SpeechGPT,,,,,,,,,,,,,,2024.09.24
VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech,VALL-T,,https://arxiv.org/abs/2401.14321,2024.01.25,v4,2024.01.30,,,,,,,,,,,,,,TTS,,,,,2024.09.21
EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks,EVA-GAN,Vocoder,https://arxiv.org/abs/2402.00892,2024.01.31,v1,2024.01.31,,,,,,,,,,,,,,,,,,,2024.09.21
Natural Language Guidance of High-Fidelity Text-to-Speech with Synthetic Annotations,Parler-TTS (Reproduce),,https://arxiv.org/abs/2402.01912,2024.02.02,v1,2024.02.02,,,,Training,[Reproduce] https://github.com/huggingface/parler-tts,https://huggingface.co/parler-tts/,https://text-description-to-speech.com,6,34,https://scholar.google.com/scholar?cluster=1239973316035890942,17,,,TTS,,,,,2024.09.24
SpiRit-LM: Interleaved Spoken and Written Language Model,SpiRit-LM,,https://arxiv.org/abs/2402.05755,2024.02.08,v1,2024.02.08,,,,,,,,,,https://scholar.google.com/scholar?cluster=7368374930715826231,5,,,,,,,,2024.09.23
GLA-Grad: A Griffin-Lim Extended Waveform Generation Diffusion Model,GLA-Grad,Vocoder,https://arxiv.org/abs/2402.15516,2024.02.09,v1,2024.02.09,ICASSP2024,2024.03.18,,,,,,,,,,Diffusion,,,,,,,2024.09.24
BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data,BASE TTS,,https://arxiv.org/abs/2402.08093,2024.02.12,v2,2024.02.15,,,,,,,,,,,,,,TTS,,,,,2024.09.24
MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech,MobileSpeech,,https://arxiv.org/abs/2402.09378,2024.02.14,v2,2024.06.02,ACL2024,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding,APCodec,Codec,https://arxiv.org/abs/2402.10533,2024.02.16,v1,2024.02.16,TASLP,,,,,,,,,,,,,,,,,,2024.09.21
Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models,Language-Codec,Codec,https://arxiv.org/abs/2402.12208,2024.02.19,v3,2024.04.27,,,,,https://github.com/jishengpeng/languagecodec,,,,,,,,,,,,,,2024.09.21
Advancing Large Language Models to Capture Varied Speaking Styles and Respond Properly in Spoken Conversations,Spoken-LLM,,https://arxiv.org/abs/2402.12786,2024.02.20,v2,2024.05.30,ACL2024,,,,,,,,,https://scholar.google.com/scholar?cluster=13478771408484289779,11,,,,,,,,2024.09.23
PAVITS: Exploring Prosody-aware VITS for End-to-End Emotional Voice Conversion,PAVITS,VC,https://arxiv.org/abs/2403.01494,2024.03.03,v1,2024.03.03,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10446191,,,,,,,https://scholar.google.com/scholar?cluster=7490496767784139657,4,,,VC,,,,,2024.09.24
NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models,NaturalSpeech3,,https://arxiv.org/abs/2403.03100,2024.03.05,v3,2024.04.23,ICML2024Oral,,,,,,,,,https://scholar.google.com/scholar?cluster=11303548308295061158,50,Diffusion,,TTS,,,Zero-Shot,,2024.09.24
RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction,RFWave,Vocoder,https://arxiv.org/abs/2403.05010,2024.03.08,v2,2024.06.02,,,,,,,https://rfwave-demo.github.io/rfwave/,,,https://scholar.google.com/scholar?cluster=14982663450191514510,0,,,,,,,,2024.09.21
HAM-TTS: Hierarchical Acoustic Modeling for Token-Based Zero-Shot Text-to-Speech with Model and Data Scaling,HAM-TTS,,https://arxiv.org/abs/2403.05989,2024.03.09,v1,2024.03.09,,,,,,,,,,https://scholar.google.com/scholar?cluster=5759790909255269709,3,,,TTS,,,Zero-Shot,,2024.09.24
VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild,VoiceCraft,,https://arxiv.org/abs/2403.16973,2024.03.25,v3,2024.06.14,ACL2024,,,,,,,,,,,,,TTS/Speech Editing,,,Zero-Shot,,2024.09.24
CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models,CM-TTS,,https://arxiv.org/abs/2404.00569,2024.03.31,v1,2024.03.31,,,,,https://github.com/XiangLi2022/CM-TTS,,,,,,,,,TTS,,,,,2024.09.24
CLaM-TTS: Improving Neural Codec Language Modeling for Zero-Shot Text-to-Speech,CLaM-TTS,CLM,https://arxiv.org/abs/2404.02781,2024.04.03,v1,2024.04.03,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.21
PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning Based Adaptive Feature-aware Prompt Encoders,PromptCodec,Codec,https://arxiv.org/abs/2404.02702,2024.04.03,v2,2024.04.13,,,,,,,,,,,,,,,,,,,2024.09.21
RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis,RALL-E,CLM,https://arxiv.org/abs/2404.03204,2024.04.04,v2,2024.04.06,,,,,,,,,,,,,,TTS,,,,,2024.09.24
HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks,HyperTTS,,https://arxiv.org/abs/2404.04645,2024.04.06,v1,2024.04.06,,,,,,,,,,,,,,TTS,,,,,2024.09.24
LLaMA-VITS: Enhancing TTS Synthesis with Semantic Awareness,LLaMA-VITS,,https://arxiv.org/abs/2404.06714,2024.04.10,v2,2024.04.12,,,,,,,,,,,,,,TTS,,,,,2024.09.24
OpenELM: An Efficient Language Model Family with Open Training and Inference Framework,OpenELM,LLM,https://arxiv.org/abs/2404.14619,2024.04.22,v2,2024.05.02,ICML2024Poster,,https://openreview.net/forum?id=XNMbTkxroF,,https://github.com/apple/corenet,https://huggingface.co/apple/OpenELM,,,,https://scholar.google.com/scholar?cluster=14435877561062275373,20,,,,,,,,2024.09.23
FlashSpeech: Efficient Zero-Shot Speech Synthesis,FlashSpeech,,https://arxiv.org/abs/2404.14700,2024.04.23,v3,2024.04.25,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
USAT: A Universal Speaker-Adaptive Text-to-Speech Approach,USAT,,https://arxiv.org/abs/2404.18094,2024.04.28,v1,2024.04.28,IEEE@TASLP2024,2024.04.25,https://doi.org/10.1109/TASLP.2024.3393714,,,,,,,https://scholar.google.com/scholar?cluster=9629403301496489583,4,,,TTS,,,,,2024.09.24
MM-TTS: A Unified Framework for Multimodal Prompt-Induced Emotional Text-to-Speech Synthesis,MM-TTS,,https://arxiv.org/abs/2404.18398,2024.04.29,v1,2024.04.29,,,,,,,,,,,,,,TTS,,,,,2024.09.24
SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound,SemantiCodec,Codec,https://arxiv.org/abs/2405.00233,2024.04.30,v1,2024.04.30,,,,,https://haoheliu.github.io/SemantiCodec/,,,,,,,,,,,,,,2024.09.21
Parameter-Efficient Fine-Tuning with Discrete Fourier Transform,FourierFT,PEFT,https://arxiv.org/abs/2405.03003,2024.05.05,v1,2024.05.05,ICML2024Poster,2024.05.02,https://openreview.net/forum?id=XUOHKSsurt,,https://github.com/Chaos96/fourierft,,,,,https://scholar.google.com/scholar?cluster=9524360008038380215,2,,,,,,,,2024.09.23
HILCodec: High Fidelity and Lightweight Neural Audio Codec,HILCodec,Codec,https://arxiv.org/abs/2405.04752,2024.05.08,v1,2024.05.08,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=13917553035782982630,2,,,,,,,,2024.09.24
MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning,MoRA,PEFT,https://arxiv.org/abs/2405.12130,2024.05.20,v1,2024.05.20,,,,,,,,,,https://scholar.google.com/scholar?cluster=12904203795044394481,5,,,,,,,,2024.09.23
VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks,VB-LoRA,PEFT,https://arxiv.org/abs/2405.15179,2024.05.24,v2,2024.05.27,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=5223542161229055516,3,,,,,,,,2024.09.23
ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control with Decoupled Codec,ControlSpeech,,https://arxiv.org/abs/2406.01205,2024.06.03,v1,2024.06.03,,,,,https://github.com/jishengpeng/ControlSpeech,,,,,,,,,,,,Zero-Shot,,2024.09.24
BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation,BiVocoder,Vocoder,https://arxiv.org/abs/2406.02162,2024.06.04,v1,2024.06.04,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-255,,,,,,,,,,,,,,,,2024.09.21
Seed-TTS: A Family of High-Quality Versatile Speech Generation Models,Seed-TTS,,https://arxiv.org/abs/2406.02430,2024.06.04,v1,2024.06.04,[Unavailable],[Unavailable],[Unavailable],,,,https://bytedancespeech.github.io/seedtts_tech_report,,,https://scholar.google.com/scholar?cluster=2383691307056980942,12,,,,,,,,2024.09.23
SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models,SimpleSpeech,,https://arxiv.org/abs/2406.02328,2024.06.04,v3,2024.06.14,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1392,,,,,,,,,Diffusion,,TTS,,,,NAR,2024.09.24
LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes,LiveSpeech,,https://arxiv.org/abs/2406.02897,2024.06.05,v2,2024.06.10,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=13829823968934264570,1,,,TTS,,,Zero-Shot,AR,2024.09.24
Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis,Small-E,,https://arxiv.org/abs/2406.04467,2024.06.06,v2,2024.06.11,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-508,,https://github.com/theodorblackbird/lina-speech,,,,,,,,,TTS,,,,,2024.09.24
XTTS: A Massively Multilingual Zero-Shot Text-to-Speech Model,XTTS,,https://arxiv.org/abs/2406.04904,2024.06.07,v1,2024.06.07,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2016,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers,VALL-E 2,CLM,https://arxiv.org/abs/2406.05370,2024.06.08,v2,2024.06.17,,,,,,,https://aka.ms/valle2,,,,,,,TTS,,,Zero-Shot,,2024.09.24
WenetSpeech4TTS: A 12800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark,WenetSpeech4TTS,Dataset,https://arxiv.org/abs/2406.05763,2024.06.09,v3,2024.06.19,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2343,,,,,,,,,,,,,,,,2024.09.21
mHuBERT-147: A Compact Multilingual HuBERT Model,mHuBERT-147,Representation,https://arxiv.org/abs/2406.06371,2024.06.10,v4,2024.08.23,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-938,,,,,,,https://scholar.google.com/scholar?cluster=12861582762998629338,1,,,,,,,,2024.09.23
JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis,JenGAN,Trick,https://arxiv.org/abs/2406.06111,2024.06.10,v1,2024.06.10,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1447,,,,,,,,,,HiFi-GAN/Avocodo/BigVGAN+JenGAN(Training Strategy),TTS,LJSpeech,HiFi-GAN/Avocodo/BigVGAN,,,2024.09.24
Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation,Single-Codec,Codec,https://arxiv.org/abs/2406.07422,2024.06.11,v1,2024.06.11,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1559,,,,,,,,,,,,,,,,2024.09.21
ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37 Emotion Datasets,ExHuBERT,Representation,https://arxiv.org/abs/2406.10275,2024.06.11,v1,2024.06.11,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-280,,,https://huggingface.co/amiriparian/ExHuBERT,,,,[Unavailable],1,,,,,,,,2024.09.23
LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts for Text-to-Speech and Style Captioning,LibriTTS-P,Dataset,https://arxiv.org/abs/2406.07969,2024.06.12,v1,2024.06.12,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-692,,,,,,,,,,,TTS,,,,,2024.09.24
FreeV: Free Lunch for Vocoders Through Pseudo Inversed Mel Filter,FreeV,Vocoder,https://arxiv.org/abs/2406.08196,2024.06.12,v1,2024.06.12,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1435,,https://github.com/BakerBunker/FreeV,,,5,,https://scholar.google.com/scholar?cluster=13731432507109093105,1,,,,,,,,2024.09.21
TokSing: Singing Voice Synthesis Based on Discrete Tokens,TokSing,,https://arxiv.org/abs/2406.08416,2024.06.12,v2,2024.06.20,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2360,,,,,,,,,,,,,,,,2024.09.21
VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment,VALL-E R,,https://arxiv.org/abs/2406.07855,2024.06.12,v1,2024.06.12,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
Speech ReaLLM: Real-Time Streaming Speech Recognition with Multimodal LLMs by Teaching the Flow of Time,Speech ReaLLM,,https://arxiv.org/abs/2406.09569,2024.06.13,v1,2024.06.13,,,,,,,,,,[Unavailable],3,,,,,,,,2024.09.23
Period Singer: Integrating Periodic and Aperiodic Variational Autoencoders for Natural-Sounding End-to-End Singing Voice Synthesis,Period Singer,,https://arxiv.org/abs/2406.09894,2024.06.14,v2,2024.09.11,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1720,,,,,,,[Unavailable],0,,,,,,,,2024.09.23
UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner,UniAudio 1.5,,https://arxiv.org/abs/2406.10056,2024.06.14,v1,2024.06.14,,,,,,,,,,,,,,,,,Few-Shot,,2024.09.24
How Should We Extract Discrete Audio Tokens from Self-Supervised Models?,[Unavailable],,https://arxiv.org/abs/2406.10735,2024.06.15,v1,2024.06.15,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2135,,,,,,,[Unavailable],3,,,,,,,,2024.09.23
DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer,DiTTo-TTS,,https://arxiv.org/abs/2406.11427,2024.06.17,v1,2024.06.17,,,,,,,https://ditto-tts.github.io/,,,,,Diffusion,,TTS,,,Zero-Shot,,2024.09.24
Articulatory Encodec: Coding Speech through Vocal Tract Kinematics,Articulatory Encodec,Codec,https://arxiv.org/abs/2406.12998,2024.06.18,v2,2024.08.21,,,,,,,,,,,,,,,,,,,2024.09.21
TacoLM: GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers,TacoLM,CLM,https://arxiv.org/abs/2406.15752,2024.06.22,v1,2024.06.22,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1531,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
Improving Robustness of LLM-Based Speech Synthesis by Learning Monotonic Alignment,T5-TTS,,https://arxiv.org/abs/2406.17957,2024.06.25,v1,2024.06.25,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-335,,,,,,,https://scholar.google.com/scholar?cluster=5261611192106137747,2,,,TTS,,,,,2024.09.24
E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS,E2 TTS,,https://arxiv.org/abs/2406.18009,2024.06.26,v2,2024.09.12,SLT2024,,,,,,https://aka.ms/e2tts/,,,,,,,TTS,,,Zero-Shot,NAR,2024.09.24
DEX-TTS: Diffusion-Based EXpressive Text-to-Speech with Style Modeling on Time Variability,DEX-TTS,,https://arxiv.org/abs/2406.19135,2024.06.27,v1,2024.06.27,,,,,,,,,,,,Diffusion,,TTS,,,,,2024.09.24
BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5,BESTOW,,https://arxiv.org/abs/2406.19954,2024.06.28,v1,2024.06.28,,,,,,,,,,,,,,,,,,,2024.09.21
FLY-TTS: Fast Lightweight and High-Quality End-to-End Text-to-Speech Synthesis,FLY-TTS,,https://arxiv.org/abs/2407.00753,2024.06.30,v1,2024.06.30,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1435,,,,,,,,,,,TTS,,,,,2024.09.24
Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference Optimization,RIO,,https://arxiv.org/abs/2407.02243,2024.07.02,v1,2024.07.02,,,,,,,,,,,,,,TTS,,,Zero-Shot,,2024.09.24
FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction between Humans and LLMs,FunAudioLLM,,https://arxiv.org/abs/2407.04051,2024.07.04,v3,2024.07.11,,,,,,,,,,https://scholar.google.com/scholar?cluster=11999048316846931351,2,,,,,,,,2024.09.23
FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-Based Vocoder,FA-GAN,Vocoder,https://arxiv.org/abs/2407.04575,2024.07.05,v1,2024.07.05,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-380,,,,,,,,,,,,,,,,2024.09.21
LoRA-GA: Low-Rank Adaptation with Gradient Approximation,LoRA-GA,PEFT,https://arxiv.org/abs/2407.05000,2024.07.06,v2,2024.07.16,,,,,https://github.com/Outsider565/LoRA-GA,,,,,https://scholar.google.com/scholar?cluster=6092529847550522223,0,,,,,,,,2024.09.23
CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer Based on Supervised Semantic Tokens,CosyVoice,,https://arxiv.org/abs/2407.05407,2024.07.07,v2,2024.07.09,,,,,,,,,,https://scholar.google.com/scholar?cluster=16233573129404678819,8,,,TTS,,,Zero-Shot,,2024.09.24
AffectGPT: Dataset and Framework for Explainable Multimodal Emotion Recognition,AffectGPT,,https://arxiv.org/abs/2407.07653,2024.07.10,v1,2024.07.10,[Unavailable],[Unavailable],[Unavailable],,https://github.com/zeroQiaoba/AffectGPT,,,,,https://scholar.google.com/scholar?cluster=6374429304315607405,4,,,,,,,,2024.09.23
Autoregressive Speech Synthesis without Vector Quantization,MELLE,,https://arxiv.org/abs/2407.08551,2024.07.11,v1,2024.07.11,,,,,,,https://aka.ms/melle,,,,,,,TTS,,,,AR,2024.09.24
Qwen2-Audio Technical Report,Qwen2-Audio,,https://arxiv.org/abs/2407.10759,2024.07.15,v1,2024.07.15,,,,,https://github.com/QwenLM/Qwen2-Audio,,,,,https://scholar.google.com/scholar?cluster=13259138701210870695,12,,,,,,,,2024.09.23
TTSDS: Text-to-Speech Distribution Score,TTSDS,,https://arxiv.org/abs/2407.12707,2024.07.17,v2,2024.07.22,SLT2024,,,,,,,,,,,,,TTS,,,,,2024.09.24
MSceneSpeech: A Multi-Scene Speech Dataset for Expressive Speech Synthesis,MSceneSpeech,Dataset,https://arxiv.org/abs/2407.14006,2024.07.19,v1,2024.07.19,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-266,,,,,,,,,,,TTS,,,,,2024.09.24
LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models,LLaST,,https://arxiv.org/abs/2407.15415,2024.07.22,v1,2024.07.22,ACL@Fingdings2024,,https://aclanthology.org/2024.findings-acl.416,,https://github.com/openaudiolab/LLaST,,,,,https://scholar.google.com/scholar?cluster=15668197912305572523,2,,,,,,,,2024.09.23
LoRA-Pro: Are Low-Rank Adapters Properly Optimized?,LoRA-Pro,PEFT,https://arxiv.org/abs/2407.18242,2024.07.25,v1,2024.07.25,,,,,,,,,,https://scholar.google.com/scholar?cluster=5563318481080163149,0,,,,,,,,2024.09.23
SuperCodec: A Neural Speech Codec with Selective Back-Projection Network,SuperCodec,Codec,https://arxiv.org/abs/2407.20530,2024.07.30,v1,2024.07.30,ICASSP2024,2024.03.18,,,,,,,,,,,,,,,,,2024.09.21
The Llama 3 Herd of Models,LLaMA3,LLM,https://arxiv.org/abs/2407.21783,2024.07.31,v2,2024.08.15,,,,,,,,,,https://scholar.google.com/scholar?cluster=4075166335978822586,164,,,,,,,,2024.09.23
Language Model Can Listen While Speaking,LSLM,,https://arxiv.org/abs/2408.02622,2024.08.05,v1,2024.08.05,,,,,,,https://ddlbojack.github.io/LSLM,,,,,,,,,,,,2024.09.21
StreamVoice+: Evolving into End-to-end Streaming Zero-shot Voice Conversion,StreamVoice+,,https://arxiv.org/abs/2408.02178,2024.08.05,v1,2024.08.05,,,,,,,,,,https://scholar.google.com/scholar?cluster=358099860326856545,0,,,VC,,,Zero-Shot,,2024.09.24
VITA: Towards Open-Source Interactive Omni Multimodal LLM,VITA,MLLM,https://arxiv.org/abs/2408.05211,2024.08.09,v2,2024.09.10,,,,Training+Inference+Weight,https://github.com/VITA-MLLM/VITA,https://huggingface.co/VITA-MLLM,https://vita-home.github.io/,,,https://scholar.google.com/scholar?cluster=12137474138057550166,,,,,,,,,2024.09.24
VNet: A GAN-Based Multi-Tier Discriminator Network for Speech Synthesis Vocoders,VNet,Vocoder,https://arxiv.org/abs/2408.06906,2024.08.13,v1,2024.08.13,SMC2024,,,,,,,,,,,,G:FCN+MRF D:MTD+MPD,TTS,LibriTTS/LJSpeech,WaveGlow/Parallel WaveGAN/HiFi-GAN/BigVGAN,,,2024.09.24
Neural Speech and Audio Coding,[Unavailable],,https://arxiv.org/abs/2408.06954,2024.08.13,v1,2024.08.13,IEEE@SPM,,,,,,,,,https://scholar.google.com/scholar?cluster=5959560004447120901,1,,,,,,,,2024.09.23
PRESENT: Zero-Shot Text-to-Prosody Control,PRESENT,,https://arxiv.org/abs/2408.06827,2024.08.13,v1,2024.08.13,,,,,,,,,,https://scholar.google.com/scholar?cluster=980654330328177271,0,,,,,,Zero-Shot,,2024.09.24
PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation,PeriodWave,Vocoder,https://arxiv.org/abs/2408.07547,2024.08.14,v1,2024.08.14,[Unavailable],[Unavailable],[Unavailable],ReadMe,https://github.com/sh-lee-prml/PeriodWave,[Unavailable],https://periodwave.github.io/demo/,24,X,https://scholar.google.com/scholar?cluster=14553664054487650270,1,FlowMatching,Period-Aware Flow Matching Estimator,,LJSpeech/LibriTTS,HiFI-GAN/BigVGAN/PriorGrad/FreGrad,,,2024.09.24
Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization,PeriodWave-Turbo,Vocoder,https://arxiv.org/abs/2408.08019,2024.08.15,v1,2024.08.15,[Unavailable],[Unavailable],[Unavailable],ReadMe,https://github.com/sh-lee-prml/PeriodWave,[Unavailable],https://periodwave-turbo.github.io/audio-demo/,9,X,https://scholar.google.com/scholar?cluster=4002945941867933119,0,FlowMatching,PeriodWave+Few-Step Generator,,LJSpeech/LibriTTS,HiFI-GAN/BigVSAN/BigVGAN/PriorGrad/PeriodWave/UnivNet/Vocos,,,2024.09.24
SSL-TTS: Leveraging Self-Supervised Embeddings and kNN Retrieval for Zero-Shot Multi-speaker TTS,SSL-TTS,,https://arxiv.org/abs/2408.10771,2024.08.20,v1,2024.08.20,Submitted to SPL,,,,,,,,,,,,,TTS,,,Zero-Shot/Multi-Speaker,,2024.09.24
EELE: Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech,EELE,,https://arxiv.org/abs/2408.10852,2024.08.20,v1,2024.08.20,,,,,,,,,,,,,,TTS,,,,,2024.09.24
VoiceX: A Text-to-Speech Framework for Custom Voices,VoiceX,,https://arxiv.org/abs/2408.12170,2024.08.22,v1,2024.08.22,,,,,,,,,,,,,,TTS,,,,,2024.09.24
SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description,SpeechCraft,Dataset,https://arxiv.org/abs/2408.13608,2024.08.24,v1,2024.08.24,ACM MultiMedia2024,,,,,,,,,,,,,,,,,,2024.09.21
SimpleSpeech 2: Towards Simple and Efficient Text-to-Speech with Flow-Based Scalar Latent Transformer Diffusion Models,SimpleSpeech2,,https://arxiv.org/abs/2408.13893,2024.08.25,v2,2024.08.28,Submitted to TASLP,,,,,,,,,,,Flow/Diffusion,,TTS,,,,,2024.09.24
DualSpeech: Enhancing Speaker-Fidelity and Text-Intelligibility Through Dual Classifier-Free Guidance,DualSpeech,,https://arxiv.org/abs/2408.14423,2024.08.26,v2,2024.08.27,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2005,,,,,,,,,,,,,,,,2024.09.21
VoiceTailor: Lightweight Plug-In Adapter for Diffusion-Based Personalized Text-to-Speech,VoiceTailor,,https://arxiv.org/abs/2408.14739,2024.08.27,v2,2024.08.28,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-63,,,,,,,,,Diffusion,,TTS,,,,,2024.09.24
Mini-Omni: Language Models Can Hear Talk While Thinking in Streaming,Mini-Omni,MLLM,https://arxiv.org/abs/2408.16725,2024.08.27,v2,2024.08.30,,,,,https://github.com/gpt-omni/mini-omni,,,,,,,,,,,,,,2024.09.21
VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling,VoxInstruct,CLM,https://arxiv.org/abs/2408.15676,2024.08.28,v1,2024.08.28,,,,,,,,,,,,,,,,,,,2024.09.24
WavTokenizer: An Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling,WavTokenizer,Codec,https://arxiv.org/abs/2408.16532,2024.08.29,v1,2024.08.29,,,,,,,,,,,,,,,,,,,2024.09.21
Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model,X-Codec,Codec,https://arxiv.org/abs/2408.17175,2024.08.30,v2,2024.09.19,,,,,https://github.com/zhenye234/xcodec,,https://x-codec-audio.github.io/,,,,,,,,,,,,2024.09.21
SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection,SelectTTS,,https://arxiv.org/abs/2408.17432,2024.08.30,v1,2024.08.30,Submitted to SPL,,,,,,,,,,,,,,,,,,2024.09.21
Sample-Efficient Diffusion for Text-to-Speech Synthesis,SESD,,https://arxiv.org/abs/2409.03717,2024.09.01,v1,2024.09.01,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2235,,,,,,,,,Diffusion,,TTS,,,,,2024.09.24
SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis,SoCodec,Codec,https://arxiv.org/abs/2409.00933,2024.09.02,v1,2024.09.02,SLT2024,,,,,,,,,,,,,TTS,,,,,2024.09.24
vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders,Vec2Wav2.0,VC,https://arxiv.org/abs/2409.01995,2024.09.03,v2,2024.09.11,Submitted to ICASSP2025,,,,,,https://cantabile-kwok.github.io/vec2wav2/,5,40,https://scholar.google.com/scholar?cluster=7879906795829704534,0,,Follow CTX-Vec2Wav/WavLM+VQ-Wav2Vec+Conformer+G:BigVGAN+D:MSD+MPD,VC,LibriTTS,YourTTS/DiffVC/Diff-HierVC/UUVC/FACodec,,,2024.09.24
LAST: Language Model Aware Speech Tokenization,LAST,,https://arxiv.org/abs/2409.03701,2024.09.05,v1,2024.09.05,,,,,,,,,,https://scholar.google.com/scholar?cluster=17232524767389669426,1,,,,,,,,2024.09.23
Investigating Neural Audio Codecs for Speech Language Model-Based Speech Generation,[Unavailable],,https://arxiv.org/abs/2409.04016,2024.09.06,v1,2024.09.06,SLT2024,[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=342682668474965838,0,,,,,,,,2024.09.25
BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec,BigCodec,Codec,https://arxiv.org/abs/2409.05377,2024.09.09,v1,2024.09.09,,,,Inference+Weight,https://github.com/Aria-K-Alethia/BigCodec,,https://aria-k-alethia.github.io/bigcodec-demo/,,,,,,,,,,,,2024.09.21
LLaMA-Omni: Seamless Speech Interaction with Large Language Models,LLaMA-Omni,MLLM,https://arxiv.org/abs/2409.06666,2024.09.10,v1,2024.09.10,,,,,https://github.com/ictnlp/LLaMA-Omni,,,,,,,,,,,,,,2024.09.21
SSR-Speech: Towards Stable Safe and Robust Zero-Shot Text-Based Speech Editing and Synthesis,SSR-Speech,,https://arxiv.org/abs/2409.07556,2024.09.11,v1,2024.09.11,Submitted to ICASSP2025,,,Training+Inference+Weight,https://github.com/WangHelin1997/SSR-Speech,,https://WangHelin1997.github.io/SSR-Speech-Demo,5,35,,,,,TTS/Speech Editing,,,Zero-Shot,,2024.09.24
Super Monotonic Alignment Search,Super-MAS,Alignment,https://arxiv.org/abs/2409.07704,2024.09.12,v1,2024.09.12,,,,,,,,,,https://scholar.google.com/scholar?cluster=911413713631039962,0,,,,,,,,2024.09.24
E1 TTS: Simple and Fast Non-Autoregressive TTS,E1 TTS,,https://arxiv.org/abs/2409.09351,2024.09.14,v1,2024.09.14,,,,,,,,,,https://scholar.google.com/scholar?cluster=14501484319113297136,0,,,,,,,NAR,2024.09.23
Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation,CoFi-Speech,CLM,https://arxiv.org/abs/2409.11630,2024.09.18,v1,2024.09.18,,,,,,,https://hhguo.github.io/DemoCoFiSpeech,5,30,,0,,CoFi-Codec (SoCodec [OPQ])+CoFi-LM-Cos/SoS+BigVGAN,TTS,WenetSpeech4TTS,VALL-E/CosyVoice/SoCodec-TTS,Mel2Code/BPE/Multi-Scale,,2024.09.23
Low Frame-rate Speech Codec: A Codec Designed for Fast High-quality Speech LLM Training and Inference,LFSC,Codec,https://arxiv.org/abs/2409.12117,2024.09.18,v1,2024.09.18,Submitted to ICASSP2025,,,,https://github.com/NVIDIA/NeMo,,https://edresson.github.io/Low-Frame-rate-Speech-Codec/,5,40,,,,,,,,,,2024.09.21
WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification,WMCodec,Codec,https://arxiv.org/abs/2409.12121,2024.09.18,v1,2024.09.18,[Unavailable],[Unavailable],[Unavailable],,,,,,,https://scholar.google.com/scholar?cluster=11399932079667190471,0,,,,,,,,2024.09.23
NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization,NDVQ,Codec,https://arxiv.org/abs/2409.12717,2024.09.19,v1,2024.09.19,,,,,,,,,,[Unavailable],0,,,,,,,,2024.09.23
MuCodec: Ultra Low-Bitrate Music Codec,MuCodec,Codec,https://arxiv.org/abs/2409.13216,2024.09.20,v1,2024.09.20,,,,Readme,https://github.com/xuyaoxun/MuCodec,,https://xuyaoxun.github.io/MuCodec_demo/,6,39,,,,,,,,,,2024.09.23
