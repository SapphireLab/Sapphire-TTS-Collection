Title,Abbreviation,Class,ArXiv,ArXiv v1 Date,ArXiv New Version,ArXiv New Date,Publication,Publication Date,DOI,OpenSource,Official Code,HuggingFace,Demo Page,Page Number,Cite Number,Google Scholar,Cited by,Theory,Architecture,Tasks,Datasets,Compare Methods,Tags,AR/NAR,Update Time
Adam: A Method for Stochastic Optimization,Adam,Optimizer,https://arxiv.org/abs/1412.6980,2014.12.22,v9,2017.01.30,ICLR2015,,,,,,,,,,,,,,,,,,2024.09.21
Batch Normlization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,BatchNormalization,Trick,https://arxiv.org/abs/1502.03167,2015.02.11,v3,2015.03.02,,,,,,,,,,,,,,,,,,,2024.09.21
WORLD: A Vocoder-Based High-Quality Speech Synthesis System for Real-Time Applications,WORLD,Vocoder,,2016.07.01,,2016.07.01,IEICE TransInf2016,2016.07.01,https://doi.org/10.1587/transinf.2015EDP7457,,,,,,,,,,,,,,,,2024.09.21
WaveNet: A Generative Model for Raw Audio,WaveNet,Vocoder,https://arxiv.org/abs/1609.03499,2016.09.12,v2,2016.09.19,,,,,,,,,,,,,,,,,,AR,2024.09.21
SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,SampleRNN,Vocoder,https://arxiv.org/abs/1612.07837,2016.12.22,v2,2017.02.11,ICLR2017,,,,,,,,,,,,,,,,,,2024.09.21
,Char2Wav,,,2017.02.18,,,,,,,,,,,,,,,,,,,,,
,DeepVoice,,https://arxiv.org/abs/1702.07825,2017.02.25,,,,,,,,,,,,,,,,,,,,,
Tacotron: Towards End-to-End Speech Synthesis,Tacotron,,https://arxiv.org/abs/1703.10135,2017.03.29,v2,2017.04.06,InterSpeech2017,,,,,,,,,,,,,,,,,,2024.09.21
,DeepVoice2,,,2017.05.24,,,,,,,,,,,,,,,,,,,,,
VoiceLoop: Voice Fitting and Synthesis via a Phonological Loop,VoiceLoop,,https://arxiv.org/abs/1707.06588,2017.07.20,v3,2018.02.01,ICLR2018Poster,2018.02.16,https://openreview.net/forum?id=SkFAWax0-,,https://github.com/facebookarchive/loop,,,,,https://scholar.google.com/scholar?cluster=14159878382438547497,,,,,,,,,2024.09.21
Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning,DeepVoice3,,https://arxiv.org/abs/1710.07654,2017.10.20,v3,2018.02.22,ICLR2018Poster,2018.02.16,https://openreview.net/forum?id=HJtEm4p6Z,,,,,,,https://scholar.google.com/scholar?cluster=1828409622662260131,,,,,,,,,2024.09.21
Neural Discrete Representation Learning,VQ-VAE,Trick,https://arxiv.org/abs/1711.00937,2017.11.02,v2,2018.05.30,,,,,,,,,,,,,,,,,,,2024.09.21
Decoupled Weight Decay Regularization,AdamW,Optimizer,https://arxiv.org/abs/1711.05101,2017.11.14,v3,2019.01.04,ICLR2019,,,,,,,,,,,,,,,,,,2024.09.21
Parallel WaveNet: Fast High-Fidelity Speech Synthesis,Parallel WaveNet,Vocoder,https://arxiv.org/abs/1711.10433,2017.11.28,v1,2017.11.28,,,,,,,,,,,,,,,,,,,2024.09.21
Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions,Tacotron2,,https://arxiv.org/abs/1712.05884,2017.12.16,v2,2018.02.16,ICASSP2018,,,,,,,,,,,,,,,,,,2024.09.21
Adversarial Audio Synthesis,WaveGAN,Vocoder,https://arxiv.org/abs/1802.04208,2018.02.12,v3,2019.02.09,ICLR2019,,,,,,,,,,,,,,,,,,2024.09.21
Efficient Neural Audio Synthesis,WaveRNN,Vocoder,https://arxiv.org/abs/1802.08435,2018.02.23,v2,2018.06.25,,,,,,,,,,,,,,,,,,,2024.09.21
Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis,SV2TTS,,https://arxiv.org/abs/1806.04558,2018.06.12,v4,2019.01.02,NeurIPS2018,,,,,,,,,,,,,,,,,,
,CPC,,,2018.07.10,,,,,,,,,,,,,,,,,,,,,
,ClariNet,,,2018.07.19,,,,,,,,,,,,,,,,,,,,,
Neural Speech Synthesis with Transformer Network,Transformer TTS,,https://arxiv.org/abs/1809.08895,2018.09.19,v3,2019.01.30,,,,,,,,,,,,,,,,,,,2024.09.21
LPCNet: Improving Neural Speech Synthesis Through Linear Prediction,LPCNet,Vocoder,https://arxiv.org/abs/1810.11846,2018.10.28,v2,2019.02.19,ICASSP2019,,,,,,,,,,,,,,,,,,2024.09.21
WaveGlow: A Flow-based Generative Network for Speech Synthesis,WaveGlow,Vocoder,https://arxiv.org/abs/1811.00002,2018.10.31,v1,2018.10.31,,,,,,,,,,,,,,,,,,,2024.09.21
FloWaveNet : A Generative Flow for Raw Audio,FloWaveNet,Vocoder,https://arxiv.org/abs/1811.02155,2018.11.06,v3,2019.05.20,ICML2019,,,,,,,,,,,,,,,,,,2024.09.21
,Flow++,,,2019.02.01,,,,,,,,,,,,,,,,,,,,,
GANSynth: Adversarial Neural Audio Synthesis,GANSynth,Vocoder,https://arxiv.org/abs/1902.08710,2019.02.23,v2,2019.04.15,,,,,,,,,,,,,,,,,,,2024.09.21
LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech,LibriTTS,Dataset,https://arxiv.org/abs/1904.02882,2019.04.05,v1,2019.04.05,InterSpeech2019,,,,,,,,,,,,,,,,,,2024.09.21
Wav2Vec: Unsupervised Pre-Training for Speech Recognition,Wav2Vec,Representation,https://arxiv.org/abs/1904.05862,2019.04.11,v4,2019.09.11,InterSpeech,,,,https://github.com/pytorch/fairseq,,,,,,,,,,,,,,2024.09.21
Non-Autoregressive Neural Text-to-Speech,ParaNet,,https://arxiv.org/abs/1905.08459,2019.05.21,v3,2020.06.29,ICML2020,,,,,,,,,,,,,,,,,,2024.09.21
FastSpeech: Fast Robust and Controllable Text to Speech,FastSpeech,,https://arxiv.org/abs/1905.09263,2019.05.22,v5,2019.11.20,NeurIPS2019,,,,,,,,,,,,,,,,,,2024.09.21
High Fidelity Speech Synthesis with Adversarial Networks,GAN-TTS,Vocoder,https://arxiv.org/abs/1909.11646,2019.09.25,v2,2019.09.26,,,,,,,,,,,,,,,,,,,2024.09.21
MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis,MelGAN,Vocoder,https://arxiv.org/abs/1910.06711,2019.10.08,v3,2019.12.09,,,,,,,,,,,,,,,,,,,2024.09.21
,VQ-Wav2Vec,Representation,,2019.10.12,,,,,,,,,,,,,,,,,,,,,
WaveFlow: A Compact Flow-based Model for Raw Audio,WaveFlow,Vocoder,https://arxiv.org/abs/1912.01219,2019.12.03,v4,2020.06.24,ICML2020,,,,,,,,,,,,,,,,,,2024.09.21
AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment,AlignTTS,,https://arxiv.org/abs/2003.01950,2020.03.04,v1,2020.03.04,ICASSP2020,,,,,,,,,https://scholar.google.com/scholar?cluster=1600438380822500245,86,,,,,,,,2024.09.21
Flow-TTS: A non-autoregressive network for text to speech based on flow,Flow-TTS,,,2020.04.09,,2020.04.09,ICASSP2020,2020.04.09,https://doi.org/10.1109/ICASSP40776.2020.9054484,,,,,,,https://scholar.google.com/scholar?cluster=7765078935283625839,134,Flow,,,,,,NAR,2024.09.21
Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis,Flowtron,,https://arxiv.org/abs/2005.05957,2020.05.12,v3,2020.07.16,ICLR2021Poster,2021.01.12,https://openreview.net/forum?id=Ig53hpHxS4,,https://github.com/NVIDIA/flowtron,,,10,,,170,,,,,,,,2024.09.21
JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment,JDI-T,,https://arxiv.org/abs/2005.07799,2020.05.15,v3,2020.10.05,InterSpeech2020,,,,,,,,,,,,,,,,,,2024.09.21
Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search,Glow-TTS,,https://arxiv.org/abs/2005.11129,2020.05.22,v2,2020.10.23,NeurIPS2020,,,,,,,,,,,Flow,,,,,,,2024.09.21
Language Models are Few-Shot Learners,GPT-3,LLM,https://arxiv.org/abs/2005.14165,2020.05.28,v4,2020.07.22,,,,,,,,,,,,,,,,,,,
End-to-End Adversarial Text-to-Speech,EATS,,https://arxiv.org/abs/2006.03575,2020.06.05,v3,2021.03.17,ICLR2021Oral,,,,,,,,,,,,,,,,,,2024.09.21
MultiSpeech: Multi-Speaker Text to Speech with Transformer,MultiSpeech,,https://arxiv.org/abs/2006.04664,2020.06.08,v2,2022.08.01,,,,,,,,,,,,,,,,,,,2024.09.21
FastSpeech 2: Fast and High-Quality End-to-End Text to Speech,FastSpeech2,,https://arxiv.org/abs/2006.04558,2020.06.08,v8,2022.08.08,ICLR2021,,,,,,https://speechresearch.github.io/fastspeech2/,,,,,,,,,,,,2024.09.21
NanoFlow: Scalable Normalizing Flows with Sublinear Parameter Complexity,NanoFlow,Vocoder,https://arxiv.org/abs/2006.06280,2020.06.11,v4,2020.10.23,NeurIPS2020,,,,https://github.com/L0SG/NanoFlow,,,,,,,,,,,,,,2024.09.21
FastPitch: Parallel Text-to-speech with Pitch Prediction,FastPitch,,https://arxiv.org/abs/2006.06873,2020.06.11,v2,2021.02.16,ICASSP2021,,,,,,,,,,,,,,,,,,2024.09.21
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,Wav2Vec 2.0,Representation,https://arxiv.org/abs/2006.11477,2020.06.20,v3,2020.10.22,NeurIPS2020,,,,,,,,,,,,,,,,,,2024.09.21
VocGAN: A High-Fidelity Real-time Vocoder with a Hierarchically-nested Adversarial Network,VocGAN,Vocoder,https://arxiv.org/abs/2007.15256,2020.07.30,v1,2020.07.30,InterSpeech2020,,,,,,,,,,,,,,,,,,2024.09.21
SpeedySpeech: Efficient Neural Speech Synthesis,SpeedySpeech,,https://arxiv.org/abs/2008.03802,2020.08.09,v1,2020.08.09,InterSpeech2020,,,,,,,,,,,,,,,,,,2024.09.21
WaveGrad: Estimating Gradients for Waveform Generation,WaveGrad,Vocoder,https://arxiv.org/abs/2009.00713,2020.09.02,v2,2020.10.09,ICLR2021Poster,,,,,,https://wavegrad.github.io/,,,https://scholar.google.com/scholar?cluster=9166479714962885889,724,,,,,,,,2024.09.21
DiffWave: A Versatile Diffusion Model for Audio Synthesis,DiffWave,Vocoder,https://arxiv.org/abs/2009.09761,2020.09.21,v3,2021.03.30,ICLR2021Oral,,,,,,,,,https://scholar.google.com/scholar?cluster=8775132726722534164,1176,,,,,,,,2024.09.21
HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis,HiFi-GAN,Vocoder,https://arxiv.org/abs/2010.05646,2020.10.12,v2,2020.10.23,NeurIPS2020,,,,https://github.com/jik876/hifi-gan,,,,,,,,,,,,,,2024.09.21
Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech,BVAE-TTS,,,2021.01.13,,2021.01.13,ICLR2021Poster,2021.01.13,https://openreview.net/forum?id=o3iritJHLfO,,https://github.com/LEEYOONHYUNG/BVAE-TTS,,,,,,,,,,,,,,2024.09.21
On Generative Spoken Language Modeling from Raw Audio,GSLM,,https://arxiv.org/abs/2102.01192,2021.02.01,v2,2021.09.09,TACL2021,2022.01.04,https://transacl.org/index.php/tacl/article/view/3241,,https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm,,,19,,https://scholar.google.com/scholar?cluster=10339951252730122651,304,,CPC/Wav2Vec2.0/HuBERT+Transformer+Tacotron2,Acoustic Unit Discovery/Spoken Language Modeling/Discrete Speech Resynthesis/Speech Generation,,,,,2024.09.21
LightSpeech: Lightweight and Fast Text to Speech with Neural Architecture Search,LightSpeech,,https://arxiv.org/abs/2102.04040,2021.02.08,v1,2021.02.08,ICASSP2021,,,,,,https://speechresearch.github.io/lightspeech,,,,,,,,,,,,2024.09.21
AdaSpeech: Adaptive Text to Speech for Custom Voice,AdaSpeech,,https://arxiv.org/abs/2103.00993,2021.03.01,v1,2021.03.01,ICLR2021,,,,,,,,,,,,,,,,,,2024.09.21
Expressive Text-to-Speech using Style Tag,ST-TTS,,https://arxiv.org/abs/2104.00436,2021.04.01,v2,2022.10.06,InterSpeech2021,,,,,,,,,,,,,,,,,,2024.09.21
,Diff-TTS,,,2021.04.03,,,,,,,,,,,,,,,,,,,,,
AdaSpeech 2: Adaptive Text to Speech with Untranscribed Data,AdaSpeech2,,https://arxiv.org/abs/2104.09715,2021.04.20,v1,2021.04.20,ICASSP2021,,,,,,https://speechresearch.github.io/adaspeech2/,,,,,,,,,,,,2024.09.21
,Grad-TTS,,,2021.05.13,,,,,,,,,,,,,,,,,,,,,
PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior,PriorGrad,Vocoder,https://arxiv.org/abs/2106.06406,2021.06.11,v2,2022.02.20,,,,,,,https://speechresearch.github.io/priorgrad/,,,,,,,,,,,,2024.09.21
Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech,VITS,,https://arxiv.org/abs/2106.06103,2021.06.11,v1,2021.06.11,ICML2021,,https://proceedings.mlr.press/v139/kim21f,Training+Inference+Weight,https://github.com/jaywalnut310/vits,,https://jaywalnut310.github.io/vits-demo/index.html,15,45,,720,,,,LJSpeech/VCTK,Tacotron2+HiFi-GAN/Glow-TTS+HiFi-GAN,,,2024.09.21
HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units,HuBERT,Representation,https://arxiv.org/abs/2106.07447,2021.06.14,v1,2021.06.14,TASLP2021,,,,,,,,,,,,,,,,,,2024.09.21
UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation,UnivNet,Vocoder,https://arxiv.org/abs/2106.07889,2021.06.15,v1,2021.06.15,InterSpeech2021,,,,,,,,,,,,,,,,,,2024.09.21
RAD-TTS: Parallel Flow-Based TTS with Robust Alignment Learning and Diverse Synthesis,RAD-TTS,,,2021.06.16,,2021.06.16,ICML2021Poster,,https://openreview.net/forum?id=0NQwnnwAORi,,,,,,,,,,,,,,,,2024.09.21
WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis,WaveGrad2,Vocoder,https://arxiv.org/abs/2106.09660,2021.06.17,v2,2021.06.19,InterSpeech2021,,,,,,https://wavegrad.github.io/v2,,,https://scholar.google.com/scholar?cluster=7794140642380946818,52,,,,,,,,2024.09.21
Glow-WaveGAN: Learning Speech Representations from GAN-based Variational Auto-Encoder For High Fidelity Flow-based Speech Synthesis,Glow-WaveGAN,,https://arxiv.org/abs/2106.10831,2021.06.21,v2,2021.06.22,InterSpeech2021,,,,,,,,,,,,,,,,,,2024.09.21
AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style,AdaSpeech3,,https://arxiv.org/abs/2107.02530,2021.07.06,v1,2021.07.06,InterSpeech2021,,,,,,,,,,,,,,,,,,2024.09.21
SoundStream: An End-to-End Neural Audio Codec,SoundStream,Codec,https://arxiv.org/abs/2107.03312,2021.07.07,v1,2021.07.07,IEEE@TASLP2021,,https://doi.org/10.1109/TASLP.2021.3129994,,,,https://google-research.github.io/seanet/soundstream/examples/,13,68,,483,,,,,,,,2024.09.21
,W2V-BERT,Representation,,2021.08.07,,,,,,,,,,,,,,,,,,,,,
,pGSLM,,,2021.09.07,,,,,,,,,,,,,,,,,,,,,
DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2021,DelightfulTTS,,https://arxiv.org/abs/2110.12612,2021.10.15,v2,2021.11.19,,,,,,,,,,,,,,,,,,,2024.09.21
VISinger: Variational Inference with Adversarial Learning for End-to-End Singing Voice Synthesis,VISinger,,https://arxiv.org/abs/2110.08813,2021.10.17,,,,,,,,,,,,,,,,,,,,,
,WavLM,,,2021.10.26,,,,,,,,,,,,,,,,,,,,,
YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for Everyone,YourTTS,,https://arxiv.org/abs/2112.02418,2021.12.04,v4,2023.04.30,ICML,,,,,,,,,,,,,,,,,,2024.09.21
High-Resolution Image Synthesis with Latent Diffusion Models,LDM,Image,https://arxiv.org/abs/2112.10752,2021.12.20,,,,,,,,,,,,,,,,,,,,,
MaskGIT: Masked Generative Image Transformer,MaskGIT,Image,https://arxiv.org/abs/2202.04200,2022.02.08,v1,2022.02.08,,,,,,,,,,,,,,,,,,,2024.09.21
iSTFTNet: Fast and Lightweight Mel-Spectrogram Vocoder Incorporating Inverse Short-Time Fourier Transform,iSTFTNet,Vocoder,https://arxiv.org/abs/2203.02395,2022.03.04,v1,2022.03.04,ICASSP2022,,,,,,https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet/,,,,,,,,,,,,2024.09.21
HiFi++: a Unified Framework for Bandwidth Extension and Speech Enhancement,HiFi++,Vocoder,https://arxiv.org/abs/2203.13086,2022.03.24,v4,2023.12.10,ICASSP2023,,,,,,,,,,,,,,,,,,2024.09.21
VoiceMe: Personalized Voice Generation in TTS,VoiceMe,,https://arxiv.org/abs/2203.15379,2022.03.29,v2,2022.07.11,InterSpeech2022,,,,,,https://polvanrijn.github.io/VoiceMe/,,,,,,,,,,,,2024.09.21
,dGSLM,,,2022.03.30,,,,,,,,,,,,,,,,,,,,,
SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping,SpecGrad,Vocoder,https://arxiv.org/abs/2203.16749,2022.03.31,v2,2022.08.04,InterSpeech2022,,,,,,http://wavegrad.github.io/specgrad/,,,,,,,,,,,,2024.09.21
AdaSpeech 4: Adaptive Text to Speech in Zero-Shot Scenarios,AdaSpeech4,,https://arxiv.org/abs/2204.00436,2022.04.01,v1,2022.04.01,InterSpeech2022,,https://doi.org/10.21437/Interspeech.2022-901,,,,,,,,,,,,,,,,2024.09.21
FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis,FastDiff,,https://arxiv.org/abs/2204.09934,2022.04.21,v1,2022.04.21,IJCAI2022,,,,,,https://fastdiff.github.io/,,,,,,,,,,,,2024.09.21
NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality,NaturalSpeech,,https://arxiv.org/abs/2205.04421,2022.05.09,v2,2022.05.10,TPAMI,,,,,,,,,,,,,,,,,,2024.09.21
GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech,GenerSpeech,,https://arxiv.org/abs/2205.07211,2022.05.15,v2,2022.10.12,NeurIPS2022,,,,,,https://generspeech.github.io/,,,,,,,,,,,,2024.09.21
StyleTTS: A Style-Based Generative Model for Natural and Diverse Text-to-Speech Synthesis,StyleTTS,,https://arxiv.org/abs/2205.15439,2022.05.30,v2,2023.11.20,,,,,,,,,,,,,,,,,,,2024.09.21
BigVGAN: A Universal Neural Vocoder with Large-Scale Training,BigVGAN,Vocoder,https://arxiv.org/abs/2206.04658,2022.06.09,v2,2023.02.16,ICLR2023Poster,,https://openreview.net/forum?id=iTtGCMDEzS_,,https://github.com/NVIDIA/BigVGAN,,https://bigvgan-demo.github.io/,,,https://scholar.google.com/scholar?cluster=14265847301322679424,159,GAN,,,,,,,2024.09.21
SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech,SANE-TTS,,https://arxiv.org/abs/2206.12132,2022.06.24,v1,2022.06.24,InterSpeech2022,,,,,,,,,,,,,,,,,,2024.09.21
,JETS,,,2022.07.01,,,,,,,,,,,,,,,,,,,,,
Glow-WaveGAN 2: High-quality Zero-shot Text-to-speech Synthesis and Any-to-any Voice Conversion,Glow-WaveGAN2,,https://arxiv.org/abs/2207.01832,2022.07.05,v1,2022.07.05,,,,,,,,,,,,,,,,,,,2024.09.21
DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders,DelightfulTTS2,,https://arxiv.org/abs/2207.04646,2022.07.11,v1,2022.07.11,InterSpeech2022,,,,,,,,,,,,,,,,,,2024.09.21
WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation,WaveGAN,Image,https://arxiv.org/abs/2207.07288,2022.07.15,v2,2022.08.09,ECCV2022,,,Training+Inference+Weight,https://github.com/kobeshegu/ECCV2022_WaveGAN,,,,,https://scholar.google.com/scholar?cluster=3247766894580497169,50,GAN,,,,,,,2024.09.21
AudioLM: A Language Modeling Approach to Audio Generation,AudioLM,,https://arxiv.org/abs/2209.03143,2022.09.07,v2,2023.07.26,TASLP2023,2023.06.21,https://doi.org/10.1109/TASLP.2023.3288409,,,,,11,65,https://scholar.google.com/scholar?cluster=16664344357726277649,,,,,,,,,2024.09.21
AudioGen: Textually Guided Audio Generation,AudioGen,,https://arxiv.org/abs/2209.15352,2022.09.30,v2,2023.06.05,ICLR,,https://openreview.net/forum?id=CYK7RfcOzQ4,,,,,,,https://scholar.google.com/scholar?cluster=11166122285082527856,,,,,,,,,2024.09.21
High Fidelity Neural Audio Compression,EnCodec,Codec,https://arxiv.org/abs/2210.13438,2022.10.24,v1,2022.10.24,TMLR,,,Training+Inference+Weight,https://github.com/facebookresearch/encodec,,,19,,https://scholar.google.com/scholar?cluster=11269141130994676820,,,,,,,,,2024.09.21
HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis,HierSpeech,,,2022.11.01,,2022.11.01,NeurIPS2022,2022.11.01,https://openreview.net/forum?id=awdyRVnfQKX,,,,,,,https://scholar.google.com/scholar?cluster=10216809622451649383,39,,,,,,,,2024.09.21
VISinger 2: High-Fidelity End-to-End Singing Voice Synthesis Enhanced by Digital Signal Processing Synthesizer,VISinger2,,https://arxiv.org/abs/2211.02903,2022.11.05,,,,,,,,,,,,,,,,,,,,,
OverFlow: Putting flows on top of neural transducers for better TTS,OverFlow,,https://arxiv.org/abs/2211.06892,2022.11.13,v2,2023.05.29,InterSpeech2023,,,,,,https://shivammehta25.github.io/OverFlow/,,,,,,,,,,,,2024.09.21
PromptTTS: Controllable Text-to-Speech with Text Descriptions,PromptTTS,,https://arxiv.org/abs/2211.12171,2022.11.22,v1,2022.11.22,ICASSP2023,,,,,,,,,,,,,,,,,,2024.09.21
Robust Speech Recognition via Large-Scale Weak Supervision,Whisper,,https://arxiv.org/abs/2212.04356,2022.12.06,v1,2022.12.06,,,,,,,,,,,,,,,,,,,2024.09.21
Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers,VALL-E,,https://arxiv.org/abs/2301.02111,2023.01.05,v1,2023.01.05,,,,,,,,,,,,,,,,,,,2024.09.21
,MusicLM,,,2023.01.26,,,,,,,,,,,,,,,,,,,,,
AudioLDM: Text-To-Audio Generation with Latent Diffusion Models,AudioLDM,,,2023.01.29,,,,,,,,,,,,,,,,,,,,,
,Make An Audio,,,2023.01.30,,,,,,,,,,,,,,,,,,,,,
InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt,InstructTTS,,https://arxiv.org/abs/2301.13662,2023.01.31,v2,2023.06.25,IEEE@TASLP2024,2024.05.20,https://doi.org/10.1109/TASLP.2024.3402088,,,,,,,,,,,,,,,,2024.09.21
"Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision",SPEAR-TTS,,https://arxiv.org/abs/2302.03540,2023.02.07,v1,2023.02.07,MIT-TACL,2023.12.21,https://doi.org/10.1162/tacl_a_00618,,,,https://google-research.github.io/seanet/speartts/examples/,,,,,,,,,,,,2024.09.21
Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis,Vocos,Vocoder,https://arxiv.org/abs/2306.00814,2023.03.01,v3,2024.05.29,,,,,https://github.com/gemelo-ai/vocos,,,,,,33,,,,,,,,2024.09.21
SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks,SpeechPrompt v2,,https://arxiv.org/abs/2303.00733,2023.03.01,v1,2023.03.01,,,,,,,,,,,,,,,,,,,
Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages,Google USM,,https://arxiv.org/abs/2303.01037,2023.03.02,v3,2023.09.25,,,,,,,,,,,,,,,,,,,
FoundationTTS: Text-to-Speech for ASR Customization with Generative Language Model,FoundationTTS,,https://arxiv.org/abs/2303.02939,2023.03.06,v3,2023.03.06,,,,,,,,,,,,,,,,,,,
Speak Foreign Languages with Your Own Voice:Cross-Lingual Neural Codec Language Modeling,VALL-E X,,https://arxiv.org/abs/2303.03926,2023.03.07,v1,2023.03.07,,,,,,,https://aka.ms/vallex,,,,,,,,,,,,2024.09.21
LMCodec: A Low Bitrate Speech Codec With Causal Transformer Models,LMCodec,Codec,https://arxiv.org/abs/2303.12984,2023.03.23,v1,2023.03.23,ICASSP2023,,,,,,https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec,,,,,,,,,,,,2024.09.21
NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers,NaturalSpeech2,,https://arxiv.org/abs/2304.09116,2023.04.18,v3,2023.05.30,,,,,,,,,,,,,,,,,,,2024.09.21
HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec,HiFi-Codec,Codec,https://arxiv.org/abs/2305.02765,2023.05.04,v2,2023.05.07,,,,,,,,,,,,,,,,,,,2024.09.21
,CoMoSpeech,,,2023.05.11,,,,,,,,,,,,,,,,,,,,,
APNet: An All-Frame-Level Neural Vocoder Incorporating Direct Prediction of Amplitude and Phase Spectra,APNet,Vocoder,https://arxiv.org/abs/2305.07952,2023.05.13,v1,2023.05.13,TASLP,,,,,,,,,,,,,,,,,,2024.09.21
SoundStorm: Efficient Parallel Audio Generation,SoundStorm,,https://arxiv.org/abs/2305.09636,2023.05.16,v1,2023.05.16,,,,,,,,,,,,,,,,,,,2024.09.21
SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities,SpeechGPT,,https://arxiv.org/abs/2305.11000,2023.05.18,v2,2023.05.19,,,,,,,,,,,,,,,,,,,2024.09.21
Listen Think and Understand,LTU,,https://arxiv.org/abs/2305.10790,2023.05.18,v3,2024.02.19,ICLR2024,,,,https://github.com/YuanGongND/ltu,https://huggingface.co/spaces/yuangongfdu/ltu,,,,,,,,,,,,,
,Pengi,,https://arxiv.org/abs/2305.11834,2023.05.19,,,,,,,,,,,,,,,,,,,,,
,TWIST,,,2023.05.22,,,,,,,,,,,,,,,,,,,,,
U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech,U-DiT TTS,,https://arxiv.org/abs/2305.13195,2023.05.22,v1,2023.05.22,,,,,,,,,,,,,,,,,,,
,VioLA,,,2023.05.25,,,,,,,,,,,,,,,,,,,,,
AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec,AudioDec,Codec,https://arxiv.org/abs/2305.16608,2023.05.26,v1,2023.05.26,ICASSP2023,,,,,,,,,,,,,,,,,,2024.09.21
,PromptStyle,,,2023.05.31,,,,,,,,,,,,,,,,,,,,,
,SpeechGen,,,2023.06.03,,,,,,,,,,,,,,,,,,,,,
Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias,Mega-TTS,,https://arxiv.org/abs/2306.03509,2023.06.06,v1,2023.06.06,,,,,,,https://mega-tts.github.io/demo-page,,,,,,,,,,,,2024.09.21
Simple and Controllable Music Generation,MusicGen,,https://arxiv.org/abs/2306.05284,2023.06.08,v3,2024.01.30,NeurIPS2023Poster,2023.09.22,https://openreview.net/forum?id=jtiQ26sCJi,Training+Inference+Weight,https://github.com/facebookresearch/audiocraft/blob/main/docs/MUSICGEN.md,,https://ai.honu.io/papers/musicgen/,17,X,https://scholar.google.com/scholar?cluster=8869808453563782269,274,,,,,,,,2024.09.23
High-Fidelity Audio Compression with Improved RVQGAN,DAC,Codec,https://arxiv.org/abs/2306.06546,2023.06.11,v2,2023.10.26,NeurIPS2023Spotlight,,,,,,,,,,,,,,,,,,2024.09.21
StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models,StyleTTS2,,https://arxiv.org/abs/2306.07691,2023.06.13,v2,2023.11.20,NeurIPS2023,,,,,,https://styletts2.github.io/,,,,,,,,,,,,2024.09.21
,AudioPaLM,,,2023.06.22,,,,,,,,,,,,,,,,,,,,,
Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale,Voicebox,,https://arxiv.org/abs/2306.15687,2023.06.23,v2,2023.10.19,NeurIPS2023,,,,,,https://voicebox.metademolab.com/,,,,,,,,,,,,2024.09.21
UnitSpeech: Speaker-adaptive Speech Synthesis with Untranscribed Data,UnitSpeech,,https://arxiv.org/abs/2306.16083,2023.06.28,v1,2023.06.28,InterSpeech2023 Oral,,,,,,,,,,,,,,,,,,2024.09.21
Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis,Mega-TTS2,,https://arxiv.org/abs/2307.07218,2023.07.14,v4,2024.04.10,ICLR,,,,,,,,,,,,,,,,,,2024.09.21
VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design,VITS2,,https://arxiv.org/abs/2307.16430,2023.07.31,v1,2023.07.31,InterSpeech2023,,,,,,,,,,,,,,,,,,2024.09.21
,DiffProsody,,,2023.07.31,,,,,,,,,,,,,,,,,,,,,
,AudioLDM2,,,2023.08.10,,,,,,,,,,,,,,,,,,,,,
iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN,iSTFTNet2,Vocoder,https://arxiv.org/abs/2308.07117,2023.08.14,v1,2023.08.14,InterSpeech2023,,,,,,https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/,,,,,,,,,,,,2024.09.21
,SpeechX,,,2023.08.14,,,,,,,,,,,,,,,,,,,,,
TextrolSpeech: A Text Style Control Speech Corpus With Codec Language Text-to-Speech Models,TextrolSpeech,Dataset,https://arxiv.org/abs/2308.14430,2023.08.28,v1,2023.08.28,,,,,,,https://sall-e.github.io/,,,,,,,,,,,,2024.09.21
RepCodec: A Speech Representation Codec for Speech Tokenization,RepCodec,Codec,https://arxiv.org/abs/2309.00169,2023.08.31,v3,2024.07.22,ACL2024,,,,,,,,,,,,,,,,,,2024.09.21
SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models,SpeechTokenizer,Codec,https://arxiv.org/abs/2308.16692,2023.08.31,v2,2024.01.23,ICLR2024,,,,https://github.com/ZhangXInFD/SpeechTokenizer/,,,,,,,,,,,,,,2024.09.21
PromptTTS 2: Describing and Generating Voices with Text Prompt,PromptTTS2,,https://arxiv.org/abs/2309.02285,2023.09.05,v2,2023.10.12,,,,,,,https://speechresearch.github.io/prompttts2,,,,,,,,,,,,2024.09.21
BigVSAN: Enhancing GAN-based Neural Vocoders with Slicing Adversarial Network,BigVSAN,Vocoder,https://arxiv.org/abs/2309.02836,2023.09.06,v2,2024.03.25,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
Matcha-TTS: A fast TTS architecture with conditional flow matching,Matcha-TTS,,https://arxiv.org/abs/2309.03199,2023.09.06,v2,2024.01.09,ICASSP2024,,,,,,https://shivammehta25.github.io/Matcha-TTS/,5,,https://scholar.google.com/scholar?cluster=3378090602595584425,21,,,,,,,,2024.09.21
VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching,VoiceFlow,,https://arxiv.org/abs/2309.05027,2023.09.10,v3,2024.09.01,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
,NExT-GPT,,,2023.09.11,,,,,,,,,,,,,,,,,,,,,
SnakeGAN: A Universal Vocoder Leveraging DDSP Prior Knowledge and Periodic Inductive Bias,SnakeGAN,Vocoder,https://arxiv.org/abs/2309.07803,2023.09.14,v1,2023.09.14,ICME2023,,,,,,,,,,,,,,,,,,2024.09.21
FunCodec: A Fundamental Reproducible and Integrable Open-source Toolkit for Neural Speech Codec,FunCodec,Codec,https://arxiv.org/abs/2309.07405,2023.09.14,v2,2023.10.07,ICASSP2024,,,,https://github.com/alibaba-damo-academy/FunCodec,,,,,,,,,,,,,,2024.09.21
Fewer-token Neural Speech Codec with Time-invariant Codes,TiCodec,Codec,https://arxiv.org/abs/2310.00014,2023.09.15,v2,2024.03.11,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise Filter and Inverse Short Time Fourier Transform,HiFTNet,Vocoder,https://arxiv.org/abs/2309.09493,2023.09.18,v1,2023.09.18,,,,,,,,,,,,,,,,,,,2024.09.21
VoiceLDM: Text-to-Speech with Environmental Context,VoiceLDM,,https://arxiv.org/abs/2309.13664,2023.09.24,v1,2023.09.24,ICASSP2024,2024.03.18,https://doi.org/10.1109/ICASSP48485.2024.10448268,,,,https://voiceldm.github.io/,,,https://scholar.google.com/scholar?cluster=3766695167763370661,,,,,,,,,
UniAudio: An Audio Foundation Model Toward Universal Audio Generation,UniAudio,,https://arxiv.org/abs/2310.00704,2023.10.01,v5,2023.12.11,,,,,https://github.com/yangdongchao/UniAudio,,,,,,,,,,,,,,2024.09.21
,MR-HuBERT,,,2023.10.04,,,,,,,,,,,,,,,,,,,,,
,UniverSLU,,https://arxiv.org/abs/2310.02973,2023.10.04,,,,,,,,,,,,,,,,,,,,,
"LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT",LauraGPT,,https://arxiv.org/abs/2310.04673,2023.10.07,v4,2024.07.03,ICLR2024(Reject),,,,,,,,,,,,,,,,,,2024.09.21
,SALMONN,,,2023.10.20,,,,,,,,,,,,,,,,,,,,,
E3 TTS: Easy End-to-End Diffusion-based Text to Speech,E3 TTS,,https://arxiv.org/abs/2311.00945,2023.11.02,v1,2023.11.02,ASRU2023,,,,,,,,,,,,,,,,,,2024.09.21
,COSMIC,,,2023.11.03,,,,,,,,,,,,,,,,,,,,,
Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models,Qwen-Audio,,https://arxiv.org/abs/2311.07919,2023.11.14,v2,2023.12.21,,,,,https://github.com/QwenLM/Qwen-Audio,,,,,,,,,,,,,,2024.09.21
APNet2: High-quality and High-efficiency Neural Vocoder with Direct Prediction of Amplitude and Phase Spectra,APNet2,Vocoder,https://arxiv.org/abs/2311.11545,2023.11.20,v1,2023.11.20,NCMMSC2023,,https://link.springer.com/chapter/10.1007/978-981-97-0601-3_6,,,,,,,https://scholar.google.com/scholar?cluster=360953352732613526,2,,,,,,,,2024.09.21
HierSpeech++: Bridging the Gap between Semantic and Acoustic Representation of Speech by Hierarchical Variational Inference for Zero-shot Speech Synthesis,HierSpeech++,,https://arxiv.org/abs/2311.12454,2023.11.21,v2,2023.11.27,,,,,https://github.com/sh-lee-prml/HierSpeechpp,,,,,,,,,,,,,,2024.09.21
OpenVoice: Versatile Instant Voice Cloning,OpenVoice,,https://arxiv.org/abs/2312.01479,2023.12.03,v6,2024.08.18,,,,,,,,,,,,,,,,,,,2024.09.21
Amphion: An Open-Source Audio Music and Speech Generation Toolkit,Amphion,Toolkit,https://arxiv.org/abs/2312.09911,2023.12.15,v3,2024.09.16,SLT2024,,,,,,,,,,,,,,,,,,2024.09.21
,SECap,,,2023.12.16,,,,,,,,,,,,,,,,,,,,,
MM-TTS: Multi-Modal Prompt Based Style Transfer for Expressive Text-to-Speech Synthesis,MM-TTS,,https://arxiv.org/abs/2312.10687,2023.12.17,v4,2024.01.31,AAAI2024,,,,,,,,,,,,,,,,,,2024.09.21
,Emotion2Vec,,https://arxiv.org/abs/2312.15185,2023.12.23,,,,,,,https://github.com/ddlBoJack/emotion2vec,,,,,,,,,,,,,,
,Audiobox,,https://arxiv.org/abs/2312.15821,2023.12.25,,,,,,,,,,,,,,,,,,,,,
ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering,ELLA-V,,https://arxiv.org/abs/2401.07333,2024.01.14,v1,2024.01.14,,,,,,,,,,,,,,,,,,,2024.09.21
FreGrad: Lightweight and Fast Frequency-aware Diffusion Vocoder,FreGrad,Vocoder,https://arxiv.org/abs/2401.10032,2024.01.18,v1,2024.01.18,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
ScoreDec: A Phase-preserving High-Fidelity Audio Codec with A Generalized Score-based Diffusion Post-filter,ScoreDec,Codec,https://arxiv.org/abs/2401.12160,2024.01.22,v1,2024.01.22,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation,SpeechGPT-Gen,,https://arxiv.org/abs/2401.13527,2024.01.24,v2,2024.01.25,,,,,https://github.com/0nutation/SpeechGPT,,,,,,,,,,,,,,2024.09.21
VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech,VALL-T,,https://arxiv.org/abs/2401.14321,2024.01.25,v4,2024.01.30,,,,,,,,,,,,,,,,,,,2024.09.21
EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks,EVA-GAN,Vocoder,https://arxiv.org/abs/2402.00892,2024.01.31,v1,2024.01.31,,,,,,,,,,,,,,,,,,,2024.09.21
Natural Language Guidance of High-Fidelity Text-to-Speech with Synthetic Annotations,Parler-TTS (Reproduce),,https://arxiv.org/abs/2402.01912,2024.02.02,v1,2024.02.02,--,--,--,Training,[Reproduce] https://github.com/huggingface/parler-tts,https://huggingface.co/parler-tts/,https://text-description-to-speech.com,6,34,https://scholar.google.com/scholar?cluster=1239973316035890942,17,,,,,,,,2024.09.23
,SpiRit-LM,,,2024.02.08,,,,,,,,,,,,,,,,,,,,,
GLA-Grad: A Griffin-Lim Extended Waveform Generation Diffusion Model,GLA-Grad,Vocoder,https://arxiv.org/abs/2402.15516,2024.02.09,v1,2024.02.09,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data,BASE TTS,,https://arxiv.org/abs/2402.08093,2024.02.12,v2,2024.02.15,,,,,,,,,,,,,,,,,,,2024.09.21
MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech,MobileSpeech,,https://arxiv.org/abs/2402.09378,2024.02.14,v2,2024.06.02,ACL2024,,,,,,,,,,,,,,,,,,2024.09.21
APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding,APCodec,Codec,https://arxiv.org/abs/2402.10533,2024.02.16,v1,2024.02.16,TASLP,,,,,,,,,,,,,,,,,,2024.09.21
Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models,Language-Codec,Codec,https://arxiv.org/abs/2402.12208,2024.02.19,v3,2024.04.27,,,,,https://github.com/jishengpeng/languagecodec,,,,,,,,,,,,,,2024.09.21
,Spoken-LLM,,,2024.02.20,,,,,,,,,,,,,,,,,,,,,
NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models,NaturalSpeech3,,https://arxiv.org/abs/2403.03100,2024.03.05,v3,2024.04.23,ICML2024Oral,,,,,,,,,https://scholar.google.com/scholar?cluster=11303548308295061158,50,,,,,,,,2024.09.21
RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction,RFWave,Vocoder,https://arxiv.org/abs/2403.05010,2024.03.08,v2,2024.06.02,,,,,,,https://rfwave-demo.github.io/rfwave/,,,https://scholar.google.com/scholar?cluster=14982663450191514510,0,,,,,,,,2024.09.21
,HAM-TTS,,,2024.03.09,,,,,,,,,,,,,,,,,,,,,
VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild,VoiceCraft,,https://arxiv.org/abs/2403.16973,2024.03.25,v3,2024.06.14,ACL2024,,,,,,,,,,,,,,,,,,2024.09.21
CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models,CM-TTS,,https://arxiv.org/abs/2404.00569,2024.03.31,v1,2024.03.31,,,,,https://github.com/XiangLi2022/CM-TTS,,,,,,,,,,,,,,2024.09.21
PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders,PromptCodec,Codec,https://arxiv.org/abs/2404.02702,2024.04.03,v2,2024.04.13,,,,,,,,,,,,,,,,,,,2024.09.21
CLaM-TTS: Improving Neural Codec Language Modeling for Zero-Shot Text-to-Speech,CLaM-TTS,,https://arxiv.org/abs/2404.02781,2024.04.03,v1,2024.04.03,,,,,,,,,,,,,,,,,,,2024.09.21
RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis,RALL-E,,https://arxiv.org/abs/2404.03204,2024.04.04,v2,2024.04.06,,,,,,,,,,,,,,,,,,,2024.09.21
HyperTTS: Parameter Efficient Adaptation in Text to Speech using Hypernetworks,HyperTTS,,https://arxiv.org/abs/2404.04645,2024.04.06,v1,2024.04.06,,,,,,,,,,,,,,,,,,,2024.09.21
LLaMA-VITS: Enhancing TTS Synthesis with Semantic Awareness,LLaMA-VITS,,https://arxiv.org/abs/2404.06714,2024.04.10,v2,2024.04.12,,,,,,,,,,,,,,,,,,,2024.09.21
FlashSpeech: Efficient Zero-Shot Speech Synthesis,FlashSpeech,,https://arxiv.org/abs/2404.14700,2024.04.23,v3,2024.04.25,,,,,,,,,,,,,,,,,,,2024.09.21
,USAT,,,2024.04.28,,,,,,,,,,,,,,,,,,,,,
MM-TTS: A Unified Framework for Multimodal Prompt-Induced Emotional Text-to-Speech Synthesis,MM-TTS,,https://arxiv.org/abs/2404.18398,2024.04.29,v1,2024.04.29,,,,,,,,,,,,,,,,,,,2024.09.21
SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound,SemantiCodec,Codec,https://arxiv.org/abs/2405.00233,2024.04.30,v1,2024.04.30,,,,,https://haoheliu.github.io/SemantiCodec/,,,,,,,,,,,,,,2024.09.21
ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control With Decoupled Codec,ControlSpeech,,https://arxiv.org/abs/2406.01205,2024.06.03,v1,2024.06.03,,,,,https://github.com/jishengpeng/ControlSpeech,,,,,,,,,,,,,,2024.09.21
SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models,SimpleSpeech,,https://arxiv.org/abs/2406.02328,2024.06.04,v3,2024.06.14,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1392,,,,,,,,,,,TTS,,,,NAR,2024.09.21
,Seed-TTS,,,2024.06.04,,,,,,,,,,,,,,,,,,,,,
BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation,BiVocoder,Vocoder,https://arxiv.org/abs/2406.02162,2024.06.04,v1,2024.06.04,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-255,,,,,,,,,,,,,,,,2024.09.21
,LiveSpeech,,,2024.06.05,,,,,,,,,,,,,,,,,,,,,
Small-E: Small Language Model with Linear Attention for Efficient Speech Synthesis,Small-E,,https://arxiv.org/abs/2406.04467,2024.06.06,v2,2024.06.11,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-508,,https://github.com/theodorblackbird/lina-speech,,,,,,,,,,,,,,2024.09.21
XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model,XTTS,,https://arxiv.org/abs/2406.04904,2024.06.07,v1,2024.06.07,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2016,,,,,,,,,,,,,,,,2024.09.21
VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers,VALL-E 2,,https://arxiv.org/abs/2406.05370,2024.06.08,v2,2024.06.17,,,,,,,https://aka.ms/valle2,,,,,,,,,,,,2024.09.21
WenetSpeech4TTS: A 12800-hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark,WenetSpeech4TTS,Dataset,https://arxiv.org/abs/2406.05763,2024.06.09,v3,2024.06.19,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2343,,,,,,,,,,,,,,,,2024.09.21
,mHuBERT,Representation,,2024.06.10,,,,,,,,,,,,,,,,,,,,,
JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis,JenGAN,Vocoder,https://arxiv.org/abs/2406.06111,2024.06.10,v1,2024.06.10,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1447,,,,,,,,,,,,,,,,2024.09.21
,ExHuBERT,Representation,,2024.06.11,,,,,,,,,,,,,,,,,,,,,
Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation,Single-Codec,Codec,https://arxiv.org/abs/2406.07422,2024.06.11,v1,2024.06.11,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1559,,,,,,,,,,,,,,,,2024.09.21
LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts for Text-to-Speech and Style Captioning,LibriTTS-P,Dataset,https://arxiv.org/abs/2406.07969,2024.06.12,v1,2024.06.12,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-692,,,,,,,,,,,,,,,,2024.09.21
FreeV: Free Lunch For Vocoders Through Pseudo Inversed Mel Filter,FreeV,Vocoder,https://arxiv.org/abs/2406.08196,2024.06.12,v1,2024.06.12,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1435,,https://github.com/BakerBunker/FreeV,,,5,,https://scholar.google.com/scholar?cluster=13731432507109093105,1,,,,,,,,2024.09.21
VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment,VALL-E R,,https://arxiv.org/abs/2406.07855,2024.06.12,v1,2024.06.12,,,,,,,,,,,,,,,,,,,2024.09.21
TokSing: Singing Voice Synthesis based on Discrete Tokens,TokSing,,https://arxiv.org/abs/2406.08416,2024.06.12,v2,2024.06.20,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2360,,,,,,,,,,,,,,,,2024.09.21
Speech ReaLLM: Real-time Streaming Speech Recognition with Multimodal LLMs by Teaching the Flow of Time,Speech ReaLLM,,https://arxiv.org/abs/2406.09569,2024.06.13,v1,2024.06.13,,,,,,,,,,,,,,,,,,,
UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner,UniAudio 1.5,,https://arxiv.org/abs/2406.10056,2024.06.14,v1,2024.06.14,,,,,,,,,,,,,,,,,,,2024.09.21
How Should We Extract Discrete Audio Tokens from Self-Supervised Models?,,,https://arxiv.org/abs/2406.10735,2024.06.15,,,InterSpeech2024,,,,,,,,,,,,,,,,,,
DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer,DiTTo-TTS,,https://arxiv.org/abs/2406.11427,2024.06.17,v1,2024.06.17,,,,,,,https://ditto-tts.github.io/,,,,,,,,,,,,2024.09.21
Articulatory Encodec: Coding Speech through Vocal Tract Kinematics,Articulatory Encodec,Codec,https://arxiv.org/abs/2406.12998,2024.06.18,v2,2024.08.21,,,,,,,,,,,,,,,,,,,2024.09.21
TacoLM: GaTed Attention Equipped Codec Language Model are Efficient Zero-Shot Text to Speech Synthesizers,TacoLM,,https://arxiv.org/abs/2406.15752,2024.06.22,v1,2024.06.22,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1531,,,,,,,,,,,,,,,,2024.09.21
Improving Robustness of LLM-based Speech Synthesis by Learning Monotonic Alignment,T5-TTS,,,2024.06.25,,,,,,,,,,,,,,,,,,,,,
E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS,E2 TTS,,https://arxiv.org/abs/2406.18009,2024.06.26,v2,2024.09.12,SLT2024,,,,,,https://aka.ms/e2tts/,,,,,,,,,,,,2024.09.21
DEX-TTS: Diffusion-based EXpressive Text-to-Speech with Style Modeling on Time Variability,DEX-TTS,,https://arxiv.org/abs/2406.19135,2024.06.27,v1,2024.06.27,,,,,,,,,,,,,,,,,,,2024.09.21
BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5,BESTOW,,https://arxiv.org/abs/2406.19954,2024.06.28,v1,2024.06.28,,,,,,,,,,,,,,,,,,,2024.09.21
"FLY-TTS: Fast, Lightweight and High-Quality End-to-End Text-to-Speech Synthesis",FLY-TTS,,https://arxiv.org/abs/2407.00753,2024.06.30,v1,2024.06.30,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-1435,,,,,,,,,,,,,,,,2024.09.21
Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference Optimization,RIO,,https://arxiv.org/abs/2407.02243,2024.07.02,v1,2024.07.02,,,,,,,,,,,,,,,,,,,2024.09.21
,FunAudioLLM,,,2024.07.04,,,,,,,,,,,,,,,,,,,,,
FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-based Vocoder,FA-GAN,Vocoder,https://arxiv.org/abs/2407.04575,2024.07.05,v1,2024.07.05,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-380,,,,,,,,,,,,,,,,2024.09.21
,CosyVoice,,,2024.07.07,,,,,,,,,,,,,,,,,,,,,
,AffectGPT,,,2024.07.10,,,,,,,,,,,,,,,,,,,,,
Autoregressive Speech Synthesis without Vector Quantization,MELLE,,https://arxiv.org/abs/2407.08551,2024.07.11,v1,2024.07.11,,,,,,,https://aka.ms/melle,,,,,,,,,,,AR,2024.09.21
,Qwen2-Audio,,https://arxiv.org/abs/2407.10759,2024.07.15,,,,,,,,,,,,,,,,,,,,,
TTSDS: Text-to-Speech Distribution Score,TTSDS,,https://arxiv.org/abs/2407.12707,2024.07.17,v2,2024.07.22,SLT2024,,,,,,,,,,,,,,,,,,2024.09.21
MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech Synthesis,MSceneSpeech,Dataset,https://arxiv.org/abs/2407.14006,2024.07.19,v1,2024.07.19,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-266,,,,,,,,,,,,,,,,2024.09.21
,LLaST,,,2024.07.22,,,,,,,,,,,,,,,,,,,,,
SuperCodec: A Neural Speech Codec with Selective Back-Projection Network,SuperCodec,Codec,https://arxiv.org/abs/2407.20530,2024.07.30,v1,2024.07.30,ICASSP2024,,,,,,,,,,,,,,,,,,2024.09.21
Language Model Can Listen While Speaking,LSLM,,https://arxiv.org/abs/2408.02622,2024.08.05,v1,2024.08.05,,,,,,,https://ddlbojack.github.io/LSLM,,,,,,,,,,,,2024.09.21
VNet: A GAN-based Multi-Tier Discriminator Network for Speech Synthesis Vocoders,VNet,Vocoder,https://arxiv.org/abs/2408.06906,2024.08.13,v1,2024.08.13,SMC2024,,,,,,,,,,,,,,,,,,2024.09.21
Neural Speech and Audio Coding,,,https://arxiv.org/abs/2408.06954,2024.08.13,,,,,,,,,,,,,,,,,,,,,
PRESENT: Zero-Shot Text-to-Prosody Control,PRESENT,,https://arxiv.org/abs/2408.06827,2024.08.13,,,,,,,,,,,,,,,,,,,,,
PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation,PeriodWave,Vocoder,https://arxiv.org/abs/2408.07547,2024.08.14,v1,2024.08.14,,,,,https://github.com/sh-lee-prml/PeriodWave,,,,,,,,,,,,,,2024.09.21
EELE: Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech,EELE,,https://arxiv.org/abs/2408.10852,2024.08.20,v1,2024.08.20,,,,,,,,,,,,,,,,,,,2024.09.21
SSL-TTS: Leveraging Self-Supervised Embeddings and kNN Retrieval for Zero-Shot Multi-speaker TTS,SSL-TTS,,https://arxiv.org/abs/2408.10771,2024.08.20,v1,2024.08.20,Submitted to SPL,,,,,,,,,,,,,,,,,,2024.09.21
VoiceX: A Text-To-Speech Framework for Custom Voices,VoiceX,,https://arxiv.org/abs/2408.12170,2024.08.22,v1,2024.08.22,,,,,,,,,,,,,,,,,,,2024.09.21
SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description,SpeechCraft,Dataset,https://arxiv.org/abs/2408.13608,2024.08.24,v1,2024.08.24,ACM MultiMedia2024,,,,,,,,,,,,,,,,,,2024.09.21
SimpleSpeech 2: Towards Simple and Efficient Text-to-Speech with Flow-based Scalar Latent Transformer Diffusion Models,SimpleSpeech2,,https://arxiv.org/abs/2408.13893,2024.08.25,v2,2024.08.28,Submitted to TASLP,,,,,,,,,,,,,,,,,,2024.09.21
DualSpeech: Enhancing Speaker-Fidelity and Text-Intelligibility Through Dual Classifier-Free Guidance,DualSpeech,,https://arxiv.org/abs/2408.14423,2024.08.26,v2,2024.08.27,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2005,,,,,,,,,,,,,,,,2024.09.21
Mini-Omni: Language Models Can Hear Talk While Thinking in Streaming,Mini-Omni,,https://arxiv.org/abs/2408.16725,2024.08.27,v2,2024.08.30,,,,,https://github.com/gpt-omni/mini-omni,,,,,,,,,,,,,,2024.09.21
VoiceTailor: Lightweight Plug-In Adapter for Diffusion-Based Personalized Text-to-Speech,VoiceTailor,,https://arxiv.org/abs/2408.14739,2024.08.27,v2,2024.08.28,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-63,,,,,,,,,,,,,,,,2024.09.21
VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling,VoxInstruct,,https://arxiv.org/abs/2408.15676,2024.08.28,v1,2024.08.28,,,,,,,,,,,,,,,,,,,2024.09.21
WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling,WavTokenizer,Codec,https://arxiv.org/abs/2408.16532,2024.08.29,v1,2024.08.29,,,,,,,,,,,,,,,,,,,2024.09.21
Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model,X-Codec,Codec,https://arxiv.org/abs/2408.17175,2024.08.30,v2,2024.09.19,,,,,https://github.com/zhenye234/xcodec,,https://x-codec-audio.github.io/,,,,,,,,,,,,2024.09.21
SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection,SelectTTS,,https://arxiv.org/abs/2408.17432,2024.08.30,v1,2024.08.30,Submitted to SPL,,,,,,,,,,,,,,,,,,2024.09.21
Sample-Efficient Diffusion for Text-To-Speech Synthesis,SESD,,https://arxiv.org/abs/2409.03717,2024.09.01,v1,2024.09.01,InterSpeech2024,,https://doi.org/10.21437/Interspeech.2024-2235,,,,,,,,,,,,,,,,2024.09.21
SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis,SoCodec,Codec,https://arxiv.org/abs/2409.00933,2024.09.02,v1,2024.09.02,SLT2024,,,,,,,,,,,,,,,,,,2024.09.21
vec2wav 2.0: Advancing Voice Conversion via Discrete Token Vocoders,Vec2Wav2.0,Vocoder,https://arxiv.org/abs/2409.01995,2024.09.03,v2,2024.09.11,Submitted to ICASSP2025,,,,,,https://cantabile-kwok.github.io/vec2wav2/,,,,,,,,,,,,2024.09.21
LAST: Language Model Aware Speech Tokenization,LAST,,https://arxiv.org/abs/2409.03701,2024.09.05,v1,2024.09.05,,,,,,,,,,,,,,,,,,,
BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec,BigCodec,Codec,https://arxiv.org/abs/2409.05377,2024.09.09,v1,2024.09.09,,,,Inference+Weight,https://github.com/Aria-K-Alethia/BigCodec,,https://aria-k-alethia.github.io/bigcodec-demo/,,,,,,,,,,,,2024.09.21
LLaMA-Omni: Seamless Speech Interaction with Large Language Models,LLaMA-Omni,,https://arxiv.org/abs/2409.06666,2024.09.10,v1,2024.09.10,,,,,https://github.com/ictnlp/LLaMA-Omni,,,,,,,,,,,,,,2024.09.21
SSR-Speech: Towards Stable Safe and Robust Zero-shot Text-based Speech Editing and Synthesis,SSR-Speech,,https://arxiv.org/abs/2409.07556,2024.09.11,v1,2024.09.11,Submitted to ICASSP2025,,,Training+Inference+Weight,https://github.com/WangHelin1997/SSR-Speech,,https://WangHelin1997.github.io/SSR-Speech-Demo,5,35,,,,,,,,,,2024.09.21
Super Monotonic Alignment Search,Super-MAS,,https://arxiv.org/abs/2409.07704,2024.09.12,,,,,,,,,,,,,,,,,,,,,
E1 TTS: Simple and Fast Non-Autoregressive TTS,E1 TTS,,https://arxiv.org/abs/2409.09351,2024.09.14,v1,2024.09.14,,,,,,,,,,,,,,,,,,NAR,
WMCodec: End-to-End Neural Speech Codec with Deep Watermarking for Authenticity Verification,WMCodec,Codec,https://arxiv.org/abs/2409.12121,2024.09.18,v1,2024.09.18,,,,,,,,,,,,,,,,,,,
Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation,CoFi-Speech,CodecLM,https://arxiv.org/abs/2409.11630,2024.09.18,v1,2024.09.18,,,,,,,https://hhguo.github.io/DemoCoFiSpeech,5,30,,0,,CoFi-Codec (SoCodec [OPQ])+CoFi-LM-Cos/SoS+BigVGAN,TTS,WenetSpeech4TTS,VALL-E/CosyVoice/SoCodec-TTS,Mel2Code/BPE,,2024.09.23
Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference,LFSC,Codec,https://arxiv.org/abs/2409.12117,2024.09.18,v1,2024.09.18,Submitted to ICASSP2025,,,,https://github.com/NVIDIA/NeMo,,https://edresson.github.io/Low-Frame-rate-Speech-Codec/,5,40,,,,,,,,,,2024.09.21
NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization,NDVQ,Codec,https://arxiv.org/abs/2409.12717,2024.09.19,v1,2024.09.19,,,,,,,,,,,,,,,,,,,
,BERT,LLM,,,,,,,,,,,,,,,,,,,,,,,
,RoBERTa,LLM,,,,,,,,,,,,,,,,,,,,,,,
,ByT5,LLM,,,,,,,,,,,,,,,,,,,,,,,
LLaMA: Open and Efficient Foundation Language Models,LLaMA,LLM,,,,,,,,,,,,,,,,,,,,,,,
,PaLM2,LLM,,,,,,,,,,,,,,,,,,,,,,,
Llama 2: Open Foundation and Fine-Tuned Chat Models,LLaMA2,LLM,,,,,,,,,,,,,,,,,,,,,,,
,LLaMA3,LLM,,,,,,,,,,,,,,,,,,,,,,,
,Qwen,LLM,,,,,,,,,,,,,,,,,,,,,,,
,OpenELM,LLM,,,,,,,,,,,,,,,,,,,,,,,
Period Singer: Integrating Periodic and Aperiodic Variational Autoencoders for Natural-Sounding End-to-End Singing Voice Synthesis,Period Singer,,https://arxiv.org/abs/2406.09894,2024.06.14,v2,2024.09.11,InterSpeech2024,,,,,,,,,,,,,,,,,,
FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion,FreeVC,,https://arxiv.org/abs/2210.15418,2022.10.27,v1,2022.10.27,,,,,,,,,,,,,,,,,,,
QuickVC: Any-to-many Voice Conversion Using Inverse Short-time Fourier Transform for Faster Conversion,QuickVC,,https://arxiv.org/abs/2302.08296,2023.02.16,v4,2023.02.23,,,,,,,,,,,,,,,,,,,
StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion,StreamVoice,,https://arxiv.org/abs/2401.11053,2024.01.19,v5,2024.07.19,ACL2024,,,,,,,,,,,,,,,,,,
PAVITS: Exploring Prosody-aware VITS for End-to-End Emotional Voice Conversion,PAVITS,,https://arxiv.org/abs/2403.01494,2024.03.03,v1,2024.03.03,ICASSP2024,,,,,,,,,,,,,,,,,,
StreamVoice+: Evolving into End-to-end Streaming Zero-shot Voice Conversion,StreamVoice+,,https://arxiv.org/abs/2408.02178,2024.08.05,v1,2024.08.05,,,,,,,,,,,,,,,,,,,
,FourierFT,PEFT,,2024.05.05,,,,,,,,,,,,,,,,,,,,,
,LoRA-GA,PEFT,,2024.07.06,,,,,,,,,,,,,,,,,,,,,
,LoRA-Pro,PEFT,,2024.07.25,,,,,,,,,,,,,,,,,,,,,
LoRA: Low-Rank Adaptation of Large Language Models,LoRA,PEFT,https://arxiv.org/abs/2106.09685,2021.06.17,V2,2021.10.16,,,,,,,,,,,,,,,,,,,
MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning,MoRA,PEFT,https://arxiv.org/abs/2405.12130,2024.05.20,v1,2024.05.20,,,,,,,,,,,,,,,,,,,
QLoRA: Efficient Finetuning of Quantized LLMs,QLoRA,PEFT,https://arxiv.org/abs/2305.14314,2023.05.23,v1,2023.05.23,,,,,,,,,,,,,,,,,,,
VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks,VB-LoRA,PEFT,https://arxiv.org/abs/2405.15179,2024.05.24,v2,2024.05.27,,,,,,,,,,,,,,,,,,,
Layer Normalization,Layer Normalization,,https://arxiv.org/abs/1607.06450,2016.07.21,v1,2016.07.21,,,,,,,,,,,,,,,,,,,
Autoregressive Image Generation using Residual Quantization,RQ-VAE,,,2022.03.03,,,,,,,,,,,,,,,,,,,,,
