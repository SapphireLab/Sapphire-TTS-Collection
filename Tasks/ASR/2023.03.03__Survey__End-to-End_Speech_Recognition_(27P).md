# End-to-End Speech Recognition: A Survey

<details>
<summary>基本信息</summary>

- 标题: "End-to-End Speech Recognition: A Survey"
- 作者:
  - 01 Rohit Prabhavalkar
  - 02 Takaaki Hori
  - 03 Tara N.Sainath
  - 04 Ralf Schluter
  - 05 Shinji Watanabe
- 链接:
  - [ArXiv](https://arxiv.org/abs/2303.03329v1)
  - [Publication](https://doi.org/10.1109/TASLP.2023.3328283)
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](PDF/2023.03.03__2303.03329v1__Survey__End-to-End_Speech_Recognition__A_Survey.pdf)
  - [Publication](PDF/2023.02.21__2303.03329p0__Survey__End-to-End_Speech_Recognition__A_Survey_TASLP2023.pdf)

</details>

## Abstract: 摘要

In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning.
In the wake of this transition, a number of all-neural ASR architectures have been introduced.
These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience.
The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach.
The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures.
All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论