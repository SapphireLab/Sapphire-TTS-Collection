- [**Adam**: A Method for Stochastic Optimization.](Modules/Optimization/2014.12.22_Adam.md) ICLR2015.
- [**AdamW**: Decoupled Weight Decay Regularization.](Modules/Optimization/2017.11.14_AdamW.md) ICLR2019.
- [**AISHELL-1**: An Open-Source Mandarin Speech Corpus and a Speech Recognition Baseline.](Datasets/2017.09.16_AISHELL-1.md) O-COCOSDA 2017.
- [**AISHELL-2**: Transforming Mandarin ASR Research into Industrial Scale.](Datasets/2018.08.31_AISHELL-2.md) ArXiv:1808.10583.
- [**AlignTTS**: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment.](Models/Acoustic/2020.03.04_AlignTTS.md) ICASSP2020.
- [**AnyGPT**: Unified Multimodal LLM with Discrete Sequence Modeling.](Models/SpeechLM/2024.02.19_AnyGPT.md) ArXiv:2402.12226.
- [**AudioLM**: A Language Modeling Approach to Audio Generation.](Models/SpeechLM/ST2S/2022.09.07_AudioLM.md) TASLP2023.
- [**AudioPaLM**: A Large Language Model that Can Speak and Listen.](Models/SpeechLM/ST2ST/2023.06.22_AudioPaLM.md) ArXiv:2306.12925.
- Autoencoding beyond Pixels Using a Learned Similarity Metric. ICML2016.
- [**Baichuan-Omni** Technical Report.](Models/SpokenDialogue/2024.10.11_Ocean-Omni.md) ArXiv:2106.09685.
- [**BASE-TTS**: Lessons from Building a Billion-Parameter Text-to-Speech Model on 100k Hours of Data.](Models/SpeechLM/ST2S/2024.02.12_BASE-TTS.md) ArXiv2024.
- [**BigCodec**: Pushing the Limits of Low-Bitrate Neural Speech Codec.](Models/SpeechCodec/2024.09.09_BigCodec.md) ArXiv2024.
- [**BPE**: Neural Machine Translation of Rare Words with Subword Units.](Models/_Basis/2015.08.31_BPE.md) ArXiv:1508.07909.
- [**BVAE-TTS**: Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech.](Models/Acoustic/2021.01.13_BVAE-TTS.md) ICLR2021.
- Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals? ArXiv2024.
- [**CFG**: Classifier-Free Diffusion Guidance.](Models/Diffusion/2022.07.26_Classifier-Free_Guidance.md) NeurIPS2021.
- [**Char2Wav**: End-to-End Speech Synthesis.](Models/E2E/2017.02.18_Char2Wav.md) ICLR2017.
- [**CLaM-TTS**: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech.](Models/SpeechLM/2024.04.03_CLaM-TTS.md) ICLR.
- Classifier-Free Guidance in LLMs Safety. ArXiv2024.
- [**Conformer**: Convolution-Augmented Transformer for Speech Recognition.](Models/ASR/2020.05.16_Conformer.md) ArXiv:2005.08100.
- Connecting Speech Encoder and Large Language Model for ASR. ICASSP2024.
- [**COSMIC**: Data Efficient Instruction-Tuning for Speech In-Context Learning](Models/SpeechLM/2023.11.03_COSMIC.md) ArXiv:2311.02248.
- [**Cosyvoice2**: Scalable Streaming Speech Synthesis with Large Language Models.](Models/SpeechLM/2024.12.13_CosyVoice2.md) ArXiv:2412.10117.
- [**Cosyvoice**: A Scalable Multilingual Zero-Shot Text-to-Speech Synthesizer Based on Supervised Semantic Tokens.](Models/SpeechLM/2024.07.07_CosyVoice.md) ArXiv:2407.05407.
- [**DAC**: High-Fidelity Audio Compression with Improved RVQGAN.](Models/SpeechCodec/2023.06.11_Descript-Audio-Codec.md) NeurIPS2024.
- [**DeepSeekMath**: Pushing the Limits of Mathematical Reasoning in Open Language Models.](Models/TextLM/2024.02.05_DeepSeekMath.md) ArXiv2024.
- [**DeepVoice3**: 2000-Speaker Neural Text-to-Speech.](Models/Acoustic/2017.10.20_DeepVoice3.md) ICLR2018.
- Density estimation using Real NVP. ICLR2017.
- Discrete Audio Representation as an Alternative to Mel-Spectrograms for Speaker and Speech Recognition. ICASSP2024.
- [**DNSMOS**: A Non-Intrusive Perceptual Objective Speech Quality metric to evaluate Noise Suppressors.](Evaluations/2020.10.28_DNSMOS.md) ICASSP2021.
- [**DPO**: Direct Preference Optimization: Your Language Model Is Secretly A Reward Model.](Modules/RLHF/2023.05.29_DPO.md) NeurIPS2024.
- [**E2 TTS**: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS.](Models/Diffusion/2024.06.26_E2_TTS.md) SLT2024.
- [**EATS**: End-to-end Adversarial Text-to-Speech.](Models/E2E/2020.06.05_EATS.md) ICLR2021.
- [**ELLA-V**: Stable Neural Codec Language Modeling with Alignment-Guided Sequence Reordering.](Models/SpeechLM/ST2S/2024.01.14_ELLA-V.md) ArXiv2024.
- [**Emilia**: An Extensive, Multi-Lingual, and Diverse Speech Dataset for Large-Scale Speech Generation.](Datasets/2024.07.07_Emilia.md) SLT2024.
- [**EnCodec**: High Fidelity Neural Audio Compression.](Models/SpeechCodec/2022.10.24_EnCodec.md) ArXiv2022.
- End-to-End Attention-Based Large Vocabulary Speech Recognition. ICASSP2016.
- End-to-End Speech Recognition Contextualization with Large Language Models. ICASSP2024.
- [**ESD**: Emotional Voice Conversion: Theory, Databases and ESD.](Datasets/2021.05.31_ESD.md) Speech Communication2022.
- Explicitly Minimizing the Blur Error of Variational Autoencoders. ICLR2023.
- [**F5-TTS**: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching.](Models/Diffusion/2024.10.09_F5-TTS.md) ArXiv:2410.06885.
- [**FastSpeech2**: Fast and High-Quality End-to-End Text-to-Speech.](Models/Acoustic/2020.06.08_FastSpeech2.md) ArXiv2022.
- [**FastSpeech**: Fast, Robust and Controllable Text to Speech.](Models/Acoustic/2019.05.22_FastSpeech.md)
- [**FireRedTTS**: A Foundation Text-to-Speech Framework for Industry-Level Generative Speech Applications.](Models/SpeechLM/2024.09.05_FireRedTTS.md) ArXiv2024.
- [**Flow Matching**: Flow Matching for Generative Modeling](Models/Diffusion/2022.10.06_Flow_Matching.md) ArXiv:2210.02747.
- [**Flow++**: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design.](Models/Flow/2019.02.01_Flow++.md) ICML2019.
- [**Flow-TTS**: A Non-Autoregressive Network for Text to Speech Based on Flow.](Models/Acoustic/2020.04.09_Flow-TTS.md) ICASSP2020.
- **FlowSeq**: Non-Autoregressive Conditional Sequence Generation with Generative Flow. EMNLP-IJCNLP2019.
- [**Flowtron**: An Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis.](Models/Acoustic/2020.05.12_Flowtron.md) ICLR2021.
- [**FSQ**: Finite Scalar Quantization: VQ-VAE Made Simple.](Modules/VQ/FSQ.md) ICLR2024.
- [**FunASR**: A Fundamental End-to-End Speech Recognition Toolkit.](Models/Toolkits/2023.05.18_FunASR.md) InterSpeech2023.
- [**FunAudioLLM**: Voice Understanding and Generation Foundation Models for Natural Interaction between Humans and LLMs.](Models/SpeechLM/2024.07.04_FunAudioLLM.md) ArXiv:2407.04051.
- [**GAN-TTS**: High Fidelity Speech Synthesis with Adversarial Networks.](Models/Vocoder/2019.09.25_GAN-TTS.md) ICLR2019.
- [**GAN**: Generative Adversarial Nets.](Models/_Basis/2014.06.10_GAN.md) NeurIPS2014.
- [**Gemini 1.5**: Unlocking Multimodal Understanding Across Millions of Tokens of Context.](Models/TextLM/2024.03.08_Gemini_1.5.md). ArXiv:2403.05530.
- Generating Sequences with Recurrent Neural Networks. ArXiv2013.
- [**GigaSpeech**: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio.](Datasets/2021.06.13_GigaSpeech.md) ArXiv2021.
- [**Glow-TTS**: A Generative Flow for Text-to-Speech via Monotonic Alignment Search.](Models/Acoustic/2020.05.22_Glow-TTS.md) NeurIPS2020.
- [**GMVAE-Tacotron**: Hierarchical Generative Modeling for Controllable Speech Synthesis.](Models/Acoustic/2018.10.16_GMVAE-Tacotron.md) ICLR2019.
- [**Google USM**: Scaling Automatic Speech Recognition Beyond 100 Languages.](Models/ASR/2023.03.02_Google_USM.md) ArXiv:2303.01037.
- [**GPT-3**: Language Models Are Few-Shot Learners.](Models/TextLM/2020.05.28_GPT-3.md) NeurIPS2020.
- [**GPT-4**: GPT-4 Technical Report.](Models/TextLM/2023.03.15_GPT-4.md) ArXiv:2303.08774.
- [GPT-4o System Card.](Models/SpokenDialogue/2024.09.06_GPT-4o.md) ArXiv:2410.21276.
- **GPT-o1**: OpenAI o1 System Card. ArXiv2024.
- [**HiFi-GAN**: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis.](Models/Vocoder/2020.10.12_HiFi-GAN.md) NeurIPS2020.
- [**IAF**: Improved Variational Inference with Inverse Autoregressive Flow.](Models/_Basis/IAF.md) NeurIPS2016.
- [**iDDPM**: Improved Denoising Diffusion Probabilistic Models.](Models/Diffusion/2021.02.18_iDDPM.md) ICML2021.
- Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps. ArXiv2025.
- [**InstructGPT**: Training Language Models to Follow Instructions with Human Feedback.](Models/TextLM/InstructGPT.md) NeurIPS2022.
- [**IPO**: A General Theoretical Paradigm to Understand Learning from Human Preferences.](Modules/RLHF/2023.10.18_IPO.md) AISTATS2024.
- [**IST-LM**: Interleaved Speech-Text Language Models Are Simple Streaming Text to Speech Synthesizers.](Models/SpeechLM/ST2S/2024.12.20_IST-LM.md) ArXiv:2412.16102.
- [**KALL-E**: Autoregressive Speech Synthesis with Next-Distribution Prediction.](Models/SpeechLM/ST2S/2024.12.22_KALL-E.md) ArXiv:2412.16846.
- [**KeSpeech**: An Open Source Speech Dataset of Mandarin and Its Eight Subdialects.](Datasets/KeSpeech.md) NeurIPS Dataset & Benchmark Track 2021.
- [**LAS** Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition.](Models/ASR/2015.08.05_LAS.md) ICASSP2016.
- Latent Normalizing Flows for Discrete Sequences. ICML2019.
- [**LauraGPT**: Listen, Attend, Understand, and Regenerate Audio with GPT.](Models/SpeechLM/ST2ST/2023.10.07_LauraGPT.md) ArXiv:2310.04673.
- Learning Latent Representations for Style Control and Transfer in End-to-End Speech Synthesis. ICASSP2019.
- [**LFSC**: Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference.](Models/SpeechCodec/2024.09.18_LFSC.md) ICASSP2025.
- [**Libriheavy**: A 50,000 Hours ASR Corpus with Punctuation Casing and Context.](Datasets/2023.09.15_Libriheavy.md) ICASSP2024.
- [**LibriSpeech**: An ASR Corpus Based on Public Domain Audio Books.](Datasets/2015.04.19_LibriSpeech.md) ICASSP2015.
- [**LJSpeech**: The LJ Speech Dataset.](Datasets/2017.07.05_LJSpeech.md)
- [**LLaMA**: Open and Efficient Foundation Language Models.](Models/TextLM/2023.02.27_LLaMA.md) ArXiv2023.
- [**LoRA**: Low-Rank Adaptation of Large Language Models.](Modules/LoRA/2021.06.17_LoRA.md) ArXiv:2106.09685.
- [**LSGAN**: Least Squares Generative Adversarial Networks.](Models/_Basis/2016.11.13_LSGAN.md) ICCV2017.
- [**MaskGCT**: Zero-Shot Text-To-Speech with Masked Generative Codec Transformer.](Models/SpeechLM/ST2S/2024.09.01_MaskGCT.md) ArXiv2024.
- [**Matcha-TTS**: A Fast TTS Architecture with Conditional Flow Matching.](Models/Diffusion/2023.09.06_Matcha-TTS.md) ICASSP2024.
- [**MelGAN**: MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis.](Models/Vocoder/2019.10.08_MelGAN.md) NeurIPS2019.
- [**MELLE**: Autoregressive Speech Synthesis without Vector Quantization.](Models/SpeechLM/ST2S/2024.07.11_MELLE.md) ArXiv2024.
- [**MelNet**: A Generative Model for Audio in the Frequency Domain.](Models/Acoustic/2019.06.04_MelNet.md) ArXiv:1906.01083.
- [**MLS**: A Large-Scale Multilingual Dataset for Speech Research.](Datasets/2020.12.07_MLS.md) ArXiv2020.
- [**Moshi**: A Speech-Text Foundation Model for Real-Time Dialogue.](Models/SpokenDialogue/2024.09.17_Moshi.md) ArXiv:/2410.00037.
- [**NaturalSpeech3**: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models.](Models/Diffusion/2024.03.05_NaturalSpeech3.md) ICML2024.
- [**Nemotron-4** 340B Technical Report.](Models/TextLM/2024.06.17_Nemotron-4.md) ArXiv2024.
- Neural Spline Flows. NeurIPS2019.
- [OpenAI. Hello GPT-4o. [URL]](https://openai.com/index/hello-gpt-4o/) 2024.
- [**PaLM2**: PaLM2 Technical Report.](Models/TextLM/2022.04.05_PaLM.md) ArXiv2023.
- [**Paraformer**: Fast and Accurate Parallel Transformer for Non-Autoregressive End-to-End Speech Recognition.](Models/ASR/2022.06.16_Paraformer.md) ArXiv:2206.08317.
- [**ParaNet**: Non-Autoregressive Neural Text-to-Speech.](Models/Acoustic/2019.05.21_ParaNet.md) ICML2020.
- [**Pengi**: An Audio Language Model for Audio Tasks.](Models/SpeechLM/ST2T/2023.05.19_Pengi.md) NeurIPS2023.
- **Phonemizer** [Github](https://github.com/bootphon/phonemizer) 2021.
- [**Qwen-Audio**: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models.](Models/SpeechLM/ST2T/2023.11.14_Qwen-Audio.md) ArXiv:2311.07919.
- [**Qwen2** Technical Report](Models/TextLM/Qwen2.md) ArXiv:2407.10671.
- [**Qwen2-Audio**: Qwen2-Audio Technical Report.](Models/SpeechLM/ST2T/2024.07.15_Qwen2-Audio.md) ArXiv:2407.10759.
- [**RALL-E**: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis.](Models/SpeechLM/ST2S/2024.04.04_RALL-E.md) ArXiv:2404.03204.
- Revisiting Over-Smoothness in Text to Speech. ACL2022.
- [**SALAD**: Continuous Speech Synthesis Using Per-Token Latent Diffusion.](Models/Diffusion/2024.10.21_SALAD.md) ArXiv:2410.16048.
- [**SALM**: Speech-Augmented Language Model with In-Context Learning for Speech Recognition and Translation.](Models/SpeechLM/2023.10.13_SALM.md) ICASSP2024.
- Scaling Laws for Neural Language Models. ArXiv2020.
- Scaling Laws for Neural Language Models. ArXiv:2001.08361.
- Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Model Parameters. ArXiv2024.
- [**Seamless**: Multilingual Expressive and Streaming Speech Translation.](Models/SpeechLM/2023.12.08_Seamless.md) ArXiv2023.
- [**Second-Pass Reranking & Deep LLM-Fusion**: Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition.](Models/ASR/2023.06.28_Prompting_LLMs_for_Zero-Shot_Domain_Adaptation_in_Speech_Recognition.md) ASRU 2023.
- [**Seed-ASR**: Understanding Diverse Speech and Contexts with LLM-Based Speech Recognition.](Models/ASR/2024.07.05_Seed-ASR.md) ArXiv:2407.04675.
- [**Seed-TTS**: A Family of High-Quality Versatile Speech Generation Models.](Models/SpeechLM/2024.06.04_Seed-TTS.md) ArXiv2024.
- Self-Attention with Relative Position Representations. ACL2018.
- [**Semanticodec**: An Ultra Low Bitrate Semantic Audio Codec For General Sound.](Models/SpeechCodec/2024.04.30_SemantiCodec.md) ArXiv2024.
- Sequence Transduction with Recurrent Neural Networks. ArXiv:1211.3711.
- [**SLAM-ASR**: An Embarrassingly Simple Approach for LLM with Strong ASR Capacity.](Models/ASR/2024.02.13_SLAM-ASR.md) ArXiv:2402.08846.
- [**SLM**: Bridge the Thin Gap between Speech and Text Foundation Models.](Models/SpeechLM/2023.09.30_SLM.md) ASRU 2023.
- [**SoundStream**: An End-to-End Neural Audio Codec.](Models/SpeechCodec/2021.07.07_SoundStream.md) TASLP2021.
- [**SPEAR-TTS**: Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision.](Models/SpeechLM/ST2S/2023.02.07_SPEAR-TTS.md) TACL2023.
- SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition. ArXiv:1904.08779.
- [**Spectral Codecs**: Spectrogram-Based Audio Codecs for High Quality Speech Synthesis.](Models/SpeechCodec/2024.06.07_Spectral_Codec.md) ArXiv2024.
- [**Speech-LLaMA**: On Decoder-Only Architecture for Speech-to-Text and Large Language Model Integration](Models/ASR/2023.07.08_Speech-LLaMA.md) ASRU 2023.
- [**SpeechAlign**: Aligning Speech Generation to Human Preferences.](Models/SpeechLM/2024.04.08_SpeechAlign.md) NeurIPS2024.
- [**SpeechGPT**: Empowering Large Language Models with Intrinsic Crossmodal Conversational Abilities.](Models/SpokenDialogue/2023.05.18_SpeechGPT.md) EMNLP2023.
- [**SpeechT5**: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing.](Models/SpeechLM/ST2ST/2021.10.14_SpeechT5.md) ACL2022.
- [**SpeechTokenizer**: Unified Speech Tokenizer for Speech Large Language Models.](Models/SpeechCodec/2023.08.31_SpeechTokenizer.md) ICLR2024.
- [**SpeechX**: Neural Codec Language Models as a Versatile Speech Transformer.](Models/SpeechLM/2023.08.14_SpeechX.md) TASLP2024.
- [**Spirit-LM**: Interleaved Spoken and Written Language Model.](Models/SpeechLM/2024.02.08_SpiRit-LM.md) ArXiv:2402.05755.
- **Stable Codec**: Scaling Transformers for Low-Bitrate High-Quality Speech Coding. ICLR2025.
- Stay on Topic with Classifier-Free Guidance. ArXiv2023.
- [**Survey** End-to-End Speech Recognition: A Survey.](Models/ASR/2023.03.03__Survey__End-to-End_Speech_Recognition_(27P).md) IEEE/ACM@TASLP 2023.
- **Survey**: A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models. ACL EMNLP 2024.
- **Survey**: A Survey on Model Compression for Large Language Models. ACL2024.
- [**Survey**: A Survey on Speech Large Language Models](Surveys/2024.10.24__Survey__A_Survey_on_Speech_Large_Language_Models_(17P).md)
- [**Survey**: Recent Advances in End-to-End Automatic Speech Recognition.](Models/ASR/2021.11.02__Survey__Recent_Advances_in_End-to-End_Automatic_Speech_Recognition_(27P).md) APSIPA TSIP 2022.
- [**Survey**: Towards Controllable Speech Synthesis in the Era of LLM](Surveys/2024.12.09_Towards_Controllable_Speech_Synthesis_in_the_Era_of_LLM_23P/Main.md)
- [**Survey**: WavChat: A Survey of Spoken Dialogue Models](Surveys/2024.11.15_WavChat_60P/Main.md)
- [**Survy**: Recent Advances in Speech Language Models: A Survey](Surveys/2024.10.01_Recent_Advances_in_Speech_Language_Models__A_Survey_20P/Main.md)
- [**T5-TTS**: Improving Robustness of LLM-Based Speech Synthesis by Learning Monotonic Alignment.](Models/SpeechLM/2024.06.25_T5-TTS.md) InterSpeech2024.
- [**Tacotron2**: Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions.](Models/Acoustic/2017.12.16_Tacotron2.md) ICASSP2018.
- [**Tacotron**: A Fully End-to-End Text-to-Speech Synthesis Model.](Models/Acoustic/2017.03.29_Tacotron.md) InterSpeech2017.
- Test-Time Computing: From System-1 Thinking to System-2 Thinking. ArXiv2025.
- [**TorToiseTTS**: Better Speech Synthesis through Scaling.](Models/Diffusion/2023.05.12_TorToise-TTS.md) ArXiv2023.
- [**TouchASP**: Elastic Automatic Speech Perception that Everyone Can Touch.](Models/_Basis/2024.12.20_TouchASP.md) ArXiv:2412.15622.
- Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis. NeurIPS2018.
- [**Transformer-XL**: Attentive Language Models Beyond a Fixed-Length Context.](Models/_Transformer/Transformer-XL.md) ArXiv:1901.02860.
- [**Transformer**: Attention is All You Need.](Models/_Transformer/2017.06.12_Transformer.md) NeurIPS2017.
- [**TransformerTTS**: Neural Speech Synthesis With Transformer Network.](Models/Acoustic/2018.09.19_TransformerTTS.md) AAAI2019.
- Two-Pass End-to-End Speech Recognition. ArXiv:1908.10992.
- [**UniAudio**: Towards Universal Audio Generation with Large Language Models.](Models/SpeechLM/2023.10.01_UniAudio.md) ICML2024.
- Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets. ISCSLP2024.
- [**UTMOS**: UTokyo-Sarulab System For VoiceMOS Challenge 2022.](Evaluations/2022.04.05_UTMOS.md) InterSpeech2022.
- [**VAE**: Auto-Encoding Variational Bayes.](Models/_Basis/VAE.md) ICLR2014.
- [**VALL-E 2**: Neural Codec Language Models Are Human Parity Zero-Shot Text to Speech Synthesizers.](Models/SpeechLM/ST2S/2024.06.08_VALL-E_2.md) ArXiv:2406.05370.
- [**VALL-E R**: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment.](Models/SpeechLM/ST2S/2024.06.12_VALL-E_R.md) ArXiv:2406.07855.
- [**VALL-E X**: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling.](Models/SpeechLM/ST2S/2023.03.07_VALL-E_X.md) ArXiv:2303.03926.
- [**VALL-E**: Neural Codec Language Models Are Zero-Shot Text to Speech Synthesizers.](Models/SpeechLM/ST2S/2023.01.05_VALL-E.md) ArXiv:2301.02111.
- Variational Inference with Normalizing Flows. ICML2015.
- [**VCTK**: CSTR VCTK Corpus: English Multi-Speaker Corpus for CSTR Voice Cloning Toolkit.](Datasets/2012.08.00_VCTK.md)
- [**VFlow**: More Expressive Generative Flows with Variational Data Augmentation.](Models/Flow/VFlow.md) ICML2020.
- [**VioLA**: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation.](Models/SpeechLM/ST2ST/2023.05.25_VioLA.md) ArXiv:2305.16107.
- **VLAE**: Variational Lossy Autoencoder. ICLR2017.
- [**Vocos**: Closing the Gap between Time-Domain and Fourier-Based Neural Vocoders for High-Quality Audio Synthesis.](Models/Vocoder/2023.03.01_Vocos.md) ICLR.
- [**VoiceBox**: Text-Guided Multilingual Universal Speech Generation at Scale.](Models/SpeechLM/2023.06.23_VoiceBox.md) NeurIPS2024.
- [**VoiceLoop**: Voice Fitting and Synthesis via a Phonological Loop.](Models/Acoustic/2017.07.20_VoiceLoop.md) ICLR2018.
- [**VoxtLM**: Unified Decoder-Only Models for Consolidating Speech Recognition/Synthesis and Speech/Text Continuation Tasks.](Models/SpeechLM/2023.09.14_VoxtLM.md) ICASSP2024.
- [**VQ-VAE**: Neural Discrete Representation Learning.](Modules/VQ/2017.11.02_VQ-VAE.md) NeurIPS2017.
- [**Wave-Tacotron**: Spectrogram-Free End-to-End Text-to-Speech Synthesis.](Models/_tmp/Wave-Tacotron.md) ArXiv2020.
- [**WaveGlow**: A Flow-Based Generative Network for Speech Synthesis.](Models/Vocoder/2018.10.31_WaveGlow.md) ICASSP2019.
- [**WaveNet**: A Generative Model for Raw Audio.](Models/Vocoder/2016.09.12_WaveNet.md) ArXiv:1609.03499.
- [**WaveRNN**: Efficient Neural Audio Synthesis.](Models/Vocoder/2018.02.23_WaveRNN.md) ICML2018.
- [**WavTokenizer**: An Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling.](Models/SpeechCodec/2024.08.29_WavTokenizer.md) ArXiv2024.
- [**WenetSpeech4TTS**: A 12,800-Hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark.](Datasets/2024.06.09_WenetSpeech4TTS.md) ArXiv2024.
- [**WenetSpeech**: A 10000+ Hours Multi-Domain Mandarin Corpus for Speech Recognition.](Datasets/2021.10.07_WenetSpeech.md) ICASSP2022.
- [**Whisper**: Robust Speech Recognition via Large-Scale Weak Supervision.](Models/ASR/2022.12.06_Whisper.md) ICML2023.
- [**X-Codec**: Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model.](Models/SpeechCodec/2024.08.30_X-Codec.md) ArXiv2024.
- **YIN**: A Fundamental Frequency Estimator for Speech and Music. 2002.
