
- [**AdamW**: Decoupled Weight Decay Regularization.](Modules/Optimization/2017.11.14_AdamW.md) ICLR2019.
- [**AlignTTS**: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment.](Models/Acoustic/2020.03.04_AlignTTS.md) ICASSP2020.
- [**AudioLM**: A Language Modeling Approach to Audio Generation.](Models/SpeechLM/ST2S/2022.09.07_AudioLM.md) TASLP2023.
- Autoencoding beyond Pixels Using a Learned Similarity Metric. ICML2016.

- [**BASE-TTS**: Lessons from Building a Billion-Parameter Text-to-Speech Model on 100k Hours of Data.](Models/SpeechLM/ST2S/2024.02.12_BASE-TTS.md) ArXiv2024.
- [**BigCodec**: Pushing the Limits of Low-Bitrate Neural Speech Codec.](Models/SpeechCodec/2024.09.09_BigCodec.md) ArXiv2024.
- [**BVAE-TTS**: Bidirectional Variational Inference for Non-Autoregressive Text-to-Speech.](Models/Acoustic/2021.01.13_BVAE-TTS.md) ICLR2021.
- Can Large Language Model Summarizers Adapt to Diverse Scientific Communication Goals? ArXiv2024.
- [**CFG**: Classifier-Free Diffusion Guidance.](Models/Diffusion/2022.07.26_Classifier-Free_Guidance.md) NeurIPS2021.
- [**CLaM-TTS**: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech.](Models/SpeechLM/2024.04.03_CLaM-TTS.md) ICLR.
- Classifier-Free Guidance in LLMs Safety. ArXiv2024.
- [**Cosyvoice**: A Scalable Multilingual Zero-Shot Text-to-Speech Synthesizer Based on Supervised Semantic Tokens.](Models/SpeechLM/2024.07.07_CosyVoice.md) ArXiv2024.
- [**Cosyvoice2**: Scalable Streaming Speech Synthesis with Large Language Models.](Models/SpeechLM/2024.12.13_CosyVoice2.md) ArXiv2024.

- [**DAC**: High-Fidelity Audio Compression with Improved RVQGAN.](Models/SpeechCodec/2023.06.11_Descript-Audio-Codec.md) NeurIPS2024.
- [**DeepSeekMath**: Pushing the Limits of Mathematical Reasoning in Open Language Models.](Models/TextLM/2024.02.05_DeepSeekMath.md) ArXiv2024.
- [**DeepVoice3**: 2000-Speaker Neural Text-to-Speech.](Models/Acoustic/2017.10.20_DeepVoice3.md) ICLR2018.
- Density estimation using Real NVP. ICLR2017.
- [**DNSMOS**: A Non-Intrusive Perceptual Objective Speech Quality metric to evaluate Noise Suppressors.](Evaluations/2020.10.28_DNSMOS.md) ICASSP2021.
- [**DPO**: Direct Preference Optimization: Your Language Model Is Secretly A Reward Model.](Modules/RLHF/2023.05.29_DPO.md) NeurIPS2024.

- [**E2 TTS**: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS.](Models/Diffusion/2024.06.26_E2_TTS.md) SLT2024.
- [**EATS**: End-to-end Adversarial Text-to-Speech.](Models/E2E/2020.06.05_EATS.md) ICLR2021.
- [**ELLA-V**: Stable Neural Codec Language Modeling with Alignment-Guided Sequence Reordering.](Models/SpeechLM/2024.01.14_ELLA-V.md) ArXiv2024.
- [**Emilia**: An Extensive, Multi-Lingual, and Diverse Speech Dataset for Large-Scale Speech Generation.](Datasets/2024.07.07_Emilia.md) SLT2024.
- [**EnCodec**: High Fidelity Neural Audio Compression.](Models/SpeechCodec/2022.10.24_EnCodec.md) ArXiv2022.
- [**ESD**: Emotional Voice Conversion: Theory, Databases and ESD.](Datasets/2021.05.31_ESD.md) Speech Communication2022.

- [**F5-TTS**: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching.](Models/Diffusion/2024.10.09_F5-TTS.md) ArXiv2024.
- [**FastSpeech**: Fast, Robust and Controllable Text to Speech.](Models/Acoustic/2019.05.22_FastSpeech.md)
- [**FastSpeech2**: Fast and High-Quality End-to-End Text-to-Speech.](Models/Acoustic/2020.06.08_FastSpeech2.md) ArXiv2022.
- [**FireRedTTS**: A Foundation Text-to-Speech Framework for Industry-Level Generative Speech Applications.](Models/SpeechLM/2024.09.05_FireRedTTS.md) ArXiv2024.
- [**Flow++**: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design.](Models/Flow/2019.02.01_Flow++.md) ICML2019.
- [**Flow-TTS**: A Non-Autoregressive Network for Text to Speech Based on Flow.](Models/Acoustic/2020.04.09_Flow-TTS.md) ICASSP2020.
- **FlowSeq**: Non-Autoregressive Conditional Sequence Generation with Generative Flow. EMNLP-IJCNLP2019.
- [**Flowtron**: An Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis.](Models/Acoustic/2020.05.12_Flowtron.md) ICLR2021.
- [**FSQ**: Finite Scalar Quantization: VQ-VAE Made Simple.](Modules/VQ/FSQ.md) ICLR2024.
- [**FunASR**: A Fundamental End-to-End Speech Recognition Toolkit.](Models/Toolkits/2023.05.18_FunASR.md) InterSpeech2023.

- [**GAN**: Generative Adversarial Nets.](Models/_Basis/2014.06.10_GAN.md) NeurIPS2014.
- [**GAN-TTS**: High Fidelity Speech Synthesis with Adversarial Networks.](Models/Vocoder/2019.09.25_GAN-TTS.md) ICLR2019.
- Generating Sequences with Recurrent Neural Networks. ArXiv2013.
- [**GigaSpeech**: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio.](Datasets/2021.06.13_GigaSpeech.md) ArXiv2021.
- [**Glow-TTS**: A Generative Flow for Text-to-Speech via Monotonic Alignment Search.](Models/Acoustic/2020.05.22_Glow-TTS.md) NeurIPS2020.
- [**GMVAE-Tacotron**: Hierarchical Generative Modeling for Controllable Speech Synthesis.](Models/Acoustic/2018.10.16_GMVAE-Tacotron.md) ICLR2019.
- [**GPT-3**: Language Models Are Few-Shot Learners.](Models/TextLM/2020.05.28_GPT-3.md) NeurIPS2020.
- [**GPT-4**: GPT-4 Technical Report.](Models/TextLM/2023.03.15_GPT-4.md) ArXiv2023.
- **GPT-o1**: OpenAI o1 System Card. ArXiv2024.

- [**HiFi-GAN**: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis.](Models/Vocoder/2020.10.12_HiFi-GAN.md) NeurIPS2020.

- [**IAF**: Improved Variational Inference with Inverse Autoregressive Flow.](Models/_Basis/IAF.md) NeurIPS2016.
- Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps. ArXiv2025.
- [**InstructGPT**: Training Language Models to Follow Instructions with Human Feedback.](Models/TextLM/InstructGPT.md) NeurIPS2022.
- [**IPO**: A General Theoretical Paradigm to Understand Learning from Human Preferences.](Modules/RLHF/2023.10.18_IPO.md) AISTATS2024.

- [**KALL-E**: Autoregressive Speech Synthesis with Next-Distribution Prediction.](Models/SpeechLM/2024.12.22_KALL-E.md) ArXiv2024.

- Latent Normalizing Flows for Discrete Sequences. ICML2019.
- Learning Latent Representations for Style Control and Transfer in End-to-End Speech Synthesis. ICASSP2019.
- [**LFSC**: Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference.](Models/SpeechCodec/2024.09.18_LFSC.md) ICASSP2025.
- [**Libriheavy**: A 50,000 Hours ASR Corpus with Punctuation Casing and Context.](Datasets/2023.09.15_Libriheavy.md) ICASSP2024.
- [**LibriSpeech**: An ASR Corpus Based on Public Domain Audio Books.](Datasets/2015.04.19_LibriSpeech.md) ICASSP2015.
- [**LJSpeech**: The LJ Speech Dataset.](Datasets/2017.07.05_LJSpeech.md)
- [**LLaMA**: Open and Efficient Foundation Language Models.](Models/TextLM/2023.02.27_LLaMA.md) ArXiv2023.
- [**LoRA**: Low-Rank Adaptation of Large Language Models.](Modules/LoRA/2021.06.17_LoRA.md) ArXiv2021.
- [**LSGAN**: Least Squares Generative Adversarial Networks.](Models/_Basis/2016.11.13_LSGAN.md) ICCV2017.
- [**MaskGCT**: Zero-Shot Text-To-Speech with Masked Generative Codec Transformer.](Models/SpeechLM/2024.09.01_MaskGCT.md) ArXiv2024.
- [**MelGAN**: MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis.](Models/Vocoder/2019.10.08_MelGAN.md) NeurIPS2019.
- [**MELLE**: Autoregressive Speech Synthesis without Vector Quantization.](Models/SpeechLM/2024.07.11_MELLE.md) ArXiv2024.
- [**MLS**: A Large-Scale Multilingual Dataset for Speech Research.](Datasets/2020.12.07_MLS.md) ArXiv2020.
- [**Moshi**: A Speech-Text Foundation Model for Real-Time Dialogue.](Models/SpokenDialogue/2024.09.17_Moshi.md) ArXiv2024.
- [**Nemotron-4** 340B Technical Report.](Models/TextLM/2024.06.17_Nemotron-4.md) ArXiv2024.
- Neural Spline Flows. NeurIPS2019.

- [**PaLM2**: PaLM2 Technical Report.](Models/TextLM/2022.04.05_PaLM.md) ArXiv2023.
- [**ParaNet**: Non-Autoregressive Neural Text-to-Speech.](Models/Acoustic/2019.05.21_ParaNet.md) ICML2020.
- **Phonemizer** [Github](https://github.com/bootphon/phonemizer) 2021.
- [**Seamless**: Multilingual Expressive and Streaming Speech Translation.](Models/SpeechLM/2023.12.08_Seamless.md) ArXiv2023.
- [**Seed-TTS**: A Family of High-Quality Versatile Speech Generation Models.](Models/SpeechLM/2024.06.04_Seed-TTS.md) ArXiv2024.
- [**Semanticodec**: An Ultra Low Bitrate Semantic Audio Codec For General Sound.](Models/SpeechCodec/2024.04.30_SemantiCodec.md) ArXiv2024.
- Scaling Laws for Neural Language Models. ArXiv2020.
- Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Model Parameters. ArXiv2024.
- Self-Attention with Relative Position Representations. ACL2018.
- [**SoundStream**: An End-to-End Neural Audio Codec.](Models/SpeechCodec/2021.07.07_SoundStream.md) TASLP2021.
- **Stable Codec**: Scaling Transformers for Low-Bitrate High-Quality Speech Coding. ICLR2025.
- Stay on Topic with Classifier-Free Guidance. ArXiv2023.
- [**SPEAR-TTS**: Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision.](Models/SpeechLM/ST2S/2023.02.07_SPEAR-TTS.md) TACL2023.
- [**Spectral Codecs**: Spectrogram-Based Audio Codecs for High Quality Speech Synthesis.](Models/SpeechCodec/2024.06.07_Spectral_Codec.md) ArXiv2024.
- [**SpeechAlign**: Aligning Speech Generation to Human Preferences.](Models/SpeechLM/2024.04.08_SpeechAlign.md) NeurIPS2024.
- [**SpeechT5**: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing.](Models/SpeechLM/ST2ST/2021.10.14_SpeechT5.md) ACL2022.
- [**SpeechTokenizer**: Unified Speech Tokenizer for Speech Large Language Models.](Models/SpeechCodec/2023.08.31_SpeechTokenizer.md) ICLR2024.
- [**SpeechX**: Neural Codec Language Models as a Versatile Speech Transformer.](Models/SpeechLM/2023.08.14_SpeechX.md) TASLP2024.

- **Survey**: A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models. ACL EMNLP 2024.
- **Survey**: A Survey on Model Compression for Large Language Models. ACL2024.

- [**T5-TTS**: Improving Robustness of LLM-Based Speech Synthesis by Learning Monotonic Alignment.](Models/SpeechLM/2024.06.25_T5-TTS.md) InterSpeech2024.
- [**Tacotron2**: Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions.](Models/Acoustic/2017.12.16_Tacotron2.md) ICASSP2018.
- Test-Time Computing: From System-1 Thinking to System-2 Thinking. ArXiv2025.
- [**TorToiseTTS**: Better Speech Synthesis through Scaling.](Models/Diffusion/2023.05.12_TorToise-TTS.md) ArXiv2023.
- [**Transformer**: Attention is All You Need.](Models/_Transformer/2017.06.12_Transformer.md) NeurIPS2017.
- [**TransformerTTS**: Neural Speech Synthesis With Transformer Network.](Models/Acoustic/2018.09.19_TransformerTTS.md) AAAI2019.
- Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis. NeurIPS2018.

- [**UniAudio**: Towards Universal Audio Generation with Large Language Models.](Models/SpeechLM/2023.10.01_UniAudio.md) ICML2024.
- [**UTMOS**: UTokyo-Sarulab System For VoiceMOS Challenge 2022.](Evaluations/2022.04.05_UTMOS.md) InterSpeech2022.

- [**VAE**: Auto-Encoding Variational Bayes.](Models/_Basis/VAE.md) ICLR2014.
- [**VALL-E**: Neural Codec Language Models Are Zero-Shot Text to Speech Synthesizers.](Models/SpeechLM/ST2S/2023.01.05_VALL-E.md) ArXiv2023.
- [**VALL-E 2**: Neural Codec Language Models Are Human Parity Zero-Shot Text to Speech Synthesizers.](Models/SpeechLM/2024.06.08_VALL-E_2.md) ArXiv2024.
- [**VALL-E R**: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment.](Models/SpeechLM/2024.06.12_VALL-E_R.md) ArXiv2024.
- [**VALL-E X**: Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling.](Models/SpeechLM/ST2S/2023.03.07_VALL-E_X.md) ArXiv2023.
- Variational Inference with Normalizing Flows. ICML2015.
- [**VCTK**: CSTR VCTK Corpus: English Multi-Speaker Corpus for CSTR Voice Cloning Toolkit.](Datasets/2012.08.00_VCTK.md)
- [**VFlow**: More Expressive Generative Flows with Variational Data Augmentation.](Models/Flow/VFlow.md) ICML2020.
- **VLAE**: Variational Lossy Autoencoder. ICLR2017.
- [**Vocos**: Closing the Gap between Time-Domain and Fourier-Based Neural Vocoders for High-Quality Audio Synthesis.](Models/Vocoder/2023.03.01_Vocos.md) ICLR.
- [**VoiceBox**: Text-Guided Multilingual Universal Speech Generation at Scale.](Models/SpeechLM/2023.06.23_VoiceBox.md) NeurIPS2024.
- [**VoiceLoop**: Voice Fitting and Synthesis via a Phonological Loop.](Models/Acoustic/2017.07.20_VoiceLoop.md) ICLR2018.
- [**VQ-VAE**: Neural Discrete Representation Learning.](Modules/VQ/2017.11.02_VQ-VAE.md) NeurIPS2017.
- [**Wave-Tacotron**: Spectrogram-Free End-to-End Text-to-Speech Synthesis.](Models/_tmp/Wave-Tacotron.md) ArXiv2020.
- [**WaveGlow**: A Flow-Based Generative Network for Speech Synthesis.](Models/Vocoder/2018.10.31_WaveGlow.md) ICASSP2019.
- [**WaveNet**: A Generative Model for Raw Audio.](Models/Vocoder/2016.09.12_WaveNet.md) ArXiv2016.
- [**WaveRNN**: Efficient Neural Audio Synthesis.](Models/Vocoder/2018.02.23_WaveRNN.md) ICML2018.
- [**WavTokenizer**: An Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling.](Models/SpeechCodec/2024.08.29_WavTokenizer.md) ArXiv2024.
- [**WenetSpeech4TTS**: A 12,800-Hour Mandarin TTS Corpus for Large Speech Generation Model Benchmark.](Datasets/2024.06.09_WenetSpeech4TTS.md) ArXiv2024.
- [**Whisper**: Robust Speech Recognition via Large-Scale Weak Supervision.](Models/ASR/2022.12.06_Whisper.md) ICML2023.

- [**X-Codec**: Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model.](Models/SpeechCodec/2024.08.30_X-Codec.md) ArXiv2024.

- **YIN**: A Fundamental Frequency Estimator for Speech and Music. 2002.
