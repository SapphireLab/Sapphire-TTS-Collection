# 06.语言模型

**语言模型 (Language Model)** 用于计算一个文字序列的概率, 评估该序列作为一段文本出现在通用或特定场景中的可能性.
每个人的语言能力蕴含了一个语言模型, 当我们说出或写下一段话的时候, 已经在不自觉地应用语言模型来帮助我们决定这段话中的每个词, 使之通顺合理.
语言模型在自然语言处理中也有诸多应用, 例如, 当我们使用拼音中文输入法输入 `ziranyuyan`, 输出的候选文字中 `自然语言` 比 `孜然鱼雁` 更靠前, 这是因为中文输入法所使用的语言模型判断出前者的概率更高.
类似地, 在机器翻译, 拼写检查, 语音识别等应用中, 语言模型也被用来在多项候选文字中选择更合理, 更有可能出现的文字.

本章将首先概述语言模型, 然后介绍不同的方法来实现语言模型, 包括最简单的 $n$ 元语法模型, 更复杂但效果更好的循环神经网络, 在循环神经网络的基础上引入的注意力机制, 以及纯粹基于注意力机制的 Transformer 模型.

## 6.1.概述

要想得到一个语言模型, 最简单的想法是从一个大型语料库中直接统计不同文字序列出现的频率.
然而由于文字序列的排列组合空间极大, 不可能找到一个包含所有合理的文字序列的语料库, 因此这个想法是不可行的.
既然序列的概率无法通过经验频率估计, 那么是否可以通过概率乘法公式将其转换为一系列条件概率的乘积, 转而估算这些条件概率呢?

$$
    P(w_1,\cdots,w_n) = \prod_{i=1}^n P(w_i|w_1,\cdots,w_{i-1})
$$

其中 $w_i$ 表示输入文字序列的第 $i$ 个词.

那么这个序列 `自然语言` 的概率可以分解为 $P(自然语言) = P(自) P(然|自) P(语|自然) P(言|自然语)$.
这种分解方式的一个潜在好处在于, 一旦能够成功估算所有可能的条件概率, 就可以用它来生成文本.
具体而言, 首先根据第一个词的概率分布采样出第一个词, 再根据给定第一个词时第二个词的条件概率分布采样出第二个词, 以此类推.
这种逐个词依次输出, 每一步根据已输出的词决定下一个词的过程称为**自回归 (Auto-Regressive)** 过程.

---

那么如何估算这些条件概率呢?
最直接的想法是最大似然估计: $P(言|自然语) = \dfrac{count(自然语言)}{count(自然语)}$.
但这显然也是不可行的, 同样因为我们无法找到一个足够大的包含所有合理文字序列的语料库来估算频率.

因此, 人们发展出 $n$ 元语法模型, 循环神经网络, Transformer 模型等一系列方法来计算这些条件概率.

- $n$ 元 ($n$-gram) 语法模型: 每个词的概率仅以前 $n-1$ 个词为条件.
- 循环神经网络 (RNN): 每个词的概率以一个包含前置序列全部信息的稠密向量为条件.
- Transformer: 每个词的概率通过对前置所有词使用注意力机制得到.

本章将对这些方法的细节进行详细介绍.
除了这些方法, 还存在一些更复杂的方法, 如基于句法结构的生成式文法等, 后面的章节会介绍其中一些方法, 这里不再展开.

---

所有这些方法所共同面临的一个问题是, 如何处理在模型训练时没有见过的词, 即所谓**未登录 (Out-Of-Vocabulary, OOV)** 词.
一个常用的方法是引入一个特殊词 `[UNK]`: 
- 在训练时, 创建一个固定的词表 (如所有高频词), 将训练语料库中所有未在词表中出现的词都替换为 `[UNK]`, 并将 `[UNK]` 作为一个正常词估算概率;
- 在测试时, 使用 `[UNK]` 的概率来代替任何未登录词的概率.

除了这个方法之外, 还可以在字符或者子词级建立语言模型.
因为任何词都可以拆解为若干字符或子词的组合, 而字符或子词的个数较少. (注: 一般不超过几万, 例如大小写英文字符只有 52 个, BERT 的词表包含约 3 万个子词).
所以这样的语言模型能够涵盖所有字符或子词, 从而涵盖所有可能的文字序列.

---

本节最后讨论如何评估一个语言模型的质量.
一种方式是在下游任务 (如机器翻译, 语音识别等) 中检验语言模型的性能, 但这往往比较费时费力, 并且不同下游任务的评估结果有可能大相径庭.
因此评估语言模型的通用方法是使用**困惑度 (Perplexity)**, 即评估模型是否给训练语料库之外的真实测试语言语料库赋予较大的概率.
对于测试语料库 $\bar{x}_{1:m}$ ($m$ 个序列), 使用待评估模型计算每个词的平均负对数概率:

$$
    l=-\dfrac{1}{M}\sum_{i=1}^m \log P(\bar{x}_i)
$$

其中 $M$ 为测试语料库中的总词数.

该评价指标相当于编码每个词平均所需的比特数, 其二次幂 $2^l$ 就被称为测试数据的困惑度.
困惑度越小则测试语料库的概率越大, 因此可认为被评估模型的质量越高.
困惑度的最小值是 1, 这仅当所有测试语料的概率均为 1 的极端情况下才能取得.

需要特别注意的是, 词表不同的两个语言模型, 其困惑度是不可比较的, 显然, 词表较小的语言模型平均会给每个词更高的概率, 因而更有可能具有较低的困惑度, 极端情况下, 如果词表只包含 `[UNK]` 这一个词, 那么模型的困惑度可以达到完美的 1.
但词表过小的语言模型会将过多的词当作 `[UNK]`, 缺乏区分度, 因而不是一个好的语言模型.
因此, 要比较不同的语言模型方法时, 需要使用统一的词表.
