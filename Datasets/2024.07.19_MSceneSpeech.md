# MSceneSpeech

<details>
<summary>基本信息</summary>

- 标题: "MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech Synthesis"
- 作者:
  - 01 Qian Yang
  - 02 Jialong Zuo
  - 03 Zhe Su
  - 04 Ziyue Jiang
  - 05 Mingze Li
  - 06 Zhou Zhao (赵洲)
  - 07 Feiyang Chen
  - 08 Zhefeng Wang
  - 09 Baoxing Huai
- 链接:
  - [ArXiv](https://arxiv.org/abs/2407.14006)
  - [Publication](https://doi.org/10.21437/Interspeech.2024-266)
  - [Github]
  - [Demo](https://speechai-demo.github.io/MSceneSpeech/)
  - [Drive](https://drive.google.com/drive/folders/12DSuH8ynBc82RYYHQZmMmp7q6O1xSVh5?usp=sharing)
- 文件:
  - [ArXiv](_PDF/2407.14006v1__MSceneSpeech__A_Multi-Scene_Speech_Dataset_for_Expressive_Speech_Synthesis.pdf)
  - [Publication](_PDF/2407.14006p0__MSceneSpeech__InterSpeech2024.pdf)

</details>

## Abstract: 摘要

We introduce an open source high-quality Mandarin TTS dataset ***MSceneSpeech*** (Multiple Scene Speech Dataset), which is intended to provide resources for expressive speech synthesis.
***MSceneSpeech*** comprises numerous audio recordings and texts performed and recorded according to daily life scenarios.
Each scenario includes multiple speakers and a diverse range of prosodic styles, making it suitable for speech synthesis that entails multi-speaker style and prosody modeling.
We have established a robust baseline, through the prompting mechanism, that can effectively synthesize speech characterized by both user-specific timbre and scene-specific prosody with arbitrary text input.
The open source ***MSceneSpeech*** Dataset and audio samples of our baseline are available at [this https URL](https://speechai-demo.github.io/MSceneSpeech/).

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论