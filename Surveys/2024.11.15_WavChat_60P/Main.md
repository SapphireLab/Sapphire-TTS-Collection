# WavChat

<details>
<summary>基本信息</summary>

- 标题: "WavChat: A Survey of Spoken Dialogue Models"
- 作者:
  - 01 Shengpeng Ji (浙江大学, shengpengji@zju.edu.cn)
  - 00 Yifu Chen (浙江大学)
  - 00 Minghui Fang (浙江大学)
  - 00 Jialong Zuo (浙江大学)
  - 00 Jingyu Lu (浙江大学)
  - 00 Hanting Wang (浙江大学)
  - 00 Ziyue Jiang (浙江大学)
  - 00 Long Zhou (微软)
  - 00 Shujie Liu (微软)
  - 00 Xize Cheng (浙江大学)
  - 00 Xiaoda Yang (浙江大学)
  - 00 Zehan Wang (浙江大学)
  - 00 Qian Yang (浙江大学)
  - 00 Jian Li (腾讯优图实验室)
  - 00 Yidi Jiang (阿里巴巴)
  - 00 Jingzhen He (阿里巴巴)
  - 00 Yunfei Chu (阿里巴巴)
  - 00 Jin Xu (阿里巴巴)
  - 00 Zhou Zhao (浙江大学, zhaozhou@zju.edu.cn)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2411.13577)
  - [Publication]
  - [Github](https://github.com/jishengpeng/WavChat)0
  - [Demo]
- 文件:
  - [ArXiv](2411.13577v1__Survey__WavChat__A_Survey_of_Spoken_Dialogue_Models.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Recent advancements in spoken dialogue models, exemplified by systems like GPT-4o, have captured significant attention in the speech domain.
In the broader context of multimodal models, the speech modality offers a direct interface for human-computer interaction, enabling direct communication between AI and users.
Compared to traditional three-tier cascaded spoken dialogue models that comprise speech recognition (ASR), large language models (LLMs), and text-to-speech (TTS), modern spoken dialogue models exhibit greater intelligence.
These advanced spoken dialogue models not only comprehend audio, music, and other speech-related features, but also capture stylistic and timbral characteristics in speech.
Moreover, they erate high-quality, multi-turn speech responses with low latency, enabling real-time interaction through simultaneous listening and speaking capability.
Despite the progress in spoken dialogue systems, there is a lack of comprehensive surveys that systematically organize and analyze these systems and the underlying technologies.
To address this, \textbf{we have first compiled existing spoken dialogue systems in the chronological order and categorized them into the cascaded and end-to-end paradigms.} We then provide an in-depth overview of the core technologies in spoken dialogue models, covering aspects such as \textbf{speech representation, training paradigm, streaming, duplex, and interaction capabilities.} Each section discusses the limitations of these technologies and outlines considerations for future research.
Additionally, we present a thorough review of \textbf{relevant datasets, evaluation metrics, and benchmarks} from the perspectives of training and evaluating spoken dialogue systems.
We hope this survey will contribute to advancing both academic research and industrial applications in the field of spoken dialogue systems.
The related material is available at [Github](https://github.com/jishengpeng/WavChat).

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论
