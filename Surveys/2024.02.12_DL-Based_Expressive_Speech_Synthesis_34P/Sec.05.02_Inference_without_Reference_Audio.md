
### 5.2.无参考音频推理 (Inference without Reference Audio)

A main drawback of the unsupervised approaches ([Section 4](#Sec4)) is that they require a reference audio for the desired prosody or style of the generated speech.
However, prosody references are not always available for the desired speaker, style, or text.
Besides, using prosody reference introduces the leakage problem as discussed in [Section 5.1]().
As a result, different techniques have been proposed that enable unsupervised expressive speech synthesis without prosody references.
Some techniques utilize the reference audio at training phase while at inference phase speech synthesis can be done with or without a reference audio.
Other techniques depend on input text only to generate prosody embedding at both training and inference phases.
In the following three sections, we will describe techniques for inference without reference audio applied with each of the three main unsupervised ETTS approaches.
In [Section 5.2.4](), we will discuss some ETTS approaches that are based on text only.
Then in Table 4, we summarize main approaches that are used to extract text-based features with related papers links.

第四节中总结的无监督方法的一个主要缺点是, 它们需要一个参考音频用于所生成语音的期望韵律或风格. 然而所需说话人/风格/文本的韵律参考并不总是能够获得.
此外使用韵律参考会引入第5.1节讨论的泄露问题.
因此出现了各种技术使得无监督表达性语音合成能够无韵律参考.
一些技术在训练阶段使用参考音频, 而推理阶段语音合成就可以用或不同参考音频.
其他技术只依赖于输入文本用于在训练和推理阶段生成韵律嵌入.
在以下三小节中将描述无参考音频的推理技术, 应用于三种主要的无监督表达性语音合成方法中.
在第四小节将讨论一些仅依赖于文本的表达性语音合成方法.
表格四总结了相关文献中用于提取基于文本的特征的主要方法.

#### 5.2.1.无参考音频的直接参考编码 Direct Reference Encoding without Reference Audio

In several studies, prosody predictors are trained jointly with the proposed reference encoder to bypass the requirement for reference audio at inference time.
The prosody predictors are trained to predict either the prosody embeddings generated by reference encoders[50] [96] [111] [116], or the acoustic features used as input to reference encoders [37] [63].
As input to these prosody predictors, most studies utilize the phoneme embeddings[37] [63] [96] [111].

在一些研究中, 韵律预测器与所提出的参考编码器联合训练, 以绕过推理时对参考音频的要求. 韵律预测器被训练用于预测参考编码器生成的韵律嵌入或用作参考编码器输入的声学特征.
作为这些韵律预测器的输入, 大多数研究使用音素嵌入.

Alternatively, features extracted from input text can also be used as input for prosody predictors.
In [50], the prosody predictor has a hierarchical structure that utilizes contextual information at both the sentence and paragraph levels to predict prosody embeddings.
The input features for this predictor are in the form of 768-dimensional phrase embeddings extracted by the pre-trained language model XLNet [160].
Sentence embeddings are initially predicted from the input features using an attention network.
Then a second attention network is used to predict the paragraph-level prosody embedding.

或者从输入文本提取的特征也可以作为韵律预测器的输入.
文献 [050] 中韵律预测其有一个层次结构, 利用句子和段落级别的上下文信息来预测韵律嵌入. 这一预测器的输入特征是使用预训练语言模型 XLNet 提取的 768 维的短语嵌入形式. 首先通过注意力网络从输入特征中预测句子嵌入, 然后第二个注意力网络用于预测段落级别的韵律嵌入.

Furthermore, in [33], emotion is modelled at three levels: global, utterance, and syllable (local).
The model employs three prosody encoders, each with a predictor trained to predict the corresponding prosody embedding based on input text.
The global-level predictor functions as an emotion classifier, where the output of its final softmax layer serves as the global emotion embedding.
The emotion label’s embedding is used as the ground truth for this emotion classifier.
Both the utterance and local prosody encoders receive level-aligned mel-spectrograms as input and produce utterance prosody embedding and local prosody strength embedding, respectively.
Similarly, two prosody predictors are used to predict utterance and local-level embeddings based on the output from the text encoder of the TTS model.

文献 [033] 中情感被建模在三个级别: 全局, 语调和音节 (局部). 模型应用三个韵律编码器, 每个编码器都有一个预测器训练成基于输入文本预测对应的韵律嵌入. 全局预测器作为情感分类器, 其最终的 softmax 层输出作为全局情感嵌入. 情感标签的嵌入作为这一情感分类器的真实值. 语调和局部韵律编码器都接收级别对齐的梅尔频谱作为输入, 并分别生成语调韵律嵌入和局部韵律强度嵌入. 类似地, 两个韵律预测器基于 TTS 模型的文本编码器的输出预测语调和局部级别嵌入.

In contrast, the prosody predictor proposed in paper [44] learns multiple mixed Gaussian distributions model (GMM) for prosody representations.
Therefore, the final outputs of the prosody predictor involve three parameters: mean, variance, and weight of multiple mixed Gaussian distributions from which prosody representations can be sampled at inference time.
As input, the predictor receives two phoneme-level sequences including embeddings from the text encoder and embeddings from a pre-trained language model.
Similar work is proposed in [95] where only phoneme embeddings are used as input to the prosody predictor.
GMM in both studies is modeled via the mixture density network [161].

文献 [044] 提出的韵律预测器学习多重混合高斯分布模型用于韵律表示. 因此韵律预测器的最终输出包含三个参数: 均值, 方差和多混合高斯分布的权重. 从这些分布中可以在推理时采样韵律表示. 作为输入, 预测器接收两个音素级别的序列包括来自文本编码器的嵌入和来自预训练语言模型的嵌入.

文献 [095] 提出的相似工作, 只使用音素嵌入作为韵律预测器的输入.

两项工作的 GMM 都通过混合密度网络进行建模.

#### 5.2.2.无参考语音的VAE类方法 (VAE‑Based Approaches without Reference Audio)

Sampling from the latent space without reference audio results in less controllability of style.
In addition, it can also introduce naturalness degradation and inappropriate contextual prosody with regard to the input text [68] [129].
Therefore, to avoid sampling the latent space without a reference, authors of [131] proposed utilizing the same prosody embedding of the most similar training sentence to input sentence at inference time.
The selection process is based on measuring cosine similarity between sentences’ linguistic features.
Three methods are proposed for extracting sentence linguistic information including
(1) calculating the syntactic distance between words in the sentence using constituency trees [162],
(2) averaging the contextual word embeddings (CWE) for the words in the sentence using BERT, and
(3) combining the previous two methods.

在没有参考音频的情况下从隐空间采样会导致风格的可控性降低. 此外它还会引入自然性退化和和不适合输入文本的语境韵律.
因此为了避免在没有参考的情况下从隐空间中采样, 文献 [131] 提出推理时用和输入句子最相似的训练句子的相同韵律嵌入. 选择过程基于句子语言特征之间的余弦相似度. 三种方法用于提取句子语言信息:
1. 使用句法树计算句子中单词的句法距离;
2. 使用 BERT 计算句子中单词的上下文词嵌入 (Contextual Word Embeddings, CWE) 的平均值;
3. 结合前两种方法.

Other studies approach the problem in alternative ways, seeking to enhance the sampling process either through refining the baseline model structure or by incorporating text-based components into the baseline.
Regarding the improvement of the baseline structure, study [68] suggests the combination of multiple variational autoencoders to generate latent variables at three distinct levels: utterance-level, phrase-level, and word-level.
Furthermore, they apply a conditional prior (CP) to learn the latent space distribution based on the input text embedding.
To account for dependencies within the input text, they employ Autoregressive (AR) latent converters to transform latent variables from coarser to finer levels.
An alternative approach is proposed in [126] by replacing the conventional VAE encoder with a residual encoder that leverages phoneme embedding and a set of learnable free parameters as inputs.
With this modified structure, the model learns a latent distribution that represents various prosody styles for a specific sentence (i.e.,the input text), in addition to capturing potential global biases within the applied dataset (represented by the free parameters).
At the same time, with this modification, the problem of speaker and content leakage into prosody embedding is addressed.

其他研究以不同的方式解决这个问题, 寻求通过改进基线模型结构或向基线模型中添加基于文本的组件来增强采样过程.
关于基线结构的改进:
- 文献 [068] 建议组合多个变分自编码器用于生成三个不同级别的隐变量: 语调级, 短语级和单词级. 此外应用了条件先验基于输入文本嵌入学习隐空间分布. 为了考虑输入文本内的依赖性, 他们应用自回归隐转化器将隐变量从粗糙级别转化为精细级别.
- 文献 [126] 提出了一种替代方法, 通过将传统 VAE 替换为一个利用音素嵌入和一组可学习自由参数作为输入的残差编码器. 采用这一结构, 模型为一个具体句子即输入文本学习一个隐分布表示各种韵律风格, 同时捕捉应用数据集的潜在全局偏差 (由自由参数表示). 同时说话人和内容泄露到韵律嵌入的问题也得到解决.

Various studies propose training a predictor for the latent prosody vectors based on features extracted from the input text [35] [47].
The proposed model in [47] generates fine-grained prosody latent codes of three dimensions at phoneme-level.
These prosody codes are then used to guide the training process of a prosody predictor that receives phoneme embeddings as input, in addition to emotion and speaker embeddings as sentence-level conditions.
In [35], the predicted mean values of the latent space distribution are employed as prosody codes.
Similarly, a prosody predictor is trained to predict these prosody codes using two text-based inputs, including sentence-level embeddings from a pre-trained BERT model and contextual information considering BERT embeddings of a few of surrounding k sentences given the current sentence.

多项研究提出基于从输入文本中提取的特征训练一个隐韵律向量的预测器.
- 文献 [047] 提出的模型在音素级别生成细粒度的三维韵律隐代码. 这些韵律代码之后用于指导韵律预测器的训练. 预测器接收音素嵌入作为输入, 此外情感和说话人嵌入作为句子级别条件.
- 文献 [035] 中隐空间分布的预测均值作为韵律编码. 类似地训练一个韵律预测器使用两个基于文本的输入包括来自预训练 BERT 模型的句子级别嵌入和考虑当前句子周围的 k 个句子的 BERT 嵌入的上下文信息用于预测这些韵律编码.

Alternatively, study [129] proposed training a sampler, i.e., Gaussian parameters, to sample the latent space using features extracted from the input text.
Three different structures are investigated for the sampler based on the input features it receives.
The applied text-based features include BERT representations of a sentence (semantic information), the parsing tree of the sentence (syntactic information) after it is fed to a graph attention network, and the concatenation of outputs from the previous two samplers.

文献 [129] 提出训练一个采样器, 即高斯参数, 使用输入文本提取的特征对隐空间进行采样. 根据采样器接收的输入特征, 研究了三种不同的结构. 应用基于文本的特征包括句子的 BERT 表示 (语义信息), 图注意力网络输出的句子的解析树 (语法信息) 和前两个采样器的输出的拼接.

#### 5.2.3.无参考音频的 GST 类方法 (GST‑Based Approaches without Reference Audio)

There are GST-TTS models that utilize text-based features from pre-trained language models such as BERT to guide expressive speech synthesis at inference time without a reference.
In [ST-TTS](../2021.04_ST-TTS/2021.04_ST-TTS.md), the training dataset is labeled with short phrases that describe the style of the utterance and are known as style tags.
A pre-trained Sentence BERT (SBERT) model is used to produce embeddings for each style tag as input to a style tag encoder.
The style embedding from the GST-TTS model is used as ground truth for the style tag encoder.
During inference, either a reference audio or a style tag can be used to generate speech.

有些 GST-TTS 模型使用来自预训练语言模型 (如 BERT) 的基于文本的特征用于指导在推理时进行无参考的表达性语音合成.
- ST-TTS 中训练集用描述语调风格的短语进行标注, 即风格标签. 用一个预训练的句子 BERT 模型 (SBERT) 为每个风格标签生成嵌入作为风格标签编码器的输入. 来自 GST-TTS 模型的风格嵌入作为风格标签编码器的真实值. 在推理时, 可以使用参考音频或风格标签用于生成语音.

Alternatively, pre-trained language models are used to extract features from the input text and train a prosody predictor to predict the style embedding based on these text-based features (Context-Aware Style Predictor, [46] [50] [73] [91] [94].
In [94], the baseline model [75] is extended with a prosody predictor module that extracts time-aggregated features from the output of the baseline text encoder.
Two pathways are suggested for the targets of the predictor output: either using the weights of the GSTs or the final style embedding.
Similarly, in [73], two prosody predictors are investigated, using different inputs from a pre-trained multi-language BERT model.
While the first predictor utilizes BERT embeddings for the sub-word sequence of input text, the other predictor employs only the CLS token from the sentence-level information extracted by the BERT model.
Both inputs provide rich information for the predictors to synthesize prosodic speech based solely on input text.

或者使用预训练的语言模型来从输入文本中提取特征并训练一个韵律预测器, 基于这些基于文本的特征来预测风格嵌入.
- 文献 [094] 中将基线模型 [075] 用韵律预测器模块进行扩展, 用于从基线文本编码器的输出中提取时间聚合特征. 对于预测器输出的目标有两个建议: 使用 GSTs 的权重或最终风格嵌入.
- 文献 [073] 研究了两个韵律预测器, 使用来自预训练多语言 BERT 模型的不同输入. 第一个预测器使用输入文本的子词序列的 BERT 嵌入, 第二个预测器仅使用从 BERT 模型提取的句子级别信息中的 CLS token. 这两个输入都为预测器提供了丰富的信息从而仅依靠输入文本合成韵律语音.

The multi-scale GST-TTS proposed in [50] which employs three style encoders, also introduces three style predictors that employ hierarchical context encoders (HCE).
The input to the first predictor is the BERT sub-word-level semantic embedding sequence.
The attention units in the HCE, however, are used to aggregate the resulting context embedding sequence from lower-level as input to higher-level predictors.
Additionally, the output of the higher-level predictor is used to condition the lower-level predictor.
BERT embeddings are also used in [46] but at word level and are passed as input to the proposed prosody predictor.
The style embedding which is generated via word-level GSTs is used to guide the prosody predictor during model training.

- 文献 [050] 提出的多尺度 GST-TTS 采用了三个风格编码器, 也引入了三个采用层次上下文编码器 (Hierarchical Context Encoders, HCE) 的风格预测器. 第一个预测器的输入是 BERT 子词级别语义嵌入序列.
HCE 中的注意力单元用于聚合由低层次的上下文嵌入序列作为高层次预测器的输入. 此外高层次预测器的输出用于条件化低层次预测器.
- 文献 [044] 同样使用 BERT 嵌入但是在单词级别, 并且作为韵律预测器的输入. 通过词级 GSTs 生成的风格嵌入在模型训练时用于指导韵律预测器.

A Context-aware prosody predictor is proposed in **"Context-Aware Coherent Speaking Style Prediction with Hierarchical Transformers for Audiobook Speech Synthesis"** which considers both text-side context information and speech-side style information from preceding speech.
This predictor comprises two hierarchical components: a sentence encoder and a fusion context encoder.
The context-aware input to the predictor includes word-level embeddings from XLNet [160] for each word in the current sentence, as well as the N preceding and following sentences.
The sentence encoder focuses on learning low-level word meanings within each sentence, while the fusion context encoder captures high-level contextual semantics between the sentences.
Additionally, style embeddings from previous sentences are integrated into the fusion context encoder input to account for speech-side information.

文献提出的上下文感知的韵律预测器, 考虑来源于之前语音的文本侧的上下文信息和语音侧的风格信息. 这一预测器包含两个层次组件: 一个句子编码器和一个融合内容编码器. 预测器的内容感知输入包括 XLNet 对当前句子每个单词的的词级嵌入和 N 个前后句子. 句子编码器重点学习句子内低层次单词含义, 而融合内容编码器捕获句子间的高级上下文语义. 此外前面句子的风格嵌入整合到融合内容编码器的输入以考虑语音侧的信息.

In [91] Speech emotion recognition model (SER) is employed as a style descriptor to learn the implicit connection between style features and input text.
Deep style features for both synthesized speech and reference speech are obtained from a small intermediate fully connected layer of a pre-trained SER model during training.
The extracted style features are compared where an additional loss is introduced to the GST-TTS model loss.
At inference time only text is used to synthesize expressive speech.

文献 [091] 语音情感识别 (Speech Emotion Recognition, SER) 模型作为风格描述器, 学习风格特征和输入文本之间的隐式联系. 合成语音和参考语音的深度风格特征在训练时从预训练 SER 模型的一个小的中间全连接层中获得. 当给 GST-TTS 模型损失引入额外的损失后, 对提取的风格特征进行了对比. 在推理时仅输入文本用于合成表达性语音.

#### 5.2.4.仅依赖于文本的表达性语音合成方法 (ETTS Approaches Based only on Text)

This category involves approaches that depend solely on input text to obtain prosody-related representations/embeddings during TTS model training.
Several features related to speech prosody have been proposed by various studies for extraction from input text and subsequent transmission to a DNN-based module to generate prosody representations.
For instance, the features extracted by the pre-trained language models can capture both semantic and syntactic relationships with the input text, making them effective representations for prosody.
In [83], input text word-level embeddings are extracted by the Embeddings from Language Models (ELMo) model [163] and used to generate context-related embeddings via a context encoder.
Similarly, in [29], BERT is employed to extract embeddings for utterance sentences and pass them to a specific context-encoder to aggregate these embeddings and form a final context vector.

这类方法包含在训练阶段仅依赖输入文本以获取韵律相关表示或嵌入的方法. 各种研究从输入文本中提取出和语音韵律相关的若干特征, 然后传输到基于深度神经网络的模块以生成韵律表示. 例如由预训练语言模型提取的特征可以捕获输入文本的语义和语法关系, 使之成为韵律的有效表示.
- 文献 [083] 通过 Embeddings from Language Models, ELMo 提取输入文本词级嵌入并通过内容编码器生成内容相关的嵌入.
- 文献 [029] 使用 BERT 提取语调序列的嵌入并将它们传递给具体文本编码器以聚合这些嵌入并形成最终的上下文向量.

Other studies, such as [30] [40] [54], utilize graph representations of input text, which can also reflect semantic and syntactic information about the given text.
In [30], the graphical representations of prosody boundaries in Chinese text are passed to a graph encoder based on Graph Neural Networks (GNN) to generate prosodic information for the input text.
The prosody boundaries of the Chinese language can be manually annotated or predicted using a pre-trained model.
In contrast, [54] combines BERT-extracted features for input text with its graph dependency tree to produce word-level prosody representations.
Specifically, the input text is passed through both BERT and a dependency parsing model to extract the dependency tree for word-level BERT embedding.
A Relational Gated Graph Network (RGGN) is used to convert this dependency tree into word-level semantic representations upon which the decoder of the TTS model is conditioned.

其他研究利用输入文本的图表示, 同样可以反映给定文本的语义和语法信息.
- 文献 [030] 将汉语文本的韵律边界的图形表示转递给基于图神经网络的图编码器以生成输入文本的韵律信息. 中文的韵律边界可以人工标注或使用预训练模型预测.
- 文献 [054] 将 BERT 从输入文本提取的特征和它的图依赖树结合用于产生词级韵律表示. 具体地, 输入文本传输到 BERT 和一个依赖解析模型用于提取词级 BERT 嵌入的依赖树. 使用相关门控图网络 (Relational Gated Graph Network, RGGN) 将依赖树转化为词级语义表示, 并以此条件化 TTS 模型的解码器.

Different text-based features have been extracted from input text to obtain prosody (style) embeddings in [40].
The paper utilizes an emotion lexicon to extract word-level emotion features, including VAD (valence, arousal, dominance) and BE5 (joy, anger, sadness, fear, disgust).
Additionally, the [CLS] embedding by BERT for each utterance is also extracted.
The obtained features are then passed to a style encoder to produce a style embedding.

- 文献 [40] 从输入文本中提取不同的基于文本的特征用于获得韵律/风格嵌入. 使用一个情感词典用于提取词级情感特征, 包括 VAD (效价, 唤醒, 支配) 和 BES (喜悦, 愤怒, 悲伤, 恐惧, 厌恶). 此外由 BERT 对每个语调提取 [CLS] 嵌入. 获得的特征之后传递给风格编码器以产生风格嵌入.

Other models under this category train a prosody encoder/predictor jointly with an autoregressive TTS model such as Tacotron 2, to encode some prosody-related features utilizing text-based features.
The trained encoder is then used at inference time to encode prosody-related features based on input text to the TTS model.
The text-based input to these prosody encoders in most of the studies is the text’s character/phoneme embeddings [20] [48] [71] [72] [103], while some studies use features extracted from the input text [64] [125].
For instance, [125] employs four ToBI (Tones and Break Indices) features as word-level prosody tags that are combined with the phoneme embedding as input to the TTS model.
A ToBI predictor is jointly trained to predict four ToBI features based on grammatical and semantic information extracted from the input text using a self-supervised language representation model ELECTRA [164].

其他模型训练一个韵律编码器或预测器, 和自回归 TTS 模型 (如 Tacotron 2) 联合训练, 使用基于文本的特征以编码一些韵律相关的特征. 训练的编码器在推理时根据 TTS 模型的输入文本编码韵律相关的特征. 这些用于韵律编码器的基于文本的输入在大多数研究中采用文本的字符/音素嵌入, 其他一些研究使用从输入文本提取的特征.
- 文献 [125] 采用四个 ToBI 特征作为词级韵律变迁, 和音素嵌入结合作为 TTS 模型的输入.
ToBI 预测器联合训练基于语法和语义信息来预测这四个 ToBI 特征, 这些信息是使用自监督语言表示模型 ELECTRA 从输入文本中提取出来的.

In addition to the previously mentioned features, several other prosodic features are also proposed as the output of the prosody predictors in other studies.
For example, the prosody predictor in [103] predicts a set of utterance-wise acoustic features, including log-pitch, log-pitch range, log-phone duration, log-energy, and spectral tilt.
In [48], the proposed pitch predictor outputs a continuous pitch representation, which is converted into discrete values using Vector Quantization (VQ) [149].
Furthermore, studies [20] [71] propose predicting the three prosody-related features, i.e., F0, energy, and duration, either by a single acoustic features predictor (AFP)[71] or via three separated predictors [20].

除了之前提到的特征, 其他研究还提出了其他韵律特征作为韵律预测器的输出.
- 文献 [103] 的韵律预测器预测一组语调声学特征, 包括对数音高, 对数音高范围, 对数音素时长, 对数能量和频谱倾斜.
- 文献 [048] 的音高预测器输出一个连续的音高表示, 使用矢量量化技术转化为离散值.
- 文献 [020] [071] 通过单个声学特征预测器 (AFP) 或三个单独的预测器预测三个韵律相关的特征, 即 F0, 能量和时长.

Another type of emotion embedding is sentiment feature embedding, which is utilized to produce expressive speech by extracting sentiment information from the input text.
This is demonstrated in work [135], where the Stanford Sentiment Parser is used to generate vector embeddings or sentiment probabilities based on the tree structure of the sentence.
To synthesize expressive speech, different combinations of probabilities and vector embeddings (for individual words or word-context) are added to the linguistic features as inputs to the TTS model.

另一种情感嵌入是情感特征嵌入, 它用于通过从输入文本中提取情感信息来产生富有表现力的语音. 这在文献 [135] 中得到了证明, 其中使用了斯坦福情感解析器来根据句子的树结构生成向量嵌入或情感概率. 为了合成富有表现力的语音, 将不同组合的概率和向量嵌入（对于单个单词或单词上下文）添加到作为 TTS 模型输入的语言特征中.
