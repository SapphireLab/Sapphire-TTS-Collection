# Audio-Language Models for Audio-Centric Tasks: A Survey

<details>
<summary>基本信息</summary>

- 标题: "Audio-Language Models for Audio-Centric Tasks: A Survey"
- 作者:
  - 01 Yi Su (College of Computer Science and Technology, Changsha)
  - 02 Jisheng Bai (School of Marine Science and Technology, Northwestern Polytechnical University)
  - 03 Qisheng Xu (College of Computer Science and Technology, Changsha)
  - 04 Kele Xu (College of Computer Science and Technology, Changsha)
  - 05 Yong Dou (College of Computer Science and Technology, Changsha)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2501.15177)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](2501.15177v1__Survey__Audio-Language_Models_for_Audio-Centric_Tasks.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Audio-Language Models (ALMs), which are trained on audio-text data, focus on the processing, understanding, and reasoning of sounds.
Unlike traditional supervised learning approaches learning from predefined labels, ALMs utilize natural language as a supervision signal, which is more suitable for describing complex real-world audio recordings.
ALMs demonstrate strong zero-shot capabilities and can be flexibly adapted to diverse downstream tasks.
These strengths not only enhance the accuracy and generalization of audio processing tasks but also promote the development of models that more closely resemble human auditory perception and comprehension.
Recent advances in ALMs have positioned them at the forefront of computer audition research, inspiring a surge of efforts to advance ALM technologies.
Despite rapid progress in the field of ALMs, there is still a notable lack of systematic surveys that comprehensively organize and analyze developments.
This deficiency not only limits researchers' comprehensive understanding and evaluation of existing technologies but also hinders the rapid adoption and improvement of new methods.
In this paper, we present a comprehensive review of ALMs with a focus on general audio tasks, aiming to fill this gap by providing a structured and holistic overview of ALMs.
Specifically, we cover:
(1) the background of computer audition and audio-language models;
(2) the foundational aspects of ALMs, including prevalent network architectures, training objectives, and evaluation methods;
(3) foundational pre-training and audio-language pre-training approaches;
(4) task-specific fine-tuning, multi-task tuning and agent systems for downstream applications;
(5) datasets and benchmarks;
(6) current challenges and future directions.

Our review provides a clear technical roadmap for researchers to understand the development and future trends of existing technologies, offering valuable references for implementation in real-world scenarios.

## 1·Introduction: 引言

Enabling machines to hear like humans and process audio-centric tasks has long been a significant challenge \cite{deshmukh2023pengi}.
Audio-Language Models (ALMs), which are trained on audio-text data, focus on the processing, understanding, and reasoning of sounds.
This area is emerging as a prominent research field at the intersection of audio processing and Natural Language Processing.
ALMs are not only applicable to basic audio tasks, such as audio classification \cite{elizalde2023clap}, but also show great potential for more complicated scenarios.
These include tasks such as audio-text retrieval \cite{yan2024MLCLAP}, audio generation \cite{liu2023audioldm}, automatic audio captioning \cite{kim2024enclap}, audio source separation \cite{liu2022_lass}, automatic speech translation \cite{rubenstein2023audiopalm}, and audio chatbots \cite{zhang2023speechgpt}.

In contrast to audio representation learning based on labeled data for specific tasks, ALM can learn from more descriptive textual information, expanding the scope of supervision to include human-annotated captions and readily available titles and descriptions from web sources \cite{laion_ai_audio_dataset}.
Natural language is well-suited for characterizing real-world audio, which frequently involves multiple overlapping sound events, thereby enabling models to learn their intrinsic relationships \cite{wu2019audio}.
Furthermore, using natural language as supervision avoids the model's reliance on task-specific predefined labels, enhancing the potential for models to generalize effectively to open-world scenarios.

As large language models (LLMs) exhibit remarkable comprehension capabilities, researchers have explored their integration as guiding components within ALMs.
However, pre-trained LLMs still face challenges in generalizing across a broad spectrum of downstream tasks \cite{zhao2023LLMsurvey}, necessitating additional transfer steps such as post-training and collaboration with other foundational models.
Within this research landscape, language provides a unified mechanism for constructing instances, enabling LLMs to undergo instruction tuning and in-context learning across diverse tasks.
This approach bridges the gap between auditory information and language understanding, facilitating the alignment of multiple components within ALMs.
Furthermore, language serves as a versatile human-machine interface, empowering users to instruct LLM agents to collaborate effectively with audio-language systems.

Despite the strong interest shown by the audio community in ALMs, there is still a lack of comprehensive surveys to review the current research status.
Existing relevant reviews include speech-language models \cite{cui2024speechlanguage, ji2024wavchat}, codec-based models \cite{wang2023codec}, ALMs for specific tasks such as audio-text retrieval \cite{koepke2022benchmarks}, automated audio captioning \cite{xu2023aac_survey}, speech-to-text translation \cite{xu2023S2TT}, and audio-language datasets \cite{wijngaard2024ald_survey}.
Here, we present the first comprehensive survey on ALMs, aiming to achieve an exhaustive coverage of the entire ALM research landscape from the perspective of model training.
Additionally, we adopt a perspective centered on general audio-centric tasks that encompasses a diverse range of audio types to provide a more detailed reflection of the current state and development of computer audition.
This survey method reflects mutual promotion and constraints among different research aspects from model to data, aids in systematically summarizes challenges and future directions, and serves as a guide for researchers and practitioners interested in ALM techniques, thereby facilitating further academic research and industrial applications in the field.

We first look at recent advances in ALM research and draw the timeline as shown in Fig.\ref{fig1: timeline}.
CLAP\cite{elizalde2023clap} is considered a significant milestone.
Previous work includes some audio-caption datasets \cite{kim2019audiocaps, drossos2020clotho, lipping2022clotho}, which were initially used for automatic audio caption model training and also served as data foundations for ALMs, inspiring subsequent work.
Since the introduction of pre-training and large-scale datasets \cite{wu2023large}, the advantages of ALMs have gradually gained attention.
Recently, numerous new works have emerged, primarily reflecting the intertwined development between pre-training and downstream models.
With increasing model research, recent studies have focused on the lack of unified evaluation standards and proposed various benchmarks.
It shows a high correlation between datasets, pre-training, downstream models, and benchmark research in ALMs.
Additionally, we observe that, driven by commercial applications, research interests have shifted more towards the speech domain.
However, audio typically encompasses a variety of environmental events, including human voices, natural sounds, music rhythms, etc., which presents significant challenges to general audio modeling \cite{chen2023beats}.

In the subsequent sections of this paper, we first introduce the background of audio-language pre-training and transfer paradigm (Section \ref{section: Background}).
We then describe the foundations of ALMs, including model architecture, training objectives, and evaluation methods (Section \ref{section: Foundations}).
Following this, we review the topics of representation pre-training (Section \ref{section: Pre-training}), downstream transfer (Section \ref{section: transfer}), and related data (Section \ref{section: Data}).
Building on these foundations, we discuss the challenges and future research directions (Section \ref{section: Challenges and future directions}), before concluding the paper (Section \ref{section: Conclusion}).

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论