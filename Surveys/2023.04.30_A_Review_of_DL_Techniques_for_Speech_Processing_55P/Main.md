# A Review of Deep Learning Techniques for Speech Processing

<details>
<summary>基本信息</summary>

- 标题: "A Review of Deep Learning Techniques for Speech Processing"
- 作者:
  - 01 Ambuj Mehrish,
  - 02 Navonil Majumder,
  - 03 Rishabh Bhardwaj,
  - 04 Rada Mihalcea,
  - 05 Soujanya Poria
- 链接:
  - [ArXiv](https://arxiv.org/abs/2305.00359)
  - [Publication](https://doi.org/10.1016/j.inffus.2023.101869)
  - [Github]
  - [Demo]
- 文件:
  - [ArXiv](2305.00359v3__Survey__A_Review_of_Deep_Learning_Techniques_for_Speech_Processing.pdf)
  - [Publication](2305.00359p0__Survey__InfFus2023.pdf)

</details>

## Abstract: 摘要

The field of speech processing has undergone a transformative shift with the advent of deep learning.
The use of multiple processing layers has enabled the creation of models capable of extracting intricate features from speech data.
This development has paved the way for unparalleled advancements in speech recognition, text-to-speech synthesis, automatic speech recognition, and emotion recognition, propelling the performance of these tasks to unprecedented heights.
The power of deep learning techniques has opened up new avenues for research and innovation in the field of speech processing, with far-reaching implications for a range of industries and applications.
This review paper provides a comprehensive overview of the key deep learning models and their applications in speech-processing tasks.
We begin by tracing the evolution of speech processing research, from early approaches, such as MFCC and HMM, to more recent advances in deep learning architectures, such as CNNs, RNNs, transformers, conformers, and diffusion models.
We categorize the approaches and compare their strengths and weaknesses for solving speech-processing tasks.
Furthermore, we extensively cover various speech-processing tasks, datasets, and benchmarks used in the literature and describe how different deep-learning networks have been utilized to tackle these tasks.
Additionally, we discuss the challenges and future directions of deep learning in speech processing, including the need for more parameter-efficient, interpretable models and the potential of deep learning for multimodal speech processing.
By examining the field's evolution, comparing and contrasting different approaches, and highlighting future directions and challenges, we hope to inspire further research in this exciting and rapidly advancing field.

## Content

- 1·Introduction
- 2·Background
  - 2.1·Speech Signals
  - 2.2·Speech Features
  - 2.3·Traditional models for speech processing
- 3·Deep Learning Architectures and Their Applications in Speech Processing Tasks
  - 3.1·Recurrent Neural Networks (RNNs)
  - 3.2·Convolutional Neural Networks
  - 3.3·Transformers
  - 3.4·Conformer
  - 3.5·Sequence to Sequence Models
  - 3.6·Reinforcement Learning
  - 3.7·Graph Neural Network
  - 3.8·Diffusion Probabilistic Model
- 4·Speech Representation Learning
  - 4.1·Supervised Learning
  - 4.2·Unsupervised learning
  - 4.3·Semi-Supervised Learning
  - 4.4·Self-Supervised Representation Learning (SSRL)
- 5·Speech Processing Tasks
  - 5.1·Automatic Speech Recognition (ASR) & Conversational Multi-Speaker AST
  - 5.2·Neural Speech Synthesis
  - 5.3·Speaker Recognition
  - 5.4·Speaker Diarization
  - 5.5·Speech-to-Speech Translation
  - 5.6·Speech Enhancement
  - 5.7·Audio Super Resolution
  - 5.8·Voice Activity Detection (VAD)
  - 5.9·Speech Quality Assessment
  - 5.10·Speech Separation
  - 5.11·Spoken Language Understanding
  - 5.12·Audio/Visual Multimodal Speech Processing
- 6·Advanced Transfer Learning Techniques for Speech Processing
  - 6.1·Domain Adaptation
  - 6.2·Meta Learning
  - 6.3·Parameter-Efficient Transfer Learning
- 7·Conclusion and Future Research Directions
