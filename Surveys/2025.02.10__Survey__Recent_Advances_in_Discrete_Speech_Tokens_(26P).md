# Recent Advances in Discrete Speech Tokens: A Review

<details>
<summary>基本信息</summary>

- 标题: "Recent Advances in Discrete Speech Tokens: A Review"
- 作者:
  - 01 Yiwei Guo
  - 02 Zhihan Li
  - 03 Hankun Wang
  - 04 Bohan Li
  - 05 Chongtian Shao
  - 06 Hanglei Zhang
  - 07 Chenpeng Du
  - 08 Xie Chen
  - 09 Shujie Liu
  - 10 Kai Yu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2502.06490)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](2025.02.10__2502.06490v2__Recent_Advances_in_Discrete_Speech_Tokens_A_Review.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<table><tr><td width="50%">

The rapid advancement of speech generation technologies in the era of large language models (LLMs) has established discrete speech tokens as a foundational paradigm for speech representation.
These tokens, characterized by their discrete, compact, and concise nature, are not only advantageous for efficient transmission and storage, but also inherently compatible with the language modeling framework, enabling seamless integration of speech into text-dominated LLM architectures.
Current research categorizes discrete speech tokens into two principal classes: acoustic tokens and semantic tokens, each of which has evolved into a rich research domain characterized by unique design philosophies and methodological approaches.
This survey systematically synthesizes the existing taxonomy and recent innovations in discrete speech tokenization, conducts a critical examination of the strengths and limitations of each paradigm, and presents systematic experimental comparisons across token types.
Furthermore, we identify persistent challenges in the field and propose potential research directions, aiming to offer actionable insights to inspire future advancements in the development and application of discrete speech tokens.

</td><td>

在大语言模型时代, 语音生成技术的迅速发展使得离散语音 Token 成为语音表示的基础范式.
这些 Token 具有离散, 紧凑和简洁的特点, 不仅有利于高效的传输和存储, 而且与语言建模框架本质上兼容, 能够实现语音与文本主导的LLM架构的无缝集成.

目前的研究将离散语音 Token 分为两类：声学 Token 和语义 Token, 每一类都已经发展成了具有独特设计理念和方法论的丰富研究领域.

本综述系统地总结了现有的分类法和离散语音 Token 化的最新创新, 批判性地分析了每种范式的优缺点, 并对不同 Token 类型进行了系统的实验比较.

此外, 我们还识别了该领域持续存在的挑战, 并提出了潜在的研究方向, 旨在为未来离散语音 Token 的开发和应用提供可行的见解, 以激发未来的进展.

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

The rapid advancement of large language models (LLMs) in natural language processing has revolutionized speech generation tasks[^cui2024recent], [^ji2024wavchat], with speech being tokenized and modeled using decoder-only Transformers[^transformer].
Efforts starting from GSLM[^lakhotia2021generative] and AudioLM[^borsos2023audiolm] aim to develop text-free spoken LLMs, akin to how current LLM-powered chatbots enable text-based interactions.
Other works, including VALL-E[^valle] and VioLA[^wang2024viola], extend this approach to conditional speech generation tasks, such as zero-shot text-to-speech and speech translation.
However, this paradigm requires data to be tokenized, as LLMs typically process discrete data only.
Textual tokens naturally meet this requirement because they are designed as discrete units separated by clear boundaries, whereas raw speech signals are continuous and boundary-less.
Therefore, a necessary step before applying speech data to LLM is the \textbf{tokenization of speech}, whose goal is:

</td><td>

</td></tr>
<tr><td>

*To convert long speech waveforms into short discrete tokens for downstream tasks. These tokens should be compatible with the underlying textual representations, especially for language modeling approaches targeted at speech.*


</td><td>

</td></tr>
<tr><td>

As a result, significant efforts have been directed towards developing efficient and powerful speech tokenization methods. Generally, these methods are based on two distinct principles, giving rise to two types of speech tokens: acoustic tokens and semantic tokens.
Acoustic tokens are derived from neural codecs designed to encode speech at a low bitrate while preserving as much information as possible. In contrast, semantic tokens originate from speech self-supervised learning (SSL)[^mohamed2022self], which aims to learn a more phonetic or semantic representation space, making it easier for speech recognition.
These two nearly independent lines of research magically intersect in the context of language modeling for speech.
Now, there are also efforts that try to design a speech tokenizer that accomplishes the two objectives simultaneously[^zhang2024speechtokenizer], [^kyutai2024moshi].

Consequently, speech tokenization has become a core problem of speech processing under the new paradigm, with versatile downstream applications, as shown in Figure.01.

</td><td>

</td></tr>
<tr><td>

Despite the rapid development and numerous recent works, a comprehensive taxonomy of methodologies in discrete speech tokens has not been clearly constructed.
Existing reviews[^mohamed2022self], [^anees2024speech], [^wu2024towards], [^cui2024recent], [^kim2024neural], [^ji2024wavchat] in this field overlook the diverse categories and methodologies in both acoustic and semantic tokens.
- For example, [^cui2024recent], [^ji2024wavchat] focus primarily on methods in spoken language modeling, providing only brief descriptions of some speech tokens used in existing models.
- The taxonomy of neural audio codecs has been summarized in [^wu2024towards], [^du2025codecfake], but the realm of semantic tokens is still overlooked.

</td><td>

</td></tr>
<tr><td>

In this review, we provide a comprehensive overview of the concepts, methods, and characteristics of various types of discrete speech tokens, with their applications in spoken language understanding, speech generation, and spoken dialogue models.
We hope that through this review, the community can have a clear understanding of the current development and key technologies of discrete speech tokens, so as to promote further research in the future.

</td><td>

</td></tr>
<tr><td>

Our contributions are summarized as follows:
- This review is the first to focus specifically on discrete speech tokens with sufficient depth in the LLM era.
- We construct a comprehensive taxonomy of current research on discrete speech tokens and meticulously review the motivation, representative approaches, and challenges in each sub-category.
- We provide a unified comparison of different types of discrete speech tokens in terms of reconstruction and voice conversion performance, covering both acoustic and semantic tokens.
- We summarize the current challenges and potential future directions for discrete speech tokens, including decoupled and variable frame rate tokens.

The structure of this review is shown in Figure.02.

</td><td>

</td></tr>
<tr><td>

Following [^borsos2023audiolm], [^kharitonov2023speak], [^yang2024towards], we classify discrete speech tokens into acoustic and semantic tokens based on their principles.
We will characterize the two types of tokens both by conceptual descriptions and unified experimental comparisons.

</td><td>

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td></tr></table>

## References: 参考文献

[^anees2024speech]:
[^borsos2023audiolm]:
[^cui2024recent]:
[^du2025codecfake]:
[^ji2024wavchat]:
[^kharitonov2023speak]:
[^kim2024neural]:
[^kyutai2024moshi]:
[^lakhotia2021generative]:
[^mohamed2022self]:
[^transformer]:
[^valle]:
[^wang2024viola]:
[^wu2024towards]:
[^yang2024towards]:
[^zhang2024speechtokenizer]:
