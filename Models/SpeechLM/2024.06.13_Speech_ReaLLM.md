# Speech ReaLLM

<details>
<summary>基本信息</summary>

- 标题: "Speech ReaLLM -- Real-time Streaming Speech Recognition with Multimodal LLMs by Teaching the Flow of Time"
- 作者:
  - 01 Frank Seide,
  - 02 Morrie Doulaty,
  - 03 Yangyang Shi,
  - 04 Yashesh Gaur,
  - 05 Junteng Jia,
  - 06 Chunyang Wu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.09569)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2406.09569v1__Speech_ReaLLM__Real-time_Streaming_Speech_Recognition_with_Multimodal_LLMs_by_Teaching_the_Flow_of_Time.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

We introduce ***Speech ReaLLM***, a new ASR architecture that marries "decoder-only" ASR with the RNN-T to make multimodal LLM architectures capable of real-time streaming.
This is the first "decoder-only" ASR architecture designed to handle continuous audio without explicit end-pointing.
***Speech ReaLLM*** is a special case of the more general ReaLLM ("real-time LLM") approach, also introduced here for the first time.
The idea is inspired by RNN-T: Instead of generating a response only at the end of a user prompt, generate after every input token received in real time (it is often empty).
On Librispeech "test", an 80M ***Speech ReaLLM*** achieves WERs of 3.0% and 7.4% in real time (without an external LM or auxiliary loss).
This is only slightly above a 3x larger Attention-Encoder-Decoder baseline.
We also show that this way, an LLM architecture can learn to represent and reproduce the flow of time; and that a pre-trained 7B LLM can be fine-tuned to do reasonably well on this task.

</details>
<br>

我们介绍了 ***Speech ReaLLM***, 这是一种新的自动语音识别 (ASR) 架构, 它将 "仅解码器" ASR 与 RNN-T 结合, 使多模态大型语言模型架构能够进行实时流式处理.
这是首个设计用来处理连续音频而无需显式终点检测的 "仅解码器" ASR 架构.
***Speech ReaLLM*** 是更通用的实时大型语言模型 (ReaLLM) 方法的一个特例, 这里也是首次介绍这种方法.
这个想法受到了 RNN-T 的启发: 不是仅在用户提示结束时生成响应, 而是在实时接收到的每个输入 token 后生成响应 (通常为空).
在 Librispeech 测试集上, 一个 80 M 的 ***Speech ReaLLM*** 在实时条件下实现了 3.0 % 和 7.4 % 的词错误率 (WERs), 且无需外部语言模型或辅助损失.
这仅比一个大三倍的注意力-编码器-解码器基线略高.
我们还展示了通过这种方法, 一个 LLM 架构可以学习表示和再现时间的流动, 并且一个预训练的 7B LLM 可以通过微调, 在这项任务上做得相当不错.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论