# MaskGCT

<details>
<summary>基本信息</summary>

- 标题: "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer"
- 作者:
  - 01 Yuancheng Wang,
  - 02 Haoyue Zhan,
  - 03 Liwei Liu,
  - 04 Ruihong Zeng,
  - 05 Haotian Guo,
  - 06 Jiachen Zheng,
  - 07 Qiang Zhang,
  - 08 Xueyao Zhang,
  - 09 Shunsi Zhang,
  - 10 Zhizheng Wu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2409.00750)
  - [Publication]()
  - [Github](https://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct)
  - [Demo](https://maskgct.github.io/)
- 文件:
  - [ArXiv](_PDF/2409.00750v3__MaskGCT__Zero-Shot_Text-to-Speech_with_Masked_Generative_Codec_Transformer.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

The recent large-scale text-to-speech (TTS) systems are usually grouped as autoregressive and non-autoregressive systems.
The autoregressive systems implicitly model duration but exhibit certain deficiencies in robustness and lack of duration controllability.
Non-autoregressive systems require explicit alignment information between text and speech during training and predict durations for linguistic units (e.g., phone), which may compromise their naturalness.
In this paper, we introduce ***Masked Generative Codec Transformer (MaskGCT)***, a fully non-autoregressive TTS model that eliminates the need for explicit alignment information between text and speech supervision, as well as phone-level duration prediction.
***MaskGCT*** is a two-stage model: in the first stage, the model uses text to predict semantic tokens extracted from a speech self-supervised learning (SSL) model, and in the second stage, the model predicts acoustic tokens conditioned on these semantic tokens.
***MaskGCT*** follows the mask-and-predict learning paradigm.
During training, ***MaskGCT*** learns to predict masked semantic or acoustic tokens based on given conditions and prompts.
During inference, the model generates tokens of a specified length in a parallel manner.
Experiments with 100K hours of in-the-wild speech demonstrate that ***MaskGCT*** outperforms the current state-of-the-art zero-shot TTS systems in terms of quality, similarity, and intelligibility.
Audio samples are available at [this https URL](https://maskgct.github.io/).
We release our code and model checkpoints at [this https URL](https://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct).

</details>
<br>

近期的大规模文本转语音系统通常分为自回归和非自回归系统.
- 自回归系统隐式建模了模型时长, 但在鲁棒性和持续时长控制性方面存在一些缺陷.
- 非自回归系统要求在训练时显式对齐文本和语音之间的信息, 并预测语言单元 (如音素) 的持续实践, 这可能妨碍了它们的自然度.

本文介绍了 ***掩膜生成式编解码 Transformer (Masked Generative Codec Transformer, MaskGCT)***, 一种完全非自回归的文本转语音模型, 消除了显式对齐文本和语音监督之间的信息, 以及音素级时长预测的需求.
***MaskGCT*** 是一种两阶段模型: 在第一阶段, 模型使用文本预测语音自监督学习 (SSL) 模型提取的语义 Token, 而在第二阶段, 模型根据这些语义 Token 为条件预测声学 Token.
***MaskGCT*** 遵循掩膜-预测学习范式.
在训练时, ***MaskGCT*** 学习根据给定的条件和提示预测掩盖的语义或声学 Token.
在推理时, 模型以并行的方式生成指定长度的 Token.

在 100K 小时的真实语音数据集上的实验表明, ***MaskGCT*** 在质量, 语义相似度, 和流畅度方面优于当前最先进的零样本 TTS 系统.
音频样本可以在 [https URL](https://maskgct.github.io/) 获得.
我们在 [https URL](https://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct) 发布了我们的代码和模型检查点.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论