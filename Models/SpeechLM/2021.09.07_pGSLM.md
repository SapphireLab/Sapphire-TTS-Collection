# pGSLM

<details>
<summary>基本信息</summary>

- 标题: "Text-Free Prosody-Aware Generative Spoken Language Modeling"
- 作者:
  - 01 Eugene Kharitonov,
  - 02 Ann Lee,
  - 03 Adam Polyak,
  - 04 Yossi Adi,
  - 05 Jade Copet,
  - 06 Kushal Lakhotia,
  - 07 Tu-Anh Nguyen,
  - 08 Morgane Riviere,
  - 09 Abdelrahman Mohamed,
  - 10 Emmanuel Dupoux,
  - 11 Wei-Ning Hsu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2109.03264)
  - [Publication](https://doi.org/10.18653/v1/2022.acl-long.593)
  - [Github](https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm)
  - [Demo](https://speechbot.github.io/pgslm)
- 文件:
  - [ArXiv](_PDF/2109.03264v2__pGSLM__Text-Free_Prosody-Aware_Generative_Spoken_Language_Modeling.pdf)
  - [Publication](_PDF/2109.03264p0__pGSLM__ACL2022.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored.
**Generative Spoken Language Modeling (GSLM)** is the only prior work addressing the generative aspect of speech pre-training, which builds a text-free language model using discovered units.
Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech.
In this work, we present a ***prosody-aware generative spoken language model (pGSLM)***.
It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms.
Experimental results show that the ***pGSLM*** can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt.
Audio samples can be found at https://speechbot.github.io/pgslm.
Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm.

</td><td>

语音预训练已经在分类任务上展示了其有效性, 但在生成新颖的语音方面, 与 GPT-2 能够生成连贯段落的能力相比, 它还很少被探索.
**GSLM** 是唯一一项探索语音预训练生成方面的工作, 它使用发现的单元构建了无文本的语言模型.
然而, 由于 GSLM 使用的单元丢弃了大部分韵律信息, GSLM 未能利用韵律来提高理解和生成富有表现力的语音.

在这项工作中, 我们提出了一种***韵律感知的生成式口语语言模型 (Prosody Aware Generative Spoken Language Model, pGSLM)***.
它由一个多流 Transformer 语言模型 (MS-TLM) 组成, 将语音表示为发现的单元和韵律特征流, 并结合一个修改的 HiFi-GAN 模型, 将 MS-TLM 输出转换为波形.

实验结果表明, ***pGSLM*** 能够利用韵律来改进韵律和内容建模, 并根据一个口语提示生成自然、有意义和连贯的语音.
音频样本可在 https://speechbot.github.io/pgslm 找到.
代码和模型可在 https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm 找到.

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td></tr></table>
