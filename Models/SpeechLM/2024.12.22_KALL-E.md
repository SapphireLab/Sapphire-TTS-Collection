# KALL-E

<details>
<summary>基本信息</summary>

- 标题: "Autoregressive Speech Synthesis with Next-Distribution Prediction"
- 作者:
  - 01 Xinfa Zhu,
  - 02 Wenjie Tian,
  - 03 Lei Xie
- 链接:
  - [ArXiv](https://arxiv.org/abs/2412.16846)
  - [Publication]
  - [Github]
  - [Demo](https://zxf-icpc.github.io/kalle/)
- 文件:
  - [ArXiv](_PDF/2412.16846v1__KALL-E__Autoregressive_Speech_Synthesis_with_Next-Distribution_Prediction.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

We introduce KALL-E, a novel autoregressive (AR) language modeling approach with next-distribution prediction for text-to-speech (TTS) synthesis.
Unlike existing methods, KALL-E directly models and predicts the continuous speech distribution conditioned on text without relying on VAE- or diffusion-based components.
Specifically, we use WaveVAE to extract continuous speech distributions from waveforms instead of using discrete speech tokens.
A single AR language model predicts these continuous speech distributions from text, with a Kullback-Leibler divergence loss as the constraint.
Experimental results show that KALL-E outperforms open-source implementations of YourTTS, VALL-E, NaturalSpeech 2, and CosyVoice in terms of naturalness and speaker similarity in zero-shot TTS scenarios.
Moreover, KALL-E demonstrates exceptional zero-shot capabilities in emotion and accent cloning.
Importantly, KALL-E presents a more straightforward and effective paradigm for using continuous speech representations in TTS.
Audio samples are available at: [this https URL](https://zxf-icpc.github.io/kalle/).

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论