# AudioPaLM

<details>
<summary>基本信息</summary>

- 标题: "AudioPaLM: A Large Language Model That Can Speak and Listen"
- 作者:
  - 01 Paul K. Rubenstein,
  - 02 Chulayuth Asawaroengchai,
  - 03 Duc Dung Nguyen,
  - 04 Ankur Bapna,
  - 05 Zalan Borsos,
  - 06 Felix de Chaumont Quitry,
  - 07 Peter Chen,
  - 08 Dalia El Badawy,
  - 09 Wei Han,
  - 10 Eugene Kharitonov,
  - 11 Hannah Muckenhirn,
  - 12 Dirk Padfield,
  - 13 James Qin,
  - 14 Danny Rozenberg,
  - 15 Tara Sainath,
  - 16 Johan Schalkwyk,
  - 17 Matt Sharifi,
  - 18 Michelle Tadmor Ramanovich,
  - 19 Marco Tagliasacchi,
  - 20 Alexandru Tudor,
  - 21 Mihajlo Velimirovic,
  - 22 Damien Vincent,
  - 23 Jiahui Yu,
  - 24 Yongqiang Wang,
  - 25 Vicky Zayats,
  - 26 Neil Zeghidour,
  - 27 Yu Zhang,
  - 28 Zhishuai Zhang,
  - 29 Lukas Zilka,
  - 30 Christian Frank
- 链接:
  - [ArXiv](https://arxiv.org/abs/2306.12925)
  - [Publication]
  - [Github]
  - [Demo](https://google-research.github.io/seanet/audiopalm/examples)
- 文件:
  - [ArXiv](_PDF/2306.12925v1__AudioPaLM__A_Large_Language_Model_That_Can_Speak_&_Listen.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

We introduce ***AudioPaLM***, a large language model for speech understanding and generation.
***AudioPaLM*** fuses text-based and speech-based language models, PaLM-2 [Anil et al., 2023] and AudioLM [Borsos et al., 2022], into a unified multimodal architecture that can process and generate text and speech with applications including speech recognition and speech-to-speech translation.
***AudioPaLM*** inherits the capability to preserve paralinguistic information such as speaker identity and intonation from AudioLM and the linguistic knowledge present only in text large language models such as PaLM-2.
We demonstrate that initializing ***AudioPaLM*** with the weights of a text-only large language model improves speech processing, successfully leveraging the larger quantity of text training data used in pretraining to assist with the speech tasks.
The resulting model significantly outperforms existing systems for speech translation tasks and has the ability to perform zero-shot speech-to-text translation for many languages for which input/target language combinations were not seen in training.
***AudioPaLM*** also demonstrates features of audio language models, such as transferring a voice across languages based on a short spoken prompt. We release examples of our method at this https URL

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论