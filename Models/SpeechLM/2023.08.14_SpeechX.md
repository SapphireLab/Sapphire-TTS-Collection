# SpeechX

<details>
<summary>基本信息</summary>

- 标题: "SpeechX: Neural Codec Language Model as a Versatile Speech Transformer"
- 作者:
  - 01 Xiaofei Wang,
  - 02 Manthan Thakker,
  - 03 Zhuo Chen,
  - 04 Naoyuki Kanda,
  - 05 Sefik Emre Eskimez,
  - 06 Sanyuan Chen,
  - 07 Min Tang,
  - 08 Shujie Liu,
  - 09 Jinyu Li,
  - 10 Takuya Yoshioka
- 链接:
  - [ArXiv](https://arxiv.org/abs/2308.06873)
  - [Publication](https://doi.org/10.1109/TASLP.2024.3419418) TASLP2024
  - [Github]()
  - [Demo](https://aka.ms/speechx)
- 文件:
  - [ArXiv](_PDF/2308.06873v1__SpeechX__Neural_Codec_Language_Model_as_A_Versatile_Speech_Transformer.pdf)
  - [Publication](_PDF/2308.06873p0__SpeechX__TASLP2024.pdf)

</details>

## Abstract: 摘要

Recent advancements in generative speech models based on audio-text prompts have enabled remarkable innovations like high-quality zero-shot text-to-speech.
However, existing models still face limitations in handling diverse audio-text speech generation tasks involving transforming input speech and processing audio captured in adverse acoustic conditions.
This paper introduces ***SpeechX***, a versatile speech generation model capable of zero-shot TTS and various speech transformation tasks, dealing with both clean and noisy signals.
***SpeechX*** combines neural codec language modeling with multi-task learning using task-dependent prompting, enabling unified and extensible modeling and providing a consistent way for leveraging textual input in speech enhancement and transformation tasks.
Experimental results show ***SpeechX***'s efficacy in various tasks, including zero-shot TTS, noise suppression, target speaker extraction, speech removal, and speech editing with or without background noise, achieving comparable or superior performance to specialized models across tasks.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论