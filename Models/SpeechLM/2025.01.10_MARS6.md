# MARS6

<details>
<summary>基本信息</summary>

- 标题: "MARS6: A Small and Robust Hierarchical-Codec Text-to-Speech Model"
- 作者:
  - 01 Matthew Baas,
  - 02 Pieter Scholtz,
  - 03 Arnav Mehta,
  - 04 Elliott Dyson,
  - 05 Akshat Prakash,
  - 06 Herman Kamper
- 链接:
  - [ArXiv](https://arxiv.org/abs/2501.05787)
  - [Publication]() ICASSP 2025
  - [Github](https://github.com/Camb-ai/mars6-turbo/)
  - [Demo](https://camb-ai.github.io/mars6-turbo/)
- 文件:
  - [ArXiv](_PDF/2501.05787v1__MARS6__A_Small_and_Robust_Hierarchical-Codec_Text-to-Speech_Model.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Codec-based text-to-speech (TTS) models have shown impressive quality with zero-shot voice cloning abilities.
However, they often struggle with more expressive references or complex text inputs.
We present MARS6, a robust encoder-decoder transformer for rapid, expressive TTS.
MARS6 is built on recent improvements in spoken language modelling.
Utilizing a hierarchical setup for its decoder, new speech tokens are processed at a rate of only 12 Hz, enabling efficient modelling of long-form text while retaining reconstruction quality.
We combine several recent training and inference techniques to reduce repetitive generation and improve output stability and quality.
This enables the 70M-parameter MARS6 to achieve similar performance to models many times larger.
We show this in objective and subjective evaluations, comparing TTS output quality and reference speaker cloning ability.

## 1·Introduction: 引言

Text-to-speech (TTS) systems have improved many-fold in recent years, showcasing new capabilities in speaker cloning capability and naturalness~\cite{casanova2024xtts_interspeech, chen2024valle2neuralcodec, li2024styletts}.
One promising area in TTS is spoken language models (SLMs)~\cite{wang2023neuralcodeclanguagemodels}, where a neural audio codec converts speech into a sequence of discrete tokens.
Like text language models, SLMs are trained to predict the  next discrete token autoregressively, typically using a transformer-based architecture.
But most prior SLM-based TTS systems exhibit a key limitation -- they are unstable~\cite{hu2024robust, han2024vallerrobustefficient}.
When the reference audio or text is complex or out-of-domain, SLMs often perform poorly compared other TTS methodologies.

While there have been several methods proposed to address such limitations, they are typically considered in isolation (e.g., repetition aware sampling~\cite{chen2024valle2neuralcodec}), or they drastically increase the runtime (e.g., multiple sampling~\cite{melle_meng2024autoregressive,chen2024valle2neuralcodec}).
To this end, we propose ***MARS6*** -- a 70M parameter SLM for robust, rapid and expressive TTS.
We combine several recent techniques, and propose some new techniques from outside the TTS domain (e.g., odds ratio preference optimization~\cite{hong2024orpo} and a new top-$p$ fallback sampling mechanism).
***MARS6*** consists of an encoder-decoder transformer, and combines a hierarchical speech codec with a hierarchical decoder architecture to process speech tokens at a rate of 12~Hz.
Together with the aforementioned inference techniques, this makes ***MARS6*** a highly robust and capable TTS model.
It is also a showcase for a `bag of tricks' that we introduce for SLM-based TTS.

For our experiments, we construct a difficult in-the-wild TTS evaluation set using the expressive EARS dataset~\cite{richter2024ears}.
We compare ***MARS6*** against prior diffusion- and autoregressive-based TTS models using objective and subjective evaluations.
***MARS6*** performs competitively, even against models many times its size.
When used with voice cloning based on a snippet of reference audio, ***MARS6*** captures the target speaker identity closely, surpassing prior models in subjective speaker similarity evaluations.
Our main contribution is to demonstrate that we can combine several recently proposed techniques with new techniques proposed herein during model design, training, and inference, to stabilize outputs and yield a more robust SLM-based TTS system.

Demo, samples, code, and checkpoints: https://camb-ai.github.io/mars6-turbo/.

## 2·Related Works: 相关工作

Within SLMs, there are broadly three ways to approach speech tokenization.
The first is to tokenize speech using acoustic tokens at a fixed sample rate, as done in EnCodec and DAC~\cite{defossez2022highfi,kumar2024high}.
The second is to mix acoustic and semantic tokens using two different quantizers~\cite{baade24_interspeech}, e.g., using clustered HuBERT features for semantic and EnCodec for acoustic tokens.
The third, which we explore here, is that of hierarchical acoustic codecs, such as SNAC~\cite{Siuzdak_SNAC_Multi-Scale_Neural_2024}.
These codecs quantize speech into acoustic tokens in different codebooks, each with its own sampling rate.
This makes lower codebooks more 'coarse', and higher sample-rate codebooks 'fine'.
The progenitor SLM TTS model, VALL-E, and its successors~\cite{wang2023neuralcodeclanguagemodels,chen2024valle2neuralcodec,han2024vallerrobustefficient},
uses an autoregressive transformer to predict the most coarse acoustic codebook, and a non-autoregressive model to predict the remaining codebook values.

Despite success, VALL-E and its descendants often suffer from stability issues.
Several studies have tried to address this~\cite{song2024ellavstableneuralcodec,dang2024livespeech}, e.g., by adding linguistic and phonemic constraints to improve coherence between the output speech  and the given input text~\cite{wang2024hamttshierarchicalacousticmodeling}.
But most of these improvements require phoneme alignments during training.
The `bag-of-tricks' we introduce in this paper does not require such resources.

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论