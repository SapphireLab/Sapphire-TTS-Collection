# Pengi

<details>
<summary>基本信息</summary>

- 标题: "Pengi: An Audio Language Model for Audio Tasks"
- 作者:
  - 01 Soham Deshmukh (Microsoft)
  - 02 Benjamin Elizalde (Microsoft)
  - 03 Rita Singh (Carnegie Mellon University)
  - 04 Huaming Wang (Microsoft)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2305.11834)
  - [Publication](https://dl.acm.org/doi/abs/10.5555/3666122.3666917) NeurIPS2023Poster
  - [Github](https://github.com/microsoft/Pengi) 最近更新 2024.04.20
  - [Demo]
- 文件:
  - [ArXiv](_PDF/2305.11834v2__Pengi__An_Audio_Language_Model_for_Audio_Tasks.pdf)
  - [Publication](_PDF/2305.11834p0__Pengi__NeurIPS2023.pdf)

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques.
These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance.
However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question & Answering.
We introduce ***Pengi***, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks.
It takes as input, an audio recording, and text, and generates free-form text as output.
The input audio is represented as a sequence of continuous embeddings by an audio encoder.
A text encoder does the same for the corresponding text input.
Both sequences are combined as a prefix to prompt a pre-trained frozen language model.
The unified architecture of ***Pengi*** enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions.
When evaluated on 21 downstream tasks, our approach yields state-of-the-art performance in several of them.
Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding.

</details>
<br>

在语音处理领域, 迁移学习促进了自监督学习和零样本学习技术的兴起。
这些方法促进了能处理广泛任务的多用途模型的发展, 同时取得了卓越的性能.
然而, 当前的模型固有缺失了生成开放式任务所需的语言能力, 如音频描述或音频问答.

我们介绍 ***Pengi***, 一种新的音频语言模型, 利用迁移学习将所有音频任务视为文本生成任务.
它接受音频录音作为输入, 并生成自由文本作为输出.
音频输入由音频编码器表示为连续嵌入的序列.
文本编码器对相应的文本输入执行相同的操作.
两个序列被合并为前缀, 用于提示一个预先冻结的语言模型.

***Pengi*** 的统一架构使得开放式任务和封闭式任务都能实现, 无需进一步的微调或特定任务的扩展.
在 21 个下游任务上进行评估, 我们的方法在几个方面都取得了卓越的性能.
我们的结果表明, 将语言模型与音频模型连接是通往通用音频理解的重要一步.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论
