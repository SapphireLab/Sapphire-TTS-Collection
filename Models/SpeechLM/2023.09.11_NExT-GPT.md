# NExT-GPT

<details>
<summary>基本信息</summary>

- 标题: "NExT-GPT: Any-to-Any Multimodal LLM"
- 作者:
  - 01 Shengqiong Wu,
  - 02 Hao Fei,
  - 03 Leigang Qu,
  - 04 Wei Ji,
  - 05 Tat-Seng Chua
- 链接:
  - [ArXiv](https://arxiv.org/abs/2309.05519)
  - [Publication]() ICML 2024 Oral
  - [Github](https://github.com/NExT-GPT/NExT-GPT)
  - [Demo](https://next-gpt.github.io)
- 文件:
  - [ArXiv](_PDF/2309.05519v3__NExT-GPT__Any-to-Any_Multimodal_LLM.pdf)
  - [Publication](_PDF/2309.05519p0__NExT-GPT__ICLR2024.pdf)

</details>

## Abstract: 摘要

While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities.
As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI.
To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT.
We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio.
By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansion to more potential modalities.
Moreover, we introduce a modality-switching instruction tuning (MosIT) and manually curate a high-quality dataset for MosIT, based on which NExT-GPT is empowered with complex cross-modal semantic understanding and content generation.
Overall, our research showcases the promising possibility of building an AI agent capable of modeling universal modalities, paving the way for more human-like AI research in the community.
Project page: this https URL

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论