# SpeechGPT

<details>
<summary>基本信息</summary>

- 标题: "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities"
- 作者:
  - 01 Dong Zhang
  - 02 Shimin Li
  - 03 Xin Zhang
  - 04 Jun Zhan
  - 05 Pengyu Wang
  - 06 Yaqian Zhou
  - 07 Xipeng Qiu (邱锡鹏)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2305.11000)
  - [Publication](https://doi.org/10.18653/v1/2023.findings-emnlp.1055)
  - [Github](https://github.com/0nutation/SpeechGPT)
  - [Demo](https://0nutation.github.io/SpeechGPT.github.io/)
- 文件:
  - [ArXiv](_PDF/2305.11000v2__SpeechGPT__Empowering_Large_Language_Models_with_Intrinsic_Cross-Modal_Conversational_Abilities.pdf)
  - [Publication](_PDF/2305.11000p0__SpeechGPT__EMNLP2023.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Multi-modal large language models are regarded as a crucial step towards Artificial General Intelligence (AGI) and have garnered significant interest with the emergence of ChatGPT.
However, current speech-language models typically adopt the cascade paradigm, preventing inter-modal knowledge transfer.
In this paper, we propose ***SpeechGPT***, a large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-model content.
With discrete speech representations, we first construct ***SpeechInstruct***, a large-scale cross-modal speech instruction dataset.
Additionally, we employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning.
The experimental results demonstrate that ***SpeechGPT*** has an impressive capacity to follow multi-modal human instructions and highlight the potential of handling multiple modalities with one model.
Demos are shown in [this https URL](https://0nutation.github.io/SpeechGPT.github.io/).

</details>
<br>

多模态大语言模型被认为是通向 AGI 的重要一步, 并且已经吸引了广泛的关注.
然而, 现有的语音语言模型通常采用级联范式, 阻止了跨模态知识转移.

在本文中, 我们提出了 ***SpeechGPT***, 一种具有内在的跨模态对话能力的大语言模型, 能够感知和生成多模态内容.
通过离散语音表示, 我们首先构建了 ***SpeechInstruct***, 一个大规模的跨模态语音指令数据集.
此外, 我们采用了三阶段训练策略包括模态适应预训练, 跨模态指令微调, 模态链指令微调.

实验结果表明 ***SpeechGPT*** 在遵循多模态人类指令方面有令人印象深刻的能力, 并突出了使用一个模型处理多个模态的潜力.
示例可在[此链接](https://0nutation.github.io/SpeechGPT.github.io/)中查看.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论