# SALMONN

<details>
<summary>基本信息</summary>

- 标题: "SALMONN: Towards Generic Hearing Abilities for Large Language Models"
- 作者:
  - 01 Changli Tang,
  - 02 Wenyi Yu,
  - 03 Guangzhi Sun,
  - 04 Xianzhao Chen,
  - 05 Tian Tan,
  - 06 Wei Li,
  - 07 Lu Lu,
  - 08 Zejun Ma,
  - 09 Chao Zhang
- 链接:
  - [ArXiv](https://arxiv.org/abs/2310.13289)
  - [Publication](https://openreview.net/forum?id=14rn7HpKVk) ICLR 2024
  - [Github](https://github.com/bytedance/SALMONN)
  - [Demo](https://bytedance.github.io/SALMONN/)
- 文件:
  - [ArXiv](../SpeechLM/_PDF/2310.13289v2__SALMONN__Towards_Generic_Hearing_Abilities_for_Large_Language_Models.pdf)
  - [Publication](../SpeechLM/_PDF/2310.13289p0__SALMONN__ICLR2024.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Hearing is arguably an essential ability of artificial intelligence (AI) agents in the physical world, which refers to the perception and understanding of general auditory information consisting of at least three types of sounds: speech, audio events, and music.
In this paper, we propose ***SALMONN***, a speech audio language music open neural network, built by integrating a pre-trained text-based large language model (LLM) with speech and audio encoders into a single multimodal model.
***SALMONN*** enables the LLM to directly process and understand general audio inputs and achieve competitive performances on a number of speech and audio tasks used in training, such as automatic speech recognition and translation, auditory-information-based question answering, emotion recognition, speaker verification, and music and audio captioning etc.
***SALMONN*** also has a diverse set of emergent abilities unseen in the training, which includes but is not limited to speech translation to untrained languages, speech-based slot filling, spoken-query-based question answering, audio-based storytelling, and speech audio co-reasoning etc.
The presence of cross-modal emergent abilities is studied, and a novel few-shot activation tuning approach is proposed to activate such abilities.
To our knowledge, ***SALMONN*** is the first model of its type and can be regarded as a step towards AI with generic hearing abilities.
The source code, model checkpoints and data are available at [this https URL](https://github.com/bytedance/SALMONN).

</details>
<br>

听觉可以说是物理世界中人工智能智能体的一项基本能力, 它指的是对一般听觉信息的理解, 至少包括三种类型的声音: 语音, 音频事件, 音乐.

在本文中, 我们提出了 ***SALMONN***, 一个***语音-音频-语言-音乐开放神经网络 (Speech Audio Language Music Open Neural Network) ***, 通过将预训练的基于文本的大语言模型与语音和音频编码器集成到单个多模态模型中构建而成.
***SALMONN*** 使得 LLM 能够直接处理和理解一般的音频输入, 并且在训练中使用的许多语音和音频任务上实现了具有竞争力的性能, 如自动语音识别和翻译, 基于听觉信息的问答, 情感识别, 说话人验证, 音乐和音频描述等.
***SALMONN*** 还具有在训练中未见过的涌现能力, 包括但不限于对未训练语言的语音翻译, 基于语音的槽位填充, 基于口头查询的问答, 基于音频的故事讲述, 语音-音频共同推理等.
本文研究了跨模态涌现能力的存在, 提出了一种新的少样本激活调参方法来激活这些能力.

到目前为止, ***SALMONN*** 是其类型的第一个模型, 可以被视为人工智能具有通用听觉能力的重要一步.
代码, 模型检查点和数据可在 [https://github.com/bytedance/SALMONN](https://github.com/bytedance/SALMONN) 获得.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论