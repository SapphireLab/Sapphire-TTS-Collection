# 标题

<details>
<summary>基本信息</summary>

- 标题: "XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model"
- 作者:
  - 01 Edresson Casanova,
  - 02 Kelly Davis,
  - 03 Eren Gölge,
  - 04 Görkem Göknar,
  - 05 Iulian Gulea,
  - 06 Logan Hart,
  - 07 Aya Aljafari,
  - 08 Joshua Meyer,
  - 09 Reuben Morais,
  - 10 Samuel Olayemi,
  - 11 Julian Weber
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.04904)
  - [Publication](https://doi.org/10.21437/Interspeech.2024-2016)
  - [Github](https://github.com/coqui-ai/TTS/tree/main)
  - [Demo](https://edresson.github.io/XTTS/)
- 文件:
  - [ArXiv](_PDF/2406.04904v1__XTTS__A_Massively_Multilingual_Zero-Shot_Text-to-Speech_Model.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Most Zero-shot Multi-speaker TTS (ZS-TTS) systems support only a single language.
Although models like YourTTS, VALL-E X, Mega-TTS 2, and Voicebox explored Multilingual ZS-TTS they are limited to just a few high/medium resource languages, limiting the applications of these models in most of the low/medium resource languages.
In this paper, we aim to alleviate this issue by proposing and making publicly available the ***XTTS*** system.
Our method builds upon the Tortoise model and adds several novel modifications to enable multilingual training, improve voice cloning, and enable faster training and inference.
***XTTS*** was trained in 16 languages and achieved state-of-the-art (SOTA) results in most of them.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论