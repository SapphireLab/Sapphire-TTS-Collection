# MobileSpeech

<details>
<summary>基本信息</summary>

- 标题: "MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech"
- 作者:
  - 01 Shengpeng Ji
  - 02 Ziyue Jiang
  - 03 Hanting Wang
  - 04 Jialong Zuo
  - 05 Zhou Zhao (赵洲)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2402.09378)
  - [Publication](https://doi.org/10.18653/v1/2024.acl-long.733)
  - [Github]()
  - [Demo](https://mobilespeech.github.io)
- 文件:
  - [ArXiv](_PDF/2402.09378v2__MobileSpeech__A_Fast_&_High-Fidelity_Framework_for_Mobile_Zero-Shot_TTS.pdf)
  - [Publication](_PDF/2402.09738p0__MobileSpeech__ACL2024.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Zero-shot text-to-speech (TTS) has gained significant attention due to its powerful voice cloning capabilities, requiring only a few seconds of unseen speaker voice prompts.
However, all previous work has been developed for cloud-based systems.Taking autoregressive models as an example, although these approaches achieve high-fidelity voice cloning, they fall short in terms of inference speed, model size, and robustness.There-fore, we propose ***MobileSpeech***, which is a fast, lightweight, and robust zero-shot text-to-speech system based on mobile devices for the first time.
Specifically:
1) leveraging discrete codec, we design a parallel speech mask decoder module called SMD, which incorpo-rates hierarchical information from the speech codec and weight mechanisms across differ-ent codec layers during the generation process.
Moreover, to bridge the gap between text and speech, we introduce a high-level probabilistic mask that simulates the progression of information flow from less to more during speech generation.
2) For speaker prompts, we extract fine-grained prompt duration from the prompt speech and incorporate text, prompt speech by cross attention in SMD.
We demonstrate the effectiveness of ***MobileSpeech*** on multilingual datasets at different levels, achieving state-of-the-art results in terms of generating speed and speech quality.

***MobileSpeech*** achieves RTF of 0.09 on a single A100 GPU and we have successfully deployed ***MobileSpeech*** on mobile devices.
Audio samples are available at https://mobilespeech.github.io/ .

</td><td>

</td></tr></table>

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论