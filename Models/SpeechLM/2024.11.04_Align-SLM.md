# Align-SLM

<details>
<summary>基本信息</summary>

- 标题: "Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback"
- 作者:
  - 01 Guan-Ting Lin,
  - 02 Prashanth Gurunath Shivakumar,
  - 03 Aditya Gourav,
  - 04 Yile Gu,
  - 05 Ankur Gandhe,
  - 06 Hung-yi Lee,
  - 07 Ivan Bulyko
- 链接:
  - [ArXiv](https://arxiv.org/abs/2411.01834)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2411.01834v1__Align-SLM__Textless_Spoken_Language_Models_with_Reinforcement_Learning_from_AI_Feedback.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

While textless Spoken Language Models (SLMs) have shown potential in end-to-end speech-to-speech modeling, they still lag behind text-based Large Language Models (LLMs) in terms of semantic coherence and relevance.
This work introduces the ***Align-SLM*** framework, which leverages preference optimization inspired by Reinforcement Learning with AI Feedback (RLAIF) to enhance the semantic understanding of SLMs.
Our approach generates multiple speech continuations from a given prompt and uses semantic metrics to create preference data for Direct Preference Optimization (DPO).
We evaluate the framework using [ZeroSpeech 2021 benchmarks](../../Evaluations/2020.11.23_ZeroSpeech.md) for lexical and syntactic modeling, the spoken version of the [StoryCloze dataset](../../Datasets/2017.04.03_StoryCloze.md) for semantic coherence, and other speech generation metrics, including the GPT4-o score and human evaluation.
Experimental results show that our method achieves state-of-the-art performance for SLMs on most benchmarks, highlighting the importance of preference optimization to improve the semantics of SLMs.

</details>
<br>

尽管无文本的口语语言模型已经在端到端的语音到语音建模方面显示出了潜力, 但它们在语义连贯性和相关性方面仍落后于基于文本的大语言模型.

本研究介绍了 ***Align-SLM*** 框架, 利用由 AI 反馈的强化学习 (RLAIF) 启发的偏好优化来增强口语语言模型的语义理解.
我们的方法从给定的提示生成多个语音续写, 并使用语义度量来为 DPO 创建偏好数据.

我们使用 [ZeroSpeech 2021 基准](../../Evaluations/2020.11.23_ZeroSpeech.md)来评估该框架的词汇和句法建模, [StoryCloze 数据集](../../Datasets/2017.04.03_StoryCloze.md)的口语版本来评估语义连贯性, 以及其他的语音生成度量, 包括 GPT4-o 得分和人工评估.

实验结果表明我们的方法在大多数基准上都实现了最先进的性能, 突显了偏好优化对提高口语语言模型语义理解的重要性.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论