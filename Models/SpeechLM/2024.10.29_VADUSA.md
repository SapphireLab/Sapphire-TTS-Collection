# VADUSA

<details>
<summary>基本信息</summary>

- 标题: "Fast and High-Quality Auto-Regressive Speech Synthesis via Speculative Decoding"
- 作者:
  - 01 Bohan Li,
  - 02 Hankun Wang,
  - 03 Situo Zhang,
  - 04 Yiwei Guo,
  - 05 Kai Yu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2410.21951)
  - [Publication]() Submitted to ICASSP 2025
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2410.21951v1__VADUSA__Fast_and_High-Quality_Auto-Regressive_Speech_Synthesis_via_Speculative_Decoding.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

The auto-regressive architecture, like GPTs, is widely used in modern Text-to-Speech (TTS) systems.
However, it incurs substantial inference time, particularly due to the challenges in the next-token prediction posed by lengthy sequences of speech tokens.
In this work, we introduce ***VADUSA***, one of the first approaches to accelerate auto-regressive TTS through speculative decoding.
Our results show that ***VADUSA*** not only significantly improves inference speed but also enhances performance by incorporating draft heads to predict future speech content auto-regressively.
Furthermore, the inclusion of a tolerance mechanism during sampling accelerates inference without compromising quality.
Our approach demonstrates strong generalization across large datasets and various types of speech tokens.

</details>
<br>

自回归架构, 如 GPTs, 被广泛用于现代文本转语音系统.
然而, 这种架构具有显著的推理时间开销, 尤其是由于长序列语音 Token 时的下一个 Token 预测.

在本文中, 我们介绍了 ***VADUSA***, 这是首个采用推测解码来加速自回归文本转语音的方法.
我们的结果表明 ***VADUSA*** 通过整合草稿头来自回归预测未来语音内容, 从而既显著提升了推理速度, 又增强了性能.
此外, 在采样过程中引入容忍度机制, 也能加速推理, 而不会损失质量.
我们的方法在大型数据集和各种语音 Token 类型上都表现出了强大的泛化能力.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论