# COSMIC

<details>
<summary>基本信息</summary>

- 标题: "COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning"
- 作者:
  - 01 Jing Pan,
  - 02 Jian Wu,
  - 03 Yashesh Gaur,
  - 04 Sunit Sivasankaran,
  - 05 Zhuo Chen,
  - 06 Shujie Liu,
  - 07 Jinyu Li
- 链接:
  - [ArXiv](https://arxiv.org/abs/2311.02248)
  - [Publication]
  - [Github]
  - [Demo]
- 文件:
  - [ArXiv](_PDF/2311.02248v2__COSMIC__Data_Efficient_Instruction-Tuning_for_Speech_In-Context_Learning.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

We present a cost-effective method to integrate speech into a large language model (LLM), resulting in a ***Contextual Speech Model with Instruction-following/in-context-learning Capabilities (COSMIC)*** multi-modal LLM.
Using GPT-3.5, we generate Speech Comprehension Test Question-Answer (SQA) pairs from speech transcriptions for supervised instruction tuning.
With under 30 million trainable parameters and only 450 hours of English speech data, ***COSMIC*** demonstrates emerging capabilities in instruction-following and in-context learning.
Equipped with such capabilities, ***COSMIC*** achieves a maximum 33.18 BLEU score in 0-shot EN-to-X speech to text translation (S2TT) and a significant boost in the 1-shot setting.
Additionally, there is an average 25.8\% relative Word Error Rate (WER) reduction for 1-shot cross-domain adaptation.
***COSMIC*** exhibits a significant automatic speech recognition (ASR) accuracy gain in contextual biasing tasks due to its instruction-following capability.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论