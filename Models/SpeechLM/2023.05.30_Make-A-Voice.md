# Make-A-Voice

<details>
<summary>基本信息</summary>

- 标题: "Make-A-Voice: Unified Voice Synthesis With Discrete Representation"
- 作者:
  - 01 Rongjie Huang
  - 02 Chunlei Zhang
  - 03 Yongqi Wang
  - 04 Dongchao Yang
  - 05 Luping Liu
  - 06 Zhenhui Ye
  - 07 Ziyue Jiang
  - 08 Chao Weng
  - 09 Zhou Zhao
  - 10 Dong Yu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2305.19269)
  - [Publication]
  - [Github]
  - [Demo](https://make-a-voice.github.io/)
- 文件:
  - [ArXiv](_PDF/2305.19269v1__Make-A-Voice__Unified_Voice_Synthesis_with_Discrete_Representation.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Various applications of voice synthesis have been developed independently despite the fact that they generate "voice" as output in common.
In addition, the majority of voice synthesis models currently rely on annotated audio data, but it is crucial to scale them to self-supervised datasets in order to effectively capture the wide range of acoustic variations present in human voice, including speaker identity, emotion, and prosody.
In this work, we propose ***Make-A-Voice***, a unified framework for synthesizing and manipulating voice signals from discrete representations.
***Make-A-Voice*** leverages a "coarse-to-fine" approach to model the human voice, which involves three stages:
1) semantic stage: model high-level transformation between linguistic content and self-supervised semantic tokens,
2) acoustic stage: introduce varying control signals as acoustic conditions for semantic-to-acoustic modeling, and
3) generation stage: synthesize high-fidelity waveforms from acoustic tokens.

***Make-A-Voice*** offers notable benefits as a unified voice synthesis framework:
1) Data scalability: the major backbone (i.e., acoustic and generation stage) does not require any annotations, and thus the training data could be scaled up.
2) Controllability and conditioning flexibility: we investigate different conditioning mechanisms and effectively handle three voice synthesis applications, including text-to-speech (TTS), voice conversion (VC), and singing voice synthesis (SVS) by re-synthesizing the discrete voice representations with prompt guidance.
Experimental results demonstrate that ***Make-A-Voice*** exhibits superior audio quality and style similarity compared with competitive baseline models.
Audio samples are available at [this https URL](https://make-a-voice.github.io/)

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论
