# FunAudioLLM

<details>
<summary>基本信息</summary>

- 标题: "FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs"
- 作者:
  - 01 Keyu An, Qian Chen, Chong Deng, Zhihao Du, Changfeng Gao, Zhifu Gao, Yue Gu, Ting He, Hangrui Hu, Kai Hu, Shengpeng Ji, Yabin Li, Zerui Li, Heng Lu, Haoneng Luo, Xiang Lv, Bin Ma, Ziyang Ma, Chongjia Ni, Changhe Song, Jiaqi Shi, Xian Shi, Hao Wang, Wen Wang, Yuxuan Wang, Zhangyu Xiao, Zhijie Yan, Yexin Yang, Bin Zhang, Qinglin Zhang, Shiliang Zhang, Nan Zhao, Siqi Zheng
- 链接:
  - [ArXiv](https://arxiv.org/abs/2407.04051)
  - [Publication]()
  - [Github](https://github.com/FunAudioLLM)
  - [Demo](https://fun-audio-llm.github.io/)
- 文件:
  - [ArXiv](_PDF/2407.04051v3__FunAudioLLM__Voice_Understanding_and_Generation_Foundation_Models_for_Natural_Interaction_between_Human_and_LLMs.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

This report introduces FunAudioLLM, a model family designed to enhance natural voice interactions between humans and large language models (LLMs).
At its core are two innovative models: ***SenseVoice***, which handles multilingual speech recognition, emotion recognition, and audio event detection; and ***CosyVoice***, which facilitates natural speech generation with control over multiple languages, timbre, speaking style, and speaker identity.
***SenseVoice***-Small delivers exceptionally low-latency ASR for 5 languages, and ***SenseVoice***-Large supports high-precision ASR for over 50 languages, while ***CosyVoice*** excels in multi-lingual voice generation, zero-shot in-context learning, cross-lingual voice cloning, and instruction-following capabilities.
The models related to ***SenseVoice*** and ***CosyVoice*** have been open-sourced on Modelscope and Huggingface, along with the corresponding training, inference, and fine-tuning codes released on GitHub.
By integrating these models with LLMs, FunAudioLLM enables applications such as speech-to-speech translation, emotional voice chat, interactive podcasts, and expressive audiobook narration, thereby pushing the boundaries of voice interaction technology.
Demos are available at [this https URL](https://fun-audio-llm.github.io/), and the code can be accessed at [this https URL](https://github.com/FunAudioLLM).

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论