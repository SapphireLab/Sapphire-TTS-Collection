# AudioPaLM

<details>
<summary>基本信息</summary>

- 标题: "AudioPaLM: A Large Language Model That Can Speak and Listen"
- 作者:
  - 01 Paul K. Rubenstein,
  - 02 Chulayuth Asawaroengchai,
  - 03 Duc Dung Nguyen,
  - 04 Ankur Bapna,
  - 05 Zalan Borsos,
  - 06 Felix de Chaumont Quitry,
  - 07 Peter Chen,
  - 08 Dalia El Badawy,
  - 09 Wei Han,
  - 10 Eugene Kharitonov,
  - 11 Hannah Muckenhirn,
  - 12 Dirk Padfield,
  - 13 James Qin,
  - 14 Danny Rozenberg,
  - 15 Tara Sainath,
  - 16 Johan Schalkwyk,
  - 17 Matt Sharifi,
  - 18 Michelle Tadmor Ramanovich,
  - 19 Marco Tagliasacchi,
  - 20 Alexandru Tudor,
  - 21 Mihajlo Velimirovic,
  - 22 Damien Vincent,
  - 23 Jiahui Yu,
  - 24 Yongqiang Wang,
  - 25 Vicky Zayats,
  - 26 Neil Zeghidour,
  - 27 Yu Zhang,
  - 28 Zhishuai Zhang,
  - 29 Lukas Zilka,
  - 30 Christian Frank
- 链接:
  - [ArXiv](https://arxiv.org/abs/2306.12925)
  - [Publication]
  - [Github]
  - [Demo](https://google-research.github.io/seanet/audiopalm/examples)
- 文件:
  - [ArXiv](../_PDF/2306.12925v1__AudioPaLM__A_Large_Language_Model_That_Can_Speak_&_Listen.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<table><tr><td width="50%">

We introduce ***AudioPaLM***, a large language model for speech understanding and generation.
***AudioPaLM*** fuses text-based and speech-based language models, **PaLM-2** and **AudioLM**, into a unified multimodal architecture that can process and generate text and speech with applications including speech recognition and speech-to-speech translation.
***AudioPaLM*** inherits the capability to preserve paralinguistic information such as speaker identity and intonation from **AudioLM** and the linguistic knowledge present only in text large language models such as **PaLM-2**.
We demonstrate that initializing ***AudioPaLM*** with the weights of a text-only large language model improves speech processing, successfully leveraging the larger quantity of text training data used in pretraining to assist with the speech tasks.
The resulting model significantly outperforms existing systems for speech translation tasks and has the ability to perform zero-shot speech-to-text translation for many languages for which input/target language combinations were not seen in training.
***AudioPaLM*** also demonstrates features of audio language models, such as transferring a voice across languages based on a short spoken prompt. We release examples of our method at [this https URL](https://google-research.github.io/seanet/audiopalm/examples).

</td><td>

我们介绍了 ***AudioPaLM***, 一个用于语音理解和生成的大型语言模型.
***AudioPaLM*** 融合了基于文本和基于语音的语言模型 **PaLM-2** 和 **AudioLM**, 形成一个统一的多模态架构, 可以处理和生成文本与语音, 应用包括语音识别和语音到语音翻译.
***AudioPaLM*** 继承了 **AudioLM** 中保存副语言信息 (如说话人身份和语调) 的能力, 以及仅存在于基于文本的大型语言模型 (如 **PaLM-2**) 中的语言知识.
我们展示了, 通过用文本专用大型语言模型的权重初始化 ***AudioPaLM***, 可以提高语音处理性能, 成功地利用预训练中使用的大量文本训练数据来辅助语音任务.
最终模型在语音翻译任务中显著优于现有系统, 并且能够实现对许多在训练中未见过的输入/目标语言组合进行零样本语音到文本翻译.
***AudioPaLM*** 还展示了音频语言模型的特点, 例如, 基于简短的语音提示跨语言传递声音.
我们在[此链接](https://google-research.github.io/seanet/audiopalm/examples)发布了我们方法的示例.

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td></tr></table>
