# SpeechT5

<details>
<summary>基本信息</summary>

- 标题: "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing"
- 作者:
  - 01 Junyi Ao
  - 02 Rui Wang
  - 03 Long Zhou
  - 04 Chengyi Wang
  - 05 Shuo Ren
  - 06 Yu Wu
  - 07 Shujie Liu
  - 08 Tom Ko
  - 09 Qing Li
  - 10 Yu Zhang
  - 11 Zhihua Wei
  - 12 Yao Qian
  - 13 Jinyu Li
  - 14 Furu Wei
- 链接:
  - [ArXiv](https://arxiv.org/abs/2110.07205)
  - [Publication]()
  - [Github](https://github.com/microsoft/SpeechT5)
  - [Demo]()
- 文件:
  - [ArXiv](../_PDF/2110.07205v3__SpeechT5__Unified-Modal_Encoder-Decoder_Pre-Training_for_Spoken_Language_Processing.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Motivated by the success of **T5 (Text-To-Text Transfer Transformer)** in pre-trained natural language processing models, we propose a unified-modal ***SpeechT5*** framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning.
The ***SpeechT5*** framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets.
After preprocessing the input speech/text through the pre-nets, the shared encoder-decoder network models the sequence-to-sequence transformation, and then the post-nets generate the output in the speech/text modality based on the output of the decoder.
Leveraging large-scale unlabeled speech and text data, we pre-train ***SpeechT5*** to learn a unified-modal representation, hoping to improve the modeling capability for both speech and text.
To align the textual and speech information into this unified semantic space, we propose a cross-modal vector quantization approach that randomly mixes up speech/text states with latent units as the interface between encoder and decoder.
Extensive evaluations show the superiority of the proposed ***SpeechT5*** framework on a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification.
We release our code and model at [this https URL](https://github.com/microsoft/SpeechT5).

</td><td>

受 **T5 (Text-To-Text Transfer Transformer)** 在预训练自然语言处理模型中的成功启发, 我们提出了一个统一模态的 ***SpeechT5*** 框架, 旨在探索编码器-解码器预训练用于自监督语音/文本表示学习.

***SpeechT5*** 框架由一个共享的编码器-解码器网络和六个特定模态（语音/文本）的预/后处理网络组成.
在通过预处理网络对输入语音/文本进行预处理后, 共享的编码器-解码器网络对序列到序列的转换进行建模, 随后后处理网络基于解码器的输出生成语音/文本模态的输出.
通过利用大规模的无标签语音和文本数据, 我们对 ***SpeechT5*** 进行了预训练, 旨在学习统一模态的表示, 从而提升对语音和文本的建模能力.

为了将文本和语音信息对齐到统一的语义空间, 我们提出了一种跨模态向量量化方法, 该方法通过随机混合语音/文本状态与潜在单元作为编码器和解码器之间的接口.

大量评估结果表明, 所提的 ***SpeechT5*** 框架在各种语音语言处理任务中具有优越性, 包括自动语音识别, 语音合成, 语音翻译, 语音转换, 语音增强和说话人识别.

我们已在[此链接](https://github.com/microsoft/SpeechT5)发布了我们的代码和模型.

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td></tr></table>
