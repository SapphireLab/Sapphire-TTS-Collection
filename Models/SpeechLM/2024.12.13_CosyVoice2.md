# CosyVoice2

<details>
<summary>基本信息</summary>

- 标题: "CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models"
- 作者:
  - 01 Zhihao Du
  - 02 Yuxuan Wang
  - 03 Qian Chen
  - 04 Xian Shi
  - 05 Xiang Lv
  - 06 Tianyu Zhao
  - 07 Zhifu Gao
  - 08 Yexin Yang
  - 09 Changfeng Gao
  - 10 Hui Wang
  - 11 Fan Yu
  - 12 Huadai Liu
  - 13 Zhengyan Sheng
  - 14 Yue Gu
  - 15 Chong Deng
  - 16 Wen Wang
  - 17 Shiliang Zhang
  - 18 Zhijie Yan
  - 19 Jingren Zhou
- 链接:
  - [ArXiv](https://arxiv.org/abs/2412.10117)
  - [Publication]
  - [Github](https://github.com/funaudiollm/cosyvoice)
  - [Demo](https://funaudiollm.github.io/cosyvoice2)
- 文件:
  - [ArXiv](_PDF/2412.10117v3__CosyVoice2__Scalable_Streaming_Speech_Synthesis_with_Large_Language_Models.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

In our previous work, we introduced CosyVoice, a multilingual speech synthesis model based on supervised discrete speech tokens.
By employing progressive semantic decoding with two popular generative models, language models (LMs) and Flow Matching, CosyVoice demonstrated high prosody naturalness, content consistency, and speaker similarity in speech in-context learning.
Recently, significant progress has been made in multi-modal large language models (LLMs), where the response latency and real-time factor of speech synthesis play a crucial role in the interactive experience.
Therefore, in this report, we present an improved streaming speech synthesis model, CosyVoice2, which incorporates comprehensive and systematic optimizations.
Specifically, we introduce finite-scalar quantization to improve the codebook utilization of speech tokens.
For the text-speech LM, we streamline the model architecture to allow direct use of a pre-trained LLM as the backbone.
In addition, we develop a chunk-aware causal flow matching model to support various synthesis scenarios, enabling both streaming and non-streaming synthesis within a single model.
By training on a large-scale multilingual dataset, CosyVoice 2 achieves human-parity naturalness, minimal response latency, and virtually lossless synthesis quality in the streaming mode.
We invite readers to listen to the demos at [this https URL](https://funaudiollm.github.io/cosyvoice2).

</details>
<br>

在我们先前的工作中, 我们提出了 CosyVoice, 一种基于监督式离散语音 Token 的多语言语音合成模型.
通过采用两种流行的生成式模型 (语言模型, 流匹配) 实现的渐进式语义解码, CosyVoice 在语音上下文学习中展现出了高韵律自然度, 内容一致性和说话人相似度.

最近, 多模态大语言模型出现了显著进展, 语音合成的响应延迟和实时因子成为了交互体验的关键.
因此, 在本报告中, 我们展示了一个改进的流式语音合成模型, CosyVoice2, 继承了全面且系统的优化.

具体来说, 我们引入有限标量量化 (Finite-Scalar Quantization, FSQ) 来提升语音 Token 的码本利用率.
对于文本-语音语言模型, 我们将模型架构简化, 允许直接使用预训练的大语言模型作为骨干.
此外, 我们开发了一个基于分块感知的因果流匹配模型, 以支持各种合成场景, 使得单个模型能够支持流式和非流式合成.

通过在大规模多语言数据集上训练, CosyVoice2 在流式模式下实现了人类齐平的自然度, 最小的响应延迟, 几乎无损的合成质量.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论