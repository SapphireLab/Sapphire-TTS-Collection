# FA-GAN

https://arxiv.org/abs/2407.04575

## Abstract: 摘要

> Generative adversarial network (GAN) based vocoders have achieved significant attention in speech synthesis with high quality and fast inference speed. 
> However, there still exist many noticeable spectral artifacts, resulting in the quality decline of synthesized speech. 
> In this work, we adopt a novel GAN-based vocoder designed for few artifacts and high fidelity, called ***FA-GAN***. 
> To suppress the aliasing artifacts caused by non-ideal upsampling layers in high-frequency components, we introduce the anti-aliased twin deconvolution module in the generator. 
> To alleviate blurring artifacts and enrich the reconstruction of spectral details, we propose a novel fine-grained multi-resolution real and imaginary loss to assist in the modeling of phase information. 
> Experimental results reveal that ***FA-GAN*** outperforms the compared approaches in promoting audio quality and alleviating spectral artifacts, and exhibits superior performance when applied to unseen speaker scenarios.

基于生成对抗网络 (GAN) 的声码器在语音合成中因其高质量和快速推理速度而获得了显著的关注.
然而, 仍然存在许多明显的频谱伪影, 导致合成语音质量的下降. 
在这项工作中, 我们采用了一种新型的基于 GAN 的声码器, 设计用于减少伪影并提高保真度, 称为 ***FA-GAN***. 
为了抑制由高频分量中的非理想上采样层引起的混叠伪影, 我们在生成器中引入了抗混叠的双重反卷积模块. 
为了减轻模糊伪影并丰富频谱细节的重建, 我们提出了一种新颖的细粒度多分辨率实部和虚部损失, 以辅助相位信息的建模. 
实验结果表明, ***FA-GAN*** 在提升音频质量和减轻频谱伪影方面优于比较的方法, 并且在应用于未见过的说话人场景时表现出优越的性能. 