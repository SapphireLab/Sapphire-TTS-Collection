# FreeV

<details>
<summary>基本信息</summary>

- 标题: FreeV: Free Lunch For Vocoders Through Pseudo Inversed Mel Filter
- 作者:
  - 01 [Yuanjun Lv](../../Authors/Yuanjun_Lv_(吕元骏).md)
  - 02 [Hai Li](../../Authors/Hai_Li.md)
  - 03 [Ying Yan](../../Authors/Ying_Yan.md)
  - 04 [Junhui Liu](../../Authors/Junhui_Liu.md)
  - 05 [Danming Xie](../../Authors/Danming_Xie.md)
  - 06 [Lei Xie](../../Authors/Lei_Xie_(谢磊).md)
- 机构:
  - 机构 
- 时间:
  - 预印时间: 2024.06.12 ArXiv v1
  - 更新笔记: 2024.08.05
- 发表:
  - [InterSpeech 2024](../../Publications/InterSpeech.md) 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.08196)
  - [DOI]()
  - [Github](https://github.com/bakerbunker/freev)
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=13731432507109093105)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: 0
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> Vocoders reconstruct speech waveforms from acoustic features and play a pivotal role in modern TTS systems. Frequent-domain GAN vocoders like Vocos and APNet2 have recently seen rapid advancements, outperforming time-domain models in inference speed while achieving comparable audio quality. However, these frequency-domain vocoders suffer from large parameter sizes, thus introducing extra memory burden. Inspired by PriorGrad and SpecGrad, we employ pseudo-inverse to estimate the amplitude spectrum as the initialization roughly. This simple initialization significantly mitigates the parameter demand for vocoder. Based on APNet2 and our streamlined Amplitude prediction branch, we propose our FreeV, compared with its counterpart APNet2, our FreeV achieves \textbf{1.8$\times$ inference speed improvement} with nearly \textbf{half parameters}. Meanwhile, our FreeV outperforms APNet2 in resynthesis quality, marking a step forward in pursuing real-time, high-fidelity speech synthesis. Code and checkpoints is available at: \url{https://github.com/BakerBunker/FreeV}

## 1.Introduction: 引言

Recently, there has been a rapid advancement in the field of neural vocoders, which transform speech acoustic features into waveforms. These vocoders play a crucial role in text-to-speech synthesis, voice conversion, and audio enhancement applications. Within these contexts, the process typically involves a model that predicts a mel-spectrogram from the source text or speech, followed by a vocoder that produces the waveform from the predicted mel-spectrogram. Consequently, the quality of the synthesized speech, the speed of inference, and the parameter size of the model constitute the three primary metrics for assessing the performance of neural vocoders.

Recent advancements in vocoders, including iSTFTNet~\cite{kaneko2022istftnet}, Vocos~\cite{siuzdak2023vocos}, and APNet~\cite{ai2023apnet}, have shifted from the prediction of waveforms in the time domain to the estimation of amplitude and phase spectra in the frequency domain, followed by waveform reconstruction via inverse short-time Fourier transform (ISTFT). This method circumvents the need to predict extensive time-domain waveforms, thus reducing the models' computational burden. ISTFTNet, for example, minimizes the computational complexity by decreasing the upsampling stages and focusing on frequency-domain spectra predictions before employing ISTFT for time-domain signal reconstruction. Vocos extends these advancements by removing all upsampling layers and utilizing the ConvNeXtV2~\cite{woo2023convnext} Block as its foundational layer. APNet~\cite{ai2023apnet} and APNet2~\cite{du2023apnet} further refine this approach by independently predicting amplitude and phase spectra and incorporating innovative supervision to guide phase spectra estimation. Nonetheless, with comparable parameter counts, these models often underperform their time-domain counterparts, highlighting potential avenues for optimization in the parameter efficiency of frequency-domain vocoders.

Several diffusion-based vocoders have integrated signal-processing insights to reduce inference steps and improve reconstruction quality. PriorGrad~\cite{lee2021priorgrad} initially refines the model's priors by aligning the covariance matrix diagonals with the energy of each frame of the Mel spectrogram. Extending this innovation, SpecGrad~\cite{koizumi2022specgrad} proposed to adjust the diffusion noise to align its dynamic spectral characteristics with those of the conditioning mel spectrogram. Moreover, GLA-Grad~\cite{liu2024glagrad} enhances the perceived audio quality by embedding the estimated amplitude spectrum into each diffusion step's post-processing stage. Nevertheless, the reliance on diffusion models results in slower inference speeds, posing challenges for their real-world application.

In this work, we introduce \textit{FreeV}, a streamlined GAN vocoder enhanced with prior knowledge from signal processing, and tested on the LJSpeech dataset~\cite{ljspeech17}. The empirical outcomes highlight FreeV's superior performance characterized by faster convergence in training, a near 50\% reduction in parameter size, and a notable boost in inference speed. Our contributions can be summarized as follows:
\begin{itemize}
    \item We innovated by using the product of the Mel spectrogram and the pseudo-inverse of the Mel filter, referred to as the pseudo-amplitude spectrum, as the model's input, effectively easing the model's complexity.
    \item Drawing on our initial insight, we substantially diminished the spectral prediction branch's parameters and the time required for inference without compromising the quality achieved by the original model.
\end{itemize}

## 2.Related Works: 相关工作

### PriorGrad & SpecGrad

### APNet & APNet2

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
