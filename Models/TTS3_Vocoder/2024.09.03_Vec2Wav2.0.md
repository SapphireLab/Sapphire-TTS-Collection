# Vec2Wav 2.0

<details>
<summary>基本信息</summary>

- 标题: ***vec2wav 2.0***: Advancing Voice Conversion via Discrete Token Vocoders
- 作者:
  | 序号 | 作者 | 机构 |
  | :-: | --- | --- |
  | 01 | [郭奕玮 (Yiwei Guo)](../../Authors/Yiwei_Guo_(郭奕玮).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
  | 02 | [李之涵 (Zhihan Li)](../../Authors/Zhihan_Li_(李之涵).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
  | 03 | [李俊杰 (Junjie Li)](../../Authors/Junjie_Li_(李俊杰).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
  | 04 | [杜晨鹏 (Chenpeng Du)](../../Authors/Chenpeng_Du_(杜晨鹏).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
  | 05 | [王翰坤 (Hankun Wang)](../../Authors/Hankun_Wang_(王翰坤).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
  | 06 | [王帅 (Shuai Wang)](../../Authors/Shuai_Wang_(王帅).md) | [深圳大数据研究院](../../Institutions/CHN-SRIBD_深圳大数据研究院.md) |
  | 07 | [陈谐 (Xie Chen)](../../Authors/Xie_Chen_(陈谐).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
  | 08 | [俞凯 (Kai Yu)](../../Authors/Kai_Yu_(俞凯).md) | [X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) |
- 机构:
  | 序号 | 机构 | 占比 |
  | :-: | :-: | :-: |
  | 01 | [上海交通大学 X-LANCE 实验室](../../Institutions/CHN-SJTU_上海交通大学.md) | 07/08 |
  | 02 | [深圳大数据研究院](../../Institutions/CHN-SRIBD_深圳大数据研究院.md) | 01/08 |
- 时间:
  - 预印时间: 2024.09.03 ArXiv v1
  - 更新笔记: 2024.09.04
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2409.01995)
  - [DOI]()
  - [Github](https://github.com/cantabile-kwok/vec2wav2.0)
  - [Demo](https://cantabile-kwok.github.io/vec2wav2/)
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: 5
- 引用: 40
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> We propose a new speech discrete token vocoder, ***vec2wav 2.0***, which advances voice conversion (VC).
> We use discrete tokens from speech self-supervised models as the content features of source speech, and treat VC as a prompted vocoding task.
> To amend the loss of speaker timbre in the content tokens, ***vec2wav 2.0*** utilizes the WavLM features to provide strong timbre-dependent information.
> A novel adaptive Snake activation function is proposed to better incorporate timbre into the waveform reconstruction process.
> In this way, ***vec2wav 2.0*** learns to alter the speaker timbre appropriately given different reference prompts.
> Also, no supervised data is required for ***vec2wav 2.0*** to be effectively trained.
> Experimental results demonstrate that ***vec2wav 2.0*** outperforms all other baselines to a considerable margin in terms of audio quality and speaker similarity in any-to-any VC.
> Ablation studies verify the effects made by the proposed techniques.
> Moreover, ***vec2wav 2.0*** achieves competitive cross-lingual VC even only trained on monolingual corpus.
> Thus, ***vec2wav 2.0*** shows timbre can potentially be manipulated only by speech token vocoders, pushing the frontiers of VC and speech synthesis.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
