# PeriodWave

<details>
<summary>基本信息</summary>

- 标题: PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation
- 作者:
  - 01 [Sang-Hoon Lee](../../Authors/Sang-Hoon_Lee.md)
  - 02 [Ha-Yeong Choi](../../Authors/Ha-Yeong_Choi.md)
  - 03 [Seong-Whan Lee](../../Authors/Seong-Whan_Lee.md)
- 机构:
  - 机构 
- 时间:
  - 预印时间: 2024.08.14 ArXiv v1
  - 更新笔记: 2024.08.15
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.07547)
  - [DOI]()
  - [Github](https://github.com/sh-lee-prml/PeriodWave)
  - [Demo](https://periodwave.github.io/demo/)
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - [开源](../../Tags/OpenSource.md)
- 页数: 24
- 引用: ?
- 被引: ?
- 数据:
  - [LJSpeech](../../Datasets/2017.07.05_LJSpeech.md)
  - [LibriTTS](../../Datasets/2019.04.05_LibriTTS.md)
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

> Recently, universal waveform generation tasks have been investigated conditioned on various out-of-distribution scenarios. 
> Although GAN-based methods have shown their strength in fast waveform generation, they are vulnerable to train-inference mismatch scenarios such as two-stage text-to-speech. 
> Meanwhile, diffusion-based models have shown their powerful generative performance in other domains; however, they stay out of the limelight due to slow inference speed in waveform generation tasks. 
> Above all, there is no generator architecture that can explicitly disentangle the natural periodic features of high-resolution waveform signals. 
> In this paper, we propose ***PeriodWave***, a novel universal waveform generation model. 
> First, we introduce a period-aware flow matching estimator that can capture the periodic features of the waveform signal when estimating the vector fields. 
> Additionally, we utilize a multi-period estimator that avoids overlaps to capture different periodic features of waveform signals. 
> Although increasing the number of periods can improve the performance significantly, this requires more computational costs. 
> To reduce this issue, we also propose a single period-conditional universal estimator that can feed-forward parallel by period-wise batch inference. 
> Additionally, we utilize discrete wavelet transform to losslessly disentangle the frequency information of waveform signals for high-frequency modeling, and introduce FreeU to reduce the high-frequency noise for waveform generation. 
> The experimental results demonstrated that our model outperforms the previous models both in Mel-spectrogram reconstruction and text-to-speech tasks. 
> All source code will be available at [Github](https://github.com/sh-lee-prml/PeriodWave).  

</details>
<br>

最近, 以各种分布外场景为条件的通用波形生成任务被加以研究.
尽管基于生成对抗网络的方法在快速波形生成方面展示了它们的实力, 但它们在训练-推理不匹配的场景如两阶段文本转语音中容易受到影响.
同时, 基于扩散的模型在其他领域展示了其强大的生成性能, 然而由于其在波形生成任务中的推理速度较慢, 并未得到太多关注.
更重要的是, 目前还没有一种生成器架构能够明确地解耦高分辨率波形信号的自然周期特征.

在本文中, 我们提出了 ***PeriodWave***, 一种新型的通用波形生成模型.
首先, 我们引入了周期感知流匹配估计器, 能够在估计矢量场时捕捉波形信号的周期特征.
此外, 我们使用多周期估计器避免重叠, 以捕捉波形信号的不同周期特征.
虽然增加周期数量可以显著提高性能, 但这需要更多的计算成本.
为了减少这一问题, 我们还提出了一个单周期条件化通用估计器, 能够通过按周期维度的批处理推理来实现并行.
此外, 我们利用离散小波变换来无损地解耦波形信号的频率信息用于高频建模, 并引入了 FreeU 来减少波形生成时的高频噪声.
实验结果表明, 我们的模型在语音合成任务和梅尔频谱重建任务方面都优于之前的模型.
所有源代码将会在 [Github](https://github.com/sh-lee-prml/PeriodWave) 上提供.

## 1.Introduction: 引言

> Deep generative models have achieved significant success in high-fidelity waveform generation. 
> In general, the neural waveform generation model which is called \textit{"Neural Vocoder"} transforms a low-resolution acoustic representation such as Mel-spectrogram or linguistic representations into a high-resolution waveform signal for regeneration learning \citep{tan2024regeneration}. 
> Conventional neural vocoder models have been investigated for text-to-speech ([WaveNet](2016.09.12_WaveNet.md); \citep{shen2018natural,ren2019fastspeech,kim2020glow,jiang2024megatts} and voice conversion \citep{lee2021voicemixer,choi2021neural}. 
> Furthermore, recent universal waveform generation models called \textit{"Universal Vocoder"} are getting more attention due to their various applicability in neural audio codec ([SoundStream](../Speech_Neural_Codec/2021.07.07_SoundStream.md); [EnCodec](../Speech_Neural_Codec/2022.10.24_EnCodec.md); [Decsript-Audio-Codec](../Speech_Neural_Codec/2023.06.11_Descript-Audio-Codec.md); ju2024naturalspeech), audio generation \citep{kreuk2023audiogen,roman2023from,yang2023diffsound,huang2023make,pmlr-v202-liu23f}, and zero-shot voice cloning systems \citep{lee2022hierspeech,huang2022generspeech,[VALL-E](../Speech_LLM/2023.01.05_VALL-E.md); li2024styletts,le2024voicebox,kim2024p,shen2024naturalspeech} where models can generate high-fidelity waveform signal from the highly compressed representations beyond the traditional acoustic features, Mel-spectrogram. 
> In addition, universal vocoder requires generalization in various out-of-distribution scenarios including unseen voice, instruments, and dynamic environments ([BigVGAN](2022.06.09_BigVGAN.md); bak2023avocodo). 
>
> Previously, generative adversarial networks (GAN) models dominated the waveform generation tasks by introducing various discriminators that can capture the different characters of waveform signals. 
> [MelGAN](2019.10.08_MelGAN.md) used the multi-scale discriminator to capture different features from the different scales of waveform signal. 
> [HiFi-GAN](2020.10.12_HiFi-GAN.md) introduced the multi-period discriminator to capture the different periodic patterns of the waveform signal. 
> [UnivNet](2021.06.15_UnivNet.md) utilized the multi-resolution spectrogram discriminator that can reflect the spectral features of waveform signal. 
> [BigVGAN](2022.06.09_BigVGAN.md) proposed the Snake activation function for the out-of-distribution modeling and scaled up the neural vocoder for universal waveform generation. 
> [Vocos](2023.03.01_Vocos.md) significantly improved the efficiency of the neural vocoder without upsampling the time-axis representation. 
> Although GAN-based models can generate the high-fidelity waveform signal fast, GAN models possess three major limitations: 
> 1) they should utilize a lot of discriminators to improve the audio quality, which increases training time; 
> 2) this also requires hyper-parameter tuning to balance multiple loss terms; 
> 3) they are vulnerable to train-inference mismatch scenarios such as two-state models, which induces metallic sound or hissing noise.
>
> Recently, the multi-band diffusion (MBD) model \citep{roman2023from} sheds light on the effectiveness of the diffusion model for high-resolution waveform modeling. 
> Although previous diffusion-based waveform models ([DiffWave](2020.09.21_DiffWave.md); [WaveGrad](2020.09.02_WaveGrad.md)) existed, they could not model the high-frequency information so the generated waveform only contains low-frequency information. 
> Additionally, they still require a lot of iterative steps to generate high-fidelity waveform signals. 
> To reduce this issue, [PriorGrad](2021.06.11_PriorGrad.md) introduced a data-driven prior and [FastDiff](../Diffusion/2022.04.21_FastDiff.md) adopted an efficient structure and noise schedule predictor. 
> However, they do not model the high-frequency information so these models only generate the low-frequency information well. 
>
> Above all, there is no generator architecture to reflect the natural periodic features of high-resolution waveform signals. 
> In this paper, we propose PeriodWave, a novel waveform generation model that can reflect different implicit periodic representations. 
> We also adopt the powerful generative model, flow matching that can estimate the vector fields directly using the optimal transport path for fast sampling. 
> Additionally, we utilize a multi-period estimator by adopting the prime number to avoid overlaps. 
> We observed that increasing the number of periods can improve the entire performance consistently. 
> However, this also induces a slow inference speed. 
> To simply reduce this limitation, we propose a period-conditional universal estimator that can feed-forward parallel by period-wise batch inference. 
> Furthermore, we utilize a discrete wavelet transformation (DWT) \citep{lee2022fre} for frequency-wise waveform modeling that can efficiently model the low and high-frequency information, respectively. 
>
> PeriodWave achieves a better performance in objective and subjective metrics than other publicly available strong baselines on both speech and out-of-distribution samples. 
> Specifically, the experimental results demonstrated that our methods can significantly improve the pitch-related metrics including pitch distance, periodicity, and V/UV F1 score with unprecedented performance. 
> Furthermore, we only train the models for only three days while previous GAN models require over three weeks.
>
> The main contributions of this study are as follows:
> - We propose PeriodWave, a novel universal waveform generator that can reflect different implicit periodic information when estimating the vector fields.
> - This is the first success utilizing flow matching for waveform-level high-resolution signal modeling, and we thoroughly analyze different ODE methods for waveform generation.
> - For efficient and fast inference, we propose a period-conditional universal estimator that can feed-forward the multiple period paths parallel by period-wise batch inference.
> - We analyze the limitation of high-frequency modeling for flow matching-based waveform generation. 
> To reduce this issue, we adopt the DWT for more accurate frequency-wise vector field estimation and FreeU approach for high-frequency noise reduction.
> - We will release all source code and checkpoints at [Github](https://github.com/sh-lee-prml/PeriodWave).

## 2.Related Works: 相关工作

### Neural Vocoder

> [WaveNet](2016.09.12_WaveNet.md) has successfully paved the way for high-quality neural waveform generation tasks. 
> However, these auto-regressive (AR) models suffer from a slow inference speed. 
> To address this limitation, teacher-student distillation-based inverse AR flow methods ([Parallel WaveNet](2017.11.28_Parallel_WaveNet.md); [ClariNet](../E2E/2018.07.19_ClariNet.md)) have been investigated for parallel waveform generation. 
> Flow-based models ([FloWaveNet](2018.11.06_FloWaveNet.md); [WaveGlow](2018.10.31_WaveGlow.md); [NanoFlow](2020.06.11_NanoFlow.md)) have also been utilized, which can be trained by simply maximizing the likelihood of the data using invertible transformation.

### GAN-based Neural Vocoder

> [MelGAN](2019.10.08_MelGAN.md) successfully incorporated generative adversarial networks (GAN) into the neural vocoder by introducing a multi-scale discriminator to reflect different features from the different scales of waveform signal and feature matching loss for stable training. 
> [Parallel WaveGAN](2019.10.25_Parallel_WaveGAN.md) introduces multi-resolution STFT losses that can improve the perceptual quality and robustness of adversarial training. 
> [GAN-TTS](2019.09.25_GAN-TTS.md) utilized an ensemble of random window discriminators that operate on random segments of waveform signal. 
> GED \citep{gritsenko2020spectral} proposed a spectral energy distance with unconditional GAN for stable and consistent training. 
> [HiFi-GAN](2020.10.12_HiFi-GAN.md) introduced a novel discriminator, a multi-period discriminator (MPD) that can capture different periodic features of waveform signal. 
> [UnivNet](2021.06.15_UnivNet.md) employed adversarial feedback on the multi-resolution spectrogram to capture the spectral representations at different resolutions. 
> [BigVGAN](2022.06.09_BigVGAN.md) adopted periodic activation function and anti-aliased representation into the generator for generalization on out-of-distribution samples. 
> [Vocos](2023.03.01_Vocos.md) proposed an efficient waveform generation framework using ConvNeXt blocks and iSTFT head without any temporal domain upsampling. 
> 
> Meanwhile, neural codec models ([SoundStream](../Speech_Neural_Codec/2021.07.07_SoundStream.md); [EnCodec](../Speech_Neural_Codec/2022.10.24_EnCodec.md); [Decsript-Audio-Codec](../Speech_Neural_Codec/2023.06.11_Descript-Audio-Codec.md)) and applications ([VALL-E](../Speech_LLM/2023.01.05_VALL-E.md); [UniAudio](../Speech_LLM/2023.10.01_UniAudio.md)) such as TTS and audio generation have been investigated together with the development of neural vocoder.

### Diffusion-based Neural Vocoder

> [DiffWave](2020.09.21_DiffWave.md) and [WaveGrad](2020.09.02_WaveGrad.md) introduced a Mel-conditional diffusion-based neural vocoder that can estimate the gradients of the data density. 
> [PriorGrad](2021.06.11_PriorGrad.md) improves the efficiency of the conditional diffusion model by adopting a data-dependent prior distribution for diffusion models instead of a standard Gaussian distribution. 
> [FastDiff](../Diffusion/2022.04.21_FastDiff.md) proposed a fast conditional diffusion model by adopting an efficient generator structure and noise schedule predictor. 
> Multi-band Diffusion \citep{roman2023from} incorporated multi-band waveform modeling into diffusion models and it significantly improved the performance by band-wise modeling because previous diffusion methods could not model high-frequency information, which only generated the low-frequency representations. 
> This model also focused on raw waveform generation from discrete tokens of neural codec model for various audio generation applications including speech, music, and environmental sound.

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论

> In this work, we proposed PeriodWave, a novel universal waveform generation model with conditional flow matching. 
> Motivated by the multiple periodic characteristics of high-resolution waveform signals, we introduce the period-aware flow matching estimators which can reflect different implicit periodic representations when estimating vector fields. 
> Furthermore, we observed that increasing the number of periods can improve the performance, and we introduce a period-conditional universal estimator for efficient structure. 
> By adopting this, we also implement a period-wise batch inference for efficient inference. 
> The experimental results demonstrate the superiority of our model in high-quality waveform generation and OOD robustness. 
> GAN-based models still hold great potential and have shown strong performance but require multiple loss functions, resulting in complex training and long training times. 
> On the other hand, we introduced a new flow matching based approach using a single loss function, which offers a notable advantage. 
> Furthermore, we see that the pre-trained flow matching generator could be utilized as a teacher model for distillation or fine-tuning. 
> We hope that our approach will facilitate the study of waveform generation by reducing training time, so we will release all source code and checkpoints. 

### Broader Impact and Limitation

#### Practical Application

> We first introduce a high-fidelity waveform generation model using flow matching. 
> We demonstrated the out-of-distribution robustness of our model, and this means that the conventional neural vocoder can be replaced with our model. 
> We see that our models can be utilized for text-to-speech, voice conversion, audio generation, and speech language models for high-quality waveform decoding. 
> For future work, we will train and release Codec-based PeriodWave for audio generation and speech language models. 

#### Social Negative Impact

> Recently, speech AI technology has shown its practical applicability by synthesizing much more realistic audio. 
> Unfortunately, this also increases the risk of the potential social negative impact including malicious use and ethical issues by deceiving people. 
> It is important to discuss a countermeasure that can address these potential negative impacts such as fake audio detection, anti-spoofing techniques, and audio watermark generation.

#### Limitation

> Although our models could generate the waveform with small sampling steps, Table \ref{appendix:inferencespeed} shows that our models have a slow synthesis speed compared to GAN-based neural vocoder. 
> To overcome this issue, we will explore distillation methods or adversarial training to reduce the sampling steps for much more fast inference by using our period-aware structure. 
> Additionally, our models still show a lack of robustness in terms of high-frequency information because we only train the model by estimating the vector fields on the waveform resolution. 
> Although we utilize multi-band modeling to reduce this issue, we have a plan to add a modified spectral objective function and blocks that can reflect the spectral representations when estimating vector fields by utilizing short-time Fourier convolution proposed in \citep{han22_interspeech} for audio super-resolution. 
> Moreover, we see that classifier-free guidance could be adapted to our model to improve the audio quality.
