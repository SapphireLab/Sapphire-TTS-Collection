# DC-Spin

<details>
<summary>基本信息</summary>

- 标题: "DC-Spin: A Speaker-invariant Speech Tokenizer for Spoken Language Models"
- 作者:
  - 01 Heng-Jui Chang (MIT CSAIL, Internship at Meta) - hengjui@mit.edu
  - 02 Hongyu Gong (Meta AI)
  - 03 Changhan Wang (Meta AI)
  - 04 James Glass (MIT CSAIL)
  - 05 Yu-An Chun (Meta AI) - andyyuan@meta.com
- 链接:
  - [ArXiv](https://arxiv.org/abs/2410.24177)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2410.24177v1__DC-Spin__A_Speaker-invariant_Speech_Tokenizer_for_Spoken_Language_Models.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Spoken language models (SLMs) have gained increasing attention with advancements in text-based, decoder-only language models.
SLMs process text and speech, enabling simultaneous speech understanding and generation.
This paper presents ***Double-Codebook Speaker-invariant Clustering (DC-Spin)***, which aims to improve speech tokenization by bridging audio signals and SLM tokens.
***DC-Spin*** extracts speaker-invariant tokens rich in phonetic information and resilient to input variations, enhancing zero-shot SLM tasks and speech resynthesis.
We propose a chunk-wise approach to enable streamable ***DC-Spin*** without retraining and degradation.
Comparisons of tokenization methods (self-supervised and neural audio codecs), model scalability, and downstream task proxies show that tokens easily modeled by an n-gram LM or aligned with phonemes offer strong performance, providing insights for designing speech tokenizers for SLMs.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论