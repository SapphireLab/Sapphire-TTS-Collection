# MusicGen

<details>
<summary>基本信息</summary>

- 标题: "Simple and Controllable Music Generation"
- 作者:
  - 01 Jade Copet,
  - 02 Felix Kreuk,
  - 03 Itai Gat,
  - 04 Tal Remez,
  - 05 David Kant,
  - 06 Gabriel Synnaeve,
  - 07 Yossi Adi,
  - 08 Alexandre Defossez
- 链接:
  - [ArXiv](https://arxiv.org/abs/2306.05284)
  - [Publication](https://openreview.net/forum?id=jtiQ26sCJi) NeurIPS2023
  - [Github](https://github.com/facebookresearch/audiocraft)
  - [Demo]()
- 文件:
  - [ArXiv](../SpeechLM/_PDF/2306.05284v3__MusicGen__Simple_and_Controllable_Music_Generation.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<table><tr><td width="50%">

We tackle the task of conditional music generation.
We introduce ***MusicGen***, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens.
Unlike prior work, ***MusicGen*** is comprised of a single-stage transformer LM together with efficient token interleaving patterns, which eliminates the need for cascading several models, e.g., hierarchically or upsampling.
Following this approach, we demonstrate how ***MusicGen*** can generate high-quality samples, both mono and stereo, while being conditioned on textual description or melodic features, allowing better controls over the generated output.
We conduct extensive empirical evaluation, considering both automatic and human studies, showing the proposed approach is superior to the evaluated baselines on a standard text-to-music benchmark.
Through ablation studies, we shed light over the importance of each of the components comprising ***MusicGen***.
Music samples, code, and models are available at [this https URL](https://github.com/facebookresearch/audiocraft).

</td><td>

我们处理的是条件音乐生成任务.
我们介绍了 ***MusicGen***, 一种单一的语言模型, 该模型作用于多个压缩的离散音乐表示流, 即 Tokens.
与之前的工作不同, ***MusicGen*** 由一个单阶段的变换器语言模型组成, 并结合高效的标记交织模式, 从而消除了级联多个模型 (例如分层结构或上采样) 的需求.
采用这种方法, 我们展示了 ***MusicGen*** 如何生成高质量的样本, 包括单声道和立体声, 同时能够根据文本描述或旋律特征进行条件化生成, 从而更好地控制生成的输出.
我们进行了广泛的实证评估, 考虑了自动化和人工研究, 结果显示, 所提出的方法在标准的文本到音乐基准测试中优于评估的基线方法.
通过消融研究, 我们揭示了构成 ***MusicGen*** 的每个组件的重要性.
音乐样本、代码和模型可以在[这个链接](https://github.com/facebookresearch/audiocraft)查看.

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td></tr></table>
