Time,Model,Submodel,Institutions,ArXiv,Publication,OpenSource,Github,Framework,Training Objectives,Discriminator,Dataset,Area
2021.07.07,SoundStream,,,https://arxiv.org/abs/2107.03312v1,,,,,,,,
2022.07.18,TF-Codec,,,https://arxiv.org/abs/2207.08363v3,TASLP2023,,,,,,,
2022.10.24,EnCodec,24kHz Monophonic,US-MetaAI,https://arxiv.org/abs/2210.13438v1,TMLR2023,Inference,http://github.com/facebookresearch/encodec,RVQ-GAN,Reconstruction+Adversarial+RVQ Commit,MS-STFT,DNS Chanllenge4 + CommonVoice + AudioSet + FSD50K,Speech + Audio
2022.10.24,EnCodec,48kHz Fullband Stereo,US-MetaAI,https://arxiv.org/abs/2210.13438v1,TMLR2023,Inference,http://github.com/facebookresearch/encodec,RVQ-GAN,Reconstruction+Adversarial+RVQ Commit,MS-STFT,Jamendo,Music
2023.03.23,LMCodec,,,https://arxiv.org/abs/2303.12984v1,ICASSP2023,,,,,,,
2023.05.04,HiFi-Codec,,"CN-PKU, CN-TencentAI, CN-ZJU",https://arxiv.org/abs/2305.02765v1,No,Train + Inference,https://github.com/yangdongchao/AcademiCodec,,,,LibriTTS + VCTK + AISHELL,Speech
2023.05.26,AudioDec,,,https://arxiv.org/abs/2305.16608v1,ICASSP2023,,https://github.com/facebookresearch/AudioDec,,,,,
2023.06.11,DAC,,,https://arxiv.org/abs/2306.06546v2,NeurIPS2023Spotlight,,https://github.com/descriptinc/descript-audio-codec,,,,,
2023.08.31,SpeechTokenizer,16kHz HuBERT_AVG,CN-FUDAN,https://arxiv.org/abs/2308.16692v2,ICLR2024,Train + Inference,https://github.com/ZhangXInFD/SpeechTokenizer/,RVQ-GAN,Reconstruction+Adversarial+RVQ Commit+Semantic Distillation,MS-STFT + MPD + MSD,LibriSpeech,Speech
2023.08.31,SpeechTokenizer,16kHz SNAKE HuBERT_AVG,CN-FUDAN,https://arxiv.org/abs/2308.16692v2,ICLR2024,Train + Inference,https://github.com/ZhangXInFD/SpeechTokenizer/,RVQ-GAN,Reconstruction+Adversarial+RVQ Commit+Semantic Distillation,MS-STFT + MPD + MSD,LibriSpeech + CommonVoice,Speech
2023.08.31,RepCodec,,,https://arxiv.org/abs/2309.00169v3,ACL2024,,,,,,,
2023.09.14,FunCodec,,,https://arxiv.org/abs/2309.07405v2,ICASSP2024,Train + Inference,https://github.com/alibaba-damo-academy/FunCodec,,,,,
2023.09.15,TiCodec,,,https://arxiv.org/abs/2310.00014v2,ICASSP2024,,,,,,,
2024.01.22,ScoreDec,,,https://arxiv.org/abs/2401.12160v1,ICASSP2024,,,,,,,
2024.02.02,CBRC,,,https://arxiv.org/abs/2402.01271v1,InterSpeech2023,,,,,,,
2024.02.16,APCodec,,,https://arxiv.org/abs/2402.10533v2,TASLP2024,Train + Inference,https://github.com/yangai520/APCodec,,,,,
2024.03.05,FACodec,,,https://arxiv.org/abs/2403.03100v3,,,,,,,,
2024.03.18,SRCodec,,,NO,ICASSP2024,,,,,,,
2024.03.18,LightCodec,,,NO,ICASSP2024,,,,,,,
2024.04.03,PSCodec,,,https://arxiv.org/abs/2404.02702v3,,,,,,,,
2024.04.30,SemantiCodec,,,https://arxiv.org/abs/2405.00233v2,JSTSP,Inference,https://github.com/haoheliu/SemantiCodec-inference,,,,,
2024.05.08,HILCodec,,,https://arxiv.org/abs/2405.04752v2,JSTSP2024,,,,,,,
2024.06.11,Single-Codec,,,https://arxiv.org/abs/2406.07422v1,InterSpeech2024,,,,,,,
2024.07.30,SuperCodec,,,https://arxiv.org/abs/2407.20530v1,ICASSP2024,,,,,,,
2024.08.29,WavTokenizer,,,https://arxiv.org/abs/2408.16532v3,ICLR2025,Train + Inference,https://github.com/jishengpeng/WavTokenizer,,,,,
2024.08.30,X-Codec,,,https://arxiv.org/abs/2408.17175v3,,,https://github.com/zhenye234/xcodec,,,,,
2024.09.02,SoCodec,,,https://arxiv.org/abs/2409.00933v1,SLT2024,,,,,,,
2024.09.09,BigCodec,,,https://arxiv.org/abs/2409.05377v1,,Train + Inference,https://github.com/Aria-K-Alethia/BigCodec,,,,,
2024.09.18,LFSC,,,https://arxiv.org/abs/2409.12117v1,ICASSP2025,,,,,,,
2024.09.18,WMCodec,,,https://arxiv.org/abs/2409.12121v3,,Train + Inference,https://github.com/zjzser/WMCodec,,,,,
2024.09.19,NDVQ,,,https://arxiv.org/abs/2409.12717v1,,,,,,,,
2024.09.20,MuCodec,,,https://arxiv.org/abs/2409.13216v3,,,https://github.com/tencent-ailab/MuCodec,,,,,
2024.09.26,FlowMAC,,,https://arxiv.org/abs/2409.17635v2,ICASSP2025,,,,,,,
2024.10.18,SNAC,,,https://arxiv.org/abs/2410.14411v1,NeurIPS2024Workshop,Inference,https://github.com/hubertsiuzdak/snac,,,,,
2024.10.19,DM-Codec,,,https://arxiv.org/abs/2410.15017v2,EMNLP2025,,https://github.com/mubtasimahasan/DM-Codec,,,,,
2024.10.21,LSCodec,25Hz,CN-SJTU-XLANCE,https://arxiv.org/abs/2410.15764v3,InterSpeech2025,Inference,https://github.com/X-LANCE/LSCodec-Inference,,,,LibriTTS,Speech
2024.10.21,LSCodec,50Hz,CN-SJTU-XLANCE,https://arxiv.org/abs/2410.15764v3,InterSpeech2025,Inference,https://github.com/X-LANCE/LSCodec-Inference,,,,LibriTTS,Speech
2024.10.30,APCodec+,,,https://arxiv.org/abs/2410.22807v1,ISCSLP2025,,,,,,,
2024.11.01,MDCTCodec,,CN-USTC-NERC-SLIP,https://arxiv.org/abs/2411.00464v1,SLT2024,No,,,,,,
2024.11.27,TS3-Codec,No,US-Microsoft,https://arxiv.org/abs/2411.18803v2,,No,,,Reconstruction+LQ-GAN+Feature+VQ,MPD + MS-STFT,Libri-Light,Speech
2024.12.02,FreeCodec,,"[CN-WHU, CN-TencentYouTu]",https://arxiv.org/abs/2412.01053v3,InterSpeech2025,Not Yet,https://github.com/exercise-book-yq/FreeCodec,,Reconstruction+VQ Commit+Content+Feature Matching+Adversarial,MS-STFT,LibriSpeech,Speech
2024.12.16,SECodec,,CN-KUST,https://arxiv.org/abs/2501.00018v1,AAAI2025,Not Yet,https://github.com/wlq2019/SECodec,RVQ-GAN,Reconstruction+Adversarial+RVQ Commit,MSD+MPD+MSTFTD,LibriSpeech,Speech
2025.02.27,UniCodec,,,https://arxiv.org/abs/2502.20067v1,,,,,,,,
2025.03.03,FlowDec,,,https://arxiv.org/abs/2503.01485v1,ICLR2025,,https://github.com/facebookresearch/FlowDec,,,,,
