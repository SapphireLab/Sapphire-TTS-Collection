# RapFlow-TTS

<details>
<summary>基本信息</summary>

- 标题: "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching."
- 作者:
  - 01 Hyun Joon Park,
  - 02 Jeongmin Liu,
  - 03 Jin Sob Kim,
  - 04 Jeong Yeol Yang,
  - 05 Sung Won Han,
  - 06 Eunwoo Song
- 链接:
  - [ArXiv](https://arxiv.org/abs/2506.16741)
  - [Publication]()
  - [Github](https://github.com/naver-ai/RapFlow-TTS)
  - [Demo](https://tts-demo.github.io/rap.github.io/)
- 文件:
  - [ArXiv](_PDF/2025.06.20_2506.16741v1__RapFlow-TTS__Rapid_and_High-Fidelity_Text-to-Speech_with_Improved_Consistency_Flow_Matching.pdf)
  - [Publication] #TODO InterSpeech2025

</details>

## 摘要

<!--
We introduce ***RapFlow-TTS***, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in Flow Matching (FM) training.
Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed.
To address this challenge, ***RapFlow-TTS*** enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps.
Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis.
Experimental results show that ***RapFlow-TTS*** achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.
-->

本文提出了 ***RapFlow-TTS***，一个在**流匹配 (Flow Matching, FM)** 训练中利用速度一致性约束的快速且高保真的 TTS 声学模型.
尽管基于常微分方程的 TTS 生成可以实现自然质量的语音, 但往往需要大量的生成步骤, 从而需要在质量和推理速度之间进行权衡.

为了解决这一挑战, ***RapFlow-TTS*** 在流匹配直化的 ODE 轨迹上强制在速度场中保持一致性, 从而实现用更少的生成步骤获得一致的合成质量.
此外, 我们引入了如时间区间调度和对抗训练等技术以进一步增强少步合成的质量.
实验结果表明, ***RapFlow-TTS*** 能够实现高保真语音合成, 其生成步骤比传统的基于流匹配和得分的模型减少了 5-10 倍.

## 1·引言

## 2·背景

## 3·方法

## 4·实验

## 5·结果

## 6·结论

## 参考文献