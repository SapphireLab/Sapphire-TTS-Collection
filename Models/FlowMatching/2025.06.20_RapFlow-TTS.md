# RapFlow-TTS

<details>
<summary>基本信息</summary>

- 标题: "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching."
- 作者:
  - 01 Hyun Joon Park,
  - 02 Jeongmin Liu,
  - 03 Jin Sob Kim,
  - 04 Jeong Yeol Yang,
  - 05 Sung Won Han,
  - 06 Eunwoo Song
- 链接:
  - [ArXiv](https://arxiv.org/abs/2506.16741)
  - [Publication]()
  - [Github](https://github.com/naver-ai/RapFlow-TTS)
  - [Demo](https://tts-demo.github.io/rap.github.io/)
- 文件:
  - [ArXiv](_PDF/2025.06.20_2506.16741v1__RapFlow-TTS__Rapid_and_High-Fidelity_Text-to-Speech_with_Improved_Consistency_Flow_Matching.pdf)
  - [Publication] #TODO InterSpeech2025

</details>

## 摘要

<!--
We introduce ***RapFlow-TTS***, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in Flow Matching (FM) training.
Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed.
To address this challenge, ***RapFlow-TTS*** enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps.
Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis.
Experimental results show that ***RapFlow-TTS*** achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.
-->

本文提出了 ***RapFlow-TTS***，一个在**流匹配 (Flow Matching, FM)** 训练中利用速度一致性约束的快速且高保真的 TTS 声学模型.
尽管基于常微分方程的 TTS 生成可以实现自然质量的语音, 但往往需要大量的生成步骤, 从而需要在质量和推理速度之间进行权衡.

为了解决这一挑战, ***RapFlow-TTS*** 在流匹配直化的 ODE 轨迹上强制在速度场中保持一致性, 从而实现用更少的生成步骤获得一致的合成质量.
此外, 我们引入了如时间区间调度和对抗训练等技术以进一步增强少步合成的质量.
实验结果表明, ***RapFlow-TTS*** 能够实现高保真语音合成, 其生成步骤比传统的基于流匹配和得分的模型减少了 5-10 倍.

## 1·引言

Text-to-speech (TTS), also known as speech synthesis, aims to synthesize high-fidelity speech, given an input text \cite{wang2017tacotron, shen2018natural, kim2020glow}.
Among the various generative modeling approaches \cite{ren2019fastspeech, miao2020flow, li2019neural, ren2020fastspeech, jeong2021diff}, ordinary differential equations (ODE)-based models \cite{popov2021grad, park2024dex} have become strong solutions for outstanding TTS.
One representative method involves diffusion models using stochastic differential equations (SDE) \cite{song2020score, karras2022elucidating}, e.g., Grad-TTS \cite{popov2021grad}.
It trains a score network with an SDE-based diffusion process and solves the probability flow ODE for speech synthesis.
However, ODE trajectories obtained by diffusion models are complicated \cite{lipman2022flow, tong2023improving}, requiring numerous steps to generate high-quality speech \cite{guo2024voiceflow}.
Since TTS functions as a user interaction channel, the slow inference speed caused by numerous diffusion steps is a major drawback of diffusion-based TTS.

To resolve this limitation, researchers investigated improved ODE-based models \cite{lipman2022flow, tong2023improving, liu2022flow, song2023consistency} for TTS.
For example, Comospeech \cite{ye2023comospeech} applied consistency distillation \cite{song2023consistency} to transfer the knowledge of a diffusion teacher model to a consistent student model.
As the consistency constraint maps any point on the ODE trajectory to the endpoint, i.e., the target data, the student model can consistently produce high-quality speech regardless of the number of diffusion steps.
However, the complexity of diffusion-based ODE trajectories limited the effective construction of consistency models along those trajectories.

Meanwhile, flow matching (FM), which learns the vector field for the ODE and probability path, is another approach for improving ODE-based models.
Using an optimal transport plan that makes the probability path linear in time \cite{lipman2022flow, tong2023improving}, the ODE trajectory tends to be straight, making the few-step performance of FM superior to that of the diffusion models.
In TTS frameworks, Matcha-TTS \cite{mehta2024matcha} and VoiceFlow \cite{guo2024voiceflow} adopted the FM-based straight ODE trajectory, demonstrating high-quality speech synthesis with even fewer generation steps than conventional diffusion-based models.
However, completely generalizing the real distribution to a straight ODE trajectory is difficult; thus, the quality of the few-step synthesized speech has not yet reached that of the ground truth.
In summary, previous ODE-based TTS approaches failed to simultaneously satisfy both aspects, i.e., inference speed and speech synthesis quality.

In this study, we present ***RapFlow-TTS***, a rapid and high-fidelity TTS acoustic model that effectively addresses the limitations above.
Inspired by advancements in image generation, we adopt consistency FM \cite{yang2024consistency}, a novel FM method that explicitly enforces self-consistency in the velocity field.
By imposing consistency constraints on the velocity values, consistency FM directly defines straight flows from different time points to a common endpoint.
This allows ***RapFlow-TTS*** to learn how to produce consistent outputs along the straight trajectory more effectively, unlike diffusion-based methods with complicated trajectories, yielding a more effective consistency model.
Consequently, high-quality speech synthesis is achievable with only a few generation steps.
To the best of our knowledge, ***RapFlow-TTS*** is the first TTS framework based on consistency FM.

Furthermore, we propose several improved training techniques to enhance the performance, including shared dropout, Huber loss, time-interval scheduling, and adversarial learning, none of which have been explored in the context of consistency FM.
Experimental results show that the proposed ***RapFlow-TTS*** can synthesize more natural speech in just 2 steps, reducing generation steps by 5 to 10 times compared to previous ODE-based methods.
Our code and demos are available at [Github.IO](https://tts-demo.github.io/rap.github.io/).

## 2·背景

Here, we review the consistency FM \cite{yang2024consistency} method for training the ***RapFlow-TTS***.
Given a time index $t\in[0,1]$, sampled from a uniform distribution, FM learns a ground truth vector field $u_{t}$ to build the probability path $p_{t}(x_{t})$ from the random noise $x_{0} \sim p_{0}$ to target data $x_{1} \sim p_{1}$.
The vector field is defined as an ODE for a flow $\phi_{t}$, where $\phi_{t}$ is a function that transforms data over time, as follows:

$$
\frac{d}{dt}\phi_{t}(x)=u_{t}(\phi_{t}(x)); \quad \phi_{0}(x)=x,
\tag{01}
$$

The solution of Eq.01, i.e., flow, represents the sampling path.
For training FM models, a simple regression with the ground-truth vector field is applied as follows:

$$
\mathcal{L}_{FM}=||v_{\theta}(t, x_{t}) - u(t, x_{t})||^{2}_{2},
\tag{02}
$$

where $v_{\theta}(t, x_{t})$ denotes the learnable vector field network.

In contrast to the FM, consistency FM trains the vector field by ensuring that any point on the trajectory reaches the same endpoint with the same velocity.
Let the linearly interpolated noise sample at time $t$ be ${x}_{t}=tx_{1} + (1-t)x_{0}$.
Its objective function is composed of a straight flow loss $\mathcal{L}_{sf}$ and a velocity consistency loss $\mathcal{L}_{vc}$ as follows:

$$
\begin{aligned}
\mathcal{L}_{cfm}&=\mathcal{L}_{sf}+\alpha\mathcal{L}_{vc},\\
\mathcal{L}_{sf}&=||f_{\theta}(t, x_{t}) - f_{\theta^{-}}(t+\Delta t, x_{t+\Delta t})||^{2}_{2},\\
\mathcal{L}_{vc}&=||v_{\theta}(t, x_{t}) - v_{\theta^{-}}(t+\Delta t, x_{t+\Delta t})||^{2}_{2},\\
f_{\theta}(t,x_{t})&=x_{t}+(1-t) \times v_{\theta}(t,x_{t}),
\end{aligned}
\tag{03}
$$

where $\theta^{-}$ denotes model parameters with a stop gradient; $\alpha$ denotes a loss weight; and $\Delta t$ denotes a time interval.
Since $f_{\theta}$ guides $x_{t}$ to the estimated endpoint of the trajectory, the straight flow loss constrains consistency from the trajectory viewpoint, ensuring straight flow.
In contrast, the velocity consistency loss directly enforces the consistency of the vector field.
This allows the consistency FM to learn how to produce consistent outputs along the straightened trajectory, accurately estimating the target distribution even with a few-step generation.

## 3·方法

### 3.1·结合一致性流匹配的 TTS

For ***RapFlow-TTS***, we follow the network design of Matcha-TTS \cite{mehta2024matcha} thanks to its fast and lightweight properties.
As shown in Figure \ref{fig:rapflow}, ***RapFlow-TTS*** consists of a text encoder, an aligner, and a flow matching decoder.
The text encoder extracts the context representations from the input text, and the aligner maps these representations to prior mel-spectrograms $\mu$.
The text encoder and aligner are trained using duration loss $\mathcal{L}_{dur}$ and prior loss $\mathcal{L}_{prior}$ based on the MAS algorithm as in \cite{kim2020glow, popov2021grad}.

Consistency FM trains the FM decoder to construct a probability path $p_{t}$ that transports the random noise $x_{0} \sim p_{0}$ to target mel-spectrogram's distribution $x_{1} \sim p_{1}$.
We condition the consistency FM objective with the prior $\mu$ to synthesize speech corresponding to the given input text.
We also adopt a multi-segment objective for flexible transportation between complex distributions \cite{yang2024consistency}.
In detail, the time range $t \in [0,1]$ is divided into $S$ segments of equal size, where each segment corresponds to the time range $[i/S, (i+1)/S]$ for $i=0,1,..., S-1$.
Then, the objective function of segmented consistency FM is expressed as follows:

$$
\begin{aligned}
\mathcal{L}_{cfm}&=\mathcal{L}_{sf}+\alpha\mathcal{L}_{vc},\\
\mathcal{L}_{sf}&=||f^{i}_{\theta}(t, x_{t}, \mu) - f^{i}_{\theta^{-}}(t+\Delta t, x_{t+\Delta t}, \mu)||^{2}_{2}, \\
\mathcal{L}_{vc}&=||v^{i}_{\theta}(t, x_{t}, \mu) - v^{i}_{\theta^{-}}(t+\Delta t, x_{t+\Delta t}, \mu)||^{2}_{2}, \\
f^{i}_{\theta}(t,x_{t}, \mu)&=x_{t}+((i+1)/S-t) \times v^{i}_{\theta}(t,x_{t}, \mu),
\end{aligned}
\tag{04}
$$

Consequently, ***RapFlow-TTS*** learns straight flow with a consistent vector field in each segment, effectively representing the data distribution by a piecewise linear trajectory.

In practice, we apply a two-stage training strategy to effectively optimize the ***RapFlow-TTS*** model.
In the first stage (the first $N$ epochs), we aim to train ***RapFlow-TTS*** to have a straight flow by focusing on the trajectory viewpoint.
To achieve it, we optimize ***RapFlow-TTS*** using only the straight flow loss $\mathcal{L}_{sf}$ in Eq.04, slightly modifying the loss term as $||f^{i}_{\theta}(t, x_{t}, \mu)-x^{i}||^{2}_{2}$, where $x^{i}$ is the ground-truth endpoint at each segment, defined as $x^{i}=(i+1)/S \times x_{1} + (1-(i+1)/S)\times x_{0}$.
Because this loss guides the ground-truth endpoint on the trajectory, ***RapFlow-TTS*** can learn the vector field with a straight flow that represents the real data distribution.

In the second stage (the following $N$ epochs), we train ***RapFlow-TTS*** to have a straight flow with a consistent vector field using the entire $\mathcal{L}_{cfm}$ in Eq.04.
By training consistency FM on a straight ODE trajectory, ***RapFlow-TTS*** can learn consistency more easily than diffusion-based methods, constructing a more effective consistency model.
As a result, ***RapFlow-TTS*** has the properties of consistency and straight flow, thus synthesizing high-quality speech in fewer synthesis steps.

### 3.2·改进技术

We introduce several techniques to improve the consistency FM model for ***RapFlow-TTS***.
All of these methods enhance few-step synthesis performance, and their effectiveness will be further analyzed in Section \ref{ssec:ablation}.

### Encoder Freeze

We freeze the encoder and optimize only $\mathcal{L}_{cfm}$ for training efficiency in the second stage.
It also stabilizes consistency training by keeping the condition $\mu$ frozen.

### Shared Dropout

Although diffusion-based consistency models and rectified flow \cite{song2023improved, kim2025simple} proved that applying dropout improves the sample quality, the effect of dropout in consistency FM has not been investigated.
Based on \cite{song2023improved}, while training the consistency FM model in the second stage, we apply dropout using the same random state for $v_{\theta}$ and $v_{\theta^{-}}$.
Empirically, we use a dropout ratio of 0.05.

### Pseudo-Huber Loss

Our loss in Eq.
(\ref{eq:ms-cfm}) is composed of the $\ell_{2}$ metric.
However, the $\ell_{2}$ metric imposes a large penalty on outliers, which can lead to an imbalanced loss with respect to time $t$, potentially increasing the gradient variance \cite{lee2024improving}.
To mitigate this issue, we adopt the pseudo-Huber metric, which is less sensitive to outliers.
We follow the implemented metric from \cite{song2023improved}, defined as $d(x,y)=\sqrt{||x-y||^{2}_{2}+c^{2}}-c$, where $c=0.00054\sqrt{d}$ and $d$ is the data dimension size.

### Delta Scheduling

The term $\Delta t$ in Eq.04 is a parameter representing the time interval between two points on the trajectory, similar to the discretization size parameter in diffusion-based consistency models \cite{song2023consistency}.
This implies that a small $\Delta t$ reduces the bias but increases the variance of the model, and vice versa for a large $\Delta t$.
Since a small bias and large variance are desirable near the end of the training, inspired by \cite{song2023consistency}, we employ scheduling that progressively reduces $\Delta t$ during the training.
To train the model uniformly across diverse $\Delta t$, we utilize linear step scheduling.
In practice, $\Delta t$ decreases from 0.1 to 0.001 over $K$ intervals, and each $\Delta t$ is used during $N/K$ epochs.

### Adversarial Learning

To enhance synthesis quality, we utilize adversarial learning after the second stage.
We adopt MSE-based adversarial loss $\mathcal{L}_{adv}$ \cite{mao2017least} and feature matching loss $\mathcal{L}_{fm}$ \cite{salimans2016improved} on the mel-spectrogram levels using a Conv2d discriminator \cite{li2022styletts}.
Furthermore, we extend it to multi-segment adversarial learning for consistency FM.
Let $x^{i}$ and $\hat{x}^{i}$ be the ground-truth and estimated endpoint at each segment, where each is obtained by $(i+1)/S \times x_{1} + (1-(i+1)/S)\times x_{0}$ and $f^{i}_{\theta}(t,x_{t}, \mu)$, respectively.
Then, the objective function is defined as follows:

$$
\begin{aligned}
\mathcal{L}_{adv}=||D(\hat{x}^{i})||^{2}_{2} + ||1-D(x^{i})||^{2}_{2}, \\
\mathcal{L}_{fm} = \sum\nolimits_{l=1}^{L} ||D^{l}(\hat{x}^{i})-D^{l}(x^{i})||_{1}, \\
\end{aligned}
\tag{05}
$$

where $D$ indicates the discriminator; $D^{l}$ denotes the $l^{th}$ feature map of $D$.
By applying multi-segment adversarial learning, we improve the endpoint quality of each segment, yielding better few-step performance.
Finally, in this stage, we optimize $\mathcal{L}_{cfm}$, $\mathcal{L}_{adv}$, and $\mathcal{L}_{fm}$ with the ratio of 3, 1, and 2.

## 4·实验

## 5·结果

## 6·结论

## 参考文献