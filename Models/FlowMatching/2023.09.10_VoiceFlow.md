# VoiceFlow

<details>
<summary>基本信息</summary>

- 标题: "VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching"
- 作者:
  - 01 Yiwei Guo (X-LANCE Lab, Shanghai Jiao Tong University, China)
  - 02 Chenpeng Du (X-LANCE Lab, Shanghai Jiao Tong University, China)
  - 03 Ziyang Ma (X-LANCE Lab, Shanghai Jiao Tong University, China)
  - 04 Xie Chen (X-LANCE Lab, Shanghai Jiao Tong University, China)
  - 05 Kai Yu (X-LANCE Lab, Shanghai Jiao Tong University, China)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2309.05027)
  - [Publication](https://doi.org/10.1109/ICASSP48485.2024.10445948)
  - [Github](https://github.com/X-LANCE/VoiceFlow-TTS)
  - [Demo](https://cantabile-kwok.github.io/VoiceFlow/)
- 文件:
  - [ArXiv v2](_PDF/2024.01.16_2309.05027v2__VoiceFlow__Efficient_Text-to-Speech_with_Rectified_Flow_Matching.pdf)
  - [ArXiv v3](_PDF/2024.09.01_2309.05027v3__VoiceFlow__Efficient_Text-to-Speech_with_Rectified_Flow_Matching.pdf)
  - [Publication] #TODO

</details>

## 摘要

Although diffusion models in text-to-speech have become a popular choice due to their strong generative ability, the intrinsic complexity of sampling from diffusion models harms their efficiency.
Alternatively, we propose ***VoiceFlow***, an acoustic model that utilizes a rectified flow matching algorithm to achieve high synthesis quality with a limited number of sampling steps.
***VoiceFlow*** formulates the process of generating mel-spectrograms into an ordinary differential equation conditional on text inputs, whose vector field is then estimated.
The rectified flow technique then effectively straightens its sampling trajectory for efficient synthesis.
Subjective and objective evaluations on both single and multi-speaker corpora showed the superior synthesis quality of ***VoiceFlow*** compared to the diffusion counterpart.
Ablation studies further verified the validity of the rectified flow technique in ***VoiceFlow***.

## 1·引言

Modern text-to-speech (TTS) has witnessed tremendous progress by adopting different types of advanced generative algorithms, such as TTS models with GANs~\cite{binkowski2019high,kim2021conditional}, normalizing flows~\cite{kim2020glow,valle2021flowtron,kim2021conditional}, self-supervised features~\cite{du2022vqtts,du2023speaker} or denoising diffusion models~\cite{popov2021grad,liu2022diffsinger,liu2023diffvoice,du2023unicats}.
Among them, diffusion-based TTS models recently received growing attention because of their high synthesis quality, such as GradTTS~\cite{popov2021grad} and DiffVoice~\cite{liu2023diffvoice}.
They also show versatile functionalities such as conditional generation~\cite{kim2022guided,guo2023emodiff}, speech editing~\cite{tae2021editts,liu2023diffvoice, du2023unicats} and speaker adaptation~\cite{liu2023diffvoice, du2023unicats}.
By estimating the score function $\nabla \log p_t(\bm x)$ of a stochastic differential equation (SDE), diffusion models are stable to train~\cite{dhariwal2021diffusion}.
They generate realistic samples by numerically solving the reverse-time SDE or the associated probability-flow ordinary differential equation (ODE).

However, a major drawback of diffusion models lies in their efficiency.
Regardless of SDE or ODE sampling methods, diffusion models typically require numerous steps to generate a satisfying sample, causing a large latency in inference.
Some efforts have been made to mitigate this issue and improve the speed-quality tradeoff in diffusion-based TTS models, usually by extra mathematical tools or knowledge distillation.
Fast GradTTS\cite{vovk2022fast} adopts maximum likelihood SDE solver~\cite{popov2022diffusionbased}, progressive distillation~\cite{salimans2022progressive} and denoising diffusion GAN~\cite{xiao2022tackling} to accelerate diffusion sampling.
FastDiff~\cite{huang2022fastdiff} optimizes diffusion noise schedules inspired by BDDM~\cite{lam2022bddm}.
ProDiff~\cite{huang2022prodiff} also uses a progressive distillation technique to halve the sampling steps from DDIM~\cite{song2021denoising} teacher iteratively.
LightGrad~\cite{chen2023lightgrad} adopts DPM-Solver~\cite{lu2022dpm} to explicitly derive a solution of probability-flow ODE.
A concurrent work, CoMoSpeech~\cite{ye2023comospeech}, integrates the consistency model~\cite{song2023consistency} as a special type of diffusion distillation.
These models successfully decrease the necessary number of sampling steps in diffusion models to some extent.
However, due to the intricate nature of the diffusion process, the speed-quality tradeoff still exists and is hard to overcome.

Despite denoising diffusion, another branch in the family of differential-equation-based generative models began to arise recently, namely the flow matching generative models~\cite{lipman2022flow,liu2022flow,tong2023improving}.
% Different from diffusion models which models the score function of a specific SDE, flow matching aims to model the vector field implied by an arbitrary ODE directly.
While diffusion models learn the score function of a specific SDE, flow matching aims to model the vector field implied by an arbitrary ODE directly.
A neural network is used for approximating the vector field, and the ODE can also be numerically solved to obtain data samples.
The design of such ODE and vector field often considers linearizing the sampling trajectory and minimizing the transport cost~\cite{tong2023improving}.
As a result, flow matching models have simpler formulations and fewer constraints but better quality.
VoiceBox~\cite{le2023voicebox} shows the potential of flow matching in fitting large-scale speech data, and LinDiff~\cite{liu2023boosting} shares a similar concept in the study of vocoders.
More importantly, the rectified flow~\cite{liu2022flow} technique in flow matching models further straightens the ODE trajectory in a concise way.
By training a flow matching model again but with its own generated samples, the sampling trajectory of rectified flow theoretically approaches a straightforward line, which improves the efficiency of sampling.
In essence, rectified flow matching achieves good sample quality even with a very limited number of sampling steps.
As a side note, its ODE nature also makes flow matching extensible for knowledge distillation similar in previous diffusion-based works~\cite{liu2022flow}.

Inspired by these, we propose to utilize rectified flow matching in the TTS acoustic model for the first time in literature.
We construct an ODE to flow between noise distribution and mel-spectrogram while conditioning it with phones and duration.
An estimator learns to model the underlying vector field.
Then, a flow rectification process is applied, where we generate samples from the trained flow matching model to train itself again.
In this way, our model is able to generate decent mel-spectrograms with much fewer steps.
We name our model ***VoiceFlow***.
To fully investigate its ability, we experiment both on the single-speaker benchmark LJSpeech and the larger multi-speaker dataset LibriTTS.
The results show that ***VoiceFlow*** outperforms the diffusion baseline in a sufficient number of sampling steps.
In a highly limited budget such as two steps, ***VoiceFlow*** still maintains a similar performance while the diffusion model cannot generate reasonable speech.
Therefore, ***VoiceFlow*** achieves better efficiency and speed-quality tradeoff while sampling.
The code and audio samples are available online at [Github.IO](https://cantabile-kwok.github.io/VoiceFlow).

## 2·背景

## 3·方法

## 4·实验

## 5·结果

## 6·结论

## 参考文献
