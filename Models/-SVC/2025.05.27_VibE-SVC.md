# VibE-SVC: Vibrato Extraction With High-Frequency F0 Contour for Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "VibE-SVC: Vibrato Extraction With High-Frequency F0 Contour for Singing Voice Conversion."
- 作者:
  - 01 Joon-Seung Choi
  - 02 Dong-Min Byun
  - 03 Hyung-Seok Oh
  - 04 Seong-Whan Lee
- 链接:
  - [ArXiv](https://arxiv.org/abs/2505.20794v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2505.20794v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.05.27_2505.20794v1_VibE-SVC__Vibrato_Extraction_With_High-Frequency_F0_Contour_for_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Controlling singing style is crucial for achieving an expressive and natural singing voice.
Among the various style factors, vibrato plays a key role in conveying emotions and enhancing musical depth.
However, modeling vibrato remains challenging due to its dynamic nature, making it difficult to control in singing voice conversion.
To address this, we propose VibE-SVC, a controllable singing voice conversion model that explicitly extracts and manipulates vibrato using discrete wavelet transform.
Unlike previous methods that model vibrato implicitly, our approach decomposes the F0 contour into frequency components, enabling precise transfer.
This allows vibrato control for enhanced flexibility.
Experimental results show that VibE-SVC effectively transforms singing styles while preserving speaker similarity.
Both subjective and objective evaluations confirm high-quality conversion. 

## 1·Introduction

Singing voice conversion (SVC) is a technique that converts a source singer voice into a target singer voice while retaining the source lyrics, melody, and styles.

Recently, many singing voice models have been developed using various generative models [^Nachmani2019Unsupervised], [^Zhang2022VISinger], [^Liu2022Diffsinger], [^Liu2021Diffsvc], [^Byun2024Midi-Voice].

Although SVC has improved significantly, several challenges remain.

One of the most important challenges is effectively handling pitch.

Since the singing voice is more expressive than speech, accurate pitch modeling is essential.

For this reason, several studies [^Ning2023Vits-Based], [^Bai2024Spa-SVC] have been proposed to improve pitch-related performance.

SVCC-T23 [^Ning2023Vits-Based] extracts multi-scale F0 as an auxiliary input to better capture pitch variation in singing.

SPA-SVC [^Bai2024Spa-SVC] introduces a cycle pitch shifting strategy to mitigate voiceless regions and hoarse artifacts caused by narrow pitch range of input dataset. 

Some works [^Liu2021Vibrato], [^Zhang2024TCS}inger], [^Zhao2024SinTechSVS] have focused on handling style characteristics of singing, including pitch styles.

Vibrato control is achieved in [^Liu2021Vibrato] by extracting vibrato extent from the power spectrogram of the first-order difference.

To synthesize and control singing styles, SinTechSVS [^Zhao2024SinTechSVS] proposes style recommender and singing technique local score module.

TCSinger [^Zhang2024TCS}inger] introduces clustering style encoder to capture singing styles. 
Unlike these methods which focus on synthesizing singing styles, other approaches [^Hsu2025Many-to-Many], [^Luo2020Singing], [^Chen2023Few], [^Wang2022Towards] focus on transferring singing styles. 
Since style features are not explicitly defined, these methods disentangle style information implicitly.

Extracting information via signal decomposition is a key focus in various deep learning studies [^Lim2000Text], [^Kim2015Abstract].

Discrete wavelet transform is a method for decomposing an arbitrary signal into functions defined by discretely sampled wavelets.

Wavelet transform has been utilized in various methods [^Lee1996Multiresolution], [^Ren2021FastSpeech], [^Noyum2021Boosting], [^Lee2022Fre-Gan] such as pitch representation [^Ren2021FastSpeech], singer identification [^Noyum2021Boosting], or a downsampling method [^Lee2022Fre-Gan]. 
We assume that while the overall F0 contour remains consistent across singing styles, style-related variations are reflected in the high-frequency contour.

To capture these differences, we use DWT to decompose the F0 contour into low- and high-frequency bands.

Most existing methods aim to smooth the F0 contour to eliminate minor fluctuations or singing styles using filters such as median filter [^Kim2024Period] or band-pass filter [^Song2022Singing]. 
In contrast, our method employs DWT as a pass filter to disentangle and control singing styles.

In this work, we propose VibE-SVC, which disentangles vibrato style from singing voices and enables style transfer using DWT.

By predicting the high-frequency F0 contour, VibE-SVC achieves transfer between straight and vibrato styles.

Our approach demonstrates that DWT effectively separates singing styles and allows vibrato extent control without explicitly modeling the vibrato extent feature.

Experimental results show that VibE-SVC successfully transfers singing styles.

Audio samples are available at \url{https://castlechoi.github.io/VibE-SVC-demo}.

![](Figure/architecture_svc.pdf)

<a id="fig:svc_architecture">VibE-SVC</a>
