# CoMoSVC: Consistency Model-Based Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "CoMoSVC: Consistency Model-Based Singing Voice Conversion."
- 作者:
  - 01 Yiwen Lu
  - 02 Zhen Ye
  - 03 Wei Xue
  - 04 Xu Tan
  - 05 Qifeng Liu
  - 06 Yike Guo
- 链接:
  - [ArXiv](https://arxiv.org/abs/2401.01792v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2401.01792v1](_PDF/2024.01.03_2401.01792v1_CoMoSVC__Consistency_Model-Based_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre.
However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial.
In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling.
A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling.
Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics.
Audio samples and codes are available at \href{https://comosvc.github.io/}{https://comosvc.github.io/}.

## 1·Introduction

\label{sec:intro}

Singing Voice Conversion(SVC) aims to convert one singer's voice to another one's, while preserving the content and melody.

It has wide applications in music entertainment, singing voice beautification, and art creation  [^Zhang2023Leveraging]. 

Statistical methods  [^Kobayashi2014Statistical], [^Kobayashi2015Statistical], [^Kobayashi2015Statistical] are applied to the SVC tasks with parallel training data from both the source and target singers, which is usually infeasible, and thus the non-parallel SVC methods have become the mainstream.

Two-stage methods are generally used for SVC, the first stage disentangles and encodes singer-independent and singer-dependent features from the audio.

Then the second decoding stage generates the converted audio by replacing the singer-dependent feature with the target one.

Since the substantial impact of the second stage on the quality of the converted audios, it has become crucial to design and optimize this stage.

Therefore, many generative models have been used for the SVC decoding, including the autoregressive (AR) models, generative adversarial network (GAN), Normalizing Flow, and diffusion models.

AR models are firstly used to develop USVC  [^Nachmani2019Unsupervised], and PitchNet  [^Deng2020Pitchnet] further improves USVC by adding a pitch adversarial network to learn the joint phonetic and pitch representation.

However, AR models are slow due to the recursive nature, then non-AR GAN-based UCD-SVC  [^Polyak2020Unsupervised] and FastSVC  [^Liu2021Fast{SVC] are later proposed.

Since the unstable training of GAN, a flow-based end-to-end SVC system, named SoVITS-SVC  [^SVC-Develop-Team2023SoftVC] received widespread attention for its excellent converted results in fast speed.

Recently, it has been shown that the conversion performance can be substantially improved by the diffusion-based SVC methods such as DiffSVC  [^Liu2021Diffsvc] and the diffusion version of SoVITS-SVC.

However, the iterative sampling process results to the slow inference of the diffusion-based SVC methods.

A new generative model named consistency model  [^Song2023Consistency] has been proposed to realize one-step generation.

Subsequently for speech synthesis, CoMoSpeech  [^Ye2023CoMoSpeech] exploits the consistency model to achieve both high-quality synthesis and fast inference speed.

Inspired by this, a consistency model-based SVC method, named CoMoSVC, is further developed in this paper to achieve {\em high-quality, high-similarity and high-speed}

SVC.

Based on the structure of EDM  [^Karras2022Elucidating], a diffusion-based teacher model with outstanding generative capability is firstly designed, and a student model is further distilled from it to achieve one-step sampling.

Experiments reveal that while the sampling speed of CoMoSVC is approximately 500 and 50 times faster than that of the diffusion-based SoVITS-SVC and DiffSVC respectively, the comparable performance is still retained and some improvements can even be achieved in both quality and similarity.
