# CoMoSVC: Consistency Model-Based Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "CoMoSVC: Consistency Model-Based Singing Voice Conversion."
- 作者:
  - 01 Yiwen Lu
  - 02 Zhen Ye
  - 03 Wei Xue
  - 04 Xu Tan
  - 05 Qifeng Liu
  - 06 Yike Guo
- 链接:
  - [ArXiv](https://arxiv.org/abs/2401.01792v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2401.01792v1](_PDF/2024.01.03_2401.01792v1_CoMoSVC__Consistency_Model-Based_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

The diffusion-based Singing Voice Conversion (SVC) methods have achieved remarkable performances, producing natural audios with high similarity to the target timbre.
However, the iterative sampling process results in slow inference speed, and acceleration thus becomes crucial.
In this paper, we propose CoMoSVC, a consistency model-based SVC method, which aims to achieve both high-quality generation and high-speed sampling.
A diffusion-based teacher model is first specially designed for SVC, and a student model is further distilled under self-consistency properties to achieve one-step sampling.
Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has a significantly faster inference speed than the state-of-the-art (SOTA) diffusion-based SVC system, it still achieves comparable or superior conversion performance based on both subjective and objective metrics.
Audio samples and codes are available at \href{https://comosvc.github.io/}{https://comosvc.github.io/}.

## 1·Introduction

\label{sec:intro}

Singing Voice Conversion(SVC) aims to convert one singer's voice to another one's, while preserving the content and melody.

It has wide applications in music entertainment, singing voice beautification, and art creation  [^Zhang2023Leveraging]. 

Statistical methods  [^Kobayashi2014Statistical], [^Kobayashi2015Statistical], [^Kobayashi2015Statistical] are applied to the SVC tasks with parallel training data from both the source and target singers, which is usually infeasible, and thus the non-parallel SVC methods have become the mainstream.

Two-stage methods are generally used for SVC, the first stage disentangles and encodes singer-independent and singer-dependent features from the audio.

Then the second decoding stage generates the converted audio by replacing the singer-dependent feature with the target one.

Since the substantial impact of the second stage on the quality of the converted audios, it has become crucial to design and optimize this stage.

Therefore, many generative models have been used for the SVC decoding, including the autoregressive (AR) models, generative adversarial network (GAN), Normalizing Flow, and diffusion models.

AR models are firstly used to develop USVC  [^Nachmani2019Unsupervised], and PitchNet  [^Deng2020Pitchnet] further improves USVC by adding a pitch adversarial network to learn the joint phonetic and pitch representation.

However, AR models are slow due to the recursive nature, then non-AR GAN-based UCD-SVC  [^Polyak2020Unsupervised] and FastSVC  [^Liu2021Fast{SVC] are later proposed.

Since the unstable training of GAN, a flow-based end-to-end SVC system, named SoVITS-SVC  [^SVC-Develop-Team2023SoftVC] received widespread attention for its excellent converted results in fast speed.

Recently, it has been shown that the conversion performance can be substantially improved by the diffusion-based SVC methods such as DiffSVC  [^Liu2021Diffsvc] and the diffusion version of SoVITS-SVC.

However, the iterative sampling process results to the slow inference of the diffusion-based SVC methods.

A new generative model named consistency model  [^Song2023Consistency] has been proposed to realize one-step generation.

Subsequently for speech synthesis, CoMoSpeech  [^Ye2023CoMoSpeech] exploits the consistency model to achieve both high-quality synthesis and fast inference speed.

Inspired by this, a consistency model-based SVC method, named CoMoSVC, is further developed in this paper to achieve {\em high-quality, high-similarity and high-speed}

SVC.

Based on the structure of EDM  [^Karras2022Elucidating], a diffusion-based teacher model with outstanding generative capability is firstly designed, and a student model is further distilled from it to achieve one-step sampling.

Experiments reveal that while the sampling speed of CoMoSVC is approximately 500 and 50 times faster than that of the diffusion-based SoVITS-SVC and DiffSVC respectively, the comparable performance is still retained and some improvements can even be achieved in both quality and similarity.

## 2·Background

The diffusion model generates samples by first adding noise to data during the forward process and then reconstructing the data structure in the reverse process.

We assume that the original data distribution is $p_{data}(\mathbf{x})$, and the forward process can be represented by a stochastic differential equation (SDE)  [^Song2021Score-Based], [^Karras2022Elucidating]:

$$
\mathrm{d}\mathbf{x}_t=\mathbf{f}(\mathbf{x}_t ,t)\mathrm{d}t+g(t)\mathrm{d}\mathbf{w}_t ,
$$

where $\mathbf{w}_t$ is the standard wiener process, $\mathbf{f}(\mathbf{x}_t ,t)$ and $g(t)$ are drift and diffusion coefficients respectively.

With setting $\mathbf{f}(\mathbf{x}_t,t)=0$ and $g(t)=\sqrt{2t}$, the same as the choice in  [^Karras2022Elucidating], the SDE can be defined by:

$$
\mathrm{d}\mathbf{x}_{t}=\sqrt{2t}\,\mathrm{d}\mathbf{w} _{t}. 
$$

The reverse process can also be expressed by a reverse-time SDE  [^Song2021Score-Based]:

$$
\mathrm{d}\mathbf{x}_{t}=-2t\nabla\mathrm{log}\,p_t(\mathbf{x}_t)dt+\sqrt{2t}\,\mathrm{d}\bar{\mathbf{w}}_{t} ,
$$

where $p_t(\mathbf{x}_t)$ is the distribution of $\mathbf{x}_t$, $\nabla\mathrm{log}\,p_t(\mathbf{x}_t)$ is the score function, and $\bar{\mathbf{w}}_{t}$ is the reverse-time standard wiener process.  [^Song2021Score-Based] found that there exists a probability flow (PF) ordinary differential equation (ODE), whose solution trajectories' distribution at time $t$ is the same as $p_t(\mathbf{x}_t)$.

The PF ODE with such property can be represented by

$$
\frac{\mathrm{d} \mathbf{x}_t}{\mathrm{d} t}=-t \nabla \log p_t\left(\mathbf{x}_t\right)=\frac{\mathbf{x}_t-D_\phi\left(\mathbf{x}_t, t\right)}{t},
\label{4}
$$

where $D_\phi$ is the neural network with $\phi$ as parameters to approximate the denoiser function.

Then for sampling, the PF ODE is solved by initiating from $\mathbf{x}_T$, as

$$    \mathbf{x}_0=\mathbf{x}_T+\int_T^0 \frac{\mathbf{x}_t-D_\phi\left(\mathbf{x}_t, t\right)}{t} \mathrm{~d} t.
\label{5}
$$

However, the diffusion model generally needs a large number of iterations to solve the PF ODE, making the sampling slow.

A consistency model [^Song2023Consistency] is proposed for one-step sampling based on the self-consistency property, making any point from the same PF ODE trajectory be mapped to the same initial point.

The self-consistency properties have two constraints: firstly, any pair of points $\mathbf{x}_{t_m}$ and $\mathbf{x}_{t_n}$ will be mapped to the same point, which can be represented by:

$$    D_\phi(\mathbf{x}_{t_m},t_m)=D_\phi(\mathbf{x}_{t_n},t_n).
$$

Secondly, the initial point should also be mapped to itself and this constraint is called the boundary condition.

To avoid numerical instability, it can be given by

$$
D_\phi(\mathbf{x}_\epsilon,t_\epsilon)=\mathbf{x}_\epsilon,
\label{7}
$$

where $\epsilon$ is a fixed small positive number and set as 0.002.
, all the singers have their identification number, which will be encoded as a singer embedding. 
