# SPA-SVC: Self-Supervised Pitch Augmentation for Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "SPA-SVC: Self-Supervised Pitch Augmentation for Singing Voice Conversion."
- 作者:
  - 01 Bingsong Bai
  - 02 Fengping Wang
  - 03 Yingming Gao
  - 04 Ya Li
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.05692v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2406.05692v1](_PDF/2024.06.09_2406.05692v1_SPA-SVC__Self-Supervised_Pitch_Augmentation_for_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Diffusion-based singing voice conversion (SVC) models have shown better synthesis quality compared to traditional methods.
However, in cross-domain SVC scenarios, where there is a significant disparity in pitch between the source and target voice domains, the models tend to generate audios with hoarseness, posing challenges in achieving high-quality vocal outputs.
Therefore, in this paper, we propose a **S**elf-supervised **P**itch **A**ugmentation method for **S**inging **V**oice **C**onversion (SPA-SVC), which can enhance the voice quality in SVC tasks without requiring additional data or increasing model parameters.
We innovatively introduce a cycle pitch shifting training strategy and Structural Similarity Index (SSIM) loss into our SVC model, effectively enhancing its performance.
Experimental results on the public singing datasets
M4Singer indicate that our proposed method significantly improves model performance in both general SVC scenarios and particularly in cross-domain SVC scenarios. \footnote{Audio samples of our work can be found on the homepage below: \href{https://shawnpi233.github.io/publication/paper/spasvc}{https://shawnpi233.github.io/publication/paper/spasvc}}

## 1·Introduction

Singing Voice Conversion (SVC) is a process where a piece of singing voice is transformed from one person's voice to another, while preserving the content.

The essence of SVC lies in disentangling the timbre and content features within the singing voice and reconstructing the voice based on these disentangled features.

In recent years, there has been rapid progress in self-supervised learning methods for speech encoding representations.

Notable advancements include models like wav2vec 2.0 [^Baevski2020Wav2vec], HuBERT [^Hsu2021Hubert], Contentvec [^Qian2022Contentvec], and WavLM [^Chen2022Wavlm].

These efficient self-supervised speech encoding models provide robust support for disentangling timbre and content features within SVC models.

Successful methods in this domain include state-of-the-art (SOTA) models like DDSP-SVC-Diff [^Yxlllc2023Real-Time], So-VITS-SVC [^SVC-Develop-Team2023SoftVC], DiffSVC [^Liu2021Diffsvc] and CoMoSVC [^Lu2024CoMoSVC], among others.

These models utilize the robust performance of self-supervised speech encoding models and the superior reconstruction capabilities of diffusion [^Ho2020Denoising] and VITS [^Kim2021Conditional] models, resulting in commendable performance in general SVC scenarios.

However, challenges persist in cross-domain SVC scenarios, where the pitch of the song melody exceeds the vocal range of the target domain singer.

This often leads to voice distortions or complete loss of vocal quality, especially in cases where the pitch span is large.

These limitations hinder the applicability of SVC techniques in scenarios requiring transformations across extensive vocal ranges.

To the best of our knowledge, existing voice enhancement methods primarily focus on tasks such as accompaniment noise removal [^Xu2023Mbtfnet], recording noise reduction [^Liu2022Voicefixer] and general voice enhancement within the typical vocal range [^Guo2022Singaug].

In current cross-domain SVC studies, FastSVC [^Liu2021Fastsvc] aims for superior conversion performance and faster inference compared to standard systems, while HiFi-SVC [^Zhou2022Hifi-SVC] prioritizes generating 22.05 kHz voices using advanced neural vocoders and convolutional modules for F0 modeling.

Nonetheless, these models are limited to generating voices at 16 kHz or 22.05 kHz, potentially compromising audio quality in general SVC scenarios compared to higher sample rate (44.1 kHz) voices produced by the SVC models based on diffusion or VITS.

Therefore, this paper focuses on exploring how to improve the model performance in both general SVC scenarios and particularly in cross-domain SVC scenarios.

Although existing SVC models can introduce small-scale pitch random perturbations during training, they often generate hoarse artifacts in cross-domain SVC scenarios, particularly as the vocal range span increases.

Furthermore, in further experiments, we found that using SVC models to only increase the pitch of the source vocals without changing the timbre leads to hoarse audio, with hoarse portions persisting even when the pitch is lowered back to the original.

Additionally, as the magnitude of pitch shifting increases, the range of hoarse artifacts expands, sometimes rendering the entire audio segment almost indistinguishable.

When returning the pitch shifted hoarse voice to original pitch, hoarseness still remains.

![](1.png)

<a id="fig:audios">The pipeline of cycle pitch shifting.</a>

Therefore, we explored the possibility of cycle pitch shifting during model training.

This involved introducing random perturbations within a certain range and then returning back to the original pitch, which could potentially produce partly hoarse audio alongside the original audio.

This process is illustrated in Figure [fig:audios](#fig:audios).

By calculating the loss function of features between this hoarse audio and the original audio, we can optimize the model to reduce the occurrence of hoarse artifacts in SVC model generations.

In addition, we found that the Structural Similarity Index (SSIM) [^Wang2004Image], commonly used in image processing, can enhance the performance of SVC models when employed to compute the loss of mel-spectrograms.

Due to its computational characteristics, SSIM enables the model to focus more on the overall structure and details of the data, thereby improving the overall performance of the SVC model.

Therefore, the main contributions of this work can be summarized as follows:

-  Propose a **S**elf-supervised **P**itch **A**ugmentation method for **S**inging **V**oice **C**onversion called SPA-SVC.

By integrating a cycle process of randomly raising and lowering pitch during model training, we generate hoarse voice aligned with the original voice.

This can alleviate the problem of voiceless regions caused by large pitch spans.

-  Introduce SSIM loss into SVC and experimentally demonstrated its significant contribution to improving the quality of generated singing voices. 

The structure of this paper will be arranged as follows: Section [sec:method](#sec:method) will present the methodology and Section [sec:experiments](#sec:experiments) will describe the experimental setups and showcase the experimental results.

And Section [sec:conclusions](#sec:conclusions) will conclude the paper.
