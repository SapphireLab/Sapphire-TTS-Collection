# DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion."
- 作者:
  - 01 Songxiang Liu
  - 02 Yuewen Cao
  - 03 Dan Su
  - 04 Helen Meng
- 链接:
  - [ArXiv](https://arxiv.org/abs/2105.13871v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2105.13871v1](_PDF/2021.05.28_2105.13871v1_DiffSVC__A_Diffusion_Probabilistic_Model_for_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Singing voice conversion (SVC) is one promising technique which can enrich the way of human-computer interaction by endowing a computer the ability to produce high-fidelity and expressive singing voice.
In this paper, we propose DiffSVC, an SVC system based on denoising diffusion probabilistic model.
DiffSVC uses phonetic posteriorgrams (PPGs) as content features.
A denoising module is trained in DiffSVC, which takes destroyed mel spectrogram produced by the diffusion/forward process and its corresponding step information as input to predict the added Gaussian noise.
We use PPGs, fundamental frequency features and loudness features as auxiliary input to assist the denoising process.
Experiments show that DiffSVC can achieve superior conversion performance in terms of naturalness and voice similarity to current state-of-the-art SVC approaches.

## 1·Introduction

\label{sec1:intro}

Singing plays an important role in human daily life, including information transmission, emotional expression and entertainment.

The technology of singing voice conversion (SVC) aims at converting the voice of a singing signal to a voice of a target singer without changing the underlying content and melody.

Endowing machine with the ability to produce high-fidelity and expressive singing voice provides new ways for human-computer interaction.

SVC is among the possible ways to achieve this.

Most recent SVC systems train a content encoder to extract content features from a source singing signal and a conversion model to transform content features to either acoustic features or waveform.

One class of SVC approaches jointly trains the content encoder and the conversion model as an auto-encoder model [^Nachmani2019Unsupervised], [^Deng2020Pitchnet].

Another class of SVC approaches separately trains the content encoder and the conversion model.

These approaches train an automatic speech recognition (ASR) model as the content encoder.

The ASR model can be an end-to-end model, as in [^Polyak2020Unsupervised], [^Liu2021FastSVC] or a hybrid HMM-DNN model, as in [^Li2021PPG-Based].

The conversion model can be the generator in a generative adversarial network (GAN) [^Polyak2020Unsupervised], [^Liu2021FastSVC], which directly generates waveform from content features; or a regression model, which transforms content features to spectral features (e.g., mel spectrograms), and adopts an additionally trained neural vocoder to generate waveform.

In this paper, we focus on the latter class and devote to introducing the recently-emerged diffusion probabilistic modeling into the conversion model.

Diffusion probabilistic models, or diffusion models for brevity, are a class of promising generative models [^Sohl-Dickstein2015Deep].

It has been demonstrated that diffusion models are capable of achieving state-of-the-art performance on generative modeling for natural images [^Ho2020Denoising], [^Song2021Denoising] and raw audio waveform [^Kong2020Diffwave], [^Chen2020WaveGrad].

There are two processes in a diffusion model, i.e., the diffusion/forward process and the reverse process.

The diffusion/forward process is a Markov chain with fixed parameters, which converts the complicated data into isotropic Gaussian distribution by adding Gaussian noise gradually.

The reverse process is also a Markov chain, which restores the data structure from Gaussian noise in an iterative manner.

One merit of diffusion models is that they can be efficiently trained by optimizing the evidence lower bound (ELBO), also known as variational lower bound (VLB), of the data likelihood.

In [^Ho2020Denoising], one certain parameterization trick can convert the learning process of diffusion models into a regression problem.

We follow this setting in this paper.

We propose DiffSVC, which is an SVC system based on diffusion model.

We use an ASR acousic model to extract phonetic posteriorgrams (PPGs) from singing signals as the content features.

A diffusion model is trained to recover mel spectrograms iteratively from Gaussian noise, conditioning on content, melody and loudness features.

We show that DiffSVC can achieve superior conversion performance in terms of naturalness and voice similarity, compared with  current state-of-the-art SVC approaches.

The contributions of our work include: (1) To the best of our knowledge, the proposed DiffSVC system is the first SVC system using the diffusion probabilistic model.

We show that diffusion model can be effectively adopted for the SVC task; and (2) DiffSVC achieves better conversion performance in terms of naturalness and voice similarity than previous SVC systems.

The rest of this paper is organized as follows: Section~[sec2](#sec2) presents related work.

Section~[sec3](#sec3) introduces the diffusion probabilistic model.

Details of the proposed DiffSVC system are presented in Section~[sec4](#sec4).

Experimental results are shown in Section~[sec5](#sec5) and Section~[sec6](#sec6) concludes this paper.
