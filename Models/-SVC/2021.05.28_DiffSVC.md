# DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion."
- 作者:
  - 01 Songxiang Liu
  - 02 Yuewen Cao
  - 03 Dan Su
  - 04 Helen Meng
- 链接:
  - [ArXiv](https://arxiv.org/abs/2105.13871v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2105.13871v1](_PDF/2021.05.28_2105.13871v1_DiffSVC__A_Diffusion_Probabilistic_Model_for_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Singing voice conversion (SVC) is one promising technique which can enrich the way of human-computer interaction by endowing a computer the ability to produce high-fidelity and expressive singing voice.
In this paper, we propose DiffSVC, an SVC system based on denoising diffusion probabilistic model.
DiffSVC uses phonetic posteriorgrams (PPGs) as content features.
A denoising module is trained in DiffSVC, which takes destroyed mel spectrogram produced by the diffusion/forward process and its corresponding step information as input to predict the added Gaussian noise.
We use PPGs, fundamental frequency features and loudness features as auxiliary input to assist the denoising process.
Experiments show that DiffSVC can achieve superior conversion performance in terms of naturalness and voice similarity to current state-of-the-art SVC approaches.

## 1·Introduction

\label{sec1:intro}

Singing plays an important role in human daily life, including information transmission, emotional expression and entertainment.

The technology of singing voice conversion (SVC) aims at converting the voice of a singing signal to a voice of a target singer without changing the underlying content and melody.

Endowing machine with the ability to produce high-fidelity and expressive singing voice provides new ways for human-computer interaction.

SVC is among the possible ways to achieve this.

Most recent SVC systems train a content encoder to extract content features from a source singing signal and a conversion model to transform content features to either acoustic features or waveform.

One class of SVC approaches jointly trains the content encoder and the conversion model as an auto-encoder model [^Nachmani2019Unsupervised], [^Deng2020Pitchnet].

Another class of SVC approaches separately trains the content encoder and the conversion model.

These approaches train an automatic speech recognition (ASR) model as the content encoder.

The ASR model can be an end-to-end model, as in [^Polyak2020Unsupervised], [^Liu2021FastSVC] or a hybrid HMM-DNN model, as in [^Li2021PPG-Based].

The conversion model can be the generator in a generative adversarial network (GAN) [^Polyak2020Unsupervised], [^Liu2021FastSVC], which directly generates waveform from content features; or a regression model, which transforms content features to spectral features (e.g., mel spectrograms), and adopts an additionally trained neural vocoder to generate waveform.

In this paper, we focus on the latter class and devote to introducing the recently-emerged diffusion probabilistic modeling into the conversion model.

Diffusion probabilistic models, or diffusion models for brevity, are a class of promising generative models [^Sohl-Dickstein2015Deep].

It has been demonstrated that diffusion models are capable of achieving state-of-the-art performance on generative modeling for natural images [^Ho2020Denoising], [^Song2021Denoising] and raw audio waveform [^Kong2020Diffwave], [^Chen2020WaveGrad].

There are two processes in a diffusion model, i.e., the diffusion/forward process and the reverse process.

The diffusion/forward process is a Markov chain with fixed parameters, which converts the complicated data into isotropic Gaussian distribution by adding Gaussian noise gradually.

The reverse process is also a Markov chain, which restores the data structure from Gaussian noise in an iterative manner.

One merit of diffusion models is that they can be efficiently trained by optimizing the evidence lower bound (ELBO), also known as variational lower bound (VLB), of the data likelihood.

In [^Ho2020Denoising], one certain parameterization trick can convert the learning process of diffusion models into a regression problem.

We follow this setting in this paper.

We propose DiffSVC, which is an SVC system based on diffusion model.

We use an ASR acousic model to extract phonetic posteriorgrams (PPGs) from singing signals as the content features.

A diffusion model is trained to recover mel spectrograms iteratively from Gaussian noise, conditioning on content, melody and loudness features.

We show that DiffSVC can achieve superior conversion performance in terms of naturalness and voice similarity, compared with  current state-of-the-art SVC approaches.

The contributions of our work include: (1) To the best of our knowledge, the proposed DiffSVC system is the first SVC system using the diffusion probabilistic model.

We show that diffusion model can be effectively adopted for the SVC task; and (2) DiffSVC achieves better conversion performance in terms of naturalness and voice similarity than previous SVC systems.

The rest of this paper is organized as follows: Section~[sec2](#sec2) presents related work.

Section~[sec3](#sec3) introduces the diffusion probabilistic model.

Details of the proposed DiffSVC system are presented in Section~[sec4](#sec4).

Experimental results are shown in Section~[sec5](#sec5) and Section~[sec6](#sec6) concludes this paper.

## 2·Related Work

\label{sec2}

### Singing Voice Conversion

Current SVC approaches can be categorized into two classes, i.e., parallel SVC and non-parallel SVC, in terms of whether parallel training data is required.

Most initial attempts for SVC are within the parallel SVC paradigm.

These approaches model parallel training samples using statistical methods, such as Gaussian mixture model (GMM)-based many-to-many eigenvoice conversion [^Toda2007One-to-Many], direct waveform modification based on spectrum difference [^Kobayashi2014Statistical], [^Kobayashi2015Statistical].

GAN-based parallel approach has also been proposed to improve conversion performance [^Sisman2019Singan].

Since parallel SVC approaches require parallel data, which is expensive to collect, for the training process, researchers have investigated many non-parallel SVC approaches.

Auto-encoder based on the WaveNet [^Oord2016Wavenet] structure has been used for unsupervised SVC in [^Nachmani2019Unsupervised], which can convert among singers appeared in the training set.

This approach adopts an adversarial speaker classifier to disentangle singer information from the encoder output.

To further improve this method, an additional pitch adversarial mechanism is added to remove pitch information from the encoder output in [^Deng2020Pitchnet].

Variational auto-encoder (VAE) [^Luo2020Singing], variational autoencoding Wasserstein GAN (VAW-GAN) [^Lu2020Vaw-Gan], and phonetic posteriorgram (PPG) models [^Li2021PPG-Based] are also investigated for non-parallel SVC.

Very recently, the combination of a PPG model and a waveform generator achieves promising SVC performance [^Polyak2020Unsupervised], [^Liu2021FastSVC].

### Diffusion Probabilistic Models

There are two streams of efforts, pushing the research on diffusion probabilistic models forward.

One is research on the score matching model, which originates from [^Hyv{{\"a}}rinen2005Estimation], where the problem of data density estimation is simplified into a score matching problem (the estimation of the gradient of the data distribution density).

The other is research on denoising diffusion probabilistic model, which originates from [^Sohl-Dickstein2015Deep], where a diffusion Markov chain is used to destroy data structure into Gaussian noise and another reverse process is used to generate data from Gaussian noise.

Recently, great progress has been made in these two streams.

In [^Ho2020Denoising], the diffusion model has been able to generate high-quality images.

Slightly later, the diffusion model also makes it to generate high-quality audio samples [^Kong2020Diffwave], [^Chen2020WaveGrad].

On the other hand, score matching model has also been proved to be capable of generating high-resolution images using a neural network to estimate the log gradient of the target data probabilistic density function [^Song2019Generative].

Afterwards, a unified framework is proposed in [^Song2021Score-Based], which generalizes and improves previous work on score matching model through the lens of stochastic differential equations (SDEs).

The diffusion model in [^Ho2020Denoising] and the score matching model in [^Song2019Generative] have been shown to be special cases under such framework.

![](figs/diffusion_process.pdf)

<a id="fig:diff_process">Graphical model for the reverse process and the diffusion/forward process in a diffusion probabilistic model.

The diffusion/forward process (dotted arrow) gradually converts data into noise within finite steps.

The reverse process (solid arrow) is a parametric procedure which attempts to restore data structure from noise.</a>

![](figs/DiffSVC-model.pdf)

<a id="fig:sys_overview">Schematic diagram of the conversion model in the proposed DiffSVC system, based on the diffusion probabilistic model.</a>

## 3·Diffusion Probabilistic Model

\label{sec3}

In this section, we introduce the denoising diffusion probabilistic model (or diffusion model in short) [^Sohl-Dickstein2015Deep].

We denote the data as $y_0\sim q(y_0)$.

A diffusion model is a latent variable model with the form $p_{\theta}(y_0) := \int p_\theta(y_{0:T})dy_{1:T}$, where $y_1, ..., y_T$ are latent variables with the same dimensionality as the data $y_0$ and $T$ is the total number of diffusion steps.

As shown in Fig.~[fig:diff_process](#fig:diff_process), a diffusion model contains two processes -- the diffusion/forward process and the reverse process.

In the remaining part of this section, we first introduce the two processes in a diffusion model and then discuss the training and sampling algorithms.

### Diffusion/Forward Process

The diffusion/forward process in a diffusion model is modeled as a Markov chain that gradually adds small noise to the data until the data structure is totally destroyed at step $T$.

That is, the diffusion process gradually whitens the data into Gaussian noise in $T$ diffusion steps.

The chain transitions are often modeled as conditional Gaussian transitions according to a deterministic noise schedule $\beta_1, ..., \beta_T$, which are set to satisfy $\beta_1 < \beta_2 < ... < \beta_T$.

The joint probability of the latent variables is:

$$
q(y_{1:T}|y_0) := \prod_{t=1}^{T} q(y_t|y_{t-1}),
$$

where $q(y_t|y_{t-1}) := \mathcal{N}(y_t;\sqrt{1-\beta_t}y_{t-1}, \beta_t I)$.

The mean term $\sqrt{1-\beta_t}$ gradually decays the destroyed data towards origin, and the variance term $\beta_t$ incorporates stochasticity into the process by adding small noises, for $t\in\{1, ..., T\}$.

### Reverse Process

The reverse process in a diffusion model is a parameterised process which gradually learns to restore data structure from white noise along another Markov chain.

When $\beta$'s of the diffusion/forward process are small, both the diffusion and reverse process have the same functional form [^Sohl-Dickstein2015Deep], i.e., Gaussian transitions.

Starting at isotropic Gaussian $p(y_T)=\mathcal{N}({y_T; 0, I}$), the joint distribution $p_\theta(y_{0:T})$ along the reverse process satisfies:

$$
p_\theta(y_{0:T}) := p(y_T)\prod_{t=1}^T p_\theta(y_{t-1}|y_t),
$$

where the transition probability $p_\theta(y_{t-1}|y_t)$ is parameterized as $\mathcal{N}(y_{t-1};\mu_\theta(y_t, t), \sigma_\theta(y_t, t)^2 I)$ with shared parameter $\theta$ among all the $T$ transitions.

The training process of a diffusion model is to learn the parameter $\theta$, such that $p_\theta(y_{t-1}|y_t)$ can eliminate the Gaussian noise (i.e., denoise) added during the diffusion/forward process.

### Training Diffusion Model

The goal of training a diffusion model is to maximize the model likelihood $p_{\theta}(y_0) := \int p_\theta(y_{0:T})dy_{1:T}$,  given a training set $\{y_0^m\}_{m=1}^M$ with $M$ samples.

However, the likelihood is intractable to compute in general because of the integration operation in a very high-dimensional latent space.

Thus, its evidence lower bound (ELBO), which is also known as variational lower bound (VLB), is used to train the model:

$$ \label{eq:elbo}
\mathbb{E}_{q(y_0)}[\log p_\theta(y_0)]\geq \underbrace{\mathbb{E}_{q(y_{0:T})}[\log\frac{p_\theta(y_{0:T-1}|y_T)p(y_T)}{q(y_{1:T}|y_0)}]}_{:=ELBO}
$$

We refer readers to [^Sohl-Dickstein2015Deep] for a complete proof of Eq.~([eq:elbo](#eq:elbo)).

Thanks to the property of Gaussian transitions in the diffusion process, the noisy data $y_t$ (i.e., destroyed data) at any step $t\in\{1, ..., T\}$ can be readily sampled given a data sample $y_0$:

$$
q(y_t|y_0) = \mathcal{N}(y_t;\sqrt{\bar\alpha_t}y_0,\sqrt{1-\bar\alpha_t}I),
$$

where $\alpha_t:=1-\beta_t$ and $\bar\alpha_t=\prod_{s=1}^t\alpha_s$.

Following the reparameterization trick presented in [^Ho2020Denoising], the learning process becomes a regression problem, where a neural network (parameterized with $\theta$) is trained, which takes the noisy data $y_t$ and the step variable $t$ as input to predict the  corresponding noise $\epsilon$.

Using a simplified variant of the ELBO in Eq.~([eq:elbo](#eq:elbo)) as in [^Ho2020Denoising], the negative ELBO becomes:

$$ \label{eq:simplified-elbo}
-ELBO=\mathbb{E}_{y_0, t}[||\epsilon - \epsilon_\theta(\sqrt{\bar\alpha_t}y_0+\sqrt{1-\bar\alpha_t}\epsilon, t)||_2^2],
$$

where $\epsilon\sim\mathcal{N}(0,I)$, $y_0\sim q(y_0)$, and $t$ is uniformly sampled from $1,...,T$.

In this paper, we use Eq.~([eq:simplified-elbo](#eq:simplified-elbo)) to train the diffusion model.

### Sampling with Langevin Dynamics

Given the parameterized reverse process with the well-learned parameter $\theta$, the sampling process (i.e., the generative process) is to first sample a Gaussian noise $y_T \sim \mathcal{N}(0, I)$, and then iteratively sample $y_{t-1}\sim p_\theta(y_{t-1}|y_t)$ for $t=T, T-1, ..., 1$ along the reverse process, according to Langevin dynamics:

$$ \label{eq:sample}
y_{t-1} = \frac{1}{\sqrt{\alpha_t}}(y_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(y_t, t))+\sigma_t z,
$$

where $\sigma_t^2=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$, $z\sim\mathcal{N}(0,I)$ for $t>1$ and $z=0$ for $t=1$.

The final $y_0$ is the generated data.

## 4·DiffSVC

\label{sec4}

In this section, we describe how we introduce the diffusion model to SVC and present details of the proposed DiffSVC system.

We regard the content, melody and loudness information as the most important components in a singing signal for the task of singing voice conversion.

In DiffSVC, we train a Deep-FSMN (DFSMN)-based ASR acoustic model [^Zhang2018Deep-FSMN] to extract PPGs as the content features with forced-aligned audio-text speech data.

We train the ASR model with frame-wise cross-entropy loss, where the ground-truth labels are phonemes (i.e., initials and finals with tone) for Mandarin Chinese SVC.

We introduce the concept of denoising diffusion modeling into the conversion model in DiffSVC.

The overall architecture is depicted in Fig.~[fig:sys_overview](#fig:sys_overview).

During the training process, DiffSVC aims at predicting the isotropic Gaussian noise $\epsilon$ from the noisy mel spectrogram $y_t$ and the step variable $t$, leveraging additional information from PPG $x$, logarithmic fundamental frequency feature (Log-F0) $f_0$ and loudness feature $l$.

We introduce the details in the following subsections.

### PPG, Log-F0 and Loudness

The PPG prenet adopts a simple fully-connected (FC) layer on the PPG input.

DiffSVC represents the melody of a singing signal using its fundamental frequency contour in logarithmic scale.

A-weighting mechanism of a singing signal's power spectrum is adopted to compute loudness features, following [^Liu2021FastSVC].

We process the Log-F0 features and loudness features in the same way.

The Log-F0 features and loudness features are first quantized into 256 bins, and then go through a melody embedding lookup table and a loudness embedding lookup table respectively. 
The processed PPG features, Log-F0 features and loudness features are added elementwisely to obtain the conditioner $e$, which is token as additional input to the diffusion decoder.

### Diffusion Modeling

**Step Encoding**.

The diffusion step variable $t$ is an important input to a diffusion model, because it indicates the amount of noise added to the noisy mel spectrogram $y_t$.

Following the setting in [^Kong2020Diffwave], we first convert integral-valued $t$ into an 128-dimensional vector $t_{emb}$ with a sinusoidal position encoding as:

$$
[\sin(10^{\frac{0\times4}{63}}t), ..., \sin(10^{\frac{63\times4}{63}}t), \cos(10^{\frac{0\times4}{63}}t), ..., \cos(10^{\frac{63\times4}{63}}t)]
$$

Then we further process $t_{emb}$ with two FC layers and Swish activation function [^Ramachandran2017Searching]. \\
**Diffusion Decoder**.

The diffusion decoder is trained to predict the noise $\epsilon$ added by the diffusion process from the noisy mel spectrogram $y_t$ and the step variable $t$, taking auxiliary conditioners $e$ obtained from PPG $x$, Log-F0 $f_0$ and loudness $l$.

Following [^Kong2020Diffwave], the diffusion decoder in DiffSVC adopts a bidirectional residual convolutional architecture proposed in [^Oord2016Wavenet] with a slight difference.

We use dialtion rate of 1 since we work on mel spectrograms instead of raw waveform.

The receptive field of the diffusion decoder is sufficiently large with a dilation rate of 1.

The diffusion decoder first conducts an one-dimensional convolutional operation with kernel-size 1 (Conv1x1) on the noisy mel spectrogram and then adopts the ReLU activation on the output.

The output of the step encoder is added to every time step of the mel spectrogram feature maps, and then fed into $N$ residual blocks.

The conditioner $e$ is imported into every residual block with separate Conv1x1 layers, whose output is elementwisely added with the mel spectrogram and step features.

Then the gated mechanism introduced in [^Oord2016Wavenet] are used to further process the feature maps.

We sum the skip connections from all the $N$ residual layers and further process with two Conv1x1 layers interleaved with a ReLU activation to get the diffusion decoder output. \\
**Training and conversion**

We summarize the training procedure of the conversion model in DiffSVC in Algorithm~[alg:training](#alg:training) and the conversion procedure in Algorithm~[alg:conversion](#alg:conversion), respectively.

\begin{algorithm}[h]
\caption{Training procedure of the conversion model in DiffSVC.}

\begin{algorithmic}[1]
\label{alg:training}
\REQUIRE The conversion model $\epsilon_\theta(\cdot)$; the training set $\mathcal{D}_{train}=\{(x, f0, l, y_0)\}_{m=1}^M$; $N_{iter}$ training iterations.
\FOR{$i=1,2,...,N_{iter}$}
\STATE Sample $(x, f_0, l, y_0)$ from $\mathcal{D}_{train}$;
\STATE $\epsilon\sim\mathcal{N}(0,I)$;
\STATE Sample $t\sim$ Uniform$(\{1, \cdots, T\})$;
\STATE Take gradient descent step on \\ \quad$\nabla_\theta||\epsilon-\epsilon_\theta(\sqrt{\bar\alpha_t}y_0+\sqrt{1-\bar\alpha_t}\epsilon, t, x, f_0, l))||_2^2$;
\ENDFOR
\RETURN $\epsilon_\theta(\cdot)$;
\end{algorithmic}

\end{algorithm}

\begin{algorithm}[h]
\caption{Conversion procedure of DiffSVC.}

\begin{algorithmic}[1]
\label{alg:conversion}
\REQUIRE The trained conversion model $\epsilon_\theta(\cdot)$; one testing sample $(x, f0, l)$.
\STATE Sample $y_T\sim\mathcal{N}(0,I)$;
\FOR{$t=T,T-1,...,1$}
\STATE Sample $(x, f_0, l, y_0)$ from $\mathcal{D}$;
\STATE $\epsilon\sim\mathcal{N}(0,I)$;
\IF{$t>1$}
\STATE Sample $z\sim\mathcal{N}(0, I)$;
\ELSE
\STATE $z=0$;
\ENDIF
\STATE $y_{t-1} = \frac{1}{\sqrt{\alpha_t}}(y_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(y_t, t, x, f_0, l))+\sigma_t z$, as in Eq.~[eq:sample](#eq:sample);
\ENDFOR
\RETURN $y_0$;
\end{algorithmic}

\end{algorithm}
