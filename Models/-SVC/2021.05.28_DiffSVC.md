# DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion."
- 作者:
  - 01 Songxiang Liu
  - 02 Yuewen Cao
  - 03 Dan Su
  - 04 Helen Meng
- 链接:
  - [ArXiv](https://arxiv.org/abs/2105.13871v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2105.13871v1](_PDF/2021.05.28_2105.13871v1_DiffSVC__A_Diffusion_Probabilistic_Model_for_Singing_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Singing voice conversion (SVC) is one promising technique which can enrich the way of human-computer interaction by endowing a computer the ability to produce high-fidelity and expressive singing voice.
In this paper, we propose DiffSVC, an SVC system based on denoising diffusion probabilistic model.
DiffSVC uses phonetic posteriorgrams (PPGs) as content features.
A denoising module is trained in DiffSVC, which takes destroyed mel spectrogram produced by the diffusion/forward process and its corresponding step information as input to predict the added Gaussian noise.
We use PPGs, fundamental frequency features and loudness features as auxiliary input to assist the denoising process.
Experiments show that DiffSVC can achieve superior conversion performance in terms of naturalness and voice similarity to current state-of-the-art SVC approaches.

## 1·Introduction

\label{sec1:intro}

Singing plays an important role in human daily life, including information transmission, emotional expression and entertainment.

The technology of singing voice conversion (SVC) aims at converting the voice of a singing signal to a voice of a target singer without changing the underlying content and melody.

Endowing machine with the ability to produce high-fidelity and expressive singing voice provides new ways for human-computer interaction.

SVC is among the possible ways to achieve this.

Most recent SVC systems train a content encoder to extract content features from a source singing signal and a conversion model to transform content features to either acoustic features or waveform.

One class of SVC approaches jointly trains the content encoder and the conversion model as an auto-encoder model [^Nachmani2019Unsupervised], [^Deng2020Pitchnet].

Another class of SVC approaches separately trains the content encoder and the conversion model.

These approaches train an automatic speech recognition (ASR) model as the content encoder.

The ASR model can be an end-to-end model, as in [^Polyak2020Unsupervised], [^Liu2021FastSVC] or a hybrid HMM-DNN model, as in [^Li2021PPG-Based].

The conversion model can be the generator in a generative adversarial network (GAN) [^Polyak2020Unsupervised], [^Liu2021FastSVC], which directly generates waveform from content features; or a regression model, which transforms content features to spectral features (e.g., mel spectrograms), and adopts an additionally trained neural vocoder to generate waveform.

In this paper, we focus on the latter class and devote to introducing the recently-emerged diffusion probabilistic modeling into the conversion model.

Diffusion probabilistic models, or diffusion models for brevity, are a class of promising generative models [^Sohl-Dickstein2015Deep].

It has been demonstrated that diffusion models are capable of achieving state-of-the-art performance on generative modeling for natural images [^Ho2020Denoising], [^Song2021Denoising] and raw audio waveform [^Kong2020Diffwave], [^Chen2020WaveGrad].

There are two processes in a diffusion model, i.e., the diffusion/forward process and the reverse process.

The diffusion/forward process is a Markov chain with fixed parameters, which converts the complicated data into isotropic Gaussian distribution by adding Gaussian noise gradually.

The reverse process is also a Markov chain, which restores the data structure from Gaussian noise in an iterative manner.

One merit of diffusion models is that they can be efficiently trained by optimizing the evidence lower bound (ELBO), also known as variational lower bound (VLB), of the data likelihood.

In [^Ho2020Denoising], one certain parameterization trick can convert the learning process of diffusion models into a regression problem.

We follow this setting in this paper.

We propose DiffSVC, which is an SVC system based on diffusion model.

We use an ASR acousic model to extract phonetic posteriorgrams (PPGs) from singing signals as the content features.

A diffusion model is trained to recover mel spectrograms iteratively from Gaussian noise, conditioning on content, melody and loudness features.

We show that DiffSVC can achieve superior conversion performance in terms of naturalness and voice similarity, compared with  current state-of-the-art SVC approaches.

The contributions of our work include: (1) To the best of our knowledge, the proposed DiffSVC system is the first SVC system using the diffusion probabilistic model.

We show that diffusion model can be effectively adopted for the SVC task; and (2) DiffSVC achieves better conversion performance in terms of naturalness and voice similarity than previous SVC systems.

The rest of this paper is organized as follows: Section~[sec2](#sec2) presents related work.

Section~[sec3](#sec3) introduces the diffusion probabilistic model.

Details of the proposed DiffSVC system are presented in Section~[sec4](#sec4).

Experimental results are shown in Section~[sec5](#sec5) and Section~[sec6](#sec6) concludes this paper.

## 2·Related Work

\label{sec2}

### Singing Voice Conversion

Current SVC approaches can be categorized into two classes, i.e., parallel SVC and non-parallel SVC, in terms of whether parallel training data is required.

Most initial attempts for SVC are within the parallel SVC paradigm.

These approaches model parallel training samples using statistical methods, such as Gaussian mixture model (GMM)-based many-to-many eigenvoice conversion [^Toda2007One-to-Many], direct waveform modification based on spectrum difference [^Kobayashi2014Statistical], [^Kobayashi2015Statistical].

GAN-based parallel approach has also been proposed to improve conversion performance [^Sisman2019Singan].

Since parallel SVC approaches require parallel data, which is expensive to collect, for the training process, researchers have investigated many non-parallel SVC approaches.

Auto-encoder based on the WaveNet [^Oord2016Wavenet] structure has been used for unsupervised SVC in [^Nachmani2019Unsupervised], which can convert among singers appeared in the training set.

This approach adopts an adversarial speaker classifier to disentangle singer information from the encoder output.

To further improve this method, an additional pitch adversarial mechanism is added to remove pitch information from the encoder output in [^Deng2020Pitchnet].

Variational auto-encoder (VAE) [^Luo2020Singing], variational autoencoding Wasserstein GAN (VAW-GAN) [^Lu2020Vaw-Gan], and phonetic posteriorgram (PPG) models [^Li2021PPG-Based] are also investigated for non-parallel SVC.

Very recently, the combination of a PPG model and a waveform generator achieves promising SVC performance [^Polyak2020Unsupervised], [^Liu2021FastSVC].

### Diffusion Probabilistic Models

There are two streams of efforts, pushing the research on diffusion probabilistic models forward.

One is research on the score matching model, which originates from [^Hyv{{\"a}}rinen2005Estimation], where the problem of data density estimation is simplified into a score matching problem (the estimation of the gradient of the data distribution density).

The other is research on denoising diffusion probabilistic model, which originates from [^Sohl-Dickstein2015Deep], where a diffusion Markov chain is used to destroy data structure into Gaussian noise and another reverse process is used to generate data from Gaussian noise.

Recently, great progress has been made in these two streams.

In [^Ho2020Denoising], the diffusion model has been able to generate high-quality images.

Slightly later, the diffusion model also makes it to generate high-quality audio samples [^Kong2020Diffwave], [^Chen2020WaveGrad].

On the other hand, score matching model has also been proved to be capable of generating high-resolution images using a neural network to estimate the log gradient of the target data probabilistic density function [^Song2019Generative].

Afterwards, a unified framework is proposed in [^Song2021Score-Based], which generalizes and improves previous work on score matching model through the lens of stochastic differential equations (SDEs).

The diffusion model in [^Ho2020Denoising] and the score matching model in [^Song2019Generative] have been shown to be special cases under such framework.

![](figs/diffusion_process.pdf)

<a id="fig:diff_process">Graphical model for the reverse process and the diffusion/forward process in a diffusion probabilistic model.

The diffusion/forward process (dotted arrow) gradually converts data into noise within finite steps.

The reverse process (solid arrow) is a parametric procedure which attempts to restore data structure from noise.</a>

![](figs/DiffSVC-model.pdf)

<a id="fig:sys_overview">Schematic diagram of the conversion model in the proposed DiffSVC system, based on the diffusion probabilistic model.</a>
