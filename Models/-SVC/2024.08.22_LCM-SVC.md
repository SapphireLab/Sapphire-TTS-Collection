# LCM-SVC: Latent Diffusion Model Based Singing Voice Conversion With Inference Acceleration via Latent Consistency Distillation

<details>
<summary>基本信息</summary>

- 标题: "LCM-SVC: Latent Diffusion Model Based Singing Voice Conversion With Inference Acceleration via Latent Consistency Distillation."
- 作者:
  - 01 Shihao Chen
  - 02 Yu Gu
  - 03 Jianwei Cui
  - 04 Jie Zhang
  - 05 Rilin Chen
  - 06 Lirong Dai
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.12354v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2408.12354v1](_PDF/2024.08.22_2408.12354v1_LCM-SVC__Latent_Diffusion_Model_Based_Singing_Voice_Conversion_With_Inference_Acceleration_via_Latent_Consistency_Distillation.pdf)
  - [Publication] #TODO

</details>

## Abstract

Any-to-any singing voice conversion (SVC) aims to transfer a target singer's timbre to other songs using a short voice sample.
However many diffusion model based any-to-any SVC methods, which have achieved impressive results, usually suffered from low efficiency caused by a mass of inference steps.
In this paper, we propose LCM-SVC, a latent consistency distillation (LCD) based latent  diffusion model (LDM) to  accelerate inference speed. 
We  achieved one-step or few-step inference while maintaining the high performance by distilling a pre-trained LDM based SVC model, which had the advantages of  timbre decoupling and sound quality.
Experimental results show that our proposed method can significantly reduce the inference time and largely preserve the sound quality and timbre similarity comparing with other state-of-the-art SVC models.
Audio samples are available at \url{https://sounddemos.github.io/lcm-svc/}.

## 1·Introduction

Singing voice conversion (SVC) is an emerging audio editing application that aims to transfer the timbre of a target singer to another piece of singing, such as allowing a celebrity to sing a song we have composed ourselves.

Unlike singing voice synthesis
[^Gu2021ByteSing], [^Cui2024Sifisinger], SVC does not require the input of musical scores or lyrics and  it can be accomplished with just singing voice input.

Due to the scarcity of paired data, current SVC models primarily focus on  the task of decoupling information in singing, e.g., content, timbre, pitch.

By training a reconstruction model provided relevant clues, these features can be reassembled into singing and some can be replaced to achieve timbre conversion or pitch correction.  There were many works that have achieved good results on SVC task, such as models based on generative adversarial networks [^Polyak2020Unsupervised], [^Liu2021Fastsvc], [^Zhou2022HiFi-SVC], models based on Variational AutoEncoder (VAE) [^Luo2020Singing], models based on Diffusion [^Liu2021Diff{SVC], [^Lu2024CoMoSVC] and end-to-end model So-VITS-SVC\footnote{\url{https://github.com/PlayVoice/so-vits-svc-5.0/tree/bigvgan-mix-v2}}.

Among these systems, diffusion models exhibit a superiority in sound quality and timbre similarity, particularly using latent diffusion model (LDM) [^Chen2024Ldm-SVC].%等Interspeech, you can arXiv your interspeech paper and then cite。

The major drawback of the diffusion model based methods is the long required inference time.

The inference iterations of diffusion models can reach up to 100 or even more than 1000, which is impractical for real-world applications.

Some efforts were thus made to accelerate the inference, such as Denoising Diffusion Implicit Models (DDIM) [^Song2020Denoising], Diffusion Probabilistic Models Solver (DPM-Solver) [^Lu2022DPM-Solver], etc.

Recently, the emergence of consistency model (CM) provides a new proposal for accelerating the inference of diffusion, where the goal is to ensure that the output at each step of the diffusion's denoising process remains consistent [^Song2023Consistency].

By learning consistency mappings that maintain point consistency on Order Linear Equations (ODE)-trajectory, CM achieves one-step generation and thus avoids computationally intensive iterations.

Further, the advent of latent consistency model (LCM) [^Luo2023Latent] suggests that applying consistency distillation in the latent space can yield superior results, which can also improve the efficiency of diffusion  models, meanwhile maintaining high-quality outputs.

In this paper, we propose an SVC method (abbreviated by LCM-SVC) using latent consistency distillation (LCD) strategy on the basis of an LDM SVC model.

This method efficiently converts a pre-trained LDM into an LCM by solving an augmented Probability Flow ODE (PF-ODE).

Initially, we train a So-VITS-SVC model as the VAE structure to extract hidden latent variables and then a teacher model based on LDM following  a classifier guidance scheme.

We then utilize the LCD method to distill the model, facilitating few-step or even one-step inference while preserving audio quality similarly to the teacher model.

We further apply a skipping-step technique to accelerate the convergence of model training.

Experimental results indicate that LCM-SVC can only incur a slight loss in audio quality using one-step inference iteration.

More importantly, in case of using 2-step or 4-step inference, the obtained audio quality is comparable to that of the teacher model and the inference time is significantly reduced, which satisfies the efficiency request of practical applications. 
The rest of this paper is organized as follows.

Section 2 outlines the proposed LCM-SVC method.

Experiments are presented in Section 3.

Finally, Section 4 concludes this work.
