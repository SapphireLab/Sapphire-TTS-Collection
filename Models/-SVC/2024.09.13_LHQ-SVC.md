# LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling

<details>
<summary>基本信息</summary>

- 标题: "LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling."
- 作者:
  - 01 Yubo Huang
  - 02 Xin Lai
  - 03 Muyang Ye
  - 04 Anran Zhu
  - 05 Zixi Wang
  - 06 Jingzehua Xu
  - 07 Shuai Zhang
  - 08 Zhiyuan Zhou
  - 09 Weijie Niu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2409.08583v2)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2409.08583v1](_PDF/2024.09.13_2409.08583v1_LHQ-SVC__Lightweight_and_High_Quality_Singing_Voice_Conversion_Modeling.pdf)
  - [ArXiv:2409.08583v2](_PDF/2024.09.13_2409.08583v2_LHQ-SVC__Lightweight_and_High_Quality_Singing_Voice_Conversion_Modeling.pdf)
  - [Publication] #TODO

</details>

## Abstract

Singing Voice Conversion (SVC) has emerged as a significant subfield of Voice Conversion (VC), enabling the transformation of one singer's voice into another while preserving musical elements such as melody, rhythm, and timbre.
Traditional SVC methods have limitations in terms of audio quality, data requirements, and computational complexity.
In this paper, we propose LHQ-SVC, a lightweight, CPU-compatible model based on the SVC framework and diffusion model, designed to reduce model size and computational demand without sacrificing performance.
We incorporate features to improve inference quality, and optimize for CPU execution by using performance tuning tools and parallel computing frameworks.
Our experiments demonstrate that LHQ-SVC maintains competitive performance, with significant improvements in processing speed and efficiency across different devices.
The results suggest that LHQ-SVC can meet real-time performance requirements, even in resource-constrained environments.

## 1·Introduction

Singing Voice Conversion (SVC) has emerged as a promising application in the music domain, offering new possibilities for music production, cover songs, and personalized voice customization.

SVC involves not only the conversion of speech characteristics but also musical elements such as melody and rhythm, making it more challenging than traditional VC tasks.

Traditional SVC methods have largely relied on generative models.

Nose et al. \cite{nose2015} proposed an HMM-based singing synthesis technique that allows users to intuitively and continuously control the singing style and intensity of synthesized singing voices.

Kobayashi et al. \cite{kobayashi2014} introduced a statistical conversion process based on GMM to estimate spectral features directly, addressing the degradation in voice quality during conversion.

Sisman et al. \cite{sisman2019} were the first to attempt using GANs for SVC and proposed a framework named SINGAN, which achieved high-quality singing voice conversion without relying on automatic speech recognition systems.

Despite their advancements, these models face several limitations, including high data requirements, loss of audio quality, and the complexity of model training.

In comparison to traditional statistical methods, deep learning has demonstrated superior performance by learning complex nonlinear mappings from large datasets, significantly improving the quality of converted voices and speaker similarity \cite{sisman2020}.

Sun et al. \cite{sun2015} proposed a sequence conversion method based on DBLSTM-RNNs, utilizing LSTM to improve the naturalness and continuity of speech output in VC tasks through parallel training data.

Xie et al. \cite{xie2016} introduced a DNN-based non-parallel training approach to VC, achieving effective conversion without parallel data.

Recently, diffusion models have emerged as a powerful generative technique in image and audio synthesis.

These models learn data distribution by gradually introducing and removing noise, capturing subtle features in audio signals, making them a promising alternative for SVC tasks.

Chen et al. \cite{chen2024} introduced a method named LCM-SVC, which accelerates inference in latent diffusion models (LDM) for SVC through Latent Consistency Distillation (LCD), while retaining high sound quality and timbre similarity.

Compared to traditional generative models, diffusion models better preserve the original sound details and musical characteristics.

However, most existing diffusion-based SVC models employ a black-box structure, lacking intuitive interpretability and control over the generation process.

This presents new challenges in optimizing and improving these models.

To address these challenges, this paper proposes a novel approach called The innovation of this study lies in the development of LHQ-SVC, a lightweight and CPU-optimized Singing Voice Conversion model.

Unlike previous models that rely on GPU-heavy computations, LHQ-SVC is designed to run efficiently on CPUs while maintaining high-quality audio conversion.

Key innovations include:

-  Model Size Reduction: LHQ-SVC significantly reduces the model size without compromising performance, making it suitable for deployment on devices with limited computational resources.

-  CPU Optimization: By converting GPU-centric code to CPU-compatible operations and leveraging optimization libraries such as Intel MKL and OpenMP, LHQ-SVC achieves efficient parallel processing on multi-core CPUs.

-  Improved Sampling Mechanism: We optimize the diffusion process by reducing the number of steps required in the conversion, enabling faster inference while maintaining high-quality results.

## 2·Related Work

### Voice Conversion

Voice Conversion (VC) is a technique that modifies the voice of a source speaker to sound like that of a target speaker while preserving the linguistic content.

In recent years, VC has seen remarkable advancements with applications spanning across areas such as speaker identity conversion, speech enhancement, and cross-lingual voice translation \cite{sisman2020}.

As a specialized subset of VC, Singing Voice Conversion (SVC) focuses on transforming one singer’s voice into another while retaining the musical elements such as pitch, rhythm, and timbre.

This presents additional challenges beyond traditional VC tasks, as SVC must handle not only the vocal characteristics but also the melodic and rhythmic aspects of singing.

Recent developments in deep learning have brought new solutions to the SVC field.

Early methods predominantly relied on statistical models like Hidden Markov Models (HMMs) and Gaussian Mixture Models (GMMs).

However, these models often struggled with issues related to the loss of audio quality and the need for parallel data, limiting their generalization capabilities \cite{kobayashi2014}.

The shift towards neural network-based approaches has significantly improved both the quality and flexibility of voice and singing conversions.

While significant progress has been made in SVC through the introduction of deep learning methods such as GANs, diffusion models, and zero-shot techniques, challenges remain.

Key issues include improving inference stability, reducing computational demands, and achieving better control over individual vocal timbres.

### Diffusion Model Applications

Diffusion models, a class of generative models, operate by first adding noise to data in the forward process, and then reconstructing the data structure during the reverse process to generate samples \cite{yang2023}.

These models have recently been introduced in the field of Singing Voice Conversion (SVC) to address the limitations of traditional methods when dealing with non-parallel data \cite{xue2024singvisio}.

The core principle of diffusion models is to decompose the complex task of generating high-dimensional data into multiple simpler steps by progressively adding noise and learning the denoising process.

Further advancing controllability in SVC, Wang et al. \cite{wang2024prompt} introduced Prompt-Singer, a method that allows users to control singer attributes such as gender, vocal range, and volume through natural language prompts.

Although this method improves style control, the model's large size limits its scalability.

Chen et al. \cite{chen2024ldmsvc} developed LDM-SVC, a zero-shot any-to-any SVC method based on latent diffusion models.

LDM-SVC achieves faster training speed, but its inference quality is unstable.

Over and above these work, Lu et al. \cite{lu2024comosvc} proposed CoMoSVC, a consistency model-based SVC method designed to balance high-quality generation with fast sampling.

The use of diffusion models in SVC has demonstrated great potential for generating high-quality audio and enabling fast inference, particularly in scenarios involving non-parallel data and complex timbre control.

However, key challenges remain, including improving model efficiency, stability, and adaptability for real-world applications.
