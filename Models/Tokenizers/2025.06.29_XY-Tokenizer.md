# XY-Tokenizer

<details>
<summary>基本信息</summary>

- 标题: "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs"
- 作者:
  - 01 Yitian Gong
  - 02 Luozhijie Jin
  - 03 Ruifan Deng,
  - 04 Dong Zhang,
  - 05 Xin Zhang,
  - 06 Qinyuan Cheng,
  - 07 Zhaoye Fei,
  - 08 Shimin Li,
  - 09 Xipeng Qiu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2506.23325)
  - [Publication]()
  - [Github](https://github.com/gyt1145028706/XY-Tokenizer)
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2025.07.09_2506.23325v2__XY-Tokenizer__Mitigating_the_Semantic-Acoustic_Conflict_in_Low-Bitrate_Speech_Codecs.pdf)
  - [Publication] #TODO

</details>

## 摘要

<!--
Speech codecs serve as bridges between speech signals and large language models.
An ideal codec for speech language models should not only preserve acoustic information but also capture rich semantic information.
However, existing speech codecs struggle to balance high-quality audio reconstruction with ease of modeling by language models.
In this study, we analyze the limitations of previous codecs in balancing semantic richness and acoustic fidelity.
We propose ***XY-Tokenizer***, a novel codec that mitigates the conflict between semantic and acoustic capabilities through multi-stage, multi-task learning.
Experimental results demonstrate that ***XY-Tokenizer*** achieves performance in both semantic and acoustic tasks comparable to that of state-of-the-art codecs operating at similar bitrates, even though those existing codecs typically excel in only one aspect.
Specifically, ***XY-Tokenizer*** achieves strong text alignment, surpassing distillation-based semantic modeling methods such as **SpeechTokenizer** and **Mimi**, while maintaining a speaker similarity score of 0.83 between reconstructed and original audio.
The reconstruction performance of ***XY-Tokenizer*** is comparable to that of **BigCodec**, the current state-of-the-art among acoustic-only codecs, which achieves a speaker similarity score of 0.84 at a similar bitrate.
Code and models are available at [this https URL](https://github.com/gyt1145028706/XY-Tokenizer).
-->

语音编解码器作为语音信号和大语言模型之间的桥梁.
语音语言模型的理想编解码器不仅应该保留声学信息, 还应该捕获丰富的语义信息.
然而, 现有的语音编解码器难以平衡高质量音频重构和语言模型建模便利性.

在本研究中, 我们分析了以前的编解码器在平衡语义丰富性和声学保真度方面的限制.
我们提出了 ***XY-Tokenizer***, 一种新型的编解码器, 通过多阶段多任务学习来缓解语义和声学能力之间的冲突.

实验结果表明 ***XY-Tokenizer*** 在语义和声学任务上都达到了与当前最先进的声学编解码器相当的性能, 即使这些现有的编解码器在同等比特率下通常只能达到单个方面.
具体而言, ***XY-Tokenizer*** 实现了强大的文本对齐, 超越基于蒸馏的语义建模方法, 比如 **SpeechTokenizer** 和 **Mimi**, 同时保持了重构音频和原始音频之间的说话人相似度得分为 0.83.
***XY-Tokenizer*** 的重构性能与 **BigCodec**, 目前仅能进行声学编码的编解码器, 达到了类似的说话人相似度得分, 即 0.84.
代码和模型可在[此处](https://github.com/gyt1145028706/XY-Tokenizer)获得.

## 1·引言

## 2·背景

## 3·方法

## 4·实验

## 5·结果

## 6·结论

## 参考文献