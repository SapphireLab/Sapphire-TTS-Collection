# WavTokenizer

<details>
<summary>基本信息</summary>

- 标题: "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling"
- 作者:
  - 01 Shengpeng Ji (季胜鹏, 浙江大学)
  - 02 Ziyue Jiang (浙江大学)
  - 03 Wen Wang (阿里巴巴)
  - 04 Yifu Chen (浙江大学)
  - 05 Minghui Fang (浙江大学)
  - 06 Jialong Zuo (浙江大学)
  - 07 Qian Yang (浙江大学)
  - 08 Xize Cheng (成曦泽, 浙江大学)
  - 09 Zehan Wang (浙江大学)
  - 10 Ruiqi Li (浙江大学)
  - 11 Ziang Zhang (浙江大学)
  - 12 Xiaoda Yang (浙江大学)
  - 13 Rongjie Huang (Meta AI@FAIR Team)
  - 14 Yidi Jiang (阿里巴巴)
  - 15 Qian Chen (阿里巴巴)
  - 16 Siqi Zheng (阿里巴巴)
  - 17 Zhou Zhao (浙江大学)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.16532)
  - [Publication]
  - [Github](https://github.com/jishengpeng/WavTokenizer)
  - [Demo]
- 文件:
  - [ArXiv](_PDF/2408.16532v2__WavTokenizer__An_Efficient_Acoustic_Discrete_Codec_Tokenizer_for_Audio_Language_Modeling.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Language models have been effectively applied to modeling natural signals, such as images, video, speech, and audio.
A crucial component of these models is the codec tokenizer, which compresses high-dimensional natural signals into lower-dimensional discrete tokens.
In this paper, we introduce ***WavTokenizer***, which offers several advantages over previous SOTA acoustic codec models in the audio domain:
1)extreme compression.
By compressing the layers of quantizers and the temporal dimension of the discrete codec, one-second audio of 24kHz sampling rate requires only a single quantizer with 40 or 75 tokens.
2)improved subjective quality.
Despite the reduced number of tokens, ***WavTokenizer*** achieves state-of-the-art reconstruction quality with outstanding UTMOS scores and inherently contains richer semantic information.
Specifically, we achieve these results by designing a broader VQ space, extended contextual windows, and improved attention networks, as well as introducing a powerful multi-scale discriminator and an inverse Fourier transform structure.
We conducted extensive reconstruction experiments in the domains of speech, audio, and music.
***WavTokenizer*** exhibited strong performance across various objective and subjective metrics compared to state-of-the-art models.
We also tested semantic information, VQ utilization, and adaptability to generative models.
Comprehensive ablation studies confirm the necessity of each module in ***WavTokenizer***.
The related code, demos, and pre-trained models are available at [this https URL](https://github.com/jishengpeng/WavTokenizer).

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
