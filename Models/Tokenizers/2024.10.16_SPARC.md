# SPARC

<details>
<summary>基本信息</summary>

- 标题: "Coding Speech through Vocal Tract Kinematics"
- 作者:
  - 01 Cheol Jun Cho - UC Berkeley - cheoljun@berkeley.edu;
  - 02 Peter Wu - UC Berkeley - peterw1@berkeley.edu;
  - 03 Tejas S.Prabhune - UC Berkeley - prabhune@berkeley.edu;
  - 04 Dhruv Agarwal - UC Berkeley - dhru-vagarwal@berkeley.edu;
  - 05 Gopala K.Anumanchipalli - UC Berkeley - gopala@berkeley.edu;
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.12998) v4
  - [Publication](https://doi.org/10.1109/JSTSP.2024.3497655)
  - [Github](https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding)
  - [Demo](https://berkeley-speech-group.github.io/sparc-demo)
- 文件:
  - [ArXiv](_PDF/2406.12998v2__Articulatory_Encodec__Vocal_Tract_Kinematics_as_a_Codec_for_Speech.pdf)
  - [Publication] #TODO

</details>

! 当前文档是 [Articulatory Encodec](2024.06.18_Articulatory_Encodec.md) 的新版本.

## Abstract: 摘要

Vocal tract articulation is a natural, grounded control space of speech production.
The spatiotemporal coordination of articulators combined with the vocal source shapes intelligible speech sounds to enable effective spoken communication.
Based on this physiological grounding of speech, we propose a new framework of neural encoding-decoding of speech – ***Speech Articulatory Coding (SPARC)***.
***SPARC*** comprises an articulatory analysis model that infers articulatory features from speech audio, and an articulatory synthesis model that synthesizes speech audio from articulatory features.
The articulatory features are kinematic traces of vocal tract articulators and source features, which are intuitively interpretable and controllable, being the actual physical interface of speech production.
An additional speaker identity encoder is jointly trained with the articulatory synthesizer to inform the voice texture of individual speakers.
By training on large-scale speech data, we achieve a fully intelligible, high-quality articulatory synthesizer that generalizes to unseen speakers.
Furthermore, the speaker embedding is effectively disentangled from articulations, which enables accent-preserving zero-shot voice conversion.
To the best of our knowledge, this is the first demonstration of universal, high-performance articulatory inference and synthesis, suggesting the proposed framework as a powerful coding system of speech.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论