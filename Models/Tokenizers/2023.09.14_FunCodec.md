# FunCodec

<details>
<summary>基本信息</summary>

- 标题: "FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec"
- 作者:
  - 01 Zhihao Du,
  - 02 Shiliang Zhang,
  - 03 Kai Hu,
  - 04 Siqi Zheng
- 链接:
  - [ArXiv](https://arxiv.org/abs/2309.07405)
  - [Publication](https://doi.org/10.1109/ICASSP48485.2024.10447523)
  - [Github](https://github.com/modelscope/FunCodec)
  - [Demo](https://funcodec.github.io)
- 文件:
  - [ArXiv](_PDF/2309.07405v2__FunCodec__A_Fundamental_Reproducible_and_Integrable_Open-Source_Toolkit_for_Neural_Speech_Codec.pdf)
  - [Publication](_PDF/2309.07405p0__FunCodec__ICASSP2024.pdf)

</details>

## Abstract: 摘要

This paper presents FunCodec, a fundamental neural speech codec toolkit, which is an extension of the open-source speech processing toolkit FunASR.
FunCodec provides reproducible training recipes and inference scripts for the latest neural speech codec models, such as SoundStream and Encodec.
Thanks to the unified design with FunASR, FunCodec can be easily integrated into downstream tasks, such as speech recognition.
Along with FunCodec, pre-trained models are also provided, which can be used for academic or generalized purposes.
Based on the toolkit, we further propose the frequency-domain codec models, FreqCodec, which can achieve comparable speech quality with much lower computation and parameter complexity.
Experimental results show that, under the same compression ratio, FunCodec can achieve better reconstruction quality compared with other toolkits and released models.
We also demonstrate that the pre-trained models are suitable for downstream tasks, including automatic speech recognition and personalized text-to-speech synthesis.
This toolkit is publicly available at [this https URL](https://github.com/alibaba-damo-academy/FunCodec).

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论