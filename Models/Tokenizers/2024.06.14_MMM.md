# MMM

<details>
<summary>基本信息</summary>

- 标题: "MMM: Multi-Layer Multi-Residual Multi-Stream Discrete Speech Representation from Self-supervised Learning Model"
- 作者:
  - 01 Jiatong Shi
  - 02 Xutai Ma
  - 03 Hirofumi Inaguma
  - 04 Anna Sun
  - 05 Shinji Watanabe
- 链接:
  - [ArXiv](https://arxiv.org/abs/2406.09869)
  - [Publication](https://doi.org/10.21437/Interspeech.2024-2251)
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv] #TODO
  - [Publication] #TODO

</details>

## Abstract: 摘要

Speech discrete representation has proven effective in various downstream applications due to its superior compression rate of the waveform, fast convergence during training, and compatibility with other modalities.
Discrete units extracted from self-supervised learning (SSL) models have emerged as a prominent approach for obtaining speech discrete representation.
However, while discrete units have shown effectiveness compared to spectral features, they still lag behind continuous SSL representations.
In this work, we propose ***MMM***, a ***Multi-layer Multi-residual Multi-stream discrete units extraction method from SSL***.
Specifically, we introduce iterative residual vector quantization with K-means for different layers in an SSL model to extract multi-stream speech discrete representation.
Through extensive experiments in speech recognition, speech resynthesis, and text-to-speech, we demonstrate the proposed MMM can surpass or on-par with neural codec's performance under various conditions.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论
