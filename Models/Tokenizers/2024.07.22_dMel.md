# dMel

<details>
<summary>基本信息</summary>

- 标题: "dMel: Speech Tokenization Made Simple"
- 作者:
  - 01 He Bai,
  - 02 Tatiana Likhomanenko,
  - 03 Ruixiang Zhang,
  - 04 Zijin Gu,
  - 05 Zakaria Aldeneh,
  - 06 Navdeep Jaitly
- 链接:
  - [ArXiv](https://arxiv.org/abs/2407.15835)
  - [Publication]
  - [Github]
  - [Demo]
- 文件:
  - [ArXiv](_PDF/2407.15835v2__dMel__Speech_Tokenization_Made_Simple.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

Large language models have revolutionized natural language processing by leveraging self-supervised pretraining on vast textual data.
Inspired by this success, researchers have investigated complicated speech tokenization methods to discretize continuous speech signals so that language modeling techniques can be applied to speech data.
However, existing approaches either model semantic (content) tokens, potentially losing acoustic information, or model acoustic tokens, risking the loss of semantic (content) information.
Having multiple token types also complicates the architecture and requires additional pretraining.
Here we show that discretizing mel-filterbank channels into discrete intensity bins produces a simple representation (***dMel***), that performs better than other existing speech tokenization methods.
Using an LM-style transformer architecture for speech-text modeling, we comprehensively evaluate different speech tokenization methods on speech recognition (ASR) and speech synthesis (TTS).
Our results demonstrate the effectiveness of ***dMel*** in achieving high performance on both tasks within a unified framework, paving the way for efficient and effective joint modeling of speech and text.

</details>
<br>

大语言模型通过利用在大量文本数据上进行自监督预训练彻底改变了自然语言处理的方式.

受此成功的启发, 研究人员已经研究了复杂的语音分词化方法, 将连续的语音信号离散化, 以便可以将语言建模技术应用于语音数据.
然而现有的方法要么对语义 (内容) Token 建模, 可能损失了声学信息, 要么对声学 Token 建模, 则冒着丢失语义 (内容) 信息的风险.
有多种 Token 类型会使得架构复杂化, 还需要额外的预训练.

在这里, 我们展示了将梅尔滤波器组通道离散化为离散强度值箱, 产生一种简单的表示 (***dMel***), 其效果比其他现有语音分词化方法要好.

使用语言模型风格的 Transformer 架构来对语音-文本建模, 我们全面评估了不同语音分词化方法在语音识别 (ASR) 和语音合成 (TTS) 上的性能.

我们的结果证明了 ***dMel*** 在统一框架下, 在语音识别和语音合成任务上都取得了卓越的性能, 为有效且高效的联合建模语音和文本提供了坚实的基础.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论