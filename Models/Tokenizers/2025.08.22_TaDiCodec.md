# TaDiCodec: Text-Aware Diffusion Speech Tokenizer for Speech Language Modeling

<details>
<summary>基本信息</summary>

- 标题: "TaDiCodec: Text-Aware Diffusion Speech Tokenizer for Speech Language Modeling."
- 作者:
  - 01 Yuancheng Wang
  - 02 Dekun Chen
  - 03 Xueyao Zhang
  - 04 Junan Zhang
  - 05 Jiaqi Li
  - 06 Zhizheng Wu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2508.16790v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2508.16790v1](_PDF/2025.08.22_2508.16790v1_TaDiCodec__Text-Aware_Diffusion_Speech_Tokenizer_for_Speech_Language_Modeling.pdf)
  - [Publication] #TODO

</details>

## Abstract

Speech tokenizers serve as foundational components for speech language models, yet current designs exhibit several limitations, including: 
1) dependence on multi-layer residual vector quantization structures or high frame rates,
2) reliance on auxiliary pre-trained models for semantic distillation, and
3) requirements for complex two-stage training processes.
In this work, we introduce the ***T**ext-**a**ware **Di**ffusion Transformer Speech **Codec*** (*\myname{*}), a novel approach designed to overcome these challenges.
\myname{} employs end-to-end optimization for quantization and reconstruction through a diffusion autoencoder, while integrating text guidance into the diffusion decoder to enhance reconstruction quality and achieve optimal compression.
\myname{} achieves an extremely low frame rate of **6.25 Hz** and a corresponding bitrate of **0.0875 kbps** with a **single-layer codebook** for 24 kHz speech, 
while maintaining superior performance on critical speech generation evaluation metrics such as Word Error Rate (WER), speaker similarity (SIM), and speech quality (UTMOS).
Notably, \myname{} employs a single-stage, end-to-end training paradigm, and obviating the need for auxiliary pre-trained models.
We also validate the compatibility of \myname{} in language model based zero-shot text-to-speech with both autoregressive modeling and masked generative modeling, demonstrating its effectiveness and efficiency for speech language modeling, as well as a significantly small *reconstruction-generation gap*.
We will open source our code and model checkpoints.
Audio samples are are available at \url{https:/tadicodec.github.io/}.
We release code and model checkpoints at \url{https:/github.com/HeCheng0625/Diffusion-Speech-Tokenizer}.
