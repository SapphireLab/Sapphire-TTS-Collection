# Paraformer-V2

<details>
<summary>基本信息</summary>

- 标题: "Paraformer-v2: An improved non-autoregressive transformer for noise-robust speech recognition"
- 作者:
  - 01 Keyu An,
  - 02 Zerui Li,
  - 03 Zhifu Gao,
  - 04 Shiliang Zhang
- 链接:
  - [ArXiv](https://arxiv.org/abs/2409.17746)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv]()
  - [Publication] #TODO

</details>

## Abstract: 摘要

Attention-based encoder-decoder, e.g., transformer and its variants, generates the output sequence in an autoregressive (AR) manner.
Despite its superior performance, AR model is computationally inefficient as its generation requires as many iterations as the output length.
In this paper, we propose ***Paraformer-v2***, an improved version of ***Paraformer***, for fast, accurate, and noise-robust non-autoregressive speech recognition.
In ***Paraformer-v2***, we use a CTC module to extract the token embeddings, as the alternative to the continuous integrate-and-fire module in ***Paraformer***.
Extensive experiments demonstrate that ***Paraformer-v2*** outperforms ***Paraformer*** on multiple datasets, especially on the English datasets (over 14% improvement on WER), and is more robust in noisy environments.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论