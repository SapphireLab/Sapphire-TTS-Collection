# GAN Vocoder

<details>
<summary>基本信息</summary>

- 标题: "GAN Vocoder: Multi-Resolution Discriminator Is All You Need"
- 作者:
  - 01 Jaeseong You,
  - 02 Dalhyun Kim,
  - 03 Gyuhyeon Nam,
  - 04 Geumbyeol Hwang,
  - 05 Gyeongsu Chae
- 链接:
  - [ArXiv](https://arxiv.org/abs/2103.05236)
  - [Publication](https://doi.org/10.21437/Interspeech.2021-41)
  - [Github]
  - [Demo](https://deepbrainai-research.github.io/gan-vocoder/)
- 文件:
  - [ArXiv](_PDF/2103.05236v2__GAN_Vocoder__Multi-Resolution_Discriminator_Is_All_You_Need.pdf)
  - [Publication](_PDF/2103.05236p0__GAN_Vocoder__InterSpeech2021.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Several of the latest GAN-based vocoders show remarkable achievements, outperforming autoregressive and flow-based competitors in both qualitative and quantitative measures while synthesizing orders of magnitude faster.
In this work, we hypothesize that the common factor underlying their success is the multi-resolution discriminating framework, not the minute details in architecture, loss function, or training strategy.
We experimentally test the hypothesis by evaluating six different generators paired with one shared multi-resolution discriminating framework.
For all evaluative measures with respect to text-to-speech syntheses and for all perceptual metrics, their performances are not distinguishable from one another, which supports our hypothesis.

</td><td>

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td><td>

</td></tr></table>
