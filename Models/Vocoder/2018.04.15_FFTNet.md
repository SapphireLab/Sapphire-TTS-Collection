# FFTNet

<details>
<summary>基本信息</summary>

- 标题: "FFTNet: A Real-Time Speaker-Dependent Neural Vocoder"
- 作者:
  - 01 Zeyu Jin;
  - 02 Adam Finkelstein;
  - 03 Gautham J.Mysore;
  - 04 Jingwan Lu
- 链接:
  - [ArXiv]
  - [Publication](https://doi.org/10.1109/ICASSP.2018.8462431)
  - [Github]
  - [Demo]
- 文件:
  - [ArXiv]
  - [Publication](_PDF/1804.00000p0__FFTNet__A_Real-Time_Speaker-Dependent_Neural_Vocoder.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

We introduce FFTNet, a deep learning approach synthesizing audio waveforms.
Our approach builds on the recent WaveNet project, which showed that it was possible to synthesize a natural sounding audio waveform directly from a deep convolutional neural network.
FFTNet offers two improvements over WaveNet.
First it is substantially faster, allowing for real-time synthesis of audio waveforms.
Second, when used as a vocoder, the resulting speech sounds more natural, as measured via a “mean opinion score” test.

</td><td>

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td><td>

</td></tr></table>
