# iSTFTNet2

<details>
<summary>基本信息</summary>

- 标题: "iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN"
- 作者:
  - 01 Takuhiro Kaneko,
  - 02 Hirokazu Kameoka,
  - 03 Kou Tanaka,
  - 04 Shogo Seki
- 链接:
  - [ArXiv](https://arxiv.org/abs/2308.07117)
  - [Publication](https://doi.org/10.21437/Interspeech.2023-1726)
  - [Github]()
  - [Demo](https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/istftnet2/)
- 文件:
  - [ArXiv](_PDF/2308.07117v1__iSTFTNet2__Faster_and_More_Lightweight_iSTFT-Based_Neural_Vocoder_Using_1D-2D_CNN.pdf)
  - [Publication](_PDF/2308.07117p0__iSTFTNet2__InterSpeech2023.pdf)

</details>

## Abstract: 摘要

The inverse short-time Fourier transform network (iSTFTNet) has garnered attention owing to its fast, lightweight, and high-fidelity speech synthesis.
It obtains these characteristics using a fast and lightweight 1D CNN as the backbone and replacing some neural processes with iSTFT. Owing to the difficulty of a 1D CNN to model high-dimensional spectrograms, the frequency dimension is reduced via temporal upsampling.
However, this strategy compromises the potential to enhance the speed.
Therefore, we propose iSTFTNet2, an improved variant of iSTFTNet with a 1D-2D CNN that employs 1D and 2D CNNs to model temporal and spectrogram structures, respectively.
We designed a 2D CNN that performs frequency upsampling after conversion in a few-frequency space.
This design facilitates the modeling of high-dimensional spectrograms without compromising the speed.
The results demonstrated that iSTFTNet2 made iSTFTNet faster and more lightweight with comparable speech quality.
Audio samples are available at this https URL.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论