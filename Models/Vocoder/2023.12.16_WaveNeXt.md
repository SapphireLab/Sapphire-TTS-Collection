# WaveNeXt

<details>
<summary>基本信息</summary>

- 标题: "WaveNeXt: ConvNeXt-Based Fast Neural Vocoder without ISTFT Layer"
- 作者:
  - 01 Takuma Okamoto,
  - 02 Haruki Yamashita,
  - 03 Yamato Ohtani,
  - 04 Tomoki Toda,
  - 05 Hisashi Kawai
- 链接:
  - [ArXiv]
  - [Publication](https://doi.org/10.1109/ASRU57964.2023.10389765)
  - [Github](https://www.okamotocamera.com/asru2023_wavenext.zip)
  - [Demo](https://ast-astrec.nict.go.jp/demo_samples/asru_2023_okamoto/index.html)
- 文件:
  - [ArXiv]
  - [Publication](_PDF/2312.00000p0__WaveNeXt__ConvNeXt-Based_Fast_Neural_Vocoder_without_ISTFT_Layer_ASRU2023.pdf)

</details>

## Abstract: 摘要

A recently proposed neural vocoder, Vocos, can perform inference ten times faster than HiFi-GAN because of its use of ConvNeXt layers that can predict high-resolution short-time Fourier transform (STFT) spectra and an inverse STFT layer.
To improve synthesis quality while preserving inference speed, this paper proposes an alternative ConvNeXt-based fast neural vocoder, WaveNeXt, in which the inverse STFT layer in Vocos is replaced with a trainable linear layer that can directly predict speech waveform samples without STFT spectra.
Additionally, by integrating the JETS-based end-to-end text-to-speech (E2E TTS) framework, E2E TTS models can also be constructed with Vocos and WaveNeXt.
Furthermore, full-band models with a sampling frequency of 48 kHz were investigated.
The results of experiments for both the analysis-synthesis and E2E TTS conditions demonstrate that the proposed WaveNeXt can achieve higher quality synthesis than Vocos while preserving its inference speed.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论