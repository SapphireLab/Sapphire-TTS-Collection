# HiFTNet

<details>
<summary>基本信息</summary>

- 标题: "HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise Filter and Inverse Short Time Fourier Transform"
- 作者:
  - 01 Yinghao Aaron Li,
  - 02 Cong Han,
  - 03 Xilin Jiang,
  - 04 Nima Mesgarani
- 链接:
  - [ArXiv](https://arxiv.org/abs/2309.09493)
  - [Publication]
  - [Github](https://github.com/yl4579/HiFTNet)
  - [Demo](https://hiftnet.github.io)
- 文件:
  - [ArXiv](_PDF/2309.09493v1__HiFTNet__A_Fast_High-Quality_Neural_Vocoder_with_Harmonic-plus-Noise_Filter_and_Inverse_Short_Time_Fourier_Transform.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Recent advancements in speech synthesis have leveraged GAN-based networks like HiFi-GAN and BigVGAN to produce high-fidelity waveforms from mel-spectrograms.
However, these networks are computationally expensive and parameter-heavy. iSTFTNet addresses these limitations by integrating inverse short-time Fourier transform (iSTFT) into the network, achieving both speed and parameter efficiency.
In this paper, we introduce an extension to iSTFTNet, termed HiFTNet, which incorporates a harmonic-plus-noise source filter in the time-frequency domain that uses a sinusoidal source from the fundamental frequency (F0) inferred via a pre-trained F0 estimation network for fast inference speed.
Subjective evaluations on LJSpeech show that our model significantly outperforms both iSTFTNet and HiFi-GAN, achieving ground-truth-level performance.
HiFTNet also outperforms BigVGAN-base on LibriTTS for unseen speakers and achieves comparable performance to BigVGAN while being four times faster with only 1/6 of the parameters.
Our work sets a new benchmark for efficient, high-quality neural vocoding, paving the way for real-time applications that demand high quality speech synthesis.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论