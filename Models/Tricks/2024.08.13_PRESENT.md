# PRESENT

<details>
<summary>基本信息</summary>

- 标题: PRESENT: Zero-Shot Text-to-Prosody Control
- 作者:
  - 01 [Perry Lam](../../Authors/Perry_Lam.md)
  - 02 [Huayun Zhang](../../Authors/Huayun_Zhang.md)
  - 03 [Nancy F. Chen](../../Authors/Nancy_F._Chen.md)
  - 04 [Berrak Sisman](../../Authors/Berrak_Sisman.md)
  - 05 [Dorien Herremans](../../Authors/Dorien_Herremans.md)
- 机构:
  - 机构 
- 时间:
  - 预印时间: 2024.08.13 ArXiv v1
  - 更新笔记: 2024.08.15
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.06827)
  - [DOI]()
  - [Github](https://github.com/iamanigeeit/present)
  - [Demo](https://present2023.web.app/)
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> Current strategies for achieving fine-grained prosody control in speech synthesis entail extracting additional style embeddings or adopting more complex architectures. To enable zero-shot application of pretrained text-to-speech (TTS) models, we present PRESENT (PRosody Editing without Style Embeddings or New Training), which exploits explicit prosody prediction in FastSpeech2-based models by modifying the inference process directly. We apply our text-to-prosody framework to zero-shot language transfer using a JETS model exclusively trained on English LJSpeech data. We obtain character error rates (CER) of 12.8\%, 18.7\% and 5.9\% for German, Hungarian and Spanish respectively, beating the previous state-of-the-art CER by over 2$\times$ for all three languages. Furthermore, we allow subphoneme-level control, a first in this field. To evaluate its effectiveness, we show that PRESENT can improve the prosody of questions, and use it to generate Mandarin, a tonal language where vowel pitch varies at subphoneme level. We attain 25.3\% hanzi CER and 13.0\% pinyin CER with the JETS model. % a state-of-the-art performance considering that the source model was trained on English only.
> All our code and audio samples are available online.
> Code: https://github.com/iamanigeeit/present
> Audio Samples: https://present2023.web.app/

## 1.Introduction: 引言

> Recent neural text-to-speech (TTS) models have approached human-like naturalness in read speech. However, attaining similar expressiveness levels remains a challenge. A growing body of research aims to add and control speech prosody variations, progressing from digital signal processing (DSP) methods to style and emotion embeddings built into TTS architectures or even entire models to extract and transfer prosody.
>
> On the waveform level, prosody control can be achieved through operations like time-stretching and pitch-shifting. DSP methods such as TD-PSOLA \cite{TD-PSOLA} and WORLD \cite{WORLD}, despite their known artifacts, are still widely applied due to their speed and ease of use. Remarkably, they can perform as effectively as neural approaches like Controllable LPCNet \cite{CLPCNet}.
>
> In contrast, expressive TTS systems \cite{expressive-tts} allow the user to specify a style or emotion label during inference. % Traditional methods rely on handcrafted rules specific to each emotion to directly manipulate the speech signal or statistical parameters during voice generation \cite{emotional-speech}.
> Recent TTS models incorporate style or emotion information by extracting a reference embedding that represents the prosody or emotion from labelled audio, and adding it to the model encoder. This can be combined with a style bank for smooth style variation, such as in Global Style Tokens \cite{gst}. Further extensions include phoneme-level prosody control and hierarchical autoencoders to ensure coherence over the whole utterance \cite{chive}. 
>
> All of these approaches, however, require extra model components and/or further training. Therefore, to combine the simplicity of DSP methods with the naturalness of neural speech generation, we empower users to directly control prosody using the input text and inference parameters without the need for any fine-tuning or architectural modifications. We contribute significantly in the following three areas:
>
> - \textbf{Extraction of prosodic effects from text}, such as extended duration in `A looooong time` or the intonation variations in questions like `What was that?`. We take these prosodic parameters and modify the inference method of any TTS model with explicit duration, pitch, and energy (DPE) predictions to generate varying speech.
> - \textbf{Zero-shot language transfer} with no target-language audio, relying solely on linguistic knowledge and modifying DPE to create new phonemes and speech patterns.
> -  \textbf{Subphoneme-level control}, achieved by subdividing phonemes and applying custom pitch and energy over the subdivisions, which helps us change long vowel intonation and model tonal languages like Mandarin.
>
> Though our primary goal is to explore the limits of editing inference-time prosody predictions, in doing so, we achieve state-of-the-art results in zero-shot language transfer.
> 
> The rest of this paper is organized as follows: Section 2 summarizes relevant research, Section 3 describes our approach, Section 4 lists our experiment results and Section 5 concludes our paper. 

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论

> We have introduced PRESENT, a novel approach that explores the limits of using only DPE predictions in a single-speaker English-only JETS model, without any additional embeddings or training. Our technique allows us to create prosodic effects from text and synthesize speech in unseen languages. % Among these tasks, we found that the subphoneme control mechanism we introduced is particularly well-suited for improving question prosody and enabling zero-shot language transfer to tonal languages.
> Our zero-shot language transfer far outstrips previous state-of-the-art for European languages. Furthermore, the phoneme conversion and tone contour techniques we develop could enable direct accented speech generation (as the results are all American-accented), or TTS for hundreds of tonal minority languages within the Mainland Southeast Asian linguistic area that are only recorded in phonetic transcriptions.
