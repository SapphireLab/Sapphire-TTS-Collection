# ParaNet

<details>
<summary>基本信息</summary>

- 标题: "Non-Autoregressive Neural Text-to-Speech"
- 作者:
  - 01 Kainan Peng
  - 02 Wei Ping
  - 03 Zhao Song
  - 04 Kexin Zhao
- 链接:
  - [ArXiv](https://arxiv.org/abs/1905.08459)
  - [Publication](https://proceedings.mlr.press/v119/peng20a)
  - [Github]
  - [Demo](https://parallel-neural-tts-demo.github.io)
- 文件:
  - [ArXiv](_PDF/1905.08459v3__ParaNet__Non-Autogressive_Neural_TTS.pdf)
  - [Publication](_PDF/1905.08459p0__ParaNet__ICML2020.pdf)

</details>

## Abstract: 摘要

<table>
<tr>
<td width="50%">

In this work, we propose ***ParaNet***, a non-autoregressive seq2seq model that converts text to spectrogram.
It is fully convolutional and brings 46.7 times speed-up over the lightweight **Deep Voice 3** at synthesis, while obtaining reasonably good speech quality.
***ParaNet*** also produces stable alignment between text and speech on the challenging test sentences by iteratively improving the attention in a layer-by-layer manner.
Furthermore, we build the parallel text-to-speech system and test various parallel neural vocoders, which can synthesize speech from text through a single feed-forward pass.
We also explore a novel VAE-based approach to train the inverse autoregressive flow (IAF) based parallel vocoder from scratch, which avoids the need for distillation from a separately trained WaveNet as previous work.

</td>
<td>

本项工作提出 ***ParaNet***, 一个非自回归的序列到序列模型, 将文本转换为频谱图.
它是完全卷积的且比轻量级的 **Deep Voice 3** 快 46.7 倍, 取得了相当好的语音质量.
***ParaNet*** 还能在具有挑战性的测试句子上产生稳定的文本-语音对齐, 通过逐层改进注意力来实现.
此外, 我们构建了并行文本-语音系统, 测试了各种并行神经语音合成器, 它们可以通过单个前馈传递将文本转换为语音.
我们还探索了一种新的基于 VAE 的**逆自回归流 (Inverse Autoregressive Flow, IAF)** 并行语音合成器的训练方法, 它避免了需要从单独训练的 WaveNet 进行蒸馏的先前工作.

</td>
</tr>
</table>

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论