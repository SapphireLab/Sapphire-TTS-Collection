# ParaNet

<details>
<summary>基本信息</summary>

- 标题: "Non-Autoregressive Neural Text-to-Speech"
- 作者:
  - 01 Kainan Peng
  - 02 Wei Ping
  - 03 Zhao Song
  - 04 Kexin Zhao
- 链接:
  - [ArXiv](https://arxiv.org/abs/1905.08459)
  - [Publication](https://proceedings.mlr.press/v119/peng20a)
  - [Github]
  - [Demo](https://parallel-neural-tts-demo.github.io)
- 文件:
  - [ArXiv](_PDF/1905.08459v3__ParaNet__Non-Autogressive_Neural_TTS.pdf)
  - [Publication](_PDF/1905.08459p0__ParaNet__ICML2020.pdf)

</details>

## Abstract: 摘要

In this work, we propose ParaNet, a non-autoregressive seq2seq model that converts text to spectrogram.
It is fully convolutional and brings 46.7 times speed-up over the lightweight Deep Voice 3 at synthesis, while obtaining reasonably good speech quality.
ParaNet also produces stable alignment between text and speech on the challenging test sentences by iteratively improving the attention in a layer-by-layer manner.
Furthermore, we build the parallel text-to-speech system and test various parallel neural vocoders, which can synthesize speech from text through a single feed-forward pass.
We also explore a novel VAE-based approach to train the inverse autoregressive flow (IAF) based parallel vocoder from scratch, which avoids the need for distillation from a separately trained WaveNet as previous work.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论