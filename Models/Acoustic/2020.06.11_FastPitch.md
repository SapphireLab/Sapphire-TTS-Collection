# FastPitch

<details>
<summary>基本信息</summary>

- 标题: "FastPitch: Parallel Text-to-speech with Pitch Prediction"
- 作者:
  - 01 Adrian Lancucki (NVIDIA)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2006.06873)
  - [Publication](https://doi.org/10.1109/ICASSP39728.2021.9413889)
  - [Github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/FastPitch)
  - [Demo](https://fastpitch.github.io/)
- 文件:
  - [ArXiv](_PDF/2006.06873v2__FastPitch__Parallel_TTS_with_Pitch_Prediction.pdf)
  - [Publication](_PDF/2006.06873p0__FastPitch__ICASSP2021.pdf)

</details>

## Abstract: 摘要

<table>
<tr>
<td width="50%">

We present FastPitch, a fully-parallel text-to-speech model based on FastSpeech, conditioned on fundamental frequency contours.
The model predicts pitch contours during inference.
By altering these predictions, the generated speech can be more expressive, better match the semantic of the utterance, and in the end more engaging to the listener.
Uniformly increasing or decreasing pitch with FastPitch generates speech that resembles the voluntary modulation of voice.
Conditioning on frequency contours improves the overall quality of synthesized speech, making it comparable to state-of-the-art.
It does not introduce an overhead, and FastPitch retains the favorable, fully-parallel Transformer architecture, with over 900× real-time factor for mel-spectrogram synthesis of a typical utterance.

</td>
<td>

</td>
</tr>
</table>

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论
