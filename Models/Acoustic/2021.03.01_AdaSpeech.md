# AdaSpeech

<details>
<summary>基本信息</summary>

- 标题: "AdaSpeech: Adaptive Text to Speech for Custom Voice"
- 作者:
  - 01 Mingjian Chen,
  - 02 Xu Tan,
  - 03 Bohan Li,
  - 04 Yanqing Liu,
  - 05 Tao Qin,
  - 06 Sheng Zhao,
  - 07 Tie-Yan Liu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2103.00993)
  - [Publication](https://openreview.net/forum?id=Drynvt7gg4L)
  - [Github]
  - [Demo](https://speechresearch.github.io/adaspeech/)
- 文件:
  - [ArXiv](_PDF/2103.00993v1__AdaSpeech__Adaptive_Text_to_Speech_for_Custom_Voice.pdf)
  - [Publication](_PDF/2103.00993p0__AdaSpeech__ICLR2021Poster.pdf)

</details>

## Abstract: 摘要

Custom voice, a specific text to speech (TTS) service in commercial speech platforms, aims to adapt a source TTS model to synthesize personal voice for a target speaker using few speech data.
Custom voice presents two unique challenges for TTS adaptation: 1) to support diverse customers, the adaptation model needs to handle diverse acoustic conditions that could be very different from source speech data, and 2) to support a large number of customers, the adaptation parameters need to be small enough for each target speaker to reduce memory usage while maintaining high voice quality.
In this work, we propose AdaSpeech, an adaptive TTS system for high-quality and efficient customization of new voices.
We design several techniques in AdaSpeech to address the two challenges in custom voice: 1) To handle different acoustic conditions, we use two acoustic encoders to extract an utterance-level vector and a sequence of phoneme-level vectors from the target speech during training; in inference, we extract the utterance-level vector from a reference speech and use an acoustic predictor to predict the phoneme-level vectors.
2) To better trade off the adaptation parameters and voice quality, we introduce conditional layer normalization in the mel-spectrogram decoder of AdaSpeech, and fine-tune this part in addition to speaker embedding for adaptation.
We pre-train the source TTS model on LibriTTS datasets and fine-tune it on VCTK and LJSpeech datasets (with different acoustic conditions from LibriTTS) with few adaptation data, e.g., 20 sentences, about 1 minute speech.
Experiment results show that AdaSpeech achieves much better adaptation quality than baseline methods, with only about 5K specific parameters for each speaker, which demonstrates its effectiveness for custom voice.
Audio samples are available at this https URL.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论