# AlignTTS

<details>
<summary>基本信息</summary>

- 标题: "AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit Alignment"
- 作者:
  - 01 Zhen Zeng,
  - 02 Jianzong Wang,
  - 03 Ning Cheng,
  - 04 Tian Xia,
  - 05 Jing Xiao
- 链接:
  - [ArXiv](https://arxiv.org/abs/2003.01950)
  - [Publication](https://doi.org/10.1109/ICASSP40776.2020.9054119)
  - [Github]
  - [Demo]
- 文件:
  - [ArXiv](_PDF/2003.01950v1__AlignTTS__Efficient_Feed-Forward_Text-to-Speech_System_without_Explicit_Alignment.pdf)
  - [Publication](_PDF/2003.01950p0__AlignTTS__ICASSP2020.pdf)

</details>

## Abstract: 摘要

<table><tr><td width="50%">

Targeting at both high efficiency and performance, we propose ***AlignTTS*** to predict the mel-spectrum in parallel.
***AlignTTS*** is based on a Feed-Forward Transformer which generates mel-spectrum from a sequence of characters, and the duration of each character is determined by a duration of predictor.
Instead of adopting the attention mechanism in Transformer TTS to align text to mel-spectrum, the alignment loss is presented to consider all possible alignments in training by use of dynamic programming.
Experiments on the LJSpeech dataset show that our model achieves not only state-of-the-art performance which outperforms Transformer TTS by 0.03 in mean option score (MOS), but also a high efficiency which is more than 50 times faster than real-time.

</td><td>

</td></tr></table>

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论