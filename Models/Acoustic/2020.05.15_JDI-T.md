# JDI-T

<details>
<summary>基本信息</summary>

- 标题: "JDI-T: Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment"
- 作者:
  - 01 Dan Lim,
  - 02 Won Jang,
  - 03 Gyeonghwan O,
  - 04 Heayoung Park,
  - 05 Bongwan Kim,
  - 06 Jaesam Yoon
- 链接:
  - [ArXiv](https://arxiv.org/abs/2005.07799)
  - [Publication](https://doi.org/10.21437/Interspeech.2020-2123)
  - [Github]()
  - [Demo](https://imdanboy.github.io/interspeech2020)
- 文件:
  - [ArXiv](_PDF/2005.07799v3__JDI-T__Jointly_Trained_Duration_Informed_Transformer_for_Text-to-Speech_without_Explicit_Alignment.pdf)
  - [Publication](_PDF/2005.07799p0__JDI-T__InterSpeech2020.pdf)

</details>

## Abstract: 摘要

We propose Jointly trained Duration Informed Transformer (JDI-T), a feed-forward Transformer with a duration predictor jointly trained without explicit alignments in order to generate an acoustic feature sequence from an input text.
In this work, inspired by the recent success of the duration informed networks such as FastSpeech and DurIAN, we further simplify its sequential, two-stage training pipeline to a single-stage training.
Specifically, we extract the phoneme duration from the autoregressive Transformer on the fly during the joint training instead of pretraining the autoregressive model and using it as a phoneme duration extractor.
To our best knowledge, it is the first implementation to jointly train the feed-forward Transformer without relying on a pre-trained phoneme duration extractor in a single training pipeline.
We evaluate the effectiveness of the proposed model on the publicly available Korean Single speaker Speech (KSS) dataset compared to the baseline text-to-speech (TTS) models trained by ESPnet-TTS.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论