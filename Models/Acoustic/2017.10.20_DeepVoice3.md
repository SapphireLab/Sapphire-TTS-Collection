# DeepVoice3

<details>
<summary>基本信息</summary>

- 标题: "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning"
- 作者:
  - 01 Wei Ping
  - 02 Kainan Peng
  - 03 Andrew Gibiansky
  - 04 Sercan O.Arik
  - 05 Ajay Kannan
  - 06 Sharan Narang
  - 07 Jonathan Raiman
  - 08 John Miller
- 链接:
  - [ArXiv](https://arxiv.org/abs/1710.07654)
  - [Publication](https://openreview.net/forum?id=HJtEm4p6Z)
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv]()
  - [Publication] #TODO

</details>

## Abstract: 摘要

<table><tr><td width="50%">

We present ***DeepVoice3***, a fully-convolutional attention-based neural text-to-speech (TTS) system.
***DeepVoice3*** matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster.
We scale ***DeepVoice3*** to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers.
In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods.
We also describe how to scale inference to ten million queries per day on one single-GPU server.

</td><td>

我们展示了 ***DeepVoice3***, 一个完全卷积的基于注意力的神经文本转语音系统.
***DeepVoice3*** 在自然度上与最先进的神经语音合成系统相匹配, 并训练速度提高了10倍.
我们将 ***DeepVoice3*** 扩展到超越以往任何数据集大小, 训练了超过两千多位演讲者的 800 多小时音频.
此外, 我们发现基于注意力的语音合成网络的常见错误模式, 并演示了如何缓解它们, 并比较了几种不同的波形合成方法.
我们还描述了如何将推理扩展到在单 GPU 服务器上一天 10 亿次查询.

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td></tr></table>
