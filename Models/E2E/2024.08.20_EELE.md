# EELE


<details>
<summary>基本信息</summary>

- 标题: EELE: Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech
- 作者:
  - 01 [Xin Qi](../../Authors/Xin_Qi.md)
  - 02 [Ruibo Fu](../../Authors/Ruibo_Fu.md)
  - 03 [Zhengqi Wen](../../Authors/Zhengqi_Wen.md)
  - 04 [Jianhua Tao](../../Authors/Jianhua_Tao.md)
  - 05 [Shuchen Shi](../../Authors/Shuchen_Shi.md)
  - 06 [Yi Lu](../../Authors/Yi_Lu.md)
  - 07 [Zhiyong Wang](../../Authors/Zhiyong_Wang.md)
  - 08 [Xiaopeng Wang](../../Authors/Xiaopeng_Wang.md)
  - 09 [Yuankun Xie](../../Authors/Yuankun_Xie.md)
  - 10 [Yukun Liu](../../Authors/Yukun_Liu.md)
  - 11 [Guanjun Li](../../Authors/Guanjun_Li.md)
  - 12 [Xuefei Liu](../../Authors/Xuefei_Liu.md)
  - 13 [Yongwei Li](../../Authors/Yongwei_Li.md)
- 机构:
  - 机构 
- 时间:
  - 预印时间: 2024.08.20 ArXiv v1
  - 更新笔记: 2024.08.21
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.10852)
  - [DOI]()
  - [Github]()
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> In the current era of Artificial Intelligence Generated Content (AIGC), a Low-Rank Adaptation (LoRA) method has emerged. It uses a plugin-based approach to learn new knowledge with lower parameter quantities and computational costs, and it can be plugged in and out based on the specific sub-tasks, offering high flexibility. However, the current application schemes primarily incorporate LoRA into the pre-introduced conditional parts of the speech models. This fixes the position of LoRA, limiting the flexibility and scalability of its application. 
> Therefore, we propose the Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech (EELE) method. Starting from a general neutral speech model, we do not pre-introduce emotional information but instead use the LoRA plugin to design a flexible adaptive scheme that endows the model with emotional generation capabilities. Specifically, we initially train the model using only neutral speech data. After training is complete, we insert LoRA into different modules and fine-tune the model with emotional speech data to find the optimal insertion scheme. Through experiments, we compare and test the effects of inserting LoRA at different positions within the model and assess LoRA's ability to learn various emotions, effectively proving the validity of our method. Additionally, we explore the impact of the rank size of LoRA and the difference compared to directly fine-tuning the entire model.

在当前人工智能生成内容（AIGC）时代，出现了一种低阶自适应（LoRA）方法。它使用基于插件的方法以较低的参数量和计算成本学习新知识，并且可以根据特定的子任务插入和插入，提供了很高的灵活性。然而，当前的应用方案主要将LoRA合并到预先引入的语音模型的条件部分中。这固定了LoRA的位置，限制了其应用程序的灵活性和可扩展性。因此，我们提出了在情感文本到语音（EELE）方法中探索有效且可扩展的LoRA集成。从一般的中性语音模型开始，我们不预先引入情感信息，而是使用LoRA插件来设计一个灵活的自适应方案，赋予模型情感生成能力。具体来说，我们最初只使用中性语音数据来训练模型。训练完成后，我们将LoRA插入到不同的模块中，并用情感语音数据对模型进行微调，以找到最佳插入方案。通过实验，我们比较和测试了在模型内不同位置插入LoRA的效果，并评估了LoRA学习各种情绪的能力，有效地证明了我们方法的有效性。此外，我们还探讨了LoRA的秩大小的影响以及与直接微调整个模型相比的差异。

## 1.Introduction: 引言

> The development of text-to-speech (TTS) has reached a point where it can generate very high-quality speech. 
> For example, VITS \cite{kim2021conditional} and Grad-TTS \cite{popov2021grad} have incorporated complex neural network architectures and training strategies to generate results that are very close to real speech.
> In this field, emotion generation has always been a hot topic that researchers are constantly exploring.
> Adding emotion to speech not only enhances the realism of generated results, but also has significant application value in various real-life scenarios, such as in movies, games, and voice acting.
>
> There has been a significant amount of work on emotion TTS, but most of these approaches incorporate emotional information during the initial model training stage.
> These approaches can be broadly categorized into three types: directly providing emotion categories, predicting emotions from text, and extracting emotions from reference speech.
> In the approach that directly provides emotion categories, C Cui et al. \cite{cui2021emovie} directly provide emotion labels, which are sent into the emotion predictor along with the results from the text encoder. The generated emotional information is then fed into the subsequent parts of the model.
> In the approach that predicts emotions from text, Tu et al. \cite{tu2022contextual} argue that emotional labels depend on the contextual situation rather than specific tags. Therefore, they predict emotions by modeling the context.
> In the approach that extracts emotions from reference audio, S. Oh et al. \cite{oh2019determination} proposed the Global Style Token (GST) method. This method encodes reference audio and combines it with global emotion labels through attention mechanisms, using the result as an emotional embedding. R. Liu et al. \cite{liu2021reinforcement} employed a similar approach, adding emotion recognition for adversarial training to improve the accuracy of label generation. Additionally, D. Min et al. \cite{min2021meta} directly encoded the style of the reference audio and fed the result into the model. Kang et al. \cite{kang2023grad} utilized a diffusion model for speech synthesis, incorporating the encoded result into the diffusion steps.
>
> Despite the outstanding emotional expression achieved by these methods, their inclusion of emotion information during training limits the inference stage to a fixed number of emotion categories, resulting in insufficient scalability and flexibility.
> In the current context of the booming development of AIGC technology, fine-tuning large models with all parameters requires a significant amount of computational cost. Therefore, the LoRA \cite{hu2021LoRA} plugin method has emerged. It records new knowledge by freezing the original parameters of the model and multiplying two low-rank matrices. When facing different downstream segmentation tasks, LoRA can train multiple sets of plugins to achieve plug-and-play simultaneously.
>
> Due to the low computational cost and flexibility of LoRA, many related works have emerged.
> V Shah et al. \cite{shah2023zipLoRA} used LoRA to independently learn the style and content of images, achieving arbitrary combinations of style and content.
> CP Hsieh et al. \cite{hsieh2022adapter} inserted LoRA into the attention mechanism of the FastPitch \cite{lancucki2021fastpitch} model to learn the timbre differences between unseen and seen speakers, enabling the model to synthesize speech for new speakers.
> Z Song et al. \cite{song2024LoRA} utilized LoRA to capture language-specific features, enabling multilingual speech recognition.
> Additionally, there are some related variants.
> Y Wang et al. \cite{wang2024residualtransformer} additionally introduced diagonal weight matrices to enhance the modeling capability of low-rank matrices.
> S. Hayou et al. \cite{hayou2024LoRA+} set different learning rates for two low-rank matrices to improve model training efficiency.
> L. Zhang et al. \cite{zhang2023LoRA} froze one of the two low-rank matrices and trained only the other matrix independently. This halved the number of parameters while maintaining performance comparable to standard LoRA techniques.
>
> Although there are many applications and improvements of LoRA, most of them are limited to adjusting the condition part of the model, which requires the model to pre-introduce control information. This actually limits the potential for further expansion of the model's functionality. Therefore, we propose the Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech (EELE) method.
> We use the VITS2 model \cite{kong2023vits2} as our baseline, training the model with neutral speech data.
> Subsequently, we added LoRA to different modules within the model and fine-tuned it with emotional speech data, using subjective and objective experiments to verify and test the impact of adding LoRA at different positions. We also trained a separate set of LoRA for each emotion to test LoRA's ability to learn different emotions. After endowing the neutral model with emotional generation capabilities, we further explore the impact of the rank size of LoRA and the difference compared to directly fine-tuning the entire model.
> The main contributions in this paper are as follows:
> - We have explored a more flexible and scalable approach for emotion adaptation in speech models.
> - Through experiments, we tested the impact of deploying the LoRA module at different positions on emotional synthesis and validated the effectiveness of the proposed method.
> - We tested and validated the impact of rank size on LoRA's emotional learning ability and compared the optimal scheme of adding LoRA with the approach of fine-tuning the entire model.

语音合成发展至今已经能合成十分高质量的语音。
如 VITS \cite{kim2021conditional}和Grad-TTS\cite{popov2021grad}，通过引入复杂的神经网络结构和训练策略，已经能够生成非常接近真实音频的结果。
在这个领域中，情感生成一直是研究者们不断深挖的热点。
让语音变得有情感，不仅可以提高生成结果的真实性，在现实诸多的生活场景中例如在电影、游戏、配音等也有极高的应用价值。

关于语音情感生成的工作有很多，但他们主要都是在一开始的模型训练阶段就加入情感信息。
大致上可以分为三类，直接给出情感类别、从文本中预测以及从参考音频中提取。
在直接给出情感类别的技术路线上，C Cui \cite{cui2021emovie}等人直接给出情感标签，连同文本编码器的结果一起送入情感预测器中，生成情感信息送入到模型的后续部分。
对于从文本预测的技术路线上，Tu \cite{tu2022contextual}认为情感的标签取决于上下文语境而非特定标签，因此通过上下文的建模来预测情感。
对于从参考音频提取情感的技术路线上，S Oh\cite{oh2019determination}等人提出了gloabl style token（GST）的方法，通过将参考音频进行编码与全局情感标签经过注意力计算，将计算结果作为情感嵌入。R Liu\cite{liu2021reinforcement}等人也采取了相同的方法，他们又额外添加的情感识别来进行对抗训练，从而提升标签生成的准确度。另外D Min\cite{min2021meta}直接将参考音频进行风格编码，将结果送入到模型中。Kang\cite{kang2023grad}则是利用扩散模型进行语音合成，将编码结果送入到扩散步骤当中。

尽管他们的方法具有出色情感表现，但由于其在训练时就加入情感信息的特点，这导致后面推理时只能推断特定数量的情感类别，可拓展性和灵活性不足。
在现如今AIGC技术蓬勃发展的背景下，全参数微调大模型需要耗费大量的计算成本。因此LoRA插件方法应运而生。它通过冻结模型原本的参数，用两个相乘的低秩矩阵记录新知识。并且LoRA面对不同的下游细分任务时可以训练多套插件同时实现即插即用。

由于LoRA计算成本低且灵活的特点，出现了很多相关工作。
- V Shah\cite{shah2023zipLoRA}等人用LoRA分别对图像的风格和内容进行独立学习，并实现任意风格和内容的组合。
- CP Hsieh \cite{hsieh2022adapter}等人在FastPitch \cite{lancucki2021fastpitch}模型的attention机制中插入LoRA学习未见说话人与已见说话人之间的音色区别，让模型能够合成新说话人的语音。
- Z Song \cite{song2024LoRA}等人利用LoRA来记录语言类别特征，实现多语言的语音识别。

另外还有一些相关的变体。
- Y Wang等人 \cite{wang2024residualtransformer}额外添加了对角权重矩阵以提高低秩矩阵的建模能力。
- S Hayou等人 \cite{hayou2024LoRA}将两个低秩矩阵设置了不同的学习率，提高模型训练效率。
- L Zhang等人 \cite{zhang2023LoRA}将两个低秩矩阵的其中一个冻结，只单独训练了一个矩阵。这样，参数数量减少了一半，而性能却与使用普通 LoRA 技术相当。

虽然目前已经有很多LoRA的应用与改进，但他们大多只局限于调整模型的condition部分，即需要模型预先引入控制信息。这其实限制了模型功能进一步拓展的可能。因此我们提出 Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech (EELE) method.
我们以 VITS2 \cite{kong2023vits2}模型作为基线，用中性语料训练模型。
之后我们在模型不同模块内添加LoRA并用情感语料微调，用主观和客观实验来验证和测试LoRA添加在不同位置的影响。我们还为每一种情感都单独训练了一套LoRA来测试LoRA对不同情感的学习效果。赋予中性模型情感生成能力后，我们还验证了秩大小对LoRA情感学习能力的影响，并且我们还比较了与直接微调的效果差异。

主要贡献如下：
- 探索了一种更加灵活、拓展性更强的语音模型情感自适应方案。
- 通过实验测试了LoRA模块不同部署位置对情感合成效果的影响，并验证了所提方法的有效性。
- 测试和验证秩大小对LoRA情感学习能力的影响，并将添加LoRA的最优方案与微调整个模型做了比较。

## 2.Related Works: 相关工作

None

## 3.Methodology: 方法

> This section mainly introduces our various attempts to add emotional generation capabilities to the neutral synthesis model using LoRA, as well as the models and methods we used.
>
> We explored using the current mainstream VITS2 model \cite{kong2023vits2}. We added LoRA modules to the model using Microsoft's open-source LoRAlib package \cite{hu2022LoRA}. We experimented with eight different combinations of adding LoRA, as shown in Figure \ref{all_try}.
>
> The VITS2 \cite{kong2023vits2} model utilizes GAN \cite{creswell2018generative} mechanisms during training. Since the discriminator does not participate in the inference process, its parameters are not frozen during fine-tuning. Similarly, the speech encoder also follows this approach.

本节主要介绍我们利用LoRA为中性合成模型添加情感生成能力所做的各种尝试，以及我们所用模型和方法。
我们用目前主流的VITS2\cite{kong2023vits2}模型进行探索。用微软开源的LoRAlib包\cite{hu2022LoRA}为模型添加LoRA模块。我们进行了8种不同添加LoRA的组合如图1所示\ref{all_try}.
VITS2模型在训练时用到了GAN的机制，由于判别器不参与推理过程，因此不考虑在微调时将其冻结参数。同时这样做的还有音频的编码器。

### 3.1.Where to add: Exploring the deployment of LoRA

> A text encoder is responsible for extracting text features. A stochastic duration predictor estimates duration features from these text features. The projection layer determines the sampling distribution. The flow layer converts the sampling results into acoustic features, and the decoder transforms these acoustic features into a speech waveform.
> 
> From the functions of these modules, it can be seen that the text encoder and projection layer are mainly responsible for front-end modeling, the flow layer and decoder are responsible for back-end modeling, and the duration predictor is responsible for modeling alignment information. So when adding LoRA to the model, it is mainly divided into these three categories for design. 
> 
> We integrated LoRA in eight different ways, as shown in Figure \ref{all_try}, to explore whether emotion is more suitable for modeling in the front-end text features or in the back-end acoustic features. Additionally, we investigated the impact of duration alignment information on emotional expression.

文本编码器负责得到文本特征，随机时长预测器从文本特征中预测时长特征，映射层负责得到采样分布，流模型将采样结果转换为声学特征，解码器将声学特征解码为音频波形。
从这些模块的作用可以看出：文本编码器和投影层主要负责前端的建模，flow层和解码器负责后端的建模，时长预测器负责建模对齐信息。所以将LoRA添加到模型当中时主要分为这三个大类来设计。
我们按照图\ref{all_try}的八种方式添加了LoRA，来探索情感是更适合建模在前端的文本特征中，还是更适合建模在后端的声学特征中。并且探索了时长对齐信息对情感表现的影响。

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论

In this paper, we introduced the EELE method, using LoRA to enable neutral TTS models to generate emotional speech without requiring emotion-specific training. This plug-and-play solution proved effective, creating a flexible, scalable emotional TTS system. Evaluations confirmed its ability to enhance emotional expression, with applications in movies, games, and voice acting. The EELE method advances adaptable emotional TTS systems, contributing to AI-generated content, with future work focusing on refining LoRA integration and broadening emotional expression.

在本文中，我们介绍了 ***EELE: Grant Synthetic Speech Emotions Using LoRA*** 方法，该方法利用 LoRA 插件来赋予中性语音模型情感生成能力。我们的方法解决了传统情感TTS模型的局限性，即在初始训练期间需要情感类别信息，从而限制了它们的灵活性和可扩展性。通过利用LoRA，我们提供了一种新的解决方案，允许以即插即用的方式将情感能力添加到预先训练的中性TTS模型中。
我们的实验证明了在模型内不同位置添加LoRA的效果，我们使用4种类别的情感语音数据训练了4套LoRA情感模块。这产生了一个高度灵活和可扩展的情绪TTS系统，该系统能够生成不同的情绪，而不需要从头开始重新训练整个模型。
主观和客观评估证实了我们方法的优越性，突出了它通过提供一种具有成本效益和适应性的解决方案来彻底改变情感TTS领域的潜力。EELE方法不仅提高了合成语音的情感表现，而且在电影、游戏和配音等应用中具有重要的实用价值。
总之，我们的工作为更灵活和可扩展的情感TTS系统铺平了道路，有助于人工智能生成内容的发展。未来的工作可能会探索LoRA集成的进一步优化，并扩大情感表达的范围，以增强TTS应用程序的多功能性。
