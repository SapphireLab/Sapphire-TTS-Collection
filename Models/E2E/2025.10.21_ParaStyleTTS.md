# ParaStyleTTS: Toward Efficient and Robust Paralinguistic Style Control for Expressive Text-to-Speech Generation

<details>
<summary>基本信息</summary>

- 标题: "ParaStyleTTS: Toward Efficient and Robust Paralinguistic Style Control for Expressive Text-to-Speech Generation."
- 作者:
  - 01 Haowei Lou
  - 02 Hye-Young Paik
  - 03 Wen Hu
  - 04 Lina Yao
- 链接:
  - [ArXiv](https://arxiv.org/abs/2510.18308v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2510.18308v1](PDF/2025.10.21_2510.18308v1_ParaStyleTTS__Toward_Efficient_and_Robust_Paralinguistic_Style_Control_for_Expressive_Text-to-Speech_Generation.pdf)
  - [Publication] #TODO

</details>

## Abstract

<table><tr><td width="50%">

Controlling speaking style in text-to-speech (TTS) systems has become a growing focus in both academia and industry.
While many existing approaches rely on reference audio to guide style generation, such methods are often impractical due to privacy concerns and limited accessibility.
More recently, large language models (LLMs) have been used to control speaking style through natural language prompts; however, their high computational cost, lack of interpretability, and sensitivity to prompt phrasing limit their applicability in real-time and resource-constrained environments.
In this work, we propose ParaStyleTTS, a lightweight and interpretable TTS framework that enables expressive style control from text prompts alone.
ParaStyleTTS features a novel two-level style adaptation architecture that separates prosodic and paralinguistic speech style modeling.
It allows fine-grained and robust control over factors such as emotion, gender, and age.
Unlike LLM-based methods, ParaStyleTTS maintains consistent style realization across varied prompt formulations and is well-suited for real-world applications, including on-device and low-resource deployment.
Experimental results show that ParaStyleTTS generates high-quality speech with performance comparable to state-of-the-art LLM-based systems while being 30x faster, using 8x fewer parameters, and requiring 2.5x less CUDA memory.
Moreover, ParaStyleTTS exhibits superior robustness and controllability over paralinguistic speaking styles, providing a practical and efficient solution for style-controllable text-to-speech generation.
Demo can be found at \url{https://parastyletts.github.io/ParaStyleTTS_Demo/}.
Code can be found at \url{https://github.com/haoweilou/ParaStyleTTS}.

</td><td>

</td></tr></table>
