# YourTTS

<details>
<summary>基本信息</summary>

- 标题: YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for Everyone
- 作者:
  - 01 [Edresson Casanova](../../Authors/Edresson_Casanova.md)
  - 02 [Julian Weber](../../Authors/Julian_Weber.md)
  - 03 [Christopher Shulby](../../Authors/Christopher_Shulby.md)
  - 04 [Arnaldo Candido Junior](../../Authors/Arnaldo_Candido_Junior.md)
  - 05 [Eren Golge](../../Authors/Eren_Golge.md)
  - 06 [Moacir Antonelli Ponti](../../Authors/Moacir_Antonelli_Ponti.md)
- 机构:
  - [Coqui.AI](../../Institutions/Coqui.AI.md)
- 时间:
  - 预印时间: 2021.12.04 ArXiv v1
  - 预印时间: 2022.01.29 ArXiv v2
  - 预印时间: 2022.02.16 ArXiv v3
  - 预印时间: 2023.04.30 ArXiv v4
  - 更新笔记: 2024.06.18
- 发表:
  - [ICML](../../Publications/ICML.md)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2112.02418)
  - [DOI](https://proceedings.mlr.press/v162/casanova22a.html)
  - [Github](https://github.com/coqui-ai/TTS)
  - [Demo](https://edresson.github.io/YourTTS/)
  - [Scholar](https://scholar.google.com/scholar?cluster=8575580251111777245)
- 标签:
  - [语音合成](../../Tags/SpeechSynthesis.md)
  - [声音转换](../../Tags/VoiceConversion.md)
  - [开源](../../Tags/OpenSource.md)
  - [零样本](../../Tags/Zero-Shot.md)
  - [多说话人](../../Tags/Multi-Speaker.md)
- 页数: 12
- 引用: 46
- 被引: 231
- 数据:

</details>

## Abstract: 摘要

> YourTTS brings the power of a multilingual approach to the task of zero-shot multi-speaker TTS. Our method builds upon the VITS model and adds several novel modifications for zero-shot multi-speaker and multilingual training. We achieved state-of-the-art (SOTA) results in zero-shot multi-speaker TTS and results comparable to SOTA in zero-shot voice conversion on the VCTK dataset. Additionally, our approach achieves promising results in a target language with a single-speaker dataset, opening possibilities for zero-shot multi-speaker TTS and zero-shot voice conversion systems in low-resource languages. Finally, it is possible to fine-tune the YourTTS model with less than 1 minute of speech and achieve state-of-the-art results in voice similarity and with reasonable quality. This is important to allow synthesis for speakers with a very different voice or recording characteristics from those seen during training.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Conclusions: 结论
