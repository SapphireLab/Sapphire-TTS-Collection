# FlowMAC

<details>
<summary>基本信息</summary>

- 标题: "FlowMAC: Conditional Flow Matching for Audio Coding at Low Bit Rates"
- 作者: 
  - 01 Nicola Pia
  - 02 Martin Strauss
  - 03 Markus Multrus 
  - 04 Bernd Edler
- 链接: 
  - [ArXiv](https://arxiv.org/abs/2409.17635)
  - [Publication] Submitted to ICASSP 2025
  - [Github]
  - [Demo]
- 文件: 
  - [ArXiv](_PDF/2409.17635v1__FlowMAC__Conditional_Flow_Matching_for_Audio_Coding_at_Low_Bit_Rates.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

This paper introduces ***FlowMAC***, a novel neural audio codec for high-quality general audio compression at low bit rates based on conditional flow matching (CFM). 
***FlowMAC*** jointly learns a mel spectrogram encoder, quantizer and decoder. 
At inference time the decoder integrates a continuous normalizing flow via an ODE solver to generate a high-quality mel spectrogram. 
This is the first time that a CFM-based approach is applied to general audio coding, enabling a scalable, simple and memory efficient training. 
Our subjective evaluations show that ***FlowMAC*** at 3 kbps achieves similar quality as state-of-the-art GAN-based and DDPM-based neural audio codecs at double the bit rate. 
Moreover, ***FlowMAC*** offers a tunable inference pipeline, which permits to trade off complexity and quality. 
This enables real-time coding on CPU, while maintaining high perceptual quality.

</details>
<br>

本文介绍 ***FlowMAC***, 一种新式神经音频编解码器, 基于条件流匹配 (Conditional Flow Matching, CFM) 在低比特率下实现高质量的通用音频压缩.
***FlowMAC*** 联合学习梅尔频谱编码器, 量化器和解码器.
在推理时, 解码器通过 ODE 求解器整合连续标准化流以生成高质量的梅尔频谱.
这是首次将基于条件流匹配的方法应用于通用音频编码, 实现可扩展, 简单且内存高效的训练.
我们的主观评估展示了 ***FlowMAC*** 在 3 kbps 时获得和当前最佳的基于 GAN 和 DDPM 的神经音频编解码器在双倍比特率下的相似质量.
此外, ***FlowMAC*** 提供了一个可调的推理管道, 提供复杂度和质量之间的权衡.
这能够在保持高感知质量的同时, 在 CPU 上实现实时编码.


## 1.Introduction: 引言

<details>
<summary>展开原文</summary>

In the modern digital world, audio codecs are used on a day-to-day basis, so every technological advancement can have a large impact.
In recent years, deep neural networks (DNNs) revolutionized the field of audio compression.
Early approaches~\cite{firstnn_coding,knet_coding,zhen2020efficientscalableneuralresidual} control the compression at via entropy-based losses and ensure good quality via reconstruction losses. 
With the advent of deep generative models the quality of neural codecs at bit rates lower than 12\,kbps greatly improved. 

While for speech coding many different approaches were proven to be successful~\cite{wavenet_coding,lpcnet_coding,ssmgan,cascade_coding}, the general audio codec SoundStream~\cite{soundstream} established a new paradigm of training a residual VQ-VAE~\cite{vq_vae} via an additional GAN loss end-to-end (e2e).
For this, a DNN-encoder extracts a learned latent, a residual VQ generates the bit stream, and a DNN-decoder synthesizes the audio.
All the modules are jointly learned via a combination of multiple spectral reconstruction, VQ-VAE codebook and commitment and adversarial losses.

Various improvements on the design of SoundStream were proposed afterwards.
EnCodec~\cite{defossez2023encodec} used recurrent networks and an improved compression capability via entropy coding based on language models in the quantizer.
The Descript-Audio-Codec (DAC)~\cite{dac} achieved high quality extending on the model size, using innovative audio-specific activations~\cite{snake}, and scaling up the discriminator architecture.

The e2e VQ-GAN approach offers a great flexibility in the design and complexity of the codec~\cite{tfnet,pia22_interspeech,funcodec}.
However, it often entails a complicated and unstable training pipeline, which sometimes fails to meet quality expectations for challenging signal types, particularly at bit rates lower than 6\,kbps.

Denoising Diffusion Probabilistic Models (DDPMs) were proposed recently for speech~\cite{ladiffcodec} and general audio~\cite{NEURIPS2023_MDB,liu2024semanticodecultralowbitrate}.
While~\cite{liu2024semanticodecultralowbitrate} targets semantic coding at ultra low bit rates, MultiBandDiffusion (MBD)~\cite{NEURIPS2023_MDB} is a decoder model that enables high-quality synthesis of the EnCodec latent at 1.5, 3 and 6\,kbps for general audio.
This model uses a time-domain subband-based decoding scheme and achieves state-of-the-art quality for music.
The high complexity of this model makes it hard to use in embedded devices and its dependency on a pre-trained bit stream might limit its compression capabilities.

VQ-GANs entail a highly involved training pipeline and the existing DDPMs are computationally heavy models.
This demonstrates the need for a solution that is easy to train, while offering high quality performance at acceptable complexity.

Recently, a new paradigm to train continuous normalizing flows (CNFs) called conditional flow matching (CFM) emerged~\cite{lipman2023flow} and demonstrated state-of-the-art quality for both image~\cite{esser2024scalingrectifiedflowtransformers} and audio generation~\cite{matcha, p_flow, le2023voicebox}.
This approach offers a simple training pipeline at much lower inference and training costs compared to DDPMs. 

In this work, we present the \textbf{Flow} \textbf{M}atching \textbf{A}udio \textbf{C}odec (\textbf{FlowMAC}), a new audio compression model for low bit rate coding of general audio at $24$\,kHz audio based on CFM.
Our proposed approach learns a mel spectrogram encoder, residual VQ, and decoder via a combination of a simple reconstruction loss and the CFM objective.
The CFM-based decoder generates realistic mel spectrograms from the discrete latent, which is then converted to waveform domain via an efficient version of BigVGAN~\cite{lee2023bigvgan}.
The model design is simple and the training pipeline is stable and efficient.

Our contributions can be summarized as follows: 
- We introduce FlowMAC, a CFM-based mel spectrogram codec offering a simple and efficient training pipeline.
- Our listening test results demonstrate that FlowMAC achieves state-of-the-art quality at 3\,kbps matching GAN-based and DDPM-based solutions at double the bit rate.
- We propose an efficient version of FlowMAC capable of coding at high quality and faster than real time on a CPU.

</details>
<br>

## 2.Flow Matching Fundamentals: 流匹配基础

<details>
<summary>展开原文</summary>

For neural audio coding, we learn an encoder-decoder architecture that compresses input mel spectrograms into a quantized bit stream.
We then use the information from this bit stream to condition a CFM-based mel spectrogram decoder for high-quality mel spectrogram generation.
To this end, we consider the distribution $q$ of mel spectrograms of the input audio signals and we learn a time-dependent vector field $\mathbf{u}_t$, whose flow transforms a Gaussian prior $p_0$ into $q$.

Flow matching~\cite{lipman2023flow} describes a method to fit a time-dependent probability density path $p_t:[0,1] \times \mathbb{R}^d \rightarrow \mathbb{R}^{\ge 0}$ between a simple sampling distribution $p_0(\mathbf{x})$ and the target data distribution $q(\mathbf{x})$, where $t \in [0,1]$ and $\mathbf{x} \in \mathbb{R}^d$.
More precisely it defines a framework to train a CNF $\phi_t$ via learning its associated vector field $\mathbf{u}_t$ directly.

Following Section 4.1 in~\cite{lipman2023flow} we define 

\[
p_t(\mathbf{x}|\mathbf{x}_1) = \mathcal{N}\left(\mathbf{x}; \mu_t(\mathbf{x}_1), \sigma_t(\mathbf{x}_1)^2\mathbf{I}\right),
\]

\noindent where $\mathbf{x}_1\sim q(\mathbf{x}_1)$ sampled from the train set, $\mu_t(x) = t \mathbf{x}_1$, and $\sigma_t = 1 - (1 - \sigma_\text{min})t$ with $\sigma_\text{min} \ll 1$.
This defines a Gaussian path where $p_0$ is the standard Gaussian and $p_1$ is a Gaussian centered at $\mathbf{x}_1$ with small variance.
Theorem 3 in \cite{lipman2023flow} shows that this probability path is generated by the Optimal Transport Conditional Vector Field

\[
\mathbf{u}_t(\mathbf{x}|\mathbf{x}_1) = \frac{\mathbf{x}_1 - (1 - \sigma_\text{min})\mathbf{x}}{1 - (1 - \sigma_\text{min})t}.
\]

This yields the conditional flow matching objective

\[
\begin{aligned}
	\mathcal{L}_{\textup{CFM}}(\theta) 
  &= \mathbb{E}_{t,q(\mathbf{x}_1),p_t(\mathbf{x}|\mathbf{x}_1)} \|\mathbf{v}_t(\mathbf{x};\theta) - \mathbf{u}_t(\mathbf{x}|\mathbf{x}_1)\|^2\\
	& = \mathbb{E}_{t,q(\mathbf{x}_1),p_0(\mathbf{x}_0)} \|\mathbf{v}_t(\mathbf{x};\theta) - \left(\mathbf{x}_1 - (1 - \sigma_\text{min})\mathbf{x}_0\right)\|^2
\end{aligned}
\]

where $\mathbf{v}_t(\mathbf{x}, \theta)$ denotes a DNN parametrized by $\theta$, the time step $t \sim \mathbb{U}[0,1]$ is sampled from a uniform distribution.

For our system the neural network $\mathbf{v}_t(\mathbf{x};\theta)$ is additionally conditioned on the decoded bit stream $c$ obtained from a learned mel spectrogram compression network.
During inference, $\mathbf{v}_t$ takes $c$ as input and a Gaussian noise sample $\mathbf{x}_0$ and outputs the derivatives of the corresponding CNF.
This flow is then integrated using an ODE solver, e.g. the Euler method.

</details>
<br>

