# LFSC (Low Frame-rate Speech Codec)

- 标题: Low Frame-rate Speech Codec: a Codec Designed for Fast High-quality Speech LLM Training and Inference

## Abstract: 摘要

> Large language models (LLMs) have significantly advanced audio processing through audio codecs that convert audio into discrete tokens, enabling the application of language modeling techniques to audio data. 
> However, audio codecs often operate at high frame rates, resulting in slow training and inference, especially for autoregressive models. 
> To address this challenge, we present the ***Low Frame-rate Speech Codec (LFSC)***: a neural audio codec that leverages finite scalar quantization and adversarial training with large speech language models to achieve high-quality audio compression with a 1.89 kbps bitrate and 21.5 frames per second. 
> We demonstrate that our novel codec can make the inference of LLM-based text-to-speech models around three times faster while improving intelligibility and producing quality comparable to previous models.

大型语言模型通过将音频转换为离散 Tokens 的音频编解码器显著推进了音频处理技术, 使得语言建模技术能够应用于音频数据.
然而, 音频编解码器通常以高帧率运行, 导致训练和推理速度缓慢, 尤其是对于自回归模型.
为了应对这一挑战, 我们提出了 ***低帧率语音编解码器 (Low Frame-rate Speech Codec, LFSC)***: 一种利用有限标量量化和与大型语音语言模型进行对抗训练的神经音频编解码器, 以 1.89 kbps 的比特率和每秒 21.5 帧的速度实现高质量的音频压缩.
我们证明我们的新型编解码器可以使基于 LLM 的文本到语音模型的推理速度提高约三倍, 同时提高可理解性并产生与先前模型相媲美的质量.

## 1.Introduction: 引言

> Audio codec is an important signal processing technique, that compresses audio signals into discrete codes and then uses these codes to reconstruct the original audio. This technology has long held a central position in fields such as audio transmission and communication \cite{ai2024apcodec}. Recently, it also has been applied to some downstream tasks. For example, some researchers use the discrete codes generated by audio codecs combined with large language models (LLMs), to achieve impressive results in zero-shot text-to-speech (ZS-TTS) \cite{borsos2023audiolm, wang2023neural, zhang2023speechtokenizer, neekhara2024improving} and Speech-to-speech translation (S2ST) \cite{li2023textless, kim2023many, wei2023joint}.
>
> In recent years, Neural Audio Codecs (NACs) with raw waveform input and output have emerged, offering a balance between decoded audio quality and bitrate \cite{kankanahalli2018end, van2017neural, garbacea2019low, zeghidour2021soundstream, defossez2022high}. For example, SoundStream \cite{zeghidour2021soundstream}, Encodec \cite{defossez2022high}, DAC \cite{kumar2024high},  and  APCodec \cite{ai2024apcodec} use the Residual Vector Quantization (RVQ) \cite{vasuki2006review} to encode audio at low bitrates while using losses from the HiFi-GAN vocoder \cite{kong2020hifi} to maintain audio fidelity. Recent research has focused on improving existing NACs, particularly in the area of quantization strategies. Researchers have worked on improving RVQ, as in \cite{ji2024language} and \cite{luo2024gull}, or exploring new vector quantization approaches. A notable example is the Spectral Codec \cite{langman2024spectral}, which encodes Mel-spectrograms using Finite Scalar Quantization (FSQ). In \cite{neekhara2024improving}, the authors applied a Spectral Codec to the TTS task, demonstrating that it can achieve high-quality audio without relying on techniques like delay patterns \cite{copet2024simple}, which were necessary in previous RVQ-based codecs due to RVQ’s hierarchical architecture. This feature is particularly beneficial for streaming, as it can significantly reduce latency for the prediction of the first audio chunk during inference.  Meanwhile, efforts have been made to introduce or disentangle semantic information during quantization to better suit specific tasks \cite{zhang2023speechtokenizer, ren2024fewer}. Moreover, researchers have worked on improving model structures \cite{xu2024intra}, incorporating additional signal processing techniques in codecs \cite{xiao2023multi} and reducing the computational complexity \cite{xu2024lightcodec}.
>
> In parallel with our work, researchers have explored the NACs bitrate reduction \cite{ai24b_interspeech, ji2024wavtokenizer}. In \cite{ai24b_interspeech}, the authors integrated APCodec with a bandwidth extension model called AP-BWE\cite{lu2024towards}, which extends bandwidth from 8kHz to 48 kHz. Their proposed model was able to achieve audio coding at 1 kbps bitrate and 25 frames per second (FPS). WavTokenizer \cite{ji2024wavtokenizer} was able to encode audio at 0.9 kbps bitrate using a single codebook at 75 FPS, achieving audio quality comparable with previous SOTA NACs.
>
> Despite these advancements, some recent works have overlooked the critical importance of low latency, which poses challenges for achieving real-time streamable inference \cite{yang2023hifi, ai2024apcodec, xu2024intra}. For Speech LLMs\footnote{We use the term "Speech LLM" to denote models that integrate LLMs for speech tasks.}, a key factor in achieving low latency is the number of audio frames produced by the codec per second of audio. This is crucial because each frame requires the autoregressive model to perform a forward pass. In scenarios where codes from multiple codebooks can be predicted in parallel, reducing the frame rate becomes even more important than lowering the bit rate. However, most of the current literature focuses primarily on bitrate reduction, often neglecting the potential benefits of frame rate reduction.  For example, the SOTAs codecs DAC and Spectral Codec produce 86 FPS of audio making the inference of Speech LLM models trained with these codecs considerably slow because the Speech LLM needs to do at least 86 forward passes to predict one second of audio. In this paper, we introduce the Low Frame-rate Speech Codec (LFSC) that reduces the frame rate by four times compared to Spectral Codec and DAC, achieving  21.5 FPS making it ideal for Speech LLM model training.
>
> The key contributions of this work are as follows:
>
> - We introduce Low Frame-rate Speech Codec, a novel neural audio codec that compresses audio in  21.5 FPS with a bitrate of {1.89} kbps while maintaining high audio quality.
> - To the best of our knowledge, we are the first to explore large speech language models as discriminators in NACs training, demonstrating significant improvements in low-frame rate scenarios.
> - To demonstrate the effectiveness of our codec in delivering high-quality audio and reducing inference time for Speech LLMs, we trained and evaluated a state-of-the-art (SOTA) LLM-based TTS model, showcasing our codec's performance in practice.
> - Our codec is publicly available in the NeMo repository\footnote{https://github.com/NVIDIA/NeMo}.
>
> The audio samples for each of our experiments are available on the demo website\footnote{https://edresson.github.io/Low-Frame-rate-Speech-Codec}.

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论

> In this work, we presented the Low Frame-rate Speech Codec, which achieved high-quality audio compression at a bitrate of {1.89} kbps and 21.5 frames per second. 
> Furthermore, we demonstrated that a Speech LLM model trained with our codec achieved quality comparable to that of the same model trained with previous state-of-the-art audio codecs, while providing approximately threefold speedup. 
>
> In future work, we intend to explore our approach in the 44 kHz audio codec training and also investigate the application of our codec to other audio domains, such as music and sound effects.

在这项工作中, 我们介绍了 ***低帧率语音编解码器 (Low Frame-rate Speech Codec, LFSC)***, 它在 1.89 kbps 的比特率和每秒 21.5 帧的速度下实现了高质量的音频压缩.
此外我们证明使用我们的编解码器训练的语音 LLM 模型在质量上与使用先前最先进的音频编解码器训练的相同模型相当, 同时提供了大约三倍的加速.

在未来的工作中, 我们计划在 44 kHz 音频编解码器训练中探索我们的方法, 并研究将我们的编解码器应用于其他音频领域, 如音乐和音效.