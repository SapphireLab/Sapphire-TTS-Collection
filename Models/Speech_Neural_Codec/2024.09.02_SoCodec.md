# SoCodec

<details>
<summary>基本信息</summary>

- 标题: SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis
- 作者:
  | 序号 | 作者 | 机构 |
  | :-: | --- | --- |
  | 01 | [郭浩翰 (Haohan Guo)](../../Authors/Haohan_Guo_(郭浩翰).md) | [香港中文大学](../../Institutions/CHN-CUHK_香港中文大学.md) |
  | 02 | [Fenglong Xie](../../Authors/Fenglong_Xie.md) | [小红书](../../Institutions/CHN-XiaohongshuInc_小红书.md) |
  | 03 | [Kun Xie](../../Authors/Kun_Xie.md) | [小红书](../../Institutions/CHN-XiaohongshuInc_小红书.md) |
  | 04 | [杨东超 (Dongchao Yang)](../../Authors/Dongchao_Yang_(杨东超).md) | [香港中文大学](../../Institutions/CHN-CUHK_香港中文大学.md) |
  | 05 | [郭大可 (Dake Guo)](../../Authors/Dake_Guo_(郭大可).md) | [西北工业大学](../../Institutions/CHN-NPU_西北工业大学.md) |
  | 06 | [Xixin Wu](../../Authors/Xixin_Wu.md) | [香港中文大学](../../Institutions/CHN-CUHK_香港中文大学.md) |
  | 07 | [蒙美玲 (Helen Meng)](../../Authors/Helen_Meng_(蒙美玲).md) | [香港中文大学](../../Institutions/CHN-CUHK_香港中文大学.md) |
- 机构:
  | 序号 | 机构 | 占比 |
  | :-: | --- | :-: |
  | 01 | [香港中文大学](../../Institutions/CHN-CUHK_香港中文大学.md) | 04/07 |
  | 02 | [小红书](../../Institutions/CHN-XiaohongshuInc_小红书.md) | 02/07 |
  | 03 | [西北工业大学](../../Institutions/CHN-NPU_西北工业大学.md) | 01/07 |
- 时间:
  - 预印时间: 2024.09.02 ArXiv v1
  - 更新笔记: 2024.09.04
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2409.00933)
  - [DOI]()
  - [Github]()
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: 8
- 引用: 31
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> The long speech sequence has been troubling language models (LM) based TTS approaches in terms of modeling complexity and efficiency. This work proposes SoCodec, a semantic-ordered multi-stream speech codec, to address this issue. It compresses speech into a shorter, multi-stream discrete semantic sequence with multiple tokens at each frame. Meanwhile, the ordered product quantization is proposed to constrain this sequence into an ordered representation. It can be applied with a multi-stream delayed LM to achieve better autoregressive generation along both time and stream axes in TTS. The experimental result strongly demonstrates the effectiveness of the proposed approach, achieving superior performance over baseline systems even if compressing the frameshift of speech from 20ms to 240ms (12x). The ablation studies further validate the importance of learning the proposed ordered multi-stream semantic representation in pursuing shorter speech sequences for efficient LM-based TTS.

## 1.Introduction: 引言

> Large language models (LLMs) have demonstrated powerful capability in text generation \cite{brown2020language,openai2023gpt4,touvron2023llama2}. This breakthrough inspires applications of LLMs in speech generation, especially for zero-shot text-to-speech (TTS) synthesis, e.g., VALL-E \cite{VALLEX}, Tortoise \cite{tortoise}, BASE-TTS \cite{lajszczak2024base}, etc. These models treat TTS as a next-token prediction task by auto-regressively generating discrete speech tokens (codes). Hence, such a language-model-based TTS system, i.e. LM-TTS, usually relies on an audio codec system \cite{encodec, hifi-codec, dac}. It encodes speech signals into discrete speech tokens and reconstructs them back. Then, we train an LM to predict speech tokens from the text to achieve TTS synthesis. However, unlike the text, speech signals contain abundant information, including phonetics, prosody, speaker identity, acoustic environment, etc., making it challenging to compress into a token sequence as short as the text. The long sequence seriously affects the LM in terms of modeling complexity and efficiency, hindering its development in the speech domain.

> In this work, we propose SoCodec, a semantic-ordered multi-stream speech codec, to provide a shorter token sequence for efficient LM-TTS. First, SoCodec leverages the self-supervised-learning-based model \cite{hsu2021hubert, wavlm} to compress speech signals into a multi-stream semantic sequence containing sufficient phonetic and prosodic information. Then, an utterance-level acoustic embedding is extracted from the Mel spectrogram to represent time-invariant acoustic information, including speaker identity, acoustic environment, etc. Meanwhile, we propose ordered product quantization (OPQ) for SoCodec to quantize speech into an ordered speech representation along the stream axis. It can be incorporated with a multi-stream LLM \cite{copet2024simple} based on a delayed pattern to achieve the high-quality and efficient zero-shot TTS, which is validated in both subjective and objective experiments.

> Our contributions are summarized as follows: 1) we propose a new speech codec, SoCodec, providing a shorter speech sequence for efficient LM-TTS; 2) we propose ordered product quantization (OPQ) to learn an ordered multi-stream sequence to adapt multi-stream LM better; 3) we propose an LM-TTS system based on SoCodec, achieving higher efficiency while keeping high synthesis quality in TTS, even with a frameshift of only 240ms, the shortest sequence across all LM-TTS approaches to the best of our knowledge.

## 2.Related Works: 相关工作

> To provide a short speech sequence for LMs, the codec is usually optimized from two aspects: 1) information reduction, compressing speech signals to represent speech with fewer tokens, and 2) representing speech with multiple streams, i.e., each frame consists of multiple tokens to increase the frameshift of the sequence. The mainstream audio codec, e.g. Encodec \cite{encodec}, Hifi-Codec \cite{hifi-codec}, DAC \cite{hifi-codec}, usually adopt residual vector quantization (RQ) based approaches to compress speech signals into a multi-stream sequence with a frameshift of around 20ms and more than 8 streams to cover sufficient acoustic information. However, the sequence is still too long to adapt LMs well. Hence, TiCodec \cite{ren2024fewer} and SingleCodec \cite{li2024single} are proposed to represent speech with fewer tokens by disentangling time-invariant acoustic information out of the discrete sequence. Meanwhile, some works \cite{ns3, zhang2023speechtokenizer, liu2024semanticodec} emphasize keeping only semantic information in speech tokens to compress the sequence further. Based on these works, we propose SoCodec to compress speech into a shorter multi-stream semantic representation.

> On the other hand, to better generate the multi-stream representation, an ordered generation process along the stream axis is also applied in LM-TTS. For example, VALL-E \cite{wang2023neural, VALLEX} predicts the first stream via one AR model, and predicts the following streams recursively by running one NAR model 7 times. Recently, a multi-stream LLM with a delayed pattern \cite{copet2024simple, kharitonov2022text} is proposed to generate tokens along both axes auto-regressively by only running one AR model once. However, this autoregressive generation from the low stream to the high stream makes it easy to deliver accumulated errors to high-stream prediction, degrading the generation quality. Hence, we intuitively aim to seek an ordered multi-stream speech representation to first generate principal speech information in low streams to ensure a stable generation process. Inspired by ordered representation learning \cite{rippel2014learning, xu2021anytime}, we propose ordered product quantization for SoCodec.

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
