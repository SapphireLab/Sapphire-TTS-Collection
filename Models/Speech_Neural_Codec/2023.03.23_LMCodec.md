# LMCodec

<details>
<summary>基本信息</summary>

- 标题: LMCodec: A Low Bitrate Speech Codec With Causal Transformer Models
- 作者:
  | 序号 | 作者 | 机构 |
  | :-: | --- | --- |
  | 01 | [Teerapat Jenrungrot](../../Authors/Teerapat_Jenrungrot.md) | [University of Washington, Seattle](../../Institutions/USA-UW_美国华盛顿大学.md) |
  | 02 | [Michael Chinen](../../Authors/Michael_Chinen.md) | [Google](../../Institutions/USA-Google.md)|
  | 03 | [W. Bastiaan Kleijn](../../Authors/W._Bastiaan_Kleijn.md) | [Google](../../Institutions/USA-Google.md) <br> [Victoria University of Wellington](../../Institutions/NZL-VUW_新西兰惠灵顿维多利亚大学.md) |
  | 04 | [Jan Skoglund](../../Authors/Jan_Skoglund.md) | [Google](../../Institutions/USA-Google.md) |
  | 05 | [Zalán Borsos](../../Authors/Zalan_Borsos.md) | [Google](../../Institutions/USA-Google.md) |
  | 06 | [Neil Zeghidour](../../Authors/Neil_Zeghidour.md) | [Google](../../Institutions/USA-Google.md) |
  | 07 | [Marco Tagliasacchi](../../Authors/Marco_Tagliasacchi.md) | [Google](../../Institutions/USA-Google.md) |
- 机构:
  | 序号 | 机构 | 占比 |
  | :-: | --- | :-: |
  | 01 | [University of Washington, Seattle](../../Institutions/USA-UW_美国华盛顿大学.md) | 01/07 |
  | 02 | [Google](../../Institutions/USA-Google.md) | 06/07 |
  | 03 | [Victoria University of Wellington](../../Institutions/NZL-VUW_新西兰惠灵顿维多利亚大学.md) | 01/07 |
- 时间:
  - 预印时间: 2023.03.23 ArXiv v1
  - 更新笔记: 2024.09.05
- 发表:
  - [ICASSP 2023](../../Publications/ICASSP.md)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2303.12984)
  - [DOI]()
  - [Github]()
  - [Demo](https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec)
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ?
- 数据:
  - ?
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

We introduce ***LMCodec***, a causal neural speech codec that provides high quality audio at very low bitrates.
The backbone of the system is a causal convolutional codec that encodes audio into a hierarchy of coarse-to-fine tokens using residual vector quantization.
***LMCodec*** trains a Transformer language model to predict the fine tokens from the coarse ones in a generative fashion, allowing for the transmission of fewer codes.
A second Transformer predicts the uncertainty of the next codes given the past transmitted codes, and is used to perform conditional entropy coding.
A MUSHRA subjective test was conducted and shows that the quality is comparable to reference codecs at higher bitrates.
Example audio is available at this https [URL](https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec).

我们介绍了 ***LMCodec***, 这是一种因果神经语音编解码器, 能够在极低比特率下提供高质量音频.
该系统的核心是一个因果卷积编解码器, 它使用残差向量量化将音频编码成从粗到细的层次化 Token.
***LMCodec*** 训练一个 Transformer 语言模型以生成方式从粗 Token 预测细 Token, 从而允许传输更少的编码.
第二个 Transformer 预测给定过去传输编码的下一个编码的不确定性，并用于执行条件熵编码.
进行了一项 MUSHRA 主观测试, 结果显示质量与高比特率的参考编解码器相当.
示例音频可在以下链接获取: [URL](https://mjenrungrot.github.io/chrome-media-audio-papers/publications/lmcodec)

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
