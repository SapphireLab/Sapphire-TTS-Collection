# HiFi-Codec

<details>
<summary>基本信息</summary>

- 标题: HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec
- 作者:
  - 01. 杨东超 (Dongchao Yang) - 北京大学
  - 02. Songxiang Liu - 腾讯 AI Lab
  - 03. 黄融杰 (Rongjie Huang) - 浙江大学
  - 04. Jinchuan Tian - 北京大学
  - 05. Chao Weng - 腾讯 AI Lab
  - 06. Yuexian Zou - 北京大学
- 机构:
  - 01. 北京大学 03/06
  - 02. 腾讯 AI Lab 02/06
  - 03. 浙江大学 01/06
- 时间:
  - 预印时间: 2023.05.04 ArXiv v1
  - 预印时间: 2023.05.07 ArXiv v2
  - 更新笔记: 2024.09.05
- 发表:
  - 期刊/会议
- 链接:
  - [ArXiv](https://arxiv.org/abs/2305.02765)
  - [DOI]()
  - [Github](https://github.com/yangdongchao/AcademiCodec)
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=16848014406171770614)
- 标签:
- 页数: ?
- 引用: ?
- 被引: 56
- 数据:
  - ?
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

Audio codec models are widely used in audio communication as a crucial technique for compressing audio into discrete representations.
Nowadays, audio codec models are increasingly utilized in generation fields as intermediate representations.
For instance, AudioLM is an audio generation model that uses the discrete representation of SoundStream as a training target, while VALL-E employs the Encodec model as an intermediate feature to aid TTS tasks.

Despite their usefulness, two challenges persist: (1) training these audio codec models can be difficult due to the lack of publicly available training processes and the need for large-scale data and GPUs; (2) achieving good reconstruction performance requires many codebooks, which increases the burden on generation models.
In this study, we propose a group-residual vector quantization (GRVQ) technique and use it to develop a novel ***High Fidelity Audio Codec model, HiFi-Codec***, which only requires 4 codebooks.
We train all the models using publicly available TTS data such as LibriTTS, VCTK, AISHELL, and more, with a total duration of over 1000 hours, using 8 GPUs.
Our experimental results show that ***HiFi-Codec*** outperforms Encodec in terms of reconstruction performance despite requiring only 4 codebooks.
To facilitate research in audio codec and generation, we introduce AcademiCodec, the first open-source audio codec toolkit that offers training codes and pre-trained models for Encodec, SoundStream, and ***HiFi-Codec***.
Code and pre-trained model can be found on: [Github](https://github.com/yangdongchao/AcademiCodec)

音频编解码器模型广泛应用于音频通信中, 是将音频压缩成离散表示的关键技术.
如今, 音频编解码器模型越来越多地被用作生成领域的中间表示.
例如, AudioLM 是一个音频生成模型, 它使用 SoundStream 的离散表示作为训练目标, 而 VALL-E 则采用 EnCodec 模型作为中间特征来辅助 TTS 任务.

尽管它们有用, 但仍存在两个挑战:
1. 由于缺乏公开可用的训练流程以及对大规模数据和 GPU 的需求, 训练这些音频编解码器模型可能很困难;
2. 要实现良好的重建性能需要许多码本, 这增加了生成模型的负担.

在本研究中, 我们提出了一种组残差向量量化 (Group-Residual Vector Quantization, GRVQ) 技术, 并利用它开发了一种新型的高保真音频编解码器模型 ***HiFi-Codec***, 该模型仅需要 4 个码本.

我们使用公开可用的TTS数据 (如 LibriTTS, VCTK, AISHELL 等) 训练所有模型, 总时长超过 1000 小时, 使用 8 个 GPU.

我们的实验结果表明, 尽管仅需要 4 个码本, ***HiFi-Codec*** 在重建性能方面优于 EnCodec.

为了促进音频编解码器和生成的研究, 我们推出了 AcademiCodec, 这是首个开源音频编解码器工具包, 提供 EnCodec, SoundStream 和 ***HiFi-Codec*** 的训练代码和预训练模型.

代码和预训练模型可在以下链接找到：[Github](https://github.com/yangdongchao/AcademiCodec).

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论