# MegaTTS3

<details>
<summary>基本信息</summary>

- 标题: "MegaTTS 3: Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis"
- 作者:
  - 01 Ziyue Jiang
  - 02 Yi Ren
  - 03 Ruiqi Li
  - 04 Shengpeng Ji
  - 05 Boyang Zhang
  - 06 Zhenhui Ye
  - 07 Chen Zhang
  - 08 Bai Jionghao
  - 09 Xiaoda Yang
  - 10 Jialong Zuo
  - 11 Yu Zhang
  - 12 Rui Liu
  - 13 Xiang Yin
  - 14 Zhou Zhao
- 链接:
  - [ArXiv](https://arxiv.org/abs/2502.18924)
  - [Publication]()
  - [Github]()
  - [Demo](https://sditdemo.github.io/sditdemo/)
- 文件:
  - [ArXiv](_PDF/2502.18924v4__MegaTTS3__Sparse_Alignment_Enhanced_Latent_Diffusion_Transformer_for_Zero-Shot_Speech_Synthesis.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<table><tr><td width="50%">

While recent zero-shot text-to-speech (TTS) models have significantly improved speech quality and expressiveness,
mainstream systems still suffer from issues related to speech-text alignment modeling:
(1) models without explicit speech-text alignment modeling exhibit less robustness, especially for hard sentences in practical applications;
(2) predefined alignment-based models suffer from naturalness constraints of forced alignments.

This paper introduces ***MegaTTS3***, a TTS system featuring an innovative sparse alignment algorithm that guides the latent diffusion transformer (DiT).
Specifically, we provide sparse alignment boundaries to MegaTTS 3 to reduce the difficulty of alignment without limiting the search space, thereby achieving high naturalness.
Moreover, we employ a multi-condition classifier-free guidance strategy for accent intensity adjustment and adopt the piecewise rectified flow technique to accelerate the generation process.
Experiments demonstrate that MegaTTS 3 achieves state-of-the-art zero-shot TTS speech quality and supports highly flexible control over accent intensity.
Notably, our system can generate high-quality one-minute speech with only 8 sampling steps.
Audio samples are available at https://sditdemo.github.io/sditdemo/.

</td><td>

</td></tr></table>

## 1·Introduction: 引言

<table><tr><td width="50%">

In recent years, neural codec language models~\citep{wang2023neural,zhang2023speak,song2024ella,xin2024rall} and large-scale diffusion models ~\citep{shen2023naturalspeech,le2023Voicebox,lee2024ditto,eskimez2024e2,ju2024naturalspeech,yang2024simplespeech,yang2024simplespeech2} have brought considerable advancements to the field of speech synthesis.
Unlike traditional text-to-speech (TTS) systems~\citep{shen2018natural,jia2018transfer,li2019neural,kim2020glow,ren2019fastspeech,kim2021conditional,kim2022guided}, these models are trained on large-scale, multi-domain speech corpora, which contributes to notable improvements in the naturalness and expressiveness of synthesized audio.
Given only seconds of speech prompt, they can synthesize identity-preserving speech in a zero-shot manner.

To generate high-quality speech with clear and expressive pronunciation, a TTS model must establish an alignment mapping from text to speech signals~\citep{kim2020glow,tan2021survey}.
However, from the perspective of speech-text alignment, current solutions suffer from the following issues:

- \textbf{Models with implicit speech-text alignment} achieve the soft alignment paths through attention mechanisms~\citep{wang2023neural,chen2024vall,du2024cosyvoice}.
These models can be categorized into: 1) autoregressive codec language models (AR LM), which are inefficient and lack robustness.
The lengthy discrete speech codes, which typically require a bit rate of 1.5 kbps~\citep{kumar2024high,wu2024towards}, impose a significant burden on these autoregressive language models; 2) diffusion-based models without explicit duration modeling~\citep{lee2024ditto,eskimez2024e2,lovelace2023simple,gao2023e3,cambara2024mapache,yang2024simplespeech,yang2024simplespeech2}, which significantly speeds up the speech generation process.
However, when compared with methods that adopt forced alignment, these models exhibit a decline in speech intelligibility.
Besides, these methods cannot provide fine-grained control over the duration of specific pronunciations and can only adjust the overall speech rate.

- \textbf{Predefined alignment-based methods} have prosodic naturalness constraints of forced alignments.
During training, alignment paths~\citep{ren2020fastspeech,kim2020glow} are directly introduced into their models~\citep{le2023Voicebox,shen2023naturalspeech,ju2024naturalspeech} to reduce the complexity of text-to-speech generation, which achieves higher intelligibility.
Nevertheless, they suffer from the following limitations: 1) predefined alignments constrain the model's search space to produce more natural-sounding speech~\citep{anastassiou2024seed,chen2024vall}; 2) the overall naturalness is highly dependent on the performance of duration models.

Intuitively, we can integrate the two aforementioned diffusion-based methods to pursue optimal performance.
To be specific, we propose a novel sparse speech-text alignment strategy to enhance the latent diffusion transformer (DiT), termed MegaTTS 3.
In our approach, phoneme tokens are sparsely distributed within the corresponding forced alignment regions to provide coarse pronunciation information that is then refined by the latent DiT model.
Experimental results demonstrate that MegaTTS 3 achieves nearly state-of-the-art speech intelligibility and speaker similarity on the LibriSpeech test-clean set~\citep{panayotov2015librispeech} with only 8 sampling steps, while also exhibiting high speech naturalness.
The main contributions of this work are summarized as follows:

- We design a sparse alignment enhanced latent diffusion transformer model, which effectively integrates the strengths of the two aforementioned speech-text alignment approaches.
Notably, our model also demonstrates greater robustness to duration prediction errors compared to methods with forced alignment.

- To achieve higher generation quality and more flexible control, we propose a multi-condition CFG strategy to adjust the guidance scales for speaker timbre and text content separately.
Furthermore, we discover that the text guidance scale can also be used to modulate the intensity of personal accents, offering a new direction for enhancing speech expressiveness.

- We successfully reduce the inference steps from 25 to 8 with the piecewise rectified flow (PeRFLow) technique, achieving highly efficient zero-shot TTS with minimal quality degradation.
We also visualize the attention matrices across various layers of MegaTTS 3 and obtain insightful findings in Appendix~\ref{app:vis_diff_attn}.

</td><td>

</td></tr></table>

## 2·Related Works: 相关工作

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 3·Methodology: 方法

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 4·Experiments: 实验

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 5·Results: 结果

<table><tr><td width="50%">

</td><td>

</td></tr></table>

## 6·Conclusions: 结论

<table><tr><td width="50%">

</td><td>

</td></tr></table>
