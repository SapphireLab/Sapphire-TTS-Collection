# SALAD

<details>
<summary>基本信息</summary>

- 标题: "Continuous Speech Synthesis using per-token Latent Diffusion"
- 作者:
  - 01 Arnon Turetzky,
  - 02 Nimrod Shabtay,
  - 03 Slava Shechtman,
  - 04 Hagai Aronowitz,
  - 05 David Haws,
  - 06 Ron Hoory,
  - 07 Avihu Dekel
- 链接:
  - [ArXiv](https://arxiv.org/abs/2410.16048)
  - [Publication] Submitted to ICLR 2025
  - [Github]
  - [Demo](https://s3.us-south.objectstorage.softlayer.net/zk-wav-data/Webpages/ICLR2025PerTokenLatentDiffusion/index.html)
- 文件:
  - [ArXiv](_PDF/2410.16048v1__SALAD__Continuous_Speech_Synthesis_Using_Per-Token_Latent_Diffusion.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

The success of autoregressive transformer models with discrete tokens has inspired quantization-based approaches for continuous modalities, though these often limit reconstruction quality.
We therefore introduce ***SALAD***, a per-token latent diffusion model for zero-shot text-to-speech, that operates on continuous representations.
***SALAD*** builds upon the recently proposed expressive diffusion head for image generation, and extends it to generate variable-length outputs.
Our approach utilizes semantic tokens for providing contextual information and determining the stopping condition.
We suggest three continuous variants for our method, extending popular discrete speech synthesis techniques.
Additionally, we implement discrete baselines for each variant and conduct a comparative analysis of discrete versus continuous speech modeling techniques.
Our results demonstrate that both continuous and discrete approaches are highly competent, and that ***SALAD*** achieves a superior intelligibility score while obtaining speech quality and speaker similarity on par with the ground-truth audio.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论