# F5-TTS

<details>
<summary>基本信息</summary>

- 标题: "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching"
- 作者:
  - 01 Yushen Chen - Shanghai Jiao Tong University
  - 02 Zhikang Niu - Shanghai Jiao Tong University
  - 03 Ziyang Ma - Shanghai Jiao Tong University
  - 04 Keqi Deng - University of Cambridge
  - 05 Chunhui Wang - Geely Automobile Research Institute
  - 06 Jian Zhao - Geely Automobile Research Institute
  - 07 Kai Yu - Shanghai Jiao Tong University
  - 08 Xie Chen - Shanghai Jiao Tong University - chenxie95@sjtu.edu.cn
- 链接:
  - [ArXiv](https://arxiv.org/abs/2410.06885)
  - [Publication]
  - [Github](https://github.com/SWivid/F5-TTS)
  - [Demo](https://swivid.github.io/F5-TTS)
- 文件:
  - [ArXiv](_PDF/2410.06885v1__F5-TTS__A_Fairytaler_that_Fakes_Fluent_and_Faithful_Speech_with_Flow_Matching.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

This paper introduces ***F5-TTS***, a fully non-autoregressive text-to-speech system based on flow matching with Diffusion Transformer (DiT).
Without requiring complex designs such as duration model, text encoder, and phoneme alignment, the text input is simply padded with filler tokens to the same length as input speech, and then the denoising is performed for speech generation, which was originally proved feasible by E2 TTS.
However, the original design of E2 TTS makes it hard to follow due to its slow convergence and low robustness.
To address these issues, we first model the input with ConvNeXt to refine the text representation, making it easy to align with the speech.
We further propose an inference-time Sway Sampling strategy, which significantly improves our model's performance and efficiency.
This sampling strategy for flow step can be easily applied to existing flow matching based models without retraining.
Our design allows faster training and achieves an inference RTF of 0.15, which is greatly improved compared to state-of-the-art diffusion-based TTS models.
Trained on a public 100K hours multilingual dataset, our ***Fairytaler Fakes Fluent and Faithful speech with Flow matching (F5-TTS)*** exhibits highly natural and expressive zero-shot ability, seamless code-switching capability, and speed control efficiency.
Demo samples can be found at [this https URL](https://swivid.github.io/F5-TTS).
We release all code and checkpoints to promote community development ([Github](https://github.com/SWivid/F5-TTS)).

</details>
<br>

本论文介绍了 ***F5-TTS***, 一个基于流匹配和 DiT 的完全非自回归文本到语音系统.
无需复杂的设计, 如时长模型, 文本编码器和音素对齐, 文本输入只需要通过补充填充符号使得长度与输入语音相同, 然后进行去噪以生成语音, 这一方式最初由 E2 TTS 证明是可行的.
然而, E2 TTS 的原始设计使其难以跟随研究, 这是因为其缓慢的收敛和低鲁棒性.
为了解决这些问题, 我们首先使用 ConvNeXt 模型对输入进行建模, 优化文本表示使其更容易与语音对齐.
我们进一步提出了一个推理时摇摆采样策略, 它显著提高了模型的性能和效率.
这个采样策略可以很容易地应用到现有的基于流匹配的模型上, 而不需要重新训练.
我们的设计允许更快的训练, 并实现了推理 RTF 为 0.15, 这比现有的基于流匹配的 TTS 模型的最新水平提高了很多.
在一个公开的 100K 小时多语言数据集上训练, 我们的 ***Fairytaler Fakes Fluent and Faithful speech with Flow matching (F5-TTS)*** 具有高度自然和富有表现力的零样本能力, 无缝切换能力, 以及速度控制的效率.
演示样本可以在[此处](https://swivid.github.io/F5-TTS) 找到.
我们发布所有代码和检查点, 以促进社区开发 ([Github](https://github.com/SWivid/F5-TTS)).

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
