# CM-TTS

<details>
<summary>基本信息</summary>

- 标题: "CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through Weighted Samplers and Consistency Models"
- 作者:
  - 01 Xiang Li
  - 02 Fan Bu
  - 03 Ambuj Mehrish
  - 04 Yingting Li
  - 05 Jiale Han
  - 06 Bo Cheng
  - 07 Soujanya Poria
- 链接:
  - [ArXiv](https://arxiv.org/abs/2404.00569)
  - [Publication](https://doi.org/10.18653/v1/2024.findings-naacl.240)
  - [Github](https://github.com/XiangLi2022/CM-TTS)
  - [Demo](https://cmtts.vercel.app/)
- 文件:
  - [ArXiv](_PDF/2404.00569v1__CM-TTS__Enhancing_Real_Time_Text-to-Speech_Synthesis_Efficiency_through_Weighted_Samplers_and_Consistency_Models.pdf)
  - [Publication](_PDF/2404.00569p0__CM-TTS__NAACL2024.pdf)

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

Neural Text-to-Speech (TTS) systems find broad applications in voice assistants, e-learning, and audiobook creation.
The pursuit of modern models, like Diffusion Models (DMs), holds promise for achieving high-fidelity, real-time speech synthesis.
Yet, the efficiency of multi-step sampling in Diffusion Models presents challenges.
Efforts have been made to integrate GANs with DMs, speeding up inference by approximating denoising distributions, but this introduces issues with model convergence due to adversarial training.
To overcome this, we introduce ***CM-TTS***, a novel architecture grounded in consistency models (CMs).
Drawing inspiration from continuous-time diffusion models, ***CM-TTS*** achieves top-quality speech synthesis in fewer steps without adversarial training or pre-trained model dependencies.
We further design weighted samplers to incorporate different sampling positions into model training with dynamic probabilities, ensuring unbiased learning throughout the entire training process.
We present a real-time mel-spectrogram generation consistency model, validated through comprehensive evaluations.
Experimental results underscore ***CM-TTS***'s superiority over existing single-step speech synthesis systems, representing a significant advancement in the field.

</details>
<br>

神经文本转语音系统在语音助手, 电子学习和有声书创作中有着广泛的应用.
现代模型 (如扩散模型) 的追求有望实现高保真实时的语音合成.
然而, 扩散模型中的多步采样效率存在挑战.
已经有人尝试将生成对抗网络与扩散模型结合, 通过近似去噪分布来加速推理, 但这引入了由于对抗训练导致的模型收敛问题.
为了克服这一点, 我们提出了 ***CM-TTS***, 一种基于一致性模型 (CM) 的新架构.
受到连续时间扩散模型的启发, ***CM-TTS*** 在更少的步骤中实现了顶级质量的语音合成, 无需对抗训练或预训练模型的依赖.
我们进一步设计了加权采样器, 以动态概率将不同采样位置纳入模型训练, 确保在整个训练过程中实现无偏学习.
我们展示了一个实时梅尔频谱一致性模型, 通过全面评估验证了它的优势.
实验结果证明了 ***CM-TTS*** 优于现有单步语音合成系统的水平, 这是一个重要的领域进步.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
