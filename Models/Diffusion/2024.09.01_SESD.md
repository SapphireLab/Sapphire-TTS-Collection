# SESD

<details>
<summary>基本信息</summary>

- 标题: Sample-Efficient Diffusion for Text-To-Speech Synthesis
- 作者:
  | 序号 | 作者 | 机构 |
  | :-: | --- | --- |
  | 01 | [Justin Lovelace](../../Authors/Justin_Lovelace.md) | [Cornell University](../../Institutions/USA-Cornell_康奈尔大学.md) <br> [ASAPP Inc.](../../Institutions/USA-ASAPP.Inc.md) | 
  | 02 | [Soham Ray](../../Authors/Soham_Ray.md) | [ASAPP Inc.](../../Institutions/USA-ASAPP.Inc.md) |
  | 03 | [Kwangyoun Kim](../../Authors/Kwangyoun_Kim.md) | [ASAPP Inc.](../../Institutions/USA-ASAPP.Inc.md) |
  | 04 | [Kilian Q. Weinberger](../../Authors/Kilian_Q._Weinberger.md) | [Cornell University](../../Institutions/USA-Cornell_康奈尔大学.md) <br> [ASAPP Inc.](../../Institutions/USA-ASAPP.Inc.md) | 
  | 05 | [Felix Wu](../../Authors/Felix_Wu.md) | [ASAPP Inc.](../../Institutions/USA-ASAPP.Inc.md) <br> [Character.AI](../../Institutions/USA-Character.AI.md)|
- 机构:
  | 序号 | 机构 | 占比 |
  | :-: | --- | :-: |
  | 01 | [Cornell University](../../Institutions/USA-Cornell_康奈尔大学.md) | 02/05 |
  | 02 | [ASAPP Inc.](../../Institutions/USA-ASAPP.Inc.md) | 05/05 |
  | 03 | [Character.AI](../../Institutions/USA-Character.AI.md) | 01/05 |
- 时间:
  - 预印时间: 2024.09.01 ArXiv v1
  - 更新笔记: 2024.09.06
- 发表:
  - [InterSpeech 2024](../../Publications/InterSpeech.md)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2409.03717)
  - [DOI]()
  - [Github](https://github.com/justinlovelace/SESD) 尚未开放
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: 5
- 引用: 32
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

> This work introduces ***Sample-Efficient Speech Diffusion (SESD)***, an algorithm for effective speech synthesis in modest data regimes through latent diffusion. 
> It is based on a novel diffusion architecture, that we call ***U-Audio Transformer (U-AT)***, that efficiently scales to long sequences and operates in the latent space of a pre-trained audio autoencoder. 
> Conditioned on character-aware language model representations, ***SESD*** achieves impressive results despite training on less than 1k hours of speech – far less than current state-of-the-art systems. 
> In fact, it synthesizes more intelligible speech than the state-of-the-art auto-regressive model, [VALL-E](../Speech_LLM/2023.01.05_VALL-E.md), while using less than 2 % the training data. 
> Our implementation is available at [Github](https://github.com/justinlovelace/SESD).

</details>

本项工作介绍了 ***样本高效语音扩散 (Sample-Efficient Speech Diffusion, SESD)***, 这是一种通过潜在扩散在适度数据条件下实现有效语音合成的算法.
它基于一种新颖的扩散架构, 我们称为 ***U-Audio Transformer (U-AT)***，它可以有效地扩展到长序列并在预训练的音频自编码器的潜在空间中运行.
以字符感知语言模型表示作为条件, ***SESD*** 能在不足 1k 小时的语音上训练并获得令人印象深刻的结果, 远少于现有的最先进系统.
事实上, 它合成的语音比当前最先进的自回归模型 [VALL-E](../Speech_LLM/2023.01.05_VALL-E.md) 更易理解, 而使用的训练数据不到后者的 2%.
我们的实现可在 [Github](https://github.com/justinlovelace/SESD) 上获得.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
