# LauraGPT

<details>
<summary>基本信息</summary>

- 标题: LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT
- 作者:
  - 01 [Zhihao Du](../../Authors/Zhihao_Du.md)
  - 02 [Jiaming Wang](../../Authors/Jiaming_Wang.md)
  - 03 [Qian Chen](../../Authors/Qian_Chen.md)
  - 04 [Yunfei Chu](../../Authors/Yunfei_Chu.md)
  - 05 [Zhifu Gao](../../Authors/Zhifu_Gao.md)
  - 06 [Zerui Li](../../Authors/Zerui_Li.md)
  - 07 [Kai Hu](../../Authors/Kai_Hu.md)
  - 08 [Xiaohuan Zhou](../../Authors/Xiaohuan_Zhou.md)
  - 09 [Jin Xu](../../Authors/Jin_Xu.md)
  - 10 [Ziyang Ma](../../Authors/Ziyang_Ma_(马子阳).md)
  - 11 [Wen Wang](../../Authors/Wen_Wang.md)
  - 12 [Siqi Zheng](../../Authors/Siqi_Zheng.md)
  - 13 [Chang Zhou](../../Authors/Chang_Zhou.md)
  - 14 [Zhijie Yan](../../Authors/Zhijie_Yan.md)
  - 15 [Shiliang Zhang](../../Authors/Shiliang_Zhang.md)
- 机构:
  - [阿里巴巴达摩院](../../Institutions/Alibaba.md)
- 时间:
  - 预印时间: 2023.10.07 ArXiv v1
  - 预印时间: 2023.10.10 ArXiv v2
  - 预印时间: 2023.10.11 ArXiv v3
  - 预印时间: 2024.07.03 ArXiv v4
  - 更新笔记: 2024.08.12
- 发表:
  - ~~ICLR 2024 Reject~~
- 链接:
  - [ArXiv](https://arxiv.org/abs/2310.04673)
  - [DOI]()
  - [Github]()
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: 20
- 引用: ?
- 被引: 20+9
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> Generative Pre-trained Transformer~(GPT) models have achieved remarkable performance on various natural language processing tasks, and have shown great potential as backbones for audio-and-text large language models (LLMs). Previous mainstream audio-and-text LLMs use discrete audio tokens to represent both input and output audio; however, they suffer from performance degradation on tasks such as automatic speech recognition, speech-to-text translation, and speech enhancement over models using continuous speech features. In this paper, we propose \textbf{LauraGPT}, a novel unified audio-and-text GPT-based LLM for audio recognition, understanding, and generation. LauraGPT is a versatile LLM that can process both audio and text inputs and generate outputs in either modalities. We propose a novel data representation that combines continuous and discrete features for audio: LauraGPT encodes input audio into continuous representations using an audio encoder and generates output audio from discrete codec codes. We propose a one-step codec vocoder to overcome the prediction challenge caused by the multimodal distribution of codec tokens. We fine-tune LauraGPT using supervised multi-task learning. Extensive experiments show that LauraGPT consistently achieves comparable to superior performance compared to strong baselines on a wide range of audio tasks related to content, semantics, paralinguistics, and audio-signal analysis, such as automatic speech recognition, speech-to-text translation, text-to-speech synthesis, speech enhancement, automated audio captioning, speech emotion recognition, and spoken language understanding. 

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
