# LSLM

<details>
<summary>基本信息</summary>

- 标题: Language Model Can Listen While Speaking
- 作者:
  - 01 [Ziyang Ma](../../Authors/Ziyang_Ma_(马子阳).md)
  - 02 [Yakun Song](../../Authors/Yakun_Song.md)
  - 03 [Chenpeng Du](../../Authors/Chenpeng_Du.md)
  - 04 [Jian Cong](../../Authors/Jian_Cong.md)
  - 05 [Zhuo Chen](../../Authors/Zhuo_Chen_(陈卓).md)
  - 06 [Yuping Wang](../../Authors/Yuping_Wang.md)
  - 07 [Yuxuan Wang](../../Authors/Yuxuan_Wang_(王雨轩).md)
  - 08 [Xie Chen](../../Authors/Xie_Chen_(陈谐).md)
- 机构:
  - [上海交通大学 X-LANCE](../../Institutions/SJTU_上海交通大学.md)
  - [字节跳动](../../Institutions/ByteDance.md)
- 时间:
  - 预印时间: 2024.08.05 ArXiv v1
  - 更新笔记: 2024.08.08
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.02622)
  - [DOI]()
  - [Github]()
  - [Demo](https://ziyang.tech/LSLM/)
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> Dialogue serves as the most natural manner of human-computer interaction (HCI). 
> Recent advancements in speech language models (SLM), have significantly enhanced speech-based conversational AI. 
> However, these models are limited to turn-based conversation, lacking the ability to interact with humans in real-time spoken scenarios, for example, being interrupted when the generated content is not satisfactory. 
> To address these limitations, we explore full duplex modeling (FDM) in interactive speech language models (iSLM), focusing on enhancing real-time interaction and, more explicitly, exploring the quintessential ability of interruption. 
> We introduce a novel model design, namely listening-while-speaking language model (LSLM), an end-to-end system equipped with both listening and speaking channels. 
> Our LSLM employs a token-based decoder-only TTS for speech generation and a streaming self-supervised learning (SSL) encoder for real-time audio input. 
> LSLM fuses both channels for autoregressive generation and detects turn-taking in real time. 
> Three fusion strategies—early fusion, middle fusion, and late fusion—are explored, with middle fusion achieving an optimal balance between speech generation and real-time interaction. 
> Two experimental settings, command-based FDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity to diverse instructions. 
> Our results highlight LSLM's capability to achieve duplex communication with minimal impact on existing systems. 
> This study aims to advance the development of interactive speech dialogue systems, enhancing their applicability in real-world contexts.
> Demo can be found at https://ddlbojack.github.io/LSLM.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论
