# SelectTTS

<details>
<summary>基本信息</summary>

- 标题: SelectTTS: Synthesizing Anyone's Voice via Discrete Unit-Based Frame Selection
- 作者:
  - 01 [Ismail Rasim Ulgen](../../Authors/Ismail_Rasim_Ulgen.md)
  - 02 [Shreeram Suresh Chandra](../../Authors/Shreeram_Suresh_Chandra.md)
  - 03 [Junchen Lu](../../Authors/Junchen_Lu.md)
  - 04 [Berrak Sisman](../../Authors/Berrak_Sisman.md)
- 机构:
  - 机构 
- 时间:
  - 预印时间: 2024.08.30 ArXiv v1
  - 更新笔记: 2024.09.02
- 发表:
  - 期刊/会议 
- 链接:
  - [ArXiv](https://arxiv.org/abs/2408.17432)
  - [DOI]()
  - [Github]()
  - [Demo]()
  - [Scholar](https://scholar.google.com/scholar?cluster=)
- 标签:
  - ?
- 页数: ?
- 引用: ?
- 被引: ?
- 数据:
  - ? 
- 对比:
  - ?
- 复现:
  - ?

</details>

## Abstract: 摘要

> Synthesizing the voices of unseen speakers is a persisting challenge in multi-speaker text-to-speech (TTS). 
> Most multi-speaker TTS models rely on modeling speaker characteristics through speaker conditioning during training. 
> Modeling unseen speaker attributes through this approach has necessitated an increase in model complexity, which makes it challenging to reproduce results and improve upon them. 
> We design a simple alternative to this. 
> We propose SelectTTS, a novel method to select the appropriate frames from the target speaker and decode using frame-level self-supervised learning (SSL) features. 
> We show that this approach can effectively capture speaker characteristics for unseen speakers, and achieves comparable results to other multi-speaker TTS frameworks in both objective and subjective metrics. 
> With SelectTTS, we show that frame selection from the target speaker's speech is a direct way to achieve generalization in unseen speakers with low model complexity. 
> We achieve better speaker similarity performance than SOTA baselines XTTS-v2 and VALL-E with over an 8x reduction in model parameters and a 270x reduction in training data.

## 1.Introduction: 引言

## 2.Related Works: 相关工作

## 3.Methodology: 方法

## 4.Experiments: 实验

## 5.Results: 结果

## 6.Conclusions: 结论