# CoFi-Speech

- 标题: "Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation"

## Abstract: 摘要

> The neural codec language model (CLM) has demonstrated remarkable performance in text-to-speech (TTS) synthesis. However, troubled by `recency bias`, CLM lacks sufficient attention to coarse-grained information at a higher temporal scale, often producing unnatural or even unintelligible speech. 
> This work proposes CoFi-Speech, a coarse-to-fine CLM-TTS approach, employing multi-scale speech coding and generation to address this issue. 
> We train a multi-scale neural codec, CoFi-Codec, to encode speech into a multi-scale discrete representation, comprising multiple token sequences with different time resolutions. 
> Then, we propose CoFi-LM that can generate this representation in two modes: the single-LM-based chain-of-scale generation and the multiple-LM-based stack-of-scale generation. 
> In experiments, CoFi-Speech significantly outperforms single-scale baseline systems on naturalness and speaker similarity in zero-shot TTS. 
> The analysis of multi-scale coding demonstrates the effectiveness of CoFi-Codec in learning multi-scale discrete speech representations while keeping high-quality speech reconstruction. 
> The coarse-to-fine multi-scale generation, especially for the stack-of-scale approach, is also validated as a crucial approach in pursuing a high-quality neural codec language model for TTS.

## 1.Introduction: 引言

> The success of large language models (LLMs) in text domain \cite{brown2020language,openai2023gpt4,touvron2023llama2} has demonstrated their great capability in discrete sequence generation. It also inspires the birth of a new text-to-speech synthesis (TTS) paradigm based on the neural codec language model (CLM) \cite{VALLEX, tortoise, lajszczak2024base}, which treats TTS as a next-token prediction task. This framework usually relies on a neural codec \cite{encodec, hifi-codec, dac} to encode the speech audio into discrete tokens, which can be incorporated with the text sequence and generated by the LM, i.e. an auto-regressive decoder. Finally, we obtain the speech audio from these generated speech tokens via the codec decoder.
>
> However, different from the text, the discrete speech sequence is much longer to keep sufficient capacity to preserve phonetic and acoustic information. This long sequence length not only increases the complexity of TTS modeling but aggregates the `recency bias` of LMs \cite{peysakhovich2023attention, wang2024eliminating}, i.e. overly focusing on recent tokens during auto-regressive generation. This issue makes LM focus less on coarse-grained information \cite{guo2023msmc}, e.g. phonetics, prosody, and speaking style at higher and different temporal scales, hence causing unstable TTS performance, producing unnatural or even unintelligible speech. Although monotonic attention constraints \cite{han2024vall, du2024vall, wang2024attention} are proposed to fix stability issues, they still cannot solve `recency bias` fundamentally. Some works \cite{tortoise, socodec, li2024single} turn to directly model shorter speech sequences with a larger frameshift to avoid this issue, but limits the fine-grained expression of LMs in TTS. This dilemma implies the necessity of applying guidance to LMs to pay sufficient attention to both coarse-grained and fine-grained information of speech. 
>
> In this work, we propose a novel CLM-based zero-shot TTS approach, CoFi-Speech, that generates speech in a coarse-to-fine manner via a multi-scale speech coding and generation approach. In this framework, the multi-scale speech codec, CoFi-Codec, decomposes speech into multiple discrete sequences with different temporal resolutions and decodes them back with a high reconstruction quality. Then, we propose two LM-based approaches to predict this multi-scale speech representation from coarse to fine: single-LM-based chain-of-scale generation and multiple-LM-based stack-of-scale generation. In experiments, we present subjective and objective evaluations to demonstrate that CoFi-Speech significantly outperforms baseline systems based on single-scale speech sequences on naturalness and similarity, where stack-of-scale generation performs best. Finally, we conduct detailed ablation studies to analyze multi-scale coding and generation, to further validate the effectiveness of ``speaking from coarse to fine'' in achieving high-quality CLM-based TTS.
