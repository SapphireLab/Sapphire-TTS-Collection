# Noro: A Noise-Robust One-Shot Voice Conversion System With Hidden Speaker Representation Capabilities

<details>
<summary>基本信息</summary>

- 标题: "Noro: A Noise-Robust One-Shot Voice Conversion System With Hidden Speaker Representation Capabilities."
- 作者:
  - 01 Haorui He
  - 02 Yuchen Song
  - 03 Yuancheng Wang
  - 04 Haoyang Li
  - 05 Xueyao Zhang
  - 06 Li Wang
  - 07 Gongping Huang
  - 08 Eng Siong Chng
  - 09 Zhizheng Wu
- 链接:
  - [ArXiv](https://arxiv.org/abs/2411.19770v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2411.19770v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2024.11.29_2411.19770v1_Noro__A_Noise-Robust_One-Shot_Voice_Conversion_System_With_Hidden_Speaker_Representation_Capabilities.pdf)
  - [Publication] #TODO

</details>

## Abstract

One-shot voice conversion (VC) aims to alter the timbre of speech from a source speaker to match that of a target speaker using just a single reference speech from the target, while preserving the semantic content of the original source speech.
Despite advancements in one-shot VC, its effectiveness decreases in real-world scenarios where reference speeches, often sourced from the internet, contain various disturbances like background noise.
To address this issue, we introduce Noro, a Noise Robust One-shot VC system.
Noro features innovative components tailored for VC using noisy reference speeches, including a dual-branch reference encoding module and a noise-agnostic contrastive speaker loss.
Experimental results demonstrate that Noro outperforms our baseline system in both clean and noisy scenarios, highlighting its efficacy for real-world applications. 
Additionally, we investigate the hidden speaker representation capabilities of our baseline system by repurposing its reference encoder as a speaker encoder.
The results shows that it is competitive with several advanced self-supervised learning models for speaker representation under the SUPERB settings, highlighting the potential for advancing speaker representation learning through one-shot VC task.

## 1·Introduction

\IEEEPARstart{O}{ne-shot} voice conversion (VC) changes the timbre of speech from a source speaker to that of a target speaker using just one reference speech sample from the target, while maintaining the original speech's semantic content.

This task has been extensively researched in the deep learning era, employing various methods and producing promising results[^Popov2022Diffusion-Based], [^Li2024Sef-Vc], [^Zhang2024Amphion], [^He2024Emilia], [^Liu2024SpMis], [^Huang2024Debatts].

However, the strong performance of these one-shot VC methods is mainly demonstrated in controlled academic settings, where high-quality data is used for both training and evaluation.

As noted in[^Huang2021How], [^Huang2022Toward], [^Xie2023Noisy-to-Noisy], [^Xue2021Learning], their effectiveness significantly decreases in more challenging real-world scenarios, where reference speeches often collected from the internet are characterized by various interferences, such as background noise, which leads to a drop in the quality and similarity of the converted speech. 

Few previous works tried to address this challenge to achieve noise-robust VC.

Some researchers[^Valentini-Botinhao2016Investigating], [^Chan2021Speech] attempt to integrate a pre-trained or jointly trained speech enhancement (SE) module into standard VC systems to improve robustness.

However, these methods are not end-to-end and inevitably increase computational costs during inference.

Other researchers[^Huang2022Toward], [^Du2022Noise-Robust], [^Xue2021Learning] suggest strategies during training phase, such as direct data augmentation[^Huang2022Toward], to mitigate the impact of noise.

Despite these efforts, there is still room for improvement, especially in extremely noisy conditions where the Signal-to-Noise Ratio (SNR) is below 5 dB[^Du2022Noise-Robust].

To address these challenges, we introduce a novel Noise-Robust One-shot VC system named Noro.

Noro is built on a one-shot VC baseline system based on diffusion[^Ho2020Denoising], which generates speech from pitch and semantic representations obtained through a source encoder and speaker timbre representations via a reference encoder.
*To achieve noise-robustness of the system, we focus on learning speaker timbre representations that are agnostic to noise.*

We hypothesize that maintaining noise-agnostic input representations for the acoustic model will prevent its performance from deteriorating due to noise interference.

Therefore, we propose the following designs:
First, we introduce a novel dual-branch reference encoding module.

This module consists of a dual-branch transformer encoder structure with shared weights: one branch encodes clean reference speech, while the other encodes its noisy counterpart generated through data augmentation.

Next, we devise a noise-agnostic contrastive speaker loss to maximize the similarity between samples (whether clean or noisy) from the same speaker while minimizing it for those from different speakers.

This loss ensures that the dual-branch reference encoding module learns to represent speaker timbre independent of the acoustic environment of the reference speeches.

Experimental results demonstrate that Noro significantly improves the robustness of our baseline system in both clean and noisy environments, making it an ideal choice for real-world applications that encounter noisy reference speeches.

Additionally, inspired by[^Cho2020Learning], [^Cho2021Improving], we further investigate the speaker representation capabilities of our baseline system.

The motivation stems from the fact that the reference encoder within the VC systems, trained to encode the vocal timbre of various speakers, including unseen ones, for one-shot VC, inherently functions as a speaker encoder.

This encoder develops its capability to represent speakers in a self-supervised learning (SSL) manner without needing explicit speaker labels.

Thus, we argue that the reference encoder might possess hidden abilities to function effectively as an SSL speaker encoder.

To validate this hypothesis, we employ a pre-trained reference encoder from our baseline one-shot VC system as a speaker encoder, denoted as VC-SPK2VEC, and assess its speaker representation ability through a speaker verification task under the SUPERB[^Yang2021Superb] setting.

We compare its performance against several state-of-the-art (SOTA) SSL models, including Wav2vec[^Schneider2019Wav2vec], Wav2vec 2.0[^Baevski2020Wav2vec], HuBERT[^Hsu2021Hubert], and WavLM[^Chen2021WavLM].

Surprisingly, VC-SPK2VEC achieves a competitive Equal Error Rate (EER) of 5.32\%, comparable to these SOTA SSL models.

This result confirms the effectiveness of VC-SPK2VEC as an SSL speaker encoder and underscores the potential for leveraging one-shot VC tasks in advancing speaker representation learning.

Our contributions in this work can be summarized as follows.

-  We proposed Noro, a Noise-Robust One-shot VC system.

It achieves noise robustness through innovative designs, including a dual-branch reference encoding module, a noise-agnostic contrastive speaker loss.

Experimental results demonstrate that Noro significantly outperforms state-of-the-art one-shot VC systems in noisy scenarios, establishing it as the preferred choice for real-world applications requiring reliable, high-quality VC in diverse and challenging acoustic environments.

-  We investigated the hidden speaker representation capabilities of the proposed one-shot VC system by repurposing its reference encoder as a speaker encoder (VC-SPK2VEC).

VC-SPK2VEC exhibits comparable performance with several SOTA SSL models in speaker representation under the SUPERB setting, highlighting the overlooked potential for speaker representation learning via the one-shot VC task.

The paper is organized as follows: Section~[sec:related](#sec:related) discusses the related works.

Section~[sec:method](#sec:method) introduces the methodology, including a detailed description of our baseline one-shot voice conversion (VC) system and the proposed Noro system.

Section~[sec:exp](#sec:exp) first presents the experimental setup and results, evaluating the performance of Noro under various acoustic conditions and comparing it to baseline systems.

We then explore the impact of different source encoder models on the performance of Noro.

Subsequently, we explore the potential of re-purposing the reference encoder from our VC system as a self-supervised speaker encoder.

Finally, Section~[sec:conclude](#sec:conclude) provides concluding remarks, summarizing the findings and highlighting future research directions.

## 2·Related Work

\label{sec:related}

### Noise-robust Voice Conversion

#### One-shot Voice Conversion

Numerous studies have sought high-quality one-shot voice conversion using methods such as auto-encoders[^Hsu2016Voice], [^Kameoka2019Acvae-Vc], [^Qian2019Autovc], [^Qian2020Unsupervised], [^Wang2022DrVC], [^Popov2022Diffusion-Based], [^Wang2023Lm-Vc], [^Li2023FreeVC], [^Ju2024Naturalspeech], normalizing flows[^Kobyzev2020Normalizing], and self-supervised learning (SSL) models[^{Casanova, Edresson and Weber, Julian and Shulby, Christopher D and Junior, Arnaldo Candido and G{\"o}}lge2022YourTTS], [^Lin2021S2vc], [^Li2024Sef-Vc], [^Lim2024Wav2vec-Vc], [^Du2024UniCATS].

For example, Diff-VC[^Popov2022Diffusion-Based] uses an encoder that predicts an “average voice,” transforming mel features of each phoneme into averaged mel features across a large multi-speaker dataset, followed by decoding the mel for converted speech.

Similarly, FreeVC[^Li2023FreeVC] performs voice conversion by extracting disentangled content and target speaker information, then reconstructs the waveform using an end-to-end VITS framework.

Most recently, FaCodec-VC[^Ju2024Naturalspeech] employs a factorized codec approach to achieve state-of-the-art one-shot voice conversion performance.

It effectively disentangles speech attributes into content, prosody, and timbre representations using an information bottleneck, enabling strong one-shot voice conversion by altering the timbre of the source speech to match the target speaker.
*Despite these advances, the effectiveness of such models decreases in challenging real-world scenarios, where reference speech samples from the internet often contain interferences like background noise, reducing the quality and similarity of the converted speech.*

To address the issue of noise robustness, several studies have been conducted.

For instance, Valentini-Botinhao et al.[^Valentini-Botinhao2016Investigating] proposed an RNN-based speech enhancement method to improve noise robustness, utilizing LSTM networks for two-stage processing of input signals to effectively suppress noise.

Similarly, Chan et al.[^Chan2021Speech] developed a speech enhancement (SE)-assisted VC system, where the VC and SE components are jointly optimized to produce high-quality converted speech signals.

Additionally, Miao et al.[^Miao2019Noise-Robust] introduced a noise-robust voice conversion method that enhances high-quefrency components through sub-band cepstrum conversion and fusion.

Their approach leverages bidirectional long short-term memory networks to convert vocal tract parameters from a source to a target speaker in noisy conditions.

However, these approaches are not end-to-end, requiring separate stages for enhancement and synthesis, which adds complexity and increases computational overhead during inference.

To address this, some researchers have proposed training strategies to improve robustness.

Huang et al.[^Huang2022Toward] proposed applying random degraded data augmentations during training to force the model to filter out degradations and perform VC accurately.

Xue et al.[^Xue2021Learning] introduced a noise-controllable WaveGAN that learns noise-independent acoustic representations to improve conversion quality in noisy environments.

Du et al.[^Du2022Noise-Robust] employed domain adversarial training to ensure robustness against various noise conditions during conversion.

Despite these advancements, significant challenges remain, especially in extremely noisy environments where the Signal-to-Noise Ratio (SNR) is below 5 dB.
*This paper proposes the Noro system to address this challenge, introducing a dual-branch reference encoding module and a noise-agnostic contrastive speaker loss, which significantly enhance noise robustness even in challenging acoustic environments.*

### Self-supervised Learning for Speaker Representation Learning

Various self-supervised learning (SSL) models have been proposed for speech processing tasks.

These models are generally categorized into three types: generative, discriminative, and multi-task models[^Yang2021Superb].

Generative models, such as APC[^Chung2019Unsupervised], aim to reconstruct masked or future frames, focusing on predicting the missing or upcoming parts of the speech sequence.

Discriminative models like wav2vec[^Schneider2019Wav2vec] and HuBERT[^Hsu2021Hubert] use contrastive learning to distinguish between different segments of speech.

Multi-task models, such as WavLM+[^Chen2021WavLM], incorporate multiple pretraining objectives to learn versatile representations for downstream tasks.

These models have shown their effectiveness in various aspects of speech processing, including content, speaker, semantics, and paralinguistic information[^Yang2021Superb].

Inspired by[^Cho2020Learning], [^Cho2021Improving], \textit{this study further explores the speaker representation capabilities of one-shot VC systems.

The motivation arises from the observation that the reference encoder within one-shot VC systems, designed to capture the vocal timbre of diverse speakers—including previously unseen ones—naturally functions as a speaker encoder.

This aligns well with self-supervised speaker representation learning. }
