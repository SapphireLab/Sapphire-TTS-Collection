# Discl-Vc: Disentangled Discrete Tokens and in-Context Learning for Controllable Zero-Shot Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "Discl-Vc: Disentangled Discrete Tokens and in-Context Learning for Controllable Zero-Shot Voice Conversion."
- 作者:
  - 01 Kaidi Wang
  - 02 Wenhao Guan
  - 03 Ziyue Jiang
  - 04 Hukai Huang
  - 05 Peijie Chen
  - 06 Weijie Wu
  - 07 Qingyang Hong
  - 08 Lin Li
- 链接:
  - [ArXiv](https://arxiv.org/abs/2505.24291v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2505.24291v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.05.30_2505.24291v1_Discl-Vc__Disentangled_Discrete_Tokens_and_in-Context_Learning_for_Controllable_Zero-Shot_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Currently, zero-shot voice conversion systems are capable of synthesizing the voice of unseen speakers.
However, most existing approaches struggle to accurately replicate the speaking style of the source speaker or mimic the distinctive speaking style of the target speaker, thereby limiting the controllability of voice conversion.
In this work, we propose Discl-VC, a novel voice conversion framework that disentangles content and prosody information from self-supervised speech representations and synthesizes the target speaker's voice through in-context learning with a flow matching transformer.
To enable precise control over the prosody of generated speech, we introduce a mask generative transformer that predicts discrete prosody tokens in a non-autoregressive manner based on prompts.
Experimental results demonstrate the superior performance of Discl-VC in zero-shot voice conversion and its remarkable accuracy in prosody control for synthesized speech.
