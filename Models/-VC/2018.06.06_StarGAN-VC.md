# StarGAN-VC: Non-Parallel Many-to-Many Voice Conversion With Star Generative Adversarial Networks

<details>
<summary>基本信息</summary>

- 标题: "StarGAN-VC: Non-Parallel Many-to-Many Voice Conversion With Star Generative Adversarial Networks."
- 作者:
  - 01 Hirokazu Kameoka
  - 02 Takuhiro Kaneko
  - 03 Kou Tanaka
  - 04 Nobukatsu Hojo
- 链接:
  - [ArXiv](https://arxiv.org/abs/1806.02169v2)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:1806.02169v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2018.06.06_1806.02169v1_StarGAN-VC__Non-Parallel_Many-to-Many_Voice_Conversion_With_Star_Generative_Adversarial_Networks.pdf)
  - [ArXiv:1806.02169v2](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2018.06.06_1806.02169v2_StarGAN-VC__Non-Parallel_Many-to-Many_Voice_Conversion_With_Star_Generative_Adversarial_Networks.pdf)
  - [Publication] #TODO

</details>

## Abstract

This paper proposes a method that allows non-parallel many-to-many voice conversion (VC) by using a variant of a generative adversarial network (GAN) called StarGAN. 
Our method, which we call StarGAN-VC, is noteworthy in that it 
(1) requires no parallel utterances, transcriptions, or time alignment procedures for speech generator training, (2) simultaneously learns many-to-many mappings across different attribute domains using a single generator network, (3) is able to generate converted speech signals quickly enough to allow real-time implementations and (4) requires only several minutes of training examples to generate reasonably realistic-sounding speech.
Subjective evaluation experiments on a non-parallel many-to-many speaker identity conversion task
revealed that the proposed method obtained higher sound quality and speaker similarity than a state-of-the-art method based on variational autoencoding GANs.
