# Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion."
- 作者:
  - 01 Yu Zhang
  - 02 Baotong Tian
  - 03 Zhiyao Duan
- 链接:
  - [ArXiv](https://arxiv.org/abs/2507.14534v3)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2507.14534v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.07.19_2507.14534v1_Conan__A_Chunkwise_Online_Network_for_Zero-Shot_Adaptive_Voice_Conversion.pdf)
  - [ArXiv:2507.14534v2](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.07.19_2507.14534v2_Conan__A_Chunkwise_Online_Network_for_Zero-Shot_Adaptive_Voice_Conversion.pdf)
  - [ArXiv:2507.14534v3](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.07.19_2507.14534v3_Conan__A_Chunkwise_Online_Network_for_Zero-Shot_Adaptive_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Zero-shot online voice conversion (VC) holds significant promise for real-time communications and entertainment. 
However, current VC models struggle to preserve semantic fidelity under real-time constraints, deliver natural-sounding conversions, and adapt effectively to unseen speaker characteristics.
To address these challenges, we introduce Conan, a chunkwise online zero-shot voice conversion model that preserves the content of the source while matching the speaker identity of reference speech.
Conan comprises three core components: 
1) a Stream Content Extractor that leverages Emformer for low-latency streaming content encoding; 
2) an Adaptive Style Encoder that extracts fine-grained stylistic features from reference speech for enhanced style adaptation; 
3) a Causal Shuffle Vocoder that implements a fully causal HiFiGAN using a pixel-shuffle mechanism. 
Experimental evaluations demonstrate that Conan outperforms baseline models in subjective and objective metrics.
Audio samples can be found at \url{https://aaronz345.github.io/ConanDemo}.
