# EZ-VC: Easy Zero-Shot Any-to-Any Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "EZ-VC: Easy Zero-Shot Any-to-Any Voice Conversion."
- 作者:
  - 01 Advait Joglekar
  - 02 Divyanshu Singh
  - 03 Rooshil Rohit Bhatia
  - 04 S. Umesh
- 链接:
  - [ArXiv](https://arxiv.org/abs/2505.16691v2)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2505.16691v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.05.22_2505.16691v1_EZ-VC__Easy_Zero-Shot_Any-to-Any_Voice_Conversion.pdf)
  - [ArXiv:2505.16691v2](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.05.22_2505.16691v2_EZ-VC__Easy_Zero-Shot_Any-to-Any_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

Voice Conversion research in recent times has increasingly focused on improving the zero-shot capabilities of existing methods.
Despite remarkable advancements, current architectures still tend to struggle in zero-shot cross-lingual settings.
They are also often unable to generalize for speakers of unseen languages and accents.
In this paper, we adopt a simple yet effective approach that combines discrete speech representations from self-supervised models with a non-autoregressive Diffusion-Transformer based conditional flow matching speech decoder.
We show that this architecture allows us to train a voice-conversion model in a purely textless, self-supervised fashion.
Our technique works without requiring multiple encoders to disentangle speech features.
Our model also manages to excel in zero-shot cross-lingual settings even for unseen languages.
We provide demo samples for our model here: \href{https://ez-vc.github.io/EZ-VC-Demo/}{https://ez-vc.github.io/EZ-VC-Demo/}
