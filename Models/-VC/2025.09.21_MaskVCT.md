# MaskVCT: Masked Voice Codec Transformer for Zero-Shot Voice Conversion With Increased Controllability via Multiple Guidances

<details>
<summary>基本信息</summary>

- 标题: "MaskVCT: Masked Voice Codec Transformer for Zero-Shot Voice Conversion With Increased Controllability via Multiple Guidances."
- 作者:
  - 01 Junhyeok Lee
  - 02 Helin Wang
  - 03 Yaohan Guan
  - 04 Thomas Thebaud
  - 05 Laureano Moro-Velazquez
  - 06 Jesús Villalba
  - 07 Najim Dehak
- 链接:
  - [ArXiv](https://arxiv.org/abs/2509.17143v1)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2509.17143v1](PDF/2025.09.21_2509.17143v1_MaskVCT__Masked_Voice_Codec_Transformer_for_Zero-Shot_Voice_Conversion_With_Increased_Controllability_via_Multiple_Guidances.pdf)
  - [Publication] #TODO

</details>

## Abstract

We introduce MaskVCT, a zero‑shot voice conversion (VC) model that offers multi‑factor controllability through multiple classifier‑free guidances (CFGs).
While previous VC models rely on a fixed conditioning scheme, MaskVCT integrates diverse conditions in a single model.
To further enhance robustness and control, the model can leverage continuous or quantized linguistic features to enhance intelligibility and speaker similarity, and can use or omit pitch contour to control prosody.
These choices allow users to seamlessly balance speaker identity, linguistic content, and prosodic factors in a zero‑shot VC setting.
Extensive experiments demonstrate that MaskVCT achieves the best target speaker and accent similarities while obtaining competitive word and character error rates compared to existing baselines.
Audio samples are available at \url{https://maskvct.github.io/}.
