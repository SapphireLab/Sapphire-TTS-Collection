# GenVC: Self-Supervised Zero-Shot Voice Conversion

<details>
<summary>基本信息</summary>

- 标题: "GenVC: Self-Supervised Zero-Shot Voice Conversion."
- 作者:
  - 01 Zexin Cai
  - 02 Henry Li Xinyuan
  - 03 Ashi Garg
  - 04 Leibny Paola García-Perera
  - 05 Kevin Duh
  - 06 Sanjeev Khudanpur
  - 07 Matthew Wiesner
  - 08 Nicholas Andrews
- 链接:
  - [ArXiv](https://arxiv.org/abs/2502.04519v2)
  - [Publication]()
  - [Github]()
  - [Demo]()
- 文件:
  - [ArXiv:2502.04519v1](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.02.06_2502.04519v1_GenVC__Self-Supervised_Zero-Shot_Voice_Conversion.pdf)
  - [ArXiv:2502.04519v2](D:\Speech\Sapphire-TTS-Collection\Models\-VC\_PDF\2025.02.06_2502.04519v2_GenVC__Self-Supervised_Zero-Shot_Voice_Conversion.pdf)
  - [Publication] #TODO

</details>

## Abstract

\begin{abstract}
Most current zero-shot voice conversion methods rely on externally supervised components, particularly speaker encoders, for training.
To explore alternatives that eliminate this dependency, this paper introduces GenVC, a novel framework that disentangles speaker identity and linguistic content from speech signals in a self-supervised manner.
GenVC leverages speech tokenizers and an autoregressive, Transformer-based language model as its backbone for speech generation.
This design supports large-scale training while enhancing both source speaker privacy protection and target speaker cloning fidelity.
Experimental results demonstrate that GenVC achieves notably higher speaker similarity, with naturalness on par with leading zero-shot approaches.
Moreover, due to its autoregressive formulation, GenVC introduces flexibility in temporal alignment, reducing the preservation of source prosody and speaker-specific traits, and making it highly effective for voice anonymization.\footnote{Audio samples, code, and model checkpoints are available at \\ \indent\url{https://caizexin.github.io/GenVC/index.html}}
