# SECodec

<details>
<summary>基本信息</summary>

- 标题: "SECodec: Structural Entropy-based Compressive Speech Representation Codec for Speech Language Models"
- 作者:
  - 01 Linqin Wang,
  - 02 Yaping Liu,
  - 03 Zhengtao Yu,
  - 04 Shengxiang Gao,
  - 05 Cunli Mao,
  - 06 Yuxin Huang,
  - 07 Wenjun Wang,
  - 08 Ling Dong
- 链接:
  - [ArXiv](https://arxiv.org/abs/2501.00018)
  - [Publication]() AAAI2025
  - [Github](https://github.com/wlq2019/SECodec)
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2501.00018v1__SECodec__Structural_Entropy-based_Compressive_Speech_Representation_Codec_for_Speech_Language_Models.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

With the rapid advancement of large language models (LLMs), discrete speech representations have become crucial for integrating speech into LLMs.
Existing methods for speech representation discretization rely on a predefined codebook size and Euclidean distance-based quantization.
However,
1) the size of codebook is a critical parameter that affects both codec performance and downstream task training efficiency.
2) The Euclidean distance-based quantization may lead to audio distortion when the size of the codebook is controlled within a reasonable range.

In fact, in the field of information compression, structural information and entropy guidance are crucial, but previous methods have largely overlooked these factors.
Therefore, we address the above issues from an information-theoretic perspective, we present SECodec, a novel speech representation codec based on structural entropy (SE) for building speech language models.
Specifically, we first model speech as a graph, clustering the speech features nodes within the graph and extracting the corresponding codebook by hierarchically and disentangledly minimizing 2D SE.
Then, to address the issue of audio distortion, we propose a new quantization method.
This method still adheres to the 2D SE minimization principle, adaptively selecting the most suitable token corresponding to the cluster for each incoming original speech node.
Furthermore, we develop a Structural Entropy-based Speech Language Model (SESLM) that leverages SECodec.
Experimental results demonstrate that SECodec performs comparably to EnCodec in speech reconstruction, and SESLM surpasses VALL-E in zero-shot text-to-speech tasks.
Code, demo speeches, speech feature graph, SE codebook, and models are available at [Github](https://github.com/wlq2019/SECodec).

## 1·Introduction: 引言

Large language models (LLMs)~\cite{achiam2023gpt,touvron2023llama} have exhibited exceptional capabilities in a wide range of natural language processing tasks.
This success has spurred extensive research efforts in developing speech language models~\cite{zhang2023speechtokenizer,huang2023repcodec,borsos2023audiolm}, leading to notable advancements in numerous speech processing applications~\cite{wang2023neural,tu2024smart,rubenstein2023audiopalm,dong2023polyvoice,tu2023view}.
To bridge the gap between continuous speech and token-based language models, a crucial method called speech discretization is employed.
This process transforms an audio signal into a finite set of tokens.
By converting speech into discrete tokens, language models are able to predict future semantic content and generate coherent and realistic speech with long-term consistency~\cite{nguyen2022discrete,tu20222}.

Current discrete speech representations for
speech language models can be categorized into three types: semantic
tokens, acoustic tokens, and hybrid/unified tokens~\cite{borsos2023audiolm,zhang2023speechtokenizer}. 1) Semantic tokens~\cite{hsu2021hubert,baevski2020wav2vec,chung2021w2v} are typically generated from self-supervised pre-trained models using masked language modeling as the training objective, which are derived through $k$-means clustering on representations from a specific intermediate layer, resulting in sequences with a one-dimensional structure.
Speech language models that use semantic tokens~\cite{lakhotia2021generative,zhang2023speechgpt,hassid2024textually} can be externally connected to a vocoder for speech synthesis.
While these models effectively capture semantically accurate content, the resulting speech generation often suffers from poor quality and a loss of acoustic details.
2) Acoustic tokens~\cite{zeghidour2021soundstream,defossez2022high,yang2023hifi,du2024funcodec} are extracted from neural audio codecs, which use reconstruction as the training objective.
By employing residual vector quantization (RVQ)~\cite{gray1984vector,vasuki2006review} with hierarchical quantizers for discretization, acoustic tokens are represented as matrices with two dimensions: timesteps and quantizers.
VALL-E~\cite{wang2023neural} is a representative model of speech language models that utilize acoustic tokens.
Despite achieving impressive zero-shot text-to-speech (TTS) capabilities, it still faces issues such as inaccurate content, stemming from the complex information contained within acoustic tokens.
3) Hybrid or unified tokens~\cite{borsos2023audiolm,zhang2023speechtokenizer} employ different strategies to combine semantic tokens and acoustic tokens.
Hybrid tokens adopt a hierarchical approach, encompassing both semantic token language models and acoustic token language models, to capture content information and acoustic details, respectively~\cite{dong2023polyvoice,borsos2023audiolm,rubenstein2023audiopalm}.
Recently, unified tokens, exemplified by SpeechTokenizer~\cite{zhang2023speechtokenizer}, have emerged.
These tokens distill semantic information into acoustic tokens, effectively unifying semantic and acoustic representations.
SpeechTokenizer has achieved superior results in downstream tasks such as speech synthesis.
The ideal speech representation for speech language models should meet two key characteristics: i) Effective preservation of speech information; ii) Sufficient compressiveness for efficient training of speech language models.
However, i) existing speech discretization methods rely on $k$-means to initialize the codebook space, the size of codebook is a critical parameter that significantly impacts the performance of the codec and the training efficiency of downstream tasks, yet its size is typically determined through empirical judgment. ii) Additionally, when attempting to control the size of the codebook within a reasonable range, the quantization process, which relies on Euclidean distance, may lead to substantial differences between codebook's vector and original vector, resulting in audio distortion.
These issues result in a loss of information and produce overly long tokens that are difficult to train, thereby impairing overall performance.

In this work, we address the aforementioned issues from an information-theoretic perspective, drawing inspiration from structural entropy (SE)~\cite{li2016structural,cao2024hierarchical}, a metric that assesses the amount of information contained in a graph~\cite{yang2024hierarchical,zeng2024scalable,yang2024adaptive,yang2024sebot,cao2024multi,peng2024unsupervised,zou2024multispans}.
We present SECodec, a novel speech representation codec tokenizer based on structural entropy, which can automatically determine the appropriate codebook size and integrate structural information into the quantization process.
Experiments demonstrate that these approaches effectively mitigate the information loss problem prevalent in existing speech discretization methods.

Our main contributions are:
-  We model the speech representation codec from an information-theoretic perspective.
Compared to previous methods that use $k$-means, the proposed SECodec, by introducing structural information and entropy guidance, learns a more compressive and informative codebook without requiring a predetermined codebook size.
To the best of our knowledge, we are the first to apply structural entropy (SE) minimization for a speech representation codec.
- To address the issue of audio distortion when controlling codebook size, we propose a new quantization method that iteratively selects appropriate clusters for the added original speech features using a SE heuristic function.
This approach significantly enhances the quality of information in the speech tokens.
- Extensive experimental results demonstrate that SECodec performs comparably to EnCodec in speech reconstruction, while SESLM surpasses VALL-E in zero-shot text-to-speech tasks on a multi-speaker benchmark dataset.

## 2·Preliminary: 预备知识

Structural entropy (SE)~\cite{li2016structural} is defined as the minimum number of bits to encode the vertex that is accessible with a step of random walk on a graph.
SE is a measurement of graph complexity by encoding tree structures via characterizing the uncertainty of the hierarchical topology of graphs.
The structural entropy of graph $G$ is defined on an associated encoding tree $\mathcal{T}$, revealing the amount of uncertainty that remained in $G$ after encoded by $\mathcal{T}$.
Through structural entropy minimization, the optimized hierarchical clustering result of vertices in $G$ is retained by $\mathcal{T}$.
We present the formal definitions of encoding tree and SE as follows.

### Definition 1

Let $G=(V,E,W)$ be an undirected weighted graph, where $V=\{v_1,...,v_n\}$ is the vertex set, $E$ is the edge set, and $W \in R^{n \times n}$ is the edge weight matrix.

1) \textit{The encoding tree $\mathcal{T}$ of $G$ is a hierarchical rooted tree where each tree
node $\alpha$ associates with a vertex set $T_{\alpha}$.}

2) \textit{The root node $\lambda$ of
$\mathcal{T}$ associates with $T_{\lambda}=V$ and each leaf node $v$ associates with $T_v$ containing a vertex in $V$.}

3) \textit{For each non-leaf
node $\alpha \in \mathcal{T}$, the successors of $\alpha$ are associated with disjoint vertex subsets, and the union of these subsets is $T_{\alpha}$.}

### Definition 2

The structural entropy of $G$ given by $\mathcal{T}$ is defined as follows:

$$
\mathcal{H}^{\mathcal{T}}(G)=\sum_{\alpha \in \mathcal{T},\alpha \neq \lambda}\mathcal{H}^{\mathcal{T}}(G;\alpha)=\\ \sum_{\alpha \in \mathcal{T},\alpha \neq \lambda}-\frac{g_{\alpha}}{\mathcal{V}_G}log_2\frac{\mathcal{V}_{\alpha}}{\mathcal{V}_{{\alpha}^-}},
$$

where $\mathcal{H}^{\mathcal{T}}(G;\alpha)$ is the assigned structural entropy of $\alpha$, $g_{\alpha}$ is the cut, i.e., the sum of edge weights between vertices in and not in $T_{\alpha}$, $\mathcal{V}_{\alpha}$ and $\mathcal{V}_{G}$ are the volumes, i.e., the sum of vertex degrees in $T_{\alpha}$ and $G$, respectively.
The structural entropy of $G$ is defined as $\mathcal{H}(G)=\mathop{\min}_{\mathcal{T}} \{ \mathcal{H}^{\mathcal{T}}(G) \},$

where $\mathcal{T}$ ranges over all possible encoding trees.
The vertex sets associated with tree nodes form a clustering of vertices in $V$.

### Definition 3

The $K$-D structural entropy is the structural entropy given by the encoding trees with the height of at most $K$.
When $K=2$, the encoding tree represents graph partitioning, which can be used to perform partitioning clustering.
A $2$-D encoding tree $\mathcal{T}$ can be formulated as a graph partitioning $\mathcal{P}=\{ \mathcal{X}_1,\mathcal{X}_2,...,\mathcal{X}_L\}$ of $V$ , where $\mathcal{X}_i$ is a vertex subset called module associated with the $i$-th children of root $\lambda$.
The structural entropy of $G$ given by $\mathcal{P}$ is defined as:

$$
\mathcal{H}^{\mathcal{P}}(G)=-\sum_{\mathcal{X} \in \mathcal{P}}\sum_{v_i \in \mathcal{X}}\frac{g_i}{\mathcal{V}_G}log_2\frac{d_i}{\mathcal{V}_\mathcal{X}}\\ -\sum_{\mathcal{X} \in \mathcal{P}}\frac{g_\mathcal{X}}{\mathcal{V}_G}log_2\frac{\mathcal{V}_\mathcal{X}}{\mathcal{V}_G},
$$

where $d_i$ is the degree of vertex $v_i$, $g_i$ is the cut, i.e., the sum of edge weights connecting $v_i$ and other vertices, $\mathcal{V}_\mathcal{X}$ and $\mathcal{V}_G$ are the volumes, i.e., the sum of vertex degrees in module $\mathcal{X}$ and graph $G$, respectively, and $g_\mathcal{X}$ is the cut, i.e., the sum of edge weights between vertices in and not in module $\mathcal{X}$.

## 3·Methodology: 方法

Figure~\ref{model} presents an overview of SECodec.
Our model is based on the RVQ-GANs~\cite{du2024funcodec} framework, akin to SoundStream~\cite{zeghidour2021soundstream} and EnCodec~\cite{defossez2022high}.
However, we employ 2D structural entropy to optimize both the codebook initialization and the quantization process, resulting in more compressive codebook and more informative tokens.
We begin by formalizing the task.
Subsequently, we propose a novel structural entropy-based approach for codebook construction.
We then present our informative quantization process.
Finally, we introduce the training objective and design the SESLM.

### Problem Formalization

Considering the input speech feature $X = [x_1,...,x_T ] \in R^{H \times T}$ from a pre-trained convolutional network, where $H$ is the dimension of the speech representation and $T$ is the length of the sequence. we construct a speech feature graph $G = (V,E,W)$.
Here $V = \{v_1, v_2, ..., v_n\}$ is the set of vertices corresponding to speech features in $X$ , $E$ represents the set of edges connecting the vertices, and $W$ represents the set of edge weights measuring the similarities between every frame of speech feature.
For two frames of speech feature $x_i,x_j \in X$, we measure their the cosine similarity.  Partitioning $G$ results in $\{\textbf{e}_1,...,\textbf{e}_i,...,\textbf{e}_j,...,\textbf{e}_K\}, \textbf{e}_i \subset V, \textbf{e}_i \cap \textbf{e}_j = \emptyset$, which represents a partition of $V$ containing $K$ clusters (sets) of speech features.
These clusters correspond to the codebook $\mathcal{E}_{codebook}= [\textbf{e}_1,...,\textbf{e}_K]$.

### Codebook Construction via Hierarchical and Disentangled 2D SE Minimization

Speech feature graph partitioning decodes $G$ into $\mathcal{P}$, which defines the size of the codebook in the form of speech feature clusters.
A faithful decoding of the speech feature correlations in $G$ assigns related speech features to the same cluster and unrelated ones to different clusters.
Previous RVQ-based speech codec methods use $k$-means to initialize the codebook space.
These empirically defined codebooks, which must be predetermined, lead to a loss of information and result in overly long tokens that are difficult to train, consequently impairing overall performance.
To address this issue, SECodec conducts codebook partitioning under the guidance of 2D structural entropy (SE) minimization.
This approach reveals the essential second-order (cluster-wise) structure inherent in the raw graph without prior knowledge of the number of speech feature clusters.

li2016structural (\citeyear{li2016structural}) propose a vanilla greedy 2D structural entropy (SE) minimization algorithm that repeatedly merges any two nodes in the encoding tree $\mathcal{T}$ resulting in the largest decrease in 2D SE until reaching the minimum possible value.
This process partitions a graph without supervision or a predetermined total number of clusters.
However, this vanilla 2D SE minimization algorithm has a time complexity of $O(|V|^3)$, making it prohibitively slow for large and complex graphs.
Furthermore, the ultimate goal of our clustering is to construct codebook.
The column vectors in the codebook need to be spatially distributed as far apart as possible and avoid overlapping to ensure effective representation and diversity of the speech features.
To address these challenges, we propose to minimize 2D
SE for construct codebook in a hierarchical and disentangled manner, shown in Algorithm~\ref{algorithm:codebook}.
Specifically, each speech feature  $x_1,...,x_T$  is placed in its own cluster (line 1).
These clusters are then divided into subsets of size $n$ (line 3-5), and within each subset, the vanilla greedy algorithm is used to merge the clusters into new ones (lines 6-16).
The newly formed clusters proceed to the next iteration (line 17).
This iterative process continues until all speech feature clusters are considered simultaneously (lines 18-19).
If no clusters within a subset can be merged at any point, the subset size $n$ is increased to allow more clusters to be considered together for potential merging (lines 20-21).
Finally, we extract the corresponding codebook by minimizing the mutual information between each vector within the codebook (lines 22-34).
Figure~\ref{model}A shows the speech feature graph construction on nodes $x_1$ to $x_{10000}$.
Figure~\ref{model}B illustrates codebook construction process: initially $x_1$ to $x_{10000}$ are in separate clusters.
Clusters of size $n = 1024$ are considered at a time to form a subgraph $G'$.
Clusters in each $G'$ are merged using the vanilla 2D SE minimization to form $\mathcal{P}'$ (Figure ~\ref{model}B.1).
The partitions from the previous iteration are carried over to the next, as shown by the blue curved arrows in Figure~\ref{model}B.2.
The process concludes when a $\mathcal{P}'$ that encompasses all the speech features is achieved.
To further enhance the codebooks' ability to represent the diversity of speech, we introduce a mutual information learning algorithm to disentangle the central features of each cluster in $\mathcal{P}'$.
For the disentanglement between $\textbf{e}_i$ and $\textbf{e}_j$.
The variational contrastive log-ratio upper bound (vCLUB)~\cite{cheng2020club} is used to compute the upper bound of mutual information (MI) for irrelevant information of the $\textbf{e}$, decreasing the correlation among different clusters' representation:

$$
\mathcal{\hat{I}}(\textbf{e}_i, \textbf{e}_j)
=\frac{1}{\mathcal{N}^2}\sum_{\mathcal{M}=1}^\mathcal{N}\sum_{\mathcal{J}=1}^\mathcal{N}
[\log f_\psi({\textbf{e}_i}_\mathcal{M}|{\textbf{e}_j}_\mathcal{M})
-\log f_\psi({{\textbf{e}_j}}_\mathcal{J}|{\textbf{e}_i}_\mathcal{M})],
$$

where $\{\textbf{e}_i, \textbf{e}_j\} \in \textbf{e}$, $\mathcal{N}$ represents the samples from $\textbf{e}_i$ and $\textbf{e}_j$. $f_{\psi}(\textbf{e}_i|\textbf{e}_j)$ is a variational distribution with parameter $\psi$ to approximate $f(\textbf{e}_i|\textbf{e}_j)$.
$\mathcal{\hat{I}}$ is the unbiased estimator for vCLUB with samples $\{{\textbf{e}_i}_\mathcal{M}, {\textbf{e}_j}_\mathcal{J}\}$.
The indexes $\mathcal{M}$ and $\mathcal{J}$ are the samples of $\textbf{e}_i$ and $\textbf{e}_j$.
By minimizing Eq.~\ref{eq:mi}, we can decrease the correlation among
accent features $\textbf{e}_i$ and speech features $\textbf{e}_j$.
Finally, the central features of each cluster in $\mathcal{P}'$ are concatenated to form the codebook $\mathcal{E}_{codebook}$ columns in Figure~\ref{model}B.3.
In summary, SECodec constructs a compressive codebook from complex speech feature graphs in an unsupervised and disentangled manner.

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论

Interacting with LLMs through speech has led to an increased demand for effective speech representation discretization.
To address this, we propose SECodec, which can automatically determines the appropriate codebook size and integrates structural information into the quantization process.
Extensive experiments demonstrate that SECodec outperforms EnCodec in speech reconstruction.
Furthermore, we developed a Structural Entropy-based Speech Language Model (SESLM) that leverages SECodec, yielding superior results in terms of generated speech content accuracy and quality.
Additionally, the experiments show that SECodec is capable of learning a more compressive and discrete codebook and producing more informative speech tokens.
