# SECodec

<details>
<summary>基本信息</summary>

- 标题: "SECodec: Structural Entropy-based Compressive Speech Representation Codec for Speech Language Models"
- 作者:
  - 01 Linqin Wang,
  - 02 Yaping Liu,
  - 03 Zhengtao Yu,
  - 04 Shengxiang Gao,
  - 05 Cunli Mao,
  - 06 Yuxin Huang,
  - 07 Wenjun Wang,
  - 08 Ling Dong
- 链接:
  - [ArXiv](https://arxiv.org/abs/2501.00018)
  - [Publication]() AAAI2025
  - [Github](https://github.com/wlq2019/SECodec)
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2501.00018v1__SECodec__Structural_Entropy-based_Compressive_Speech_Representation_Codec_for_Speech_Language_Models.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

With the rapid advancement of large language models (LLMs), discrete speech representations have become crucial for integrating speech into LLMs.
Existing methods for speech representation discretization rely on a predefined codebook size and Euclidean distance-based quantization.
However,
1) the size of codebook is a critical parameter that affects both codec performance and downstream task training efficiency.
2) The Euclidean distance-based quantization may lead to audio distortion when the size of the codebook is controlled within a reasonable range.

In fact, in the field of information compression, structural information and entropy guidance are crucial, but previous methods have largely overlooked these factors.
Therefore, we address the above issues from an information-theoretic perspective, we present SECodec, a novel speech representation codec based on structural entropy (SE) for building speech language models.
Specifically, we first model speech as a graph, clustering the speech features nodes within the graph and extracting the corresponding codebook by hierarchically and disentangledly minimizing 2D SE.
Then, to address the issue of audio distortion, we propose a new quantization method.
This method still adheres to the 2D SE minimization principle, adaptively selecting the most suitable token corresponding to the cluster for each incoming original speech node.
Furthermore, we develop a Structural Entropy-based Speech Language Model (SESLM) that leverages SECodec.
Experimental results demonstrate that SECodec performs comparably to EnCodec in speech reconstruction, and SESLM surpasses VALL-E in zero-shot text-to-speech tasks.
Code, demo speeches, speech feature graph, SE codebook, and models are available at [Github](https://github.com/wlq2019/SECodec).

## 1·Introduction: 引言

Large language models (LLMs)~\cite{achiam2023gpt,touvron2023llama} have exhibited exceptional capabilities in a wide range of natural language processing tasks.
This success has spurred extensive research efforts in developing speech language models~\cite{zhang2023speechtokenizer,huang2023repcodec,borsos2023audiolm}, leading to notable advancements in numerous speech processing applications~\cite{wang2023neural,tu2024smart,rubenstein2023audiopalm,dong2023polyvoice,tu2023view}.
To bridge the gap between continuous speech and token-based language models, a crucial method called speech discretization is employed.
This process transforms an audio signal into a finite set of tokens.
By converting speech into discrete tokens, language models are able to predict future semantic content and generate coherent and realistic speech with long-term consistency~\cite{nguyen2022discrete,tu20222}.

Current discrete speech representations for
speech language models can be categorized into three types: semantic
tokens, acoustic tokens, and hybrid/unified tokens~\cite{borsos2023audiolm,zhang2023speechtokenizer}. 1) Semantic tokens~\cite{hsu2021hubert,baevski2020wav2vec,chung2021w2v} are typically generated from self-supervised pre-trained models using masked language modeling as the training objective, which are derived through $k$-means clustering on representations from a specific intermediate layer, resulting in sequences with a one-dimensional structure.
Speech language models that use semantic tokens~\cite{lakhotia2021generative,zhang2023speechgpt,hassid2024textually} can be externally connected to a vocoder for speech synthesis.
While these models effectively capture semantically accurate content, the resulting speech generation often suffers from poor quality and a loss of acoustic details.
2) Acoustic tokens~\cite{zeghidour2021soundstream,defossez2022high,yang2023hifi,du2024funcodec} are extracted from neural audio codecs, which use reconstruction as the training objective.
By employing residual vector quantization (RVQ)~\cite{gray1984vector,vasuki2006review} with hierarchical quantizers for discretization, acoustic tokens are represented as matrices with two dimensions: timesteps and quantizers.
VALL-E~\cite{wang2023neural} is a representative model of speech language models that utilize acoustic tokens.
Despite achieving impressive zero-shot text-to-speech (TTS) capabilities, it still faces issues such as inaccurate content, stemming from the complex information contained within acoustic tokens.
3) Hybrid or unified tokens~\cite{borsos2023audiolm,zhang2023speechtokenizer} employ different strategies to combine semantic tokens and acoustic tokens.
Hybrid tokens adopt a hierarchical approach, encompassing both semantic token language models and acoustic token language models, to capture content information and acoustic details, respectively~\cite{dong2023polyvoice,borsos2023audiolm,rubenstein2023audiopalm}.
Recently, unified tokens, exemplified by SpeechTokenizer~\cite{zhang2023speechtokenizer}, have emerged.
These tokens distill semantic information into acoustic tokens, effectively unifying semantic and acoustic representations.
SpeechTokenizer has achieved superior results in downstream tasks such as speech synthesis.
The ideal speech representation for speech language models should meet two key characteristics: i) Effective preservation of speech information; ii) Sufficient compressiveness for efficient training of speech language models.
However, i) existing speech discretization methods rely on $k$-means to initialize the codebook space, the size of codebook is a critical parameter that significantly impacts the performance of the codec and the training efficiency of downstream tasks, yet its size is typically determined through empirical judgment. ii) Additionally, when attempting to control the size of the codebook within a reasonable range, the quantization process, which relies on Euclidean distance, may lead to substantial differences between codebook's vector and original vector, resulting in audio distortion.
These issues result in a loss of information and produce overly long tokens that are difficult to train, thereby impairing overall performance.

In this work, we address the aforementioned issues from an information-theoretic perspective, drawing inspiration from structural entropy (SE)~\cite{li2016structural,cao2024hierarchical}, a metric that assesses the amount of information contained in a graph~\cite{yang2024hierarchical,zeng2024scalable,yang2024adaptive,yang2024sebot,cao2024multi,peng2024unsupervised,zou2024multispans}.
We present SECodec, a novel speech representation codec tokenizer based on structural entropy, which can automatically determine the appropriate codebook size and integrate structural information into the quantization process.
Experiments demonstrate that these approaches effectively mitigate the information loss problem prevalent in existing speech discretization methods.

Our main contributions are:
-  We model the speech representation codec from an information-theoretic perspective.
Compared to previous methods that use $k$-means, the proposed SECodec, by introducing structural information and entropy guidance, learns a more compressive and informative codebook without requiring a predetermined codebook size.
To the best of our knowledge, we are the first to apply structural entropy (SE) minimization for a speech representation codec.
- To address the issue of audio distortion when controlling codebook size, we propose a new quantization method that iteratively selects appropriate clusters for the added original speech features using a SE heuristic function.
This approach significantly enhances the quality of information in the speech tokens.
- Extensive experimental results demonstrate that SECodec performs comparably to EnCodec in speech reconstruction, while SESLM surpasses VALL-E in zero-shot text-to-speech tasks on a multi-speaker benchmark dataset.

## 2·Preliminary: 预备知识

Structural entropy (SE)~\cite{li2016structural} is defined as the minimum number of bits to encode the vertex that is accessible with a step of random walk on a graph.
SE is a measurement of graph complexity by encoding tree structures via characterizing the uncertainty of the hierarchical topology of graphs.
The structural entropy of graph $G$ is defined on an associated encoding tree $\mathcal{T}$, revealing the amount of uncertainty that remained in $G$ after encoded by $\mathcal{T}$.
Through structural entropy minimization, the optimized hierarchical clustering result of vertices in $G$ is retained by $\mathcal{T}$.
We present the formal definitions of encoding tree and SE as follows.

### Definition 1

Let $G=(V,E,W)$ be an undirected weighted graph, where $V=\{v_1,...,v_n\}$ is the vertex set, $E$ is the edge set, and $W \in R^{n \times n}$ is the edge weight matrix.

1) \textit{The encoding tree $\mathcal{T}$ of $G$ is a hierarchical rooted tree where each tree
node $\alpha$ associates with a vertex set $T_{\alpha}$.}

2) \textit{The root node $\lambda$ of
$\mathcal{T}$ associates with $T_{\lambda}=V$ and each leaf node $v$ associates with $T_v$ containing a vertex in $V$.}

3) \textit{For each non-leaf
node $\alpha \in \mathcal{T}$, the successors of $\alpha$ are associated with disjoint vertex subsets, and the union of these subsets is $T_{\alpha}$.}

### Definition 2

The structural entropy of $G$ given by $\mathcal{T}$ is defined as follows:

$$
\mathcal{H}^{\mathcal{T}}(G)=\sum_{\alpha \in \mathcal{T},\alpha \neq \lambda}\mathcal{H}^{\mathcal{T}}(G;\alpha)=\\ \sum_{\alpha \in \mathcal{T},\alpha \neq \lambda}-\frac{g_{\alpha}}{\mathcal{V}_G}log_2\frac{\mathcal{V}_{\alpha}}{\mathcal{V}_{{\alpha}^-}},
$$

where $\mathcal{H}^{\mathcal{T}}(G;\alpha)$ is the assigned structural entropy of $\alpha$, $g_{\alpha}$ is the cut, i.e., the sum of edge weights between vertices in and not in $T_{\alpha}$, $\mathcal{V}_{\alpha}$ and $\mathcal{V}_{G}$ are the volumes, i.e., the sum of vertex degrees in $T_{\alpha}$ and $G$, respectively.
The structural entropy of $G$ is defined as $\mathcal{H}(G)=\mathop{\min}_{\mathcal{T}} \{ \mathcal{H}^{\mathcal{T}}(G) \},$

where $\mathcal{T}$ ranges over all possible encoding trees.
The vertex sets associated with tree nodes form a clustering of vertices in $V$.

### Definition 3

The $K$-D structural entropy is the structural entropy given by the encoding trees with the height of at most $K$.
When $K=2$, the encoding tree represents graph partitioning, which can be used to perform partitioning clustering.
A $2$-D encoding tree $\mathcal{T}$ can be formulated as a graph partitioning $\mathcal{P}=\{ \mathcal{X}_1,\mathcal{X}_2,...,\mathcal{X}_L\}$ of $V$ , where $\mathcal{X}_i$ is a vertex subset called module associated with the $i$-th children of root $\lambda$.
The structural entropy of $G$ given by $\mathcal{P}$ is defined as:

$$
\mathcal{H}^{\mathcal{P}}(G)=-\sum_{\mathcal{X} \in \mathcal{P}}\sum_{v_i \in \mathcal{X}}\frac{g_i}{\mathcal{V}_G}log_2\frac{d_i}{\mathcal{V}_\mathcal{X}}\\ -\sum_{\mathcal{X} \in \mathcal{P}}\frac{g_\mathcal{X}}{\mathcal{V}_G}log_2\frac{\mathcal{V}_\mathcal{X}}{\mathcal{V}_G},
$$

where $d_i$ is the degree of vertex $v_i$, $g_i$ is the cut, i.e., the sum of edge weights connecting $v_i$ and other vertices, $\mathcal{V}_\mathcal{X}$ and $\mathcal{V}_G$ are the volumes, i.e., the sum of vertex degrees in module $\mathcal{X}$ and graph $G$, respectively, and $g_\mathcal{X}$ is the cut, i.e., the sum of edge weights between vertices in and not in module $\mathcal{X}$.

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论

Interacting with LLMs through speech has led to an increased demand for effective speech representation discretization.
To address this, we propose SECodec, which can automatically determines the appropriate codebook size and integrates structural information into the quantization process.
Extensive experiments demonstrate that SECodec outperforms EnCodec in speech reconstruction.
Furthermore, we developed a Structural Entropy-based Speech Language Model (SESLM) that leverages SECodec, yielding superior results in terms of generated speech content accuracy and quality.
Additionally, the experiments show that SECodec is capable of learning a more compressive and discrete codebook and producing more informative speech tokens.
