# FreeCodec

<details>
<summary>基本信息</summary>

- 标题: "FreeCodec: A Disentangled Neural Speech Codec with Fewer Tokens"
- 作者:
  - 01 Youqiang Zheng,
  - 02 Weiping Tu,
  - 03 Yueteng Kang,
  - 04 Jie Chen,
  - 05 Yike Zhang,
  - 06 Li Xiao,
  - 07 Yuhong Yang,
  - 08 Long Ma
- 链接:
  - [ArXiv](https://arxiv.org/abs/2412.01053)
  - [Publication]() Submiited to ICASSP 2025
  - [Github](https://github.com/exercise-book-yq/FreeCodec) 暂未开源
  - [Demo](https://exercise-book-yq.github.io/FreeCodec-Demo/)
- 文件:
  - [ArXiv](_PDF/2412.01053v2__FreeCodec__A_Disentangled_Neural_Speech_Codec_with_Fewer_Tokens.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Neural speech codecs have gained great attention for their outstanding reconstruction with discrete token representations.
It is a crucial component in generative tasks such as speech coding and large language models (LLM).
However, most works based on residual vector quantization perform worse with fewer tokens due to low coding efficiency for modeling complex coupled information.
In this paper, we propose a neural speech codec named ***FreeCodec*** which employs a more effective encoding framework by decomposing intrinsic properties of speech into different components:
1) a global vector is extracted as the timbre information,
2) a prosody encoder with a long stride level is used to model the prosody information,
3) the content information is from a content encoder.

Using different training strategies, ***FreeCodec*** achieves state-of-the-art performance in reconstruction and disentanglement scenarios.
Results from subjective and objective experiments demonstrate that our framework outperforms existing methods.
The related code will be released at [Github](https://github.com/exercise-book-yq/FreeCodec).

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论