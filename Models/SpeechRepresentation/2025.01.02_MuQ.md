# MuQ

<details>
<summary>基本信息</summary>

- 标题: "MuQ: Self-Supervised Music Representation Learning with Mel Residual Vector Quantization"
- 作者:
  - 01 Haina Zhu (SJTU@X-LANCE Lab)
  - 02 Yizhi Zhou (Nanjing University)
  - 03 Hangting Chen (Tencent AI Lab)
  - 04 Jianwei Yu (Tencent AI Lab)
  - 05 Ziyang Ma (SJTU@X-LANCE Lab)
  - 06 Rongzhi Gu (Tencent AI Lab)
  - 07 Yi Luo (Tencent AI Lab)
  - 08 Wei Tan (Tencent AI Lab)
  - 09 Xie Chen (SJTU@X-LANCE Lab)
- 链接:
  - [ArXiv](https://arxiv.org/abs/2501.01108)
  - [Publication]()
  - [Github](https://github.com/tencent-ailab/MuQ)
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/2501.01108v2__MuQ__Self-Supervised_Music_Representation_Learning_with_Mel_Residual_Vector_Quantization.pdf)
  - [Publication] #TODO

</details>

## Abstract: 摘要

Recent years have witnessed the success of foundation models pre-trained with self-supervised learning (SSL) in various music informatics understanding tasks, including music tagging, instrument classification, key detection, and more.
In this paper, we propose a self-supervised music representation learning model for music understanding.
Distinguished from previous studies adopting random projection or existing neural codec, the proposed model, named MuQ, is trained to predict tokens generated by Mel Residual Vector Quantization (Mel-RVQ).
Our Mel-RVQ utilizes residual linear projection structure for Mel spectrum quantization to enhance the stability and efficiency of target extraction and lead to better performance.
Experiments in a large variety of downstream tasks demonstrate that MuQ outperforms previous self-supervised music representation models with only 0.9K hours of open-source pre-training data.
Scaling up the data to over 160K hours and adopting iterative training consistently improve the model performance.
To further validate the strength of our model, we present MuQ-MuLan, a joint music-text embedding model based on contrastive learning, which achieves state-of-the-art performance in the zero-shot music tagging task on the MagnaTagATune dataset.
Code and checkpoints are open source in [this https URL](https://github.com/tencent-ailab/MuQ).

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论