# 标题

<details>
<summary>基本信息</summary>

- 标题: "An Unsupervised Autoregressive Model for Speech Representation Learning"
- 作者:
  - 01 Yu-An Chung (CS&AI Lab@MIT, andyyuan@mit.edu)
  - 02 Wei-Ning Hsu (CS&AI Lab@MIT, wnhsu@mit.edu)
  - 03 Hao Tang (CS&AI Lab@MIT, haotang@mit.edu)
  - 04 James Glass (CS&AI Lab@MIT, glass@mit.edu)
- 链接:
  - [ArXiv](https://arxiv.org/abs/1904.03240)
  - [Publication](https://doi.org/10.21437/Interspeech.2019-1473)
  - [Github](https://github.com/iamyuanchung/Autoregressive-Predictive-Coding)
  - [Demo]()
- 文件:
  - [ArXiv](_PDF/1904.03240v2__APC__An_Unsupervised_Autoregressive_Model_for_Speech_Representation_Learning.pdf)
  - [Publication](_PDF/1904.03240p0__APC__InterSpeech2019.pdf)

</details>

## Abstract: 摘要

<details>
<summary>展开原文</summary>

This paper proposes a novel unsupervised autoregressive neural model for learning generic speech representations.
In contrast to other speech representation learning methods that aim to remove noise or speaker variabilities, ours is designed to preserve information for a wide range of downstream tasks.
In addition, the proposed model does not require any phonetic or word boundary labels, allowing the model to benefit from large quantities of unlabeled data.
Speech representations learned by our model significantly improve performance on both phone classification and speaker verification over the surface features and other supervised and unsupervised approaches.
Further analysis shows that different levels of speech information are captured by our model at different layers.
In particular, the lower layers tend to be more discriminative for speakers, while the upper layers provide more phonetic content.

</details>
<br>

本文提出了一种新颖的无监督自回归神经网络模型, 用于学习通用的语音表示.
与其他的目的为去除噪声或说话人变化的语音表示学习方法不同, 我们的模型被设计用于保留适用于广泛的下游任务的信息.

此外, 所提出的模型不需要任何音素或单词边界标签, 允许模型利用大量未标记数据.
通过我们的模型学习到的语音表示与其他的监督和无监督方法相比, 显著提高了音素分类和说话人验证的性能.

进一步的分析表明不同层次的语音信息被我们的模型在不同的层中捕捉到.
特别是, 较低的层倾向于对说话人更具辨别力, 而较高的层则提供更多的音素内容.

## 1·Introduction: 引言

## 2·Related Works: 相关工作

## 3·Methodology: 方法

## 4·Experiments: 实验

## 5·Results: 结果

## 6·Conclusions: 结论