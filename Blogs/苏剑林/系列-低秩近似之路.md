# 低秩近似之路

可能很多读者和笔者一样, 对矩阵的低秩近似有种熟悉而又陌生的感觉.
熟悉是因为低秩近似的概念和意义都不难理解, 加之目前诸如 LoRA 等基于低秩近似的微调技术遍地开花, 让低秩近似的概念在耳濡目染之间就已经深入人心.
然而低秩近似所覆盖的内容非常广, 在低秩近似相关的论文中时常能看到一些不熟悉但又让人叹为观止的新技巧, 这就导致了一种似懂非懂的陌生感.

因此, 在这个系列文章中, 笔者将试图系统梳理一下矩阵低秩近似相关的理论内容, 以补全对低秩近似的了解.

## 伪逆 (Pseudo Inverse)

<a id="01"></a>

原文: <https://kexue.fm/archives/10366>
时间: 2024.09.16

**伪逆** 也称为 **广义逆 (Generalized Inverse)**, 顾名思义是"广义的逆矩阵". 它实际上是逆矩阵的概念对于不可逆矩阵的推广.

对于矩阵方程 $AB=M$, 如果 $A$ 是方阵且可逆, 那么直接得到 $B=A^{-1}M$.
可如果 $A$ 不可逆或者不是方阵呢? 这种情况下很可能找不到 $B$ 满足 $AB=M$.
此时如果还想继续求解, 通常是转化为优化问题:

$$
    \arg\min_{B} \| AB-M \|_F^2
$$

- $A\in\mathbb{R}^{n\times r}$, 
- $B\in\mathbb{R}^{r\times m}$, 
- $M\in\mathbb{R}^{n\times m}$,
- $\| \cdot \|_F^2$ 表示 F 范数 (Frobenius Norm), 用来衡量矩阵 $AB-M$ 与全零矩阵的距离, 其定义为:
  $$
    \| X\|_F^2 = \sqrt{\sum_{i}^{n}\sum_{j}^{m} X_{i,j}^2}
  $$

意思就是从求解精确的逆矩阵修改为最小化 $AB$ 和 $M$ 的平方误差.

本系列的主题是低秩近似, 所以假设 $r<< \min(n,m)$, 其机器学习意义就是通过低维的, 有损的输入矩阵 $A$ 和线性变换 $B$ 来重建完整的 $M$ 矩阵.

当 $m=n$ 且 $M$ 为单位矩阵时, 就得到一个只依赖于 $A$ 的结果, 记为:

$$
    A^\dagger = \arg\min_{B} \| AB-I_n \|_F^2
$$

它的作用类似于 $A$ 的逆矩阵, 所以称为 $A$ 的 (右) 伪逆.

类似地, 如果给定的是 $B$ 矩阵, 也可以将优化参数改为 $A$, 得到 $B$ 的 (左) 伪逆:

$$
    B^\dagger = \arg\min_{A} \| A B-I_n \|_F^2
$$

### 范数相关

对于向量 $x=(x_1,\cdots,x_m)$, 其 $p$-范数定义为:

$$
    \| x \|_p = \left( \sum_{i=1}^m x_i^p \right)^{1/p}
$$

$p$-范数中最常见的就是 $p=2$ 的情形, 即常说的向量模长, 也叫**欧几里得范数**.
通常范数忽略下标时, 基本上就是默认 $p=2$.

对于矩阵, 至少有两种不同但都常用的范数:
其中一种就是 $F$ 范数, 它是将矩阵展平为向量来计算的范数:

$$
    \| X \|_F = \| \text{vec}(X)\|_2 = \sqrt{\sum_{i=1}^n\sum_{j=1}^m X_{i,j}^2}
$$

由于矩阵范数的多样性, 所以 $\|X\|_F$ 的下标通常不能省略, 避免引起混淆.

$F$ 范数是将矩阵当成向量然后照搬向量范数的定义而来的, 由此启发, 我们可以尝试把更多的向量运算搬到矩阵上.

例如内积:

$$
    \langle P,Q \rangle_F = \langle \text{vec}(P), \text{vec}(Q) \rangle = \sqrt{\sum_{i=1}^n\sum_{j=1}^m P_{i,j} Q_{i,j}}
$$

其中 $P$ 和 $Q$ 是 $n\times m$ 矩阵.

这称为矩阵 $P$ $Q$ 的 $F$ 内积 (Frobenius Inner Product). 它可以使用向量的迹运算来表示:

$$
    \langle P,Q \rangle_F = \text{Tr}(P^\top Q)
$$

这可以直接由矩阵乘法和迹的定义来证明.

> #TODO: 补充证明.

当 $P$, $Q$ 是由多个矩阵连乘而来时, 转换为等价的迹运算通常能帮助我们进行化简.

例如利用它可以证明正交变换不改变 $F$ 范数:
假设 $U$ 是一个正交矩阵, 可以有

$$
\begin{aligned}
    \| UM \|_F^2 &= \langle UM, UM \rangle_F \\
    &= \text{Tr}[(UM)^{\mathsf{T}}UM]\\
    &= \text{Tr}(M^{\mathsf{T}}U^{\mathsf{T}} UM)\\
    &= \text{Tr}(M^{\mathsf{T}}M)\\
    &= \| M \|_F^2
\end{aligned}
$$

### 矩阵求导

对于一个优化目标, 最理想的结果自然是能够通过求导求出解析解.
可以发现对于前文定义的优化问题:

$$
    \arg\min_{B} \| AB-M \|_F^2
$$

其中 $AB-M$ 是关于 $B$ 的线性函数, 所以优化目标是关于 $A$ 或者 $B$ 的二次函数, 二次函数的最小值是有解析解的.

求出 $\mathcal{L}=\| AB-M \|_F^2$ 关于 $B$ 的导数, 由链式法则:

$$
    \dfrac{\partial \mathcal{L}}{\partial B_{i,j}} = \sum_{k,l} \dfrac{\partial \mathcal{L}}{\partial E_{k,l}}\dfrac{\partial E_{k,l}}{\partial B_{i,j}}
$$

其中 $\mathcal{L}=\|E\|_F^2=\sum_{i,j} E_{i,j}^2$, $E=AB-M$.

显然在求和的众多平方项中只有当 $(i,j)=(k,l)$ 时, 关于 $E_{k,l}$ 的偏导才非零, 其他项都为零.
所以 $\mathcal{L}$ 关于 $E_{k,l}$ 的导数就是 $E_{k,l}^2$ 关于 $E_{k,l}$ 的导数.
所以:

$$
    \dfrac{\partial \mathcal{L}}{\partial E_{k,l}} = 2E_{k,l} = 2[(\sum_{\alpha} A_{k,\alpha}B_{\alpha,l})-M_{k,l}]
$$

类似地, 只有当 $(\alpha,l)=(i,j)$ 时, 关于 $B_{i,j}$ 的导数才会产生非零的结果 $A_{k,i}$.
所以:

$$
    \dfrac{\partial E_{k,l}}{\partial B_{i,j}} = A_{k,i}\delta_{l,j}
$$

其中 $\delta_{l,j}$ 表示 Kronecker 符号, 表示只有当 $l=j$ 时值为 $1$, 否则为 $0$.

综上, 对于 $B_{i,j}$ 的导数:

$$
\begin{aligned}
    \dfrac{\partial \mathcal{L}}{\partial B_{i,j}} &= \sum_{k,l} \dfrac{\partial \mathcal{L}}{\partial E_{k,l}}\dfrac{\partial E_{k,l}}{\partial B_{i,j}}\\
    &= \sum_{k,l} 2E_{k,l} A_{k,i}\delta_{l,j}\\
    &= 2\sum_{k}E_{k,j}A_{k,i}
\end{aligned}
$$

如果我们约定, 标量对矩阵的梯度形状和矩阵形状本身一致, 那么上式右端项可以理解为 $A$ 的第 $i$ 行的转置乘以 $E$ 的第 $j$ 列, 可以写出:

$$
    \dfrac{\partial \mathcal{L}}{\partial B} = 2A^{\mathsf{T}}E = 2A^{\mathsf{T}}(AB-M)
$$

从直觉上, 按照通常的标量求导方式, $\mathcal{L}$ 关于 $B$ 的偏导数就是 $2(AB-M)$ 和 $A$ 的乘积.
又约定了 $\mathcal{L}$ 关于 $B$ 的偏导数的形状和 $B$ 形状一致, 即 $(r,m)$.
所以右端的两项 $2(AB-M)$ 为 $(n,m)$ 矩阵, 而 $A$ 为 $(n,r)$ 矩阵, 需要凑出一个 $(r,m)$ 的结果.

类似地, 可以得到 $\mathcal{L}$ 关于 $A$ 的偏导数:

$$
    \dfrac{\partial \mathcal{L}}{\partial A} = 2 (AB-M)B^{\mathsf{T}}
$$

### 基本结果

现在求出了 $\mathcal{L}$ 关于 $B$ 和 $A$ 的偏导数, 让它们等于零便可以得到相应的最优解.

$$
    2A^{\mathsf{T}}(AB-M) = 0 \Rightarrow A^{\mathsf{T}}AB = A^{\mathsf{T}}M \Rightarrow B = (A^{\mathsf{T}}A)^{-1}A^{\mathsf{T}}M 
$$

$$
    2(AB-M)B^{\mathsf{T}} = 0 \Rightarrow ABB^{\mathsf{T}} = MB^{\mathsf{T}} \Rightarrow A = MB^{\mathsf{T}}(BB^{\mathsf{T}})^{-1}
$$

$M=I_n$ 代入, 得到:

$$
    A^{\dagger} = (A^{\mathsf{T}}A)^{-1}A^{\mathsf{T}}\\
    B^{\dagger} = B^{\mathsf{T}}(BB^{\mathsf{T}})^{-1}
$$

若 $A$ 或 $B$ 是可逆方阵, 那么可以容易证明伪逆就等于逆矩阵, 即 $A^\dagger=A^{-1}$ 和 $B^\dagger=B^{-1}$.

此外, 根据上式可以验证:

1. $(A^\dagger)^{\dagger}=A$, $(B^\dagger)^{\dagger}=B$ 即伪逆的伪逆等于原矩阵. 这意味着伪逆在作为近似逆矩阵的同时, 保全了自身的信息;
2. $(AA^\dagger) A = A$, $(B^\dagger B) B^\dagger= B^\dagger$, 即 $AA^\dagger$ 和 $B^\dagger B$ 虽然不是单位矩阵 $I$, 但对于 $A$ 和 $B^\dagger$ 来说, 它们起到了单位阵的作用.

矩阵的伪逆实际上是一个很宽泛的概念, 它有很多种不同形式.
这里介绍的伪逆实际上是最常见的 **Moore-Penrose 逆**, 除此之外还有 "Drazin 逆", "Bott-Duffin 逆" 等.
此处不做展开.

### 一般形式

$$
    A^{\dagger} = (A^{\mathsf{T}}A)^{-1}A^{\mathsf{T}}\\
    B^{\dagger} = B^{\mathsf{T}}(BB^{\mathsf{T}})^{-1}
$$

这两个等式成立的关键前提是相应的 $A^{\mathsf{T}}A$ 和 $BB^{\mathsf{T}}$ 矩阵可逆.
但如果不可逆呢?

以 $A^\dagger$ 为例, 假设 $A^{\mathsf{T}}A\in \mathbb{R}^{r\times r}$ 不可逆, 那么意味着 $A$ 的秩不足 $r$, 即只能找到 $s<r$ 个列向量构成的极大线性无关组构成矩阵 $A_s \in \mathbb{R}^{n\times s}$.

那么 $A = A_s P$, 其中 $P\in \mathbb{R}^{s\times r}$ 是 $A_s$ 到 $A$ 的矩阵.

此时

$$
    \arg\min_{B} \| AB-I\|_F^2 = \arg\min_{B} \| A_s P B-I\|_F^2
$$

如果 $B$ 的最优解仍然记为 $A^\dagger$, 那么:

$$
    PA^\dagger = A_s^\dagger = (A_s^{\mathsf{T}}A_s)^{-1}A_s^{\mathsf{T}}
$$

此时的 $A_s$ 是 $s$ 满秩的, 所以 $A_s^{\mathsf{T}}A_s$ 是可逆的, 因此上式是良好定义的.

然而从 $A^\dagger$ 到 $PA^\dagger$ 是一个降维过程, 这意味着存在多个 $A^\dagger$ 使得 $PA^\dagger=A_s^\dagger$. 即最优解不唯一.

也就是说当 $A^{\mathsf{T}}A$ 不可逆时, 无法只凭借最小化优化目标 $\mathcal{L}$ 来确定唯一的伪逆 $A^\dagger$.

---

一个可能的思路时补充条件, 如 $(A^\dagger)^\dagger=A$ 或 $A^\dagger A A^\dagger=A^\dagger$, 结合 $PA^\dagger=A_s^\dagger$ 就能唯一确定 $A^\dagger$.

实际上可以用一个精妙的技巧更加优雅和统一地处理这个问题.

这个问题出在当 $A^{\mathsf{T}}A$ 不可逆时, 目标函数 $\mathcal{L}$ 不是严格正定的, 我们可以加上一个正则项来让它变得正定, 求出结果后再让正则项的权重趋于零:

$$
    A^\dagger = \lim_{\epsilon\to 0}\arg\min_{B} \|AB-I_n\|_F^2 + \epsilon \|B\|_F^2
$$

这里 $\epsilon>0$ 然后正向趋于 0.

由上式可以解得:

$$
    A^\dagger = \lim_{\epsilon\to 0}(A^{\mathsf{T}}A+\epsilon I_r)^{-1}A^{\mathsf{T}}
$$

当 $\epsilon>0$ 时, $A^{\mathsf{T}}A+\epsilon I_r$ 必然是可逆的. 因此上式是良好定义的.

由于 $\epsilon\to 0$ 时, 正则项可以忽略不计, 所以上述极限必然是存在的.
注意: 这里说的是整体极限的存在性, 当 $A^{\mathsf{T}}A$ 不可逆时, 极限 $\lim_{\epsilon\to 0}(A^{\mathsf{T}}A+\epsilon I_r)^{-1}$ 是不存在的, 只有乘上 $A^{\mathsf{T}}$ 后整体再取极限才是正常的.

上式作为伪逆的一般推广有什么优点呢?
1. 首先和先前求出的 $A^\dagger$ 表达式具有直观且形式一致的理论优雅性;
2. 其次, 形式上的一致性也使得 $A^{\mathsf{T}}A$ 可逆时 $A^\dagger$ 的一些性质得以保留, 从而在讨论 $A^\dagger$ 时无需考虑 $A^{\mathsf{T}}A$ 是否可逆.
